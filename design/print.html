<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Smithy Rust</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">1.</strong> Design Overview</a></li><li class="chapter-item expanded "><a href="tenets.html"><strong aria-hidden="true">2.</strong> Tenets</a></li><li class="chapter-item expanded "><a href="faq.html"><strong aria-hidden="true">3.</strong> Design FAQ</a></li><li class="chapter-item expanded "><a href="smithy/overview.html"><strong aria-hidden="true">4.</strong> Smithy</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="smithy/simple_shapes.html"><strong aria-hidden="true">4.1.</strong> Simple Shapes</a></li><li class="chapter-item expanded "><a href="smithy/recursive_shapes.html"><strong aria-hidden="true">4.2.</strong> Recursive Shapes</a></li><li class="chapter-item expanded "><a href="smithy/aggregate_shapes.html"><strong aria-hidden="true">4.3.</strong> Aggregate Shapes</a></li><li class="chapter-item expanded "><a href="smithy/backwards-compat.html"><strong aria-hidden="true">4.4.</strong> Backwards Compatibility</a></li></ol></li><li class="chapter-item expanded "><a href="client/overview.html"><strong aria-hidden="true">5.</strong> Client</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="client/orchestrator.html"><strong aria-hidden="true">5.1.</strong> What is the 'orchestrator' and why does it exist?</a></li><li class="chapter-item expanded "><a href="client/identity_and_auth.html"><strong aria-hidden="true">5.2.</strong> Identity and Auth</a></li><li class="chapter-item expanded "><a href="client/detailed_error_explanations.html"><strong aria-hidden="true">5.3.</strong> Detailed error explanations</a></li></ol></li><li class="chapter-item expanded "><a href="server/overview.html"><strong aria-hidden="true">6.</strong> Server</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="server/middleware.html"><strong aria-hidden="true">6.1.</strong> Middleware</a></li><li class="chapter-item expanded "><a href="server/instrumentation.html"><strong aria-hidden="true">6.2.</strong> Instrumentation</a></li><li class="chapter-item expanded "><a href="server/from_parts.html"><strong aria-hidden="true">6.3.</strong> Accessing Un-modelled Data</a></li><li class="chapter-item expanded "><a href="server/anatomy.html"><strong aria-hidden="true">6.4.</strong> The Anatomy of a Service</a></li><li class="chapter-item expanded "><a href="server/code_generation.html"><strong aria-hidden="true">6.5.</strong> Generating Common Service Code</a></li></ol></li><li class="chapter-item expanded "><a href="rfcs/overview.html"><strong aria-hidden="true">7.</strong> RFCs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rfcs/rfc0001_shared_config.html"><strong aria-hidden="true">7.1.</strong> RFC-0001: Sharing configuration between multiple clients</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0002_http_versions.html"><strong aria-hidden="true">7.2.</strong> RFC-0002: Supporting multiple HTTP versions for SDKs that use Event Stream</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0003_presigning_api.html"><strong aria-hidden="true">7.3.</strong> RFC-0003: API for Pre-signed URLs</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0004_retry_behavior.html"><strong aria-hidden="true">7.4.</strong> RFC-0004: Retry Behavior</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0005_service_generation.html"><strong aria-hidden="true">7.5.</strong> RFC-0005: Smithy Rust service framework</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0006_service_specific_middleware.html"><strong aria-hidden="true">7.6.</strong> RFC-0006: Service-specific middleware</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0007_split_release_process.html"><strong aria-hidden="true">7.7.</strong> RFC-0007: Split release process</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0008_paginators.html"><strong aria-hidden="true">7.8.</strong> RFC-0008: Paginators</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0009_example_consolidation.html"><strong aria-hidden="true">7.9.</strong> RFC-0009: Example Consolidation</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0010_waiters.html"><strong aria-hidden="true">7.10.</strong> RFC-0010: Waiters</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0011_crates_io_alpha_publishing.html"><strong aria-hidden="true">7.11.</strong> RFC-0011: Publishing Alpha to Crates.io</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0012_independent_crate_versioning.html"><strong aria-hidden="true">7.12.</strong> RFC-0012: Independent Crate Versioning</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0013_body_callback_apis.html"><strong aria-hidden="true">7.13.</strong> RFC-0013: Body Callback APIs</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0014_timeout_config.html"><strong aria-hidden="true">7.14.</strong> RFC-0014: Fine-grained timeout configuration</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0015_using_features_responsibly.html"><strong aria-hidden="true">7.15.</strong> RFC-0015: How Cargo "features" should be used in the SDK and runtime crates</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0016_flexible_checksum_support.html"><strong aria-hidden="true">7.16.</strong> RFC-0016: Supporting Flexible Checksums</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0017_customizable_client_operations.html"><strong aria-hidden="true">7.17.</strong> RFC-0017: Customizable Client Operations</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0018_logging_sensitive.html"><strong aria-hidden="true">7.18.</strong> RFC-0018: Logging in the Presence of Sensitive Data</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0019_event_streams_errors.html"><strong aria-hidden="true">7.19.</strong> RFC-0019: Event Streams Errors</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0020_service_builder.html"><strong aria-hidden="true">7.20.</strong> RFC-0020: Service Builder Improvements</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0021_dependency_versions.html"><strong aria-hidden="true">7.21.</strong> RFC-0021: Dependency Versions</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0022_error_context_and_compatibility.html"><strong aria-hidden="true">7.22.</strong> RFC-0022: Error Context and Compatibility</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0023_refine_builder.html"><strong aria-hidden="true">7.23.</strong> RFC-0023: Evolving the new service builder API</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0024_request_id.html"><strong aria-hidden="true">7.24.</strong> RFC-0024: RequestID</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0025_constraint_traits.html"><strong aria-hidden="true">7.25.</strong> RFC-0025: Constraint traits</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0026_client_crate_organization.html"><strong aria-hidden="true">7.26.</strong> RFC-0026: Client Crate Organization</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0027_endpoints_20.html"><strong aria-hidden="true">7.27.</strong> RFC-0027: Endpoints 2.0</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0028_sdk_credential_cache_type_safety.html"><strong aria-hidden="true">7.28.</strong> RFC-0028: SDK Credential Cache Type Safety</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0029_new_home_for_cred_types.html"><strong aria-hidden="true">7.29.</strong> RFC-0029: Finding New Home for Credential Types</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0030_serialization_and_deserialization.html"><strong aria-hidden="true">7.30.</strong> RFC-0030: Serialization And Deserialization</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0031_providing_fallback_credentials_on_timeout.html"><strong aria-hidden="true">7.31.</strong> RFC-0031: Providing Fallback Credentials on Timeout</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0032_better_constraint_violations.html"><strong aria-hidden="true">7.32.</strong> RFC-0032: Better Constraint Violations</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0033_improve_sdk_request_id_access.html"><strong aria-hidden="true">7.33.</strong> RFC-0033: Improving access to request IDs in SDK clients</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0034_smithy_orchestrator.html"><strong aria-hidden="true">7.34.</strong> RFC-0034: Smithy Orchestrator</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0035_collection_defaults.html"><strong aria-hidden="true">7.35.</strong> RFC-0035: Collection Defaults</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0036_http_dep_elimination.html"><strong aria-hidden="true">7.36.</strong> RFC-0036: HTTP Dependency Exposure</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0037_http_wrapper.html"><strong aria-hidden="true">7.37.</strong> RFC-0037: The HTTP Wrapper</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0038_retry_classifier_customization.html"><strong aria-hidden="true">7.38.</strong> RFC-0038: User-configurable retry classification</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0039_forward_compatible_errors.html"><strong aria-hidden="true">7.39.</strong> RFC-0039: Forward Compatible Errors</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0040_behavior_versions.html"><strong aria-hidden="true">7.40.</strong> RFC-0040: Behavior Versions</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0041_improve_client_error_ergonomics.html"><strong aria-hidden="true">7.41.</strong> RFC-0041: Improve client error ergonomics</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0042_file_per_change_changelog.html"><strong aria-hidden="true">7.42.</strong> RFC-0042: File-per-change changelog</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0043_identity_cache_partitions.html"><strong aria-hidden="true">7.43.</strong> RFC-0043: Identity Cache Partitions</a></li><li class="chapter-item expanded "><a href="rfcs/rfc0044_env_defined_service_config.html"><strong aria-hidden="true">7.44.</strong> RFC-0044: Environment-defined service configuration</a></li></ol></li><li class="chapter-item expanded "><a href="contributing/overview.html"><strong aria-hidden="true">8.</strong> Contributing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="contributing/writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.html"><strong aria-hidden="true">8.1.</strong> Writing and debugging a low-level feature that relies on HTTP</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Smithy Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="design-overview"><a class="header" href="#design-overview">Design Overview</a></h1>
<p>The AWS Rust SDK aims to provide an official, high quality &amp; complete interface to AWS services. We plan to eventually use the CRT to provide signing &amp; credential management. The Rust SDK will provide first-class support for the CRT as well as <a href="https://tokio.rs/">Tokio </a> &amp; <a href="https://hyper.rs">Hyper</a>. The Rust SDK empowers advanced customers to bring their own HTTP/IO implementations.</p>
<p>Our design choices are guided by our <a href="./tenets.html">Tenets</a>.</p>
<h2 id="acknowledgments"><a class="header" href="#acknowledgments">Acknowledgments</a></h2>
<p>The design builds on the learnings, ideas, hard work, and GitHub issues of the 142 Rusoto contributors &amp; thousands of users who built this first and learned the hard way.</p>
<h2 id="external-api-overview"><a class="header" href="#external-api-overview">External API Overview</a></h2>
<p>The Rust SDK is "modular" meaning that each AWS service is its own crate. Each crate provides two layers to access the service:</p>
<ol>
<li>The "fluent" API. For most use cases, a high level API that ties together connection management and serialization will be the quickest path to success.</li>
</ol>
<pre><code class="language-rust ignore">#[tokio::main]
async fn main() {
    let client = dynamodb::Client::from_env();
    let tables = client
        .list_tables()
        .limit(10)
        .send()
        .await.expect("failed to load tables");
}</code></pre>
<ol start="2">
<li>The "low-level" API: It is also possible for customers to assemble the pieces themselves. This offers more control over operation construction &amp; dispatch semantics:</li>
</ol>
<pre><code class="language-rust ignore">#[tokio::main]
async fn main() {
    let conf = dynamodb::Config::builder().build();
    let conn = aws_hyper::Client::https();
    let operation = dynamodb::ListTables::builder()
        .limit(10)
        .build(&amp;conf)
        .expect("invalid operation");
    let tables = conn.call(operation).await.expect("failed to list tables");
}</code></pre>
<p>The Fluent API is implemented as a thin wrapper around the core API to improve ergonomics.</p>
<h2 id="internals"><a class="header" href="#internals">Internals</a></h2>
<p>The Rust SDK is built on Tower Middleware, Tokio &amp; Hyper. We're continuing to iterate on the internals to enable running the AWS SDK in other executors &amp; HTTP stacks. As an example, you can see a demo of adding <code>reqwest</code> as a custom HTTP stack to gain access to its HTTP Proxy support!</p>
<p>For more details about the SDK internals see <a href="transport/operation.html">Operation Design</a></p>
<h2 id="code-generation"><a class="header" href="#code-generation">Code Generation</a></h2>
<p>The Rust SDK is code generated from Smithy models, using Smithy codegeneration utilities. The Code generation is written in Kotlin. More details can be found in the <a href="./smithy/overview.html">Smithy</a> section.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rust-sdk-design-tenets"><a class="header" href="#rust-sdk-design-tenets">Rust SDK Design Tenets</a></h1>
<blockquote>
<p>Unless you know better ones! These are our tenets today, but we'd love your thoughts. Do you wish we had different priorities? Let us know by opening and issue or starting a discussion.</p>
</blockquote>
<ol>
<li><a href="tenets.html#batteries-included-but-replaceable"><strong>Batteries included, but replaceable.</strong></a> The AWS SDK for Rust should provide a best-in-class experience for many use cases, <strong>but</strong>, customers will use the SDK in unique and unexpected ways. <strong>Meet customers where they are;</strong> strive to be compatible with their tools. Provide mechanisms to allow customers make different choices.</li>
<li><a href="tenets.html#make-common-problems-easy-to-solve"><strong>Make common problems easy to solve.</strong></a> The AWS SDK for Rust should make common problems solvable. Guide customers to patterns that set them up for long-term success.</li>
<li><a href="tenets.html#design-for-the-future"><strong>Design for the Future.</strong></a> The AWS SDK for Rust should evolve with AWS without breaking existing customers. APIs will evolve in unpredictable directions, new protocols will gain adoption, and new services will be created that we never could have imagined. Don’t simplify or unify code today that prevents evolution tomorrow.</li>
</ol>
<h2 id="details-justifications-and-ramifications"><a class="header" href="#details-justifications-and-ramifications">Details, Justifications, and Ramifications</a></h2>
<h3 id="batteries-included-but-replaceable"><a class="header" href="#batteries-included-but-replaceable">Batteries included, but replaceable.</a></h3>
<p>Some customers will use the Rust SDK as their first experience with async Rust, potentially <strong>any</strong> Rust. They may not be familiar with Tokio or the concept of an async executor. We are not afraid to have an opinion about the best solution for most customers.</p>
<p>Other customers will come to the SDK with specific requirements. Perhaps they're integrating the SDK into a much larger project that uses <code>async_std</code>. Maybe they need to set custom headers, modify the user agent, or audit every request. They should be able to use the Rust SDK without forking it to meet their needs.</p>
<h3 id="make-common-problems-easy-to-solve"><a class="header" href="#make-common-problems-easy-to-solve">Make common problems easy to solve</a></h3>
<p>If solving a common problem isn’t obvious from the API, it should be obvious from the documentation. The SDK should guide users towards the best solutions for common tasks, <strong>first</strong> with well named methods, <strong>second</strong> with documentation, and <strong>third</strong> with real -world usage examples. Provide misuse resistant APIs. Async Rust has the potential to introduce subtle bugs; the Rust SDK should help customers avoid them.</p>
<h3 id="design-for-the-future"><a class="header" href="#design-for-the-future">Design for the Future</a></h3>
<p>APIs evolve in unpredictable ways, and it's crucial that the SDK can evolve without breaking existing customers. This means designing the SDK so that fundamental changes to the internals can be made without altering the external interface we surface to customers:</p>
<ul>
<li>Keeping the shared core as small &amp; opaque as possible.</li>
<li>Don’t leak our internal dependencies to customers</li>
<li>With every design choice, consider, "Can I reverse this choice in the future?"</li>
</ul>
<p>This may not result in DRY code, and that’s OK! Code that is auto generated has different goals and tradeoffs than code that has been written by hand.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="design-faq"><a class="header" href="#design-faq">Design FAQ</a></h1>
<h2 id="what-is-smithy"><a class="header" href="#what-is-smithy">What is Smithy?</a></h2>
<p>Smithy is the interface design language used by AWS services. <code>smithy-rs</code> allows users to generate a Rust client for any
Smithy based service (pending protocol support), including those outside of AWS.</p>
<h2 id="why-is-there-one-crate-per-service"><a class="header" href="#why-is-there-one-crate-per-service">Why is there one crate per service?</a></h2>
<ol>
<li>
<p><strong>Compilation time:</strong> Although it's possible to use cargo features to conditionally compile individual services, we
decided that this added significant complexity to the generated code. In Rust the "unit of compilation" is a Crate,
so by using smaller crates we can get better compilation parallelism. Furthermore, ecosystem services like <code>docs.rs</code>
have an upper limit on the maximum amount of time required to build an individual crate—if we packaged the entire SDK
as a single crate, we would quickly exceed this limit.</p>
</li>
<li>
<p><strong>Versioning:</strong> It is expected that over time we may major-version-bump individual services. New updates will be pushed
for <em>some</em> AWS service nearly every day. Maintaining separate crates allows us to only increment versions for the
relevant pieces that change. See <a href="./rfcs/rfc0012_independent_crate_versioning.html">Independent Crate Versioning</a> for
more info.</p>
</li>
</ol>
<h2 id="why-dont-the-sdk-service-crates-implement-serdeserialize-or-serdedeserialize-for-any-types"><a class="header" href="#why-dont-the-sdk-service-crates-implement-serdeserialize-or-serdedeserialize-for-any-types">Why don't the SDK service crates implement <code>serde::Serialize</code> or <code>serde::Deserialize</code> for any types?</a></h2>
<ol>
<li>
<p><strong>Compilation time:</strong> <code>serde</code> makes heavy use of <a href="https://crates.io/crates/serde_derive/1.0.136/dependencies">several crates</a>
<em>(<code>proc-macro2</code>, <code>quote</code>, and <code>syn</code>)</em> that are very expensive to compile. Several service crates are already quite large
and adding a <code>serde</code> dependency would increase compile times beyond what we consider acceptable. When we last checked,
adding <code>serde</code> derives made compilation 23% slower.</p>
</li>
<li>
<p><strong>Misleading results:</strong> We can't use <code>serde</code> for serializing requests to AWS or deserializing responses from AWS because
both sides of that process would require too much customization. Adding serialize/deserialize impls for operations has
the potential to confuse users when they find it doesn't actually capture all the necessary information (like headers and
trailers) sent in a request or received in a response.</p>
</li>
</ol>
<p>In the future, we may add <code>serde</code> support behind a feature gate. However, we would only support this for operation <code>Input</code>
and <code>Output</code> structs with the aim of making SDK-related tests easier to set up and run.</p>
<h2 id="i-want-to-add-new-request-building-behavior-should-i-add-that-functionality-to-the-make_operation-codegen-or-write-a-request-altering-middleware"><a class="header" href="#i-want-to-add-new-request-building-behavior-should-i-add-that-functionality-to-the-make_operation-codegen-or-write-a-request-altering-middleware">I want to add new request building behavior. Should I add that functionality to the <code>make_operation</code> codegen or write a request-altering middleware?</a></h2>
<p>The main question to ask yourself in this case is <em>"is this new behavior relevant to all services or is it only relevant to some services?"</em></p>
<ul>
<li><strong>If the behavior is relevant to all services:</strong> Behavior like this should be defined as a middleware. Behavior like this is often AWS-specific and may not be relevant to non-AWS smithy clients. Middlewares are defined outside of codegen. One example of behavior that should be defined as a middleware is request signing because all requests to AWS services must be signed.</li>
<li><strong>If the behavior is only relevant to some services/depends on service model specifics:</strong> Behavior like this should be defined within <code>make_operation</code>. Avoid defining AWS-specific behavior within <code>make_operation</code>. One example of behavior that should be defined in <code>make_operation</code> is checksum validation because only some AWS services have APIs that support checksum validation.</li>
</ul>
<p><em>"Wait a second"</em> I hear you say, <em>"checksum validation is part of the AWS smithy spec, not the core smithy spec. Why is that behavior defined in <code>make_operation</code>?"</em> The answer is that that feature only applies to some operations and we don't want to codegen a middleware that only supports a subset of operations for a service.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smithy"><a class="header" href="#smithy">Smithy</a></h1>
<p>The Rust SDK uses Smithy models and code generation tooling to generate an SDK. Smithy is an open source IDL (interface design language) developed by Amazon. Although the Rust SDK uses Smithy models for AWS services, smithy-rs and Smithy models in general are not AWS specific.</p>
<p>Design documentation here covers both our implementation of Smithy Primitives (e.g. simple shape) as well as more complex Smithy traits like <code>Endpoint</code>.</p>
<h2 id="internals-1"><a class="header" href="#internals-1">Internals</a></h2>
<p>Smithy introduces a few concepts that are defined here:</p>
<ol>
<li>
<p>Shape: The core Smithy primitive. A smithy model is composed of nested shapes defining an API.</p>
</li>
<li>
<p><code>Symbol</code>: A Representation of a type including namespaces and any dependencies required to use a type. A shape can be converted into a symbol by a <code>SymbolVisitor</code>. A <code>SymbolVisitor</code> maps shapes to types in your programming language (e.g. Rust). In the Rust SDK, see <a href="https://github.com/smithy-lang/smithy-rs/blob/c049a37f8cba5f9bec2e96c28db83e7efb2edc53/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/SymbolVisitor.kt">SymbolVisitor.kt</a>. Symbol visitors are composable—many specific behaviors are mixed in via small &amp; focused symbol providers, e.g. support for the streaming trait is mixed in separately.</p>
</li>
<li>
<p><code>Writer</code>: Writers are code generation primitives that collect code prior to being written to a file. Writers enable language specific helpers to be added to simplify codegen for a given language. For example, <code>smithy-rs</code> adds <code>rustBlock</code> to <a href="https://github.com/smithy-lang/smithy-rs/blob/908dec558e26bbae6fe4b7d9d1c221dd81699b59/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/RustWriter.kt"><code>RustWriter</code></a> to create a "Rust block" of code.</p>
<pre><code class="language-kotlin">writer.rustBlock("struct Model") {
    model.fields.forEach {
        write("${field.name}: #T", field.symbol)
    }
}
</code></pre>
<p>This would produce something like:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Model {
   field1: u32,
   field2: String
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Generators: A Generator, e.g. <code>StructureGenerator</code>, <code>UnionGenerator</code> generates more complex Rust code from a Smithy model. Protocol generators pull these individual tools together to generate code for an entire service / protocol.</p>
</li>
</ol>
<p>A developer's view of code generation can be found in <a href="smithy/../server/code_generation.html">this document</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="simple-shapes"><a class="header" href="#simple-shapes">Simple Shapes</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Smithy Type (links to design discussions)</th><th>Rust Type (links to Rust documentation)</th></tr></thead><tbody>
<tr><td>blob</td><td><code>Vec&lt;u8&gt;</code></td></tr>
<tr><td>boolean</td><td><a href="https://doc.rust-lang.org/std/primitive.bool.html"><code>bool</code></a></td></tr>
<tr><td><a href="smithy/simple_shapes.html#strings">string</a></td><td><a href="https://doc.rust-lang.org/std/string/struct.String.html"><code>String</code></a></td></tr>
<tr><td>byte</td><td><code>i8</code></td></tr>
<tr><td>short</td><td><code>i16</code></td></tr>
<tr><td>integer</td><td><code>i32</code></td></tr>
<tr><td>long</td><td><code>i64</code></td></tr>
<tr><td>float</td><td><code>f32</code></td></tr>
<tr><td>double</td><td><code>f64</code></td></tr>
<tr><td><a href="smithy/simple_shapes.html#big-numbers">bigInteger</a></td><td><code>BigInteger</code> (Not implemented yet)</td></tr>
<tr><td><a href="smithy/simple_shapes.html#big-numbers">bigDecimal</a></td><td><code>BigDecimal</code> (Not implemented yet)</td></tr>
<tr><td><a href="smithy/simple_shapes.html#timestamps">timestamp</a></td><td><a href="https://github.com/smithy-lang/smithy-rs/blob/main/rust-runtime/aws-smithy-types/src/date_time/mod.rs"><code>DateTime</code></a></td></tr>
<tr><td><a href="smithy/simple_shapes.html#documents">document</a></td><td><a href="https://github.com/smithy-lang/smithy-rs/blob/v0.14/rust-runtime/aws-smithy-types/src/lib.rs#L38-L52"><code>Document</code></a></td></tr>
</tbody></table>
</div>
<h3 id="big-numbers"><a class="header" href="#big-numbers">Big Numbers</a></h3>
<p>Rust currently has no standard library or universally accepted large-number crate. Until one is stabilized, a string representation is a reasonable compromise:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct BigInteger(String);
pub struct BigDecimal(String);
<span class="boring">}</span></code></pre></pre>
<p>This will enable us to add helpers over time as requested. Users will also be able to define their own conversions into their preferred large-number libraries.</p>
<p>As of 5/23/2021 BigInteger / BigDecimal are not included in AWS models. Implementation is tracked <a href="https://github.com/smithy-lang/smithy-rs/issues/312">here</a>.</p>
<h3 id="timestamps"><a class="header" href="#timestamps">Timestamps</a></h3>
<p><a href="https://github.com/chronotope/chrono">chrono</a> is the current de facto library for datetime in Rust, but it is pre-1.0. DateTimes are represented by an SDK defined structure modeled on <code>std::time::Duration</code> from the Rust standard library.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span>
<span class="boring">fn main() {
</span>/// DateTime in time.
///
/// DateTime in time represented as seconds and sub-second nanos since
/// the Unix epoch (January 1, 1970 at midnight UTC/GMT).
///
/// This type can be converted to/from the standard library's [`SystemTime`]:
/// ```rust
/// # fn doc_fn() -&gt; Result&lt;(), aws_smithy_types::date_time::ConversionError&gt; {
/// # use aws_smithy_types::date_time::DateTime;
/// # use std::time::SystemTime;
/// use std::convert::TryFrom;
///
/// let the_millennium_as_system_time = SystemTime::try_from(DateTime::from_secs(946_713_600))?;
/// let now_as_date_time = DateTime::from(SystemTime::now());
/// # Ok(())
/// # }
/// ```
///
/// The [`aws-smithy-types-convert`](https://crates.io/crates/aws-smithy-types-convert) crate
/// can be used for conversions to/from other libraries, such as
/// [`time`](https://crates.io/crates/time) or [`chrono`](https://crates.io/crates/chrono).
#[derive(PartialEq, Eq, Hash, Clone, Copy)]
pub struct DateTime {
    pub(crate) seconds: i64,
    /// Subsecond nanos always advances the wallclock time, even for times where seconds is negative
    ///
    /// Bigger subsecond nanos =&gt; later time
    pub(crate) subsecond_nanos: u32,
}

<span class="boring">}</span></code></pre></pre>
<p>Functions in the <code>aws-smithy-types-convert</code> crate provide conversions to other crates, such as <code>time</code> or <code>chrono</code>.</p>
<h3 id="strings"><a class="header" href="#strings">Strings</a></h3>
<p>Rust has two different String representations:</p>
<ul>
<li><code>String</code>, an owned, heap allocated string.</li>
<li><code>&amp;str</code>, a reference to a string, owned elsewhere.</li>
</ul>
<p>In ideal world, input shapes, where there is no reason for the strings to be owned would use <code>&amp;'a str</code>. Outputs would likely use <code>String</code>. However, Smithy does not provide a distinction between input and output shapes.</p>
<p>A third compromise could be storing <code>Arc&lt;String&gt;</code>, an atomic reference counted pointer to a <code>String</code>. This may be ideal for certain advanced users, but is likely to confuse most users and produces worse ergonomics. <em>This is an open design area where we will seek user feedback.</em> Rusoto uses <code>String</code> and there has been <a href="https://github.com/rusoto/rusoto/issues/1806">one feature request</a> to date to change that.</p>
<p>Current models represent strings as <code>String</code>.</p>
<h3 id="document-types"><a class="header" href="#document-types">Document Types</a></h3>
<p>Smithy defines the concept of "Document Types":</p>
<blockquote>
<p>[Documents represent] protocol-agnostic open content that is accessed like JSON data. Open content is useful for modeling unstructured data that has no schema, data that can't be modeled using rigid types, or data that has a schema that evolves outside of the purview of a model. The serialization format of a document is an implementation detail of a protocol and MUST NOT have any effect on the types exposed by tooling to represent a document value.</p>
</blockquote>
<pre><code class="language-rust ignore"></code></pre>
<p>Individual protocols define their own document serialization behavior, with some protocols such as AWS and EC2 Query not supporting document types.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recursive-shapes"><a class="header" href="#recursive-shapes">Recursive Shapes</a></h1>
<blockquote>
<p>Note: Throughout this document, the word "box" always refers to a Rust <a href="https://doc.rust-lang.org/std/boxed/struct.Box.html"><code>Box&lt;T&gt;</code></a>, a heap allocated pointer to T, and not the Smithy concept of boxed vs. unboxed.</p>
</blockquote>
<p>Recursive shapes pose a problem for Rust, because the following Rust code will not compile:</p>
<pre><pre class="playground"><code class="language-rust compile_fail edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TopStructure {
    intermediate: IntermediateStructure
}

struct IntermediateStructure {
    top: Option&lt;TopStructure&gt;
}
<span class="boring">}</span></code></pre></pre>
<pre><code class="language-text">  |
3 | struct TopStructure {
  | ^^^^^^^^^^^^^^^^^^^ recursive type has infinite size
4 |     intermediate: IntermediateStructure
  |     ----------------------------------- recursive without indirection
  |
  = help: insert indirection (e.g., a `Box`, `Rc`, or `&amp;`) at some point to make `main::TopStructure` representable
</code></pre>
<p>This occurs because Rust types must be a size known at compile time. The way around this, as the message suggests, is to Box the offending type. <code>smithy-rs</code> implements this design in <a href="https://github.com/smithy-lang/smithy-rs/blob/main/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/transformers/RecursiveShapeBoxer.kt">RecursiveShapeBoxer.kt</a></p>
<p>To support this, as the message suggests, we must "<code>Box</code>" the offending type. There is a touch of trickiness—only one element in the cycle needs to be boxed, but we need to select it deterministically such that we always pick the same element between multiple codegen runs. To do this the Rust SDK will:</p>
<ol>
<li>Topologically sort the graph of shapes.</li>
<li>Identify cycles that do not pass through an existing Box<T>, List, Set, or Map</li>
<li>For each cycle, select the earliest shape alphabetically &amp; mark it as Box<T> in the Smithy model by attaching the custom <code>RustBoxTrait</code> to the member.</li>
<li>Go back to step 1.</li>
</ol>
<p>This would produce valid Rust:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TopStructure {
    intermediate: IntermediateStructure
}

struct IntermediateStructure {
    top: Box&lt;Option&lt;TopStructure&gt;&gt;
}
<span class="boring">}</span></code></pre></pre>
<p><strong>Backwards Compatibility Note!</strong></p>
<p>Box<T> is not generally compatible with T in Rust. There are several unlikely but valid model changes that will cause the SDK to produce code that may break customers. If these are problematic, all are avoidable with customizations.</p>
<ol>
<li>
<p>A recursive link is added to an existing structure. This causes a member that was not boxed before to become Box<T>.</p>
<blockquote>
<p><strong>Workaround</strong>: Mark the new member as Box<T> in a customization.</p>
</blockquote>
</li>
<li>
<p>A field is removed from a structure that removes the recursive dependency. The SDK would generate T instead of Box<T>.</p>
<blockquote>
<p><strong>Workaround</strong>: Mark the member that used to be boxed as Box<T> in a customization. The Box will be unnecessary, but we will keep it for backwards compatibility.</p>
</blockquote>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aggregate-shapes"><a class="header" href="#aggregate-shapes">Aggregate Shapes</a></h1>
<div class="table-wrapper"><table><thead><tr><th>Smithy Type</th><th>Rust Type</th></tr></thead><tbody>
<tr><td><a href="smithy/aggregate_shapes.html#list">List</a></td><td><code>Vec&lt;Member&gt;</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#set">Set</a></td><td><code>Vec&lt;Member&gt;</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#map">Map</a></td><td><code>HashMap&lt;String, Value&gt;</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#structure">Structure</a></td><td><code>struct</code></td></tr>
<tr><td><a href="smithy/aggregate_shapes.html#union">Union</a></td><td><code>enum</code></td></tr>
</tbody></table>
</div>
<p>Most generated types are controlled by <a href="https://github.com/smithy-lang/smithy-rs/blob/main/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/SymbolVisitor.kt">SymbolVisitor</a>.</p>
<h2 id="list"><a class="header" href="#list">List</a></h2>
<p>List objects in Smithy are transformed into vectors in Rust. Based on the output of the <a href="https://awslabs.github.io/smithy/javadoc/1.5.1/software/amazon/smithy/model/knowledge/NullableIndex.html">NullableIndex</a>, the generated list may be <code>Vec&lt;T&gt;</code> or <code>Vec&lt;Option&lt;T&gt;&gt;</code>.</p>
<h2 id="set"><a class="header" href="#set">Set</a></h2>
<p>Because floats are not Hashable in Rust, for simplicity smithy-rs translates all sets to into <code>Vec&lt;T&gt;</code> instead of <code>HashSet&lt;T&gt;</code>. In the future, a breaking change may be made to introduce a library-provided wrapper type for Sets.</p>
<h2 id="map"><a class="header" href="#map">Map</a></h2>
<p>Because <code>key</code> MUST be a string in Smithy maps, we avoid the hashibility issue encountered with <code>Set</code>. There are optimizations that could be considered (e.g. since these maps will probably never be modified), however, pending customer feedback, Smithy Maps become <code>HashMap&lt;String, V&gt;</code> in Rust.</p>
<h2 id="structure"><a class="header" href="#structure">Structure</a></h2>
<blockquote>
<p>See <code>StructureGenerator.kt</code> for more details</p>
</blockquote>
<p>Smithy <code>structure</code> becomes a <code>struct</code> in Rust. Backwards compatibility &amp; usability concerns lead to a few design choices:</p>
<ol>
<li>As specified by <code>NullableIndex</code>, fields are <code>Option&lt;T&gt;</code> when Smithy models them as nullable.</li>
<li>All structs are marked <code>#[non_exhaustive]</code></li>
<li>All structs derive <code>Debug</code> &amp; <code>PartialEq</code>. Structs <strong>do not</strong> derive <code>Eq</code> because a <code>float</code> member may be added in the future.</li>
<li>Struct fields are public. Public struct fields allow for <a href="https://doc.rust-lang.org/nomicon/borrow-splitting.html">split borrows</a>. When working with output objects this significantly improves ergonomics, especially with optional fields.
<pre><code class="language-rust ignore">let out = dynamo::ListTablesOutput::new();
out.some_field.unwrap(); // &lt;- partial move, impossible with an accessor</code></pre>
</li>
<li>Builders are generated for structs that provide ergonomic and backwards compatible constructors. A builder for a struct is always available via the convenience method <code>SomeStruct::builder()</code></li>
<li>Structures manually implement debug: In order to support the <a href="https://awslabs.github.io/smithy/1.0/spec/core/documentation-traits.html#sensitive-trait">sensitive trait</a>, a <code>Debug</code> implementation for structures is manually generated.</li>
</ol>
<h3 id="example-structure-output"><a class="header" href="#example-structure-output">Example Structure Output</a></h3>
<p><strong>Smithy Input</strong>:</p>
<pre><code class="language-java">@documentation("&lt;p&gt;Contains I/O usage metrics...")
structure IOUsage {
    @documentation("... elided")
    ReadIOs: ReadIOs,
    @documentation("... elided")
    WriteIOs: WriteIOs
}

long ReadIOs

long WriteIOs
</code></pre>
<p><strong>Rust Output</strong>:</p>
<pre><code class="language-rust ignore">/// &lt;p&gt;Contains I/O usage metrics for a command that was invoked.&lt;/p&gt;
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct IoUsage {
    /// &lt;p&gt;The number of read I/O requests that the command made.&lt;/p&gt;
    pub read_i_os: i64,
    /// &lt;p&gt;The number of write I/O requests that the command made.&lt;/p&gt;
    pub write_i_os: i64,
}
impl std::fmt::Debug for IoUsage {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {
        let mut formatter = f.debug_struct("IoUsage");
        formatter.field("read_i_os", &amp;self.read_i_os);
        formatter.field("write_i_os", &amp;self.write_i_os);
        formatter.finish()
    }
}
/// See [`IoUsage`](crate::model::IoUsage)
pub mod io_usage {
    /// A builder for [`IoUsage`](crate::model::IoUsage)
    #[non_exhaustive]
    #[derive(Debug, Clone, Default)]
    pub struct Builder {
        read_i_os: std::option::Option&lt;i64&gt;,
        write_i_os: std::option::Option&lt;i64&gt;,
    }
    impl Builder {
        /// &lt;p&gt;The number of read I/O requests that the command made.&lt;/p&gt;
        pub fn read_i_os(mut self, inp: i64) -&gt; Self {
            self.read_i_os = Some(inp);
            self
        }
         /// &lt;p&gt;The number of read I/O requests that the command made.&lt;/p&gt;
        pub fn set_read_i_os(mut self, inp: Option&lt;i64&gt;) -&gt; Self {
            self.read_i_os = inp;
            self
        }
        /// &lt;p&gt;The number of write I/O requests that the command made.&lt;/p&gt;
        pub fn write_i_os(mut self, inp: i64) -&gt; Self {
            self.write_i_os = Some(inp);
            self
        }
        /// &lt;p&gt;The number of write I/O requests that the command made.&lt;/p&gt;
        pub fn set_write_i_os(mut self, inp: Option&lt;i64&gt;) -&gt; Self {
            self.write_i_os = inp;
            self
        }
        /// Consumes the builder and constructs a [`IoUsage`](crate::model::IoUsage)
        pub fn build(self) -&gt; crate::model::IoUsage {
            crate::model::IoUsage {
                read_i_os: self.read_i_os.unwrap_or_default(),
                write_i_os: self.write_i_os.unwrap_or_default(),
            }
        }
    }
}
impl IoUsage {
    /// Creates a new builder-style object to manufacture [`IoUsage`](crate::model::IoUsage)
    pub fn builder() -&gt; crate::model::io_usage::Builder {
        crate::model::io_usage::Builder::default()
    }
}</code></pre>
<h2 id="union"><a class="header" href="#union">Union</a></h2>
<p>Smithy <code>Union</code> is modeled as <code>enum</code> in Rust.</p>
<ol>
<li>Generated <code>enum</code>s must be marked <code>#[non_exhaustive]</code>.</li>
<li>Generated <code>enum</code>s must provide an <code>Unknown</code> variant. If parsing receives an unknown input that doesn't match any of the given union variants, <code>Unknown</code> should be constructed. <a href="https://github.com/smithy-lang/smithy-rs/issues/185">Tracking Issue</a>.</li>
<li>Union members (enum variants) are <strong>not</strong> nullable, because Smithy union members cannot contain null values.</li>
<li>When union members contain references to other shapes, we generate a wrapping variant (see below).</li>
<li>Union members do not require <code>#[non_exhaustive]</code>, because changing the shape targeted by a union member is not backwards compatible.</li>
<li><code>is_variant</code> and <code>as_variant</code> helper functions are generated to improve ergonomics.</li>
</ol>
<h3 id="generated-union-example"><a class="header" href="#generated-union-example">Generated Union Example</a></h3>
<p>The union generated for a simplified <code>dynamodb::AttributeValue</code>
<strong>Smithy</strong>:</p>
<pre><code class="language-java">namespace test

union AttributeValue {
    @documentation("A string value")
    string: String,
    bool: Boolean,
    bools: BoolList,
    map: ValueMap
}

map ValueMap {
    key: String,
    value: AttributeValue
}

list BoolList {
    member: Boolean
}
</code></pre>
<p><strong>Rust</strong>:</p>
<pre><code class="language-rust ignore">#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub enum AttributeValue {
    /// a string value
    String(std::string::String),
    Bool(bool),
    Bools(std::vec::Vec&lt;bool&gt;),
    Map(std::collections::HashMap&lt;std::string::String, crate::model::AttributeValue&gt;),
}

impl AttributeValue {
    pub fn as_bool(&amp;self) -&gt; Result&lt;&amp;bool, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::Bool(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_bool(&amp;self) -&gt; bool {
        self.as_bool().is_some()
    }
    pub fn as_bools(&amp;self) -&gt; Result&lt;&amp;std::vec::Vec&lt;bool&gt;, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::Bools(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_bools(&amp;self) -&gt; bool {
        self.as_bools().is_some()
    }
    pub fn as_map(&amp;self) -&gt; Result&lt;&amp;std::collections::HashMap&lt;std::string::String, crate::model::AttributeValue&gt;, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::Map(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_map(&amp;self) -&gt; bool {
        self.as_map().is_some()
    }
    pub fn as_string(&amp;self) -&gt; Result&lt;&amp;std::string::String, &amp;crate::model::AttributeValue&gt; {
        if let AttributeValue::String(val) = &amp;self { Ok(&amp;val) } else { Err(self) }
    }
    pub fn is_string(&amp;self) -&gt; bool {
        self.as_string().is_some()
    }
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="backwards-compatibility"><a class="header" href="#backwards-compatibility">Backwards Compatibility</a></h1>
<p>AWS SDKs require that clients can evolve in a backwards compatible way as new fields and operations are added. The types
generated by <code>smithy-rs</code> are specifically designed to meet these requirements. Specifically, the following
transformations must not break compilation when upgrading to a new version:</p>
<ul>
<li><a href="smithy/backwards-compat.html#new-operation-added">New operation added</a></li>
<li><a href="smithy/backwards-compat.html#new-member-added-to-structure">New member added to structure</a></li>
<li><a href="smithy/backwards-compat.html#new-union-variant-added">New union variant added</a></li>
<li>New error added (todo)</li>
<li>New enum variant added (todo)</li>
</ul>
<p>However, the following changes are <em>not</em> backwards compatible:</p>
<ul>
<li>Error <strong>removed</strong> from operation.</li>
</ul>
<p>In general, the best tool in Rust to solve these issues in the <code>#[non_exhaustive]</code> attribute which will be explored in
detail below.</p>
<h2 id="new-operation-added"><a class="header" href="#new-operation-added">New Operation Added</a></h2>
<p><strong>Before</strong></p>
<pre><code class="language-smithy">$version: "1"
namespace s3

service S3 {
    operations: [GetObject]
}
</code></pre>
<p><strong>After</strong></p>
<pre><code class="language-smithy">$version: "1"
namespace s3

service S3 {
    operations: [GetObject, PutObject]
}
</code></pre>
<p>Adding support for a new operation is backwards compatible because SDKs to not expose any sort of "service trait" that
provides an interface over an entire service. This <em>prevents</em> clients from inheriting or implementing an interface that
would be broken by the addition of a new operation.</p>
<h2 id="new-member-added-to-structure"><a class="header" href="#new-member-added-to-structure">New member added to structure</a></h2>
<h3 id="summary"><a class="header" href="#summary">Summary</a></h3>
<ul>
<li>Structures are marked <code>#[non_exhaustive]</code></li>
<li>Structures must be instantiated using builders</li>
<li>Structures must not derive <code>Default</code> in the event that required fields are added in the future.</li>
</ul>
<p>In general, adding a new <code>public</code> member to a structure in Rust is not backwards compatible. However, by applying
the <code>#[non_exhaustive]</code> to the structures generated by the Rust SDK, the Rust compiler will prevent users from using our
structs in ways that prevent new fields from being added in the future. <strong>Note</strong>: in this context, the optionality of
the fields is irrelevant.</p>
<p>Specifically, <a href="https://doc.rust-lang.org/reference/attributes/type_system.html"><code>#[non_exhaustive]</code></a> prohibits the
following patterns:</p>
<ol>
<li>
<p>Direct structure instantiation:</p>
<pre><code class="language-rust ignore"><span class="boring">fn foo() {
</span>let ip_addr = IpAddress { addr: "192.168.1.1" };
<span class="boring">}</span></code></pre>
<p>If a new member <code>is_local: boolean</code> was added to the IpAddress structure, this code would not compile. To enable
users to still construct
our structures while maintaining backwards compatibility, all structures expose a builder, accessible
at <code>SomeStruct::Builder</code>:</p>
<pre><code class="language-rust ignore"><span class="boring">fn foo() {
</span>let ip_addr = IpAddress::builder().addr("192.168.1.1").build();
<span class="boring">}</span></code></pre>
</li>
<li>
<p>Structure destructuring:</p>
<pre><code class="language-rust ignore"><span class="boring">fn foo() {
</span>let IpAddress { addr } = some_ip_addr();
<span class="boring">}</span></code></pre>
<p>This will also fail to compile if a new member is added, however, by adding <code>#[non_exhaustive]</code>, the <code>..</code> multifield
wildcard MUST be added to support new fields being added in the future:</p>
<pre><code class="language-rust ignore"><span class="boring">fn foo() {
</span>let IpAddress { addr, .. } = some_ip_addr();
<span class="boring">}</span></code></pre>
</li>
</ol>
<h3 id="validation--required-members"><a class="header" href="#validation--required-members">Validation &amp; Required Members</a></h3>
<p><strong>Adding a required member to a structure is <em>not</em> considered backwards compatible.</strong> When a required member is added to
a structure:</p>
<ol>
<li>The builder will change to become fallible, meaning that instead of returning <code>T</code> it will
return <code>Result&lt;T, BuildError&gt;</code>.</li>
<li>Previous builder invocations that did not set the new field will still stop compiling if this was the first required
field.</li>
<li>Previous builder invocations will now return a <code>BuildError</code> because the required field is unset.</li>
</ol>
<h2 id="new-union-variant-added"><a class="header" href="#new-union-variant-added">New union variant added</a></h2>
<p>Similar to structures, <code>#[non_exhaustive]</code> also applies to unions. In order to allow new union variants to be added in
the future, all unions (<code>enum</code> in Rust) generated by the Rust SDK must be marked with <code>#[non_exhaustive]</code>. <strong>Note</strong>:
because new fields cannot be added to union variants, the union variants themselves do <strong>not</strong> need
to be <code>#[non_exhaustive]</code>. To support new variants from services, each union contains an <code>Unknown</code> variant. By
marking <code>Unknown</code> as non_exhaustive, we prevent customers from instantiating it directly.</p>
<pre><code class="language-rust ignore">#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
pub enum AttributeValue {
    B(aws_smithy_types::Blob),
    Bool(bool),
    Bs(std::vec::Vec&lt;aws_smithy_types::Blob&gt;),
    L(std::vec::Vec&lt;crate::model::AttributeValue&gt;),
    M(std::collections::HashMap&lt;std::string::String, crate::model::AttributeValue&gt;),
    N(std::string::String),
    Ns(std::vec::Vec&lt;std::string::String&gt;),
    Null(bool),
    S(std::string::String),
    Ss(std::vec::Vec&lt;std::string::String&gt;),

    // By marking `Unknown` as non_exhaustive, we prevent client code from instantiating it directly.
    #[non_exhaustive]
    Unknown,
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smithy-client"><a class="header" href="#smithy-client">Smithy Client</a></h1>
<p><code>smithy-rs</code> provides the ability to generate a client whose operations defined by a smithy model. The documents referenced
here explain aspects of the client in greater detail.</p>
<ul>
<li><a href="client/./orchestrator.html">What is the 'orchestrator' and why does it exist?</a></li>
<li><a href="client/./identity_and_auth.html">Identity and Auth</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="what-is-the-orchestrator"><a class="header" href="#what-is-the-orchestrator">What is the orchestrator?</a></h2>
<p>At a very high level, an orchestrator is a process for transforming requests into responses. Please enjoy this fancy chart:</p>
<pre class="mermaid">flowchart TB
	A(Orchestrate)--&gt;|Input|B(Request serialization)
	B--&gt;|Transmit Request|C(Connection)
	C--&gt;|Transmit Response|D(Response deserialization)
	D--&gt;|Success|E(&quot;Ok(Output)&quot;)
	D--&gt;|Unretryable Failure|F(&quot;Err(SdkError)&quot;)
	D--&gt;|Retryable Failure|C
</pre>
<p>This process is also referred to as the "request/response lifecycle." In this example, the types of "transmit request" and "transmit response" are protocol-dependent. Typical operations use <a href="https://en.wikipedia.org/wiki/HTTP">HTTP</a>, but we plan to support other protocols like <a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a> in the future.</p>
<p>In addition to the above steps, the orchestrator must also handle:</p>
<ul>
<li><strong>Endpoint resolution:</strong> figuring out which URL to send a request to.</li>
<li><strong>Authentication, identity resolution, and request signing:</strong> Figuring out who is sending the request, their credentials, and how we should insert the credentials into a request.</li>
<li><strong>Interceptors</strong>: Running lifecycle hooks at each point in the request/response lifecycle.</li>
<li><strong>Runtime Plugins:</strong> Resolving configuration from config builders.</li>
<li><strong>Retries:</strong> Categorizing responses from services and deciding whether to retry and how long to wait before doing so.</li>
<li><strong>Trace Probes:</strong> A <a href="https://en.wikipedia.org/wiki/Sink_(computing)">sink</a> for events that occur during the request/response lifecycle.</li>
</ul>
<h2 id="how-is-an-orchestrator-configured"><a class="header" href="#how-is-an-orchestrator-configured">How is an orchestrator configured?</a></h2>
<p>While the structure of an orchestrator is fixed, the actions it takes during its lifecycle are highly configurable. Users have two ways to configure this process:</p>
<ul>
<li><strong>Runtime Plugins</strong>:
<ul>
<li><strong>When can these be set?</strong> Any time before calling <code>orchestrate</code>.</li>
<li><strong>When are they called by the orchestrator?</strong> In two batches, at the very beginning of <code>orchestrate</code>.</li>
<li><strong>What can they do?</strong>
<ul>
<li>They can set configuration to be used by the orchestrator or in interceptors.</li>
<li>They can set interceptors.</li>
</ul>
</li>
<li><strong>Are they user-definable?</strong> No. At present, only smithy-rs maintainers may define these.</li>
</ul>
</li>
<li><strong>Interceptors</strong>:
<ul>
<li><strong>When can these be set?</strong> Any time before calling <code>orchestrate</code>.</li>
<li><strong>When are they called by the orchestrator?</strong> At each step in the request-response lifecycle.</li>
<li><strong>What can they do?</strong>
<ul>
<li>They can set configuration to be used by the orchestrator or in interceptors.</li>
<li>They can log information.</li>
<li>Depending on when they're run, they can modify the input, transmit request, transmit response, and the output/error.</li>
</ul>
</li>
<li><strong>Are they user-definable?</strong> Yes.</li>
</ul>
</li>
</ul>
<p>Configuration for a request is constructed by runtime plugins just after calling <code>orchestrate</code>. Configuration is stored in a <code>ConfigBag</code>: a hash map that's keyed on type's <a href="https://doc.rust-lang.org/stable/std/any/struct.TypeId.html"><code>TypeId</code></a> (an opaque object, managed by the Rust compiler, which references some type.)</p>
<h2 id="what-does-the-orchestrator-do"><a class="header" href="#what-does-the-orchestrator-do">What does the orchestrator do?</a></h2>
<p>The orchestrator's work is divided into four phases:</p>
<p><em>NOTE: If an interceptor fails, then the other interceptors for that lifecycle event are still run. All resulting errors are collected and emitted together.</em></p>
<ol start="0">
<li><strong>Building the <code>ConfigBag</code> and mounting interceptors</strong>.
<ul>
<li><em>This phase is fallible.</em></li>
<li>An interceptor context is created. This will hold request and response objects, making them available to interceptors.</li>
<li>All runtime plugins set at the client-level are run. These plugins can set config and mount interceptors. Any <em>"read before execution"</em> interceptors that have been set get run.</li>
<li>All runtime plugins set at the operation-level are run. These plugins can also set config and mount interceptors. Any new <em>"read before execution"</em> interceptors that have been set get run.</li>
</ul>
</li>
<li><strong>Request Construction</strong>
<ul>
<li><em>This phase is fallible.</em></li>
<li>The <em>"read before serialization"</em> and <em>"modify before serialization"</em> interceptors are called.</li>
<li>The input is serialized into a transmit request.</li>
<li>The <em>"read after serialization"</em> and <em>"modify before retry</em> loop" interceptors are called.</li>
<li>Before making an attempt, the retry handler is called to check if an attempt should be made. The retry handler makes this decision for an initial attempt as well as for the retry attempts. If an initial attempt should be made, then the orchestrator enters the Dispatch phase. Otherwise, a throttling error is returned.</li>
</ul>
</li>
<li><strong>Request Dispatch</strong>
<ul>
<li><em>This phase is fallible. This phase's tasks are performed in a loop. Retryable request failures will be retried, and unretryable failures will end the loop.</em></li>
<li>The <em>"read before attempt"</em> interceptors are run.</li>
<li>An endpoint is resolved according to an endpoint resolver. The resolved endpoint is then applied to the transmit request.</li>
<li>The <em>"read before signing"</em> and <em>"modify before signing"</em> interceptors are run.</li>
<li>An identity and a signer are resolved according to an authentication resolver. The signer then signs the transmit request with the identity.</li>
<li>The <em>"read after signing"</em>, <em>"read before transmit"</em>, and <em>"modify before transmit"</em> interceptors are run.</li>
<li>The transmit request is passed into the connection, and a transmit response is received.</li>
<li>The <em>"read after transmit"</em>, <em>"read before deserialization"</em>, and <em>"modify before deserialization"</em> interceptors are run.</li>
<li>The transmit response is deserialized.</li>
<li>The <em>"read after attempt"</em> and <em>"modify before attempt</em> completion" interceptors are run.</li>
<li>The retry strategy is called to check if a retry is necessary. If a retry is required, the Dispatch phase restarts. Otherwise, the orchestrator enters the Response Handling phase.</li>
</ul>
</li>
<li><strong>Response Handling</strong>
<ul>
<li><em>This phase is fallible.</em></li>
<li>The <em>"read after deserialization"</em> and <em>"modify before completion"</em> interceptors are run.</li>
<li>Events are dispatched to any trace probes that the user has set.</li>
<li>The <em>"read after execution"</em> interceptors are run.</li>
</ul>
</li>
</ol>
<p>At the end of all this, the response is returned. If an error occurred at any point, then the response will contain one or more errors, depending on what failed. Otherwise, the output will be returned.</p>
<h2 id="how-is-the-orchestrator-implemented-in-rust"><a class="header" href="#how-is-the-orchestrator-implemented-in-rust">How is the orchestrator implemented in Rust?</a></h2>
<h3 id="avoiding-generics-at-all-costs"><a class="header" href="#avoiding-generics-at-all-costs">Avoiding generics at all costs</a></h3>
<p>In designing the orchestrator, we sought to solve the problems we had with the original smithy client. The client made heavy use of generics, allowing for increased performance, but at the cost of increased maintenance burden and <a href="https://rustc-dev-guide.rust-lang.org/backend/monomorph.html#polymorphization">increased compile times</a>. The Rust compiler, usually very helpful, isn't well-equipped to explain trait errors when bounds are this complex, and so the resulting client was difficult to extend. <a href="https://github.com/rust-lang/rust/issues/41517">Trait aliases</a> would have helped, but they're not (at the time of writing) available.</p>
<p><em>The type signatures for the old client and its <code>call</code> method:</em></p>
<pre><code class="language-rust ignore">impl&lt;C, M, R&gt; Client&lt;C, M, R&gt;
where
    C: bounds::SmithyConnector,
    M: bounds::SmithyMiddleware&lt;C&gt;,
    R: retry::NewRequestPolicy,
{
    pub async fn call&lt;O, T, E, Retry&gt;(&amp;self, op: Operation&lt;O, Retry&gt;) -&gt; Result&lt;T, SdkError&lt;E&gt;&gt;
        where
            O: Send + Sync,
            E: std::error::Error + Send + Sync + 'static,
            Retry: Send + Sync,
            R::Policy: bounds::SmithyRetryPolicy&lt;O, T, E, Retry&gt;,
            Retry: ClassifyRetry&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;,
            bounds::Parsed&lt;&lt;M as bounds::SmithyMiddleware&lt;C&gt;&gt;::Service, O, Retry&gt;:
            Service&lt;Operation&lt;O, Retry&gt;, Response=SdkSuccess&lt;T&gt;, Error=SdkError&lt;E&gt;&gt; + Clone,
    {
        self.call_raw(op).await.map(|res| res.parsed)
    }

    pub async fn call_raw&lt;O, T, E, Retry&gt;(
        &amp;self,
        op: Operation&lt;O, Retry&gt;,
    ) -&gt; Result&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;
        where
            O: Send + Sync,
            E: std::error::Error + Send + Sync + 'static,
            Retry: Send + Sync,
            R::Policy: bounds::SmithyRetryPolicy&lt;O, T, E, Retry&gt;,
            Retry: ClassifyRetry&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;,
        // This bound is not _technically_ inferred by all the previous bounds, but in practice it
        // is because _we_ know that there is only implementation of Service for Parsed
        // (ParsedResponseService), and it will apply as long as the bounds on C, M, and R hold,
        // and will produce (as expected) Response = SdkSuccess&lt;T&gt;, Error = SdkError&lt;E&gt;. But Rust
        // doesn't know that -- there _could_ theoretically be other implementations of Service for
        // Parsed that don't return those same types. So, we must give the bound.
            bounds::Parsed&lt;&lt;M as bounds::SmithyMiddleware&lt;C&gt;&gt;::Service, O, Retry&gt;:
            Service&lt;Operation&lt;O, Retry&gt;, Response=SdkSuccess&lt;T&gt;, Error=SdkError&lt;E&gt;&gt; + Clone,
    {
        // The request/response lifecycle
    }
}</code></pre>
<p><em>The type signature for the new <code>orchestrate</code> method:</em></p>
<pre><code class="language-rust ignore">pub async fn orchestrate(
    input: Input,
    runtime_plugins: &amp;RuntimePlugins,
    // Currently, SdkError is HTTP-only. We currently use it for backwards-compatibility purposes.
    // The `HttpResponse` generic will likely be removed in the future.
) -&gt; Result&lt;Output, SdkError&lt;Error, HttpResponse&gt;&gt; {
	// The request/response lifecycle
}</code></pre>
<p>Wait a second, I hear you ask. "I see an <code>Input</code> and <code>Output</code> there, but you're not declaring any generic type arguments. What gives?"</p>
<p>I'm glad you asked. Generally, when you need traits, but you aren't willing to use generic type arguments, then you must <a href="https://doc.rust-lang.org/std/boxed/index.html"><code>Box</code></a>. Polymorphism is achieved through <a href="https://doc.rust-lang.org/book/ch17-02-trait-objects.html#trait-objects-perform-dynamic-dispatch">dynamic dispatch</a> instead of <a href="https://doc.rust-lang.org/book/ch10-01-syntax.html#performance-of-code-using-generics">static dispatch</a>, and this comes with a small runtime cost.</p>
<p>So, what are <code>Input</code> and <code>Output</code>? They're our own special flavor of a boxed trait object.</p>
<pre><code class="language-rust ignore">pub type Input = TypeErasedBox;
pub type Output = TypeErasedBox;
pub type Error = TypeErasedBox;

/// A new-type around `Box&lt;dyn Any + Send + Sync&gt;`
#[derive(Debug)]
pub struct TypeErasedBox {
    inner: Box&lt;dyn Any + Send + Sync&gt;,
}</code></pre>
<p>The orchestrator itself doesn't know about any concrete types. Instead, it passes boxed data between the various components of the request/response lifecycle. Individual components access data in two ways:</p>
<ol>
<li><strong>From the <code>ConfigBag</code>:</strong></li>
</ol>
<ul>
<li><em>(with an accessor)</em> <code>let retry_strategy = cfg.retry_strategy();</code></li>
<li><em>(with the get method)</em> <code>let retry_strategy = cfg.get::&lt;Box&lt;dyn RetryStrategy&gt;&gt;()</code></li>
</ul>
<ol start="2">
<li><strong>From the <code>InterceptorContext</code>:</strong></li>
</ol>
<ul>
<li><em>(owned)</em> <code>let put_object_input: PutObjectInput = ctx.take_input().unwrap().downcast().unwrap()?;</code></li>
<li><em>(by reference)</em> <code>let put_object_input = ctx.input().unwrap().downcast_ref::&lt;PutObjectInput&gt;().unwrap();</code></li>
</ul>
<p>Users can only call <code>ConfigBag::get</code> or <a href="https://en.wikipedia.org/wiki/Downcasting">downcast</a> a <code>TypeErasedBox</code> to types they have access to, which allows maintainers to ensure encapsulation. For example: a plugin writer may declare a private type, place it in the config bag, and then later retrieve it. Because the type is private, only code in the same crate/module can ever insert or retrieve it. Therefore, there's less worry that someone will depend on a hidden, internal detail and no worry they'll accidentally overwrite a type in the bag.</p>
<blockquote>
<p><em>NOTE: When inserting values into a config bag, using one of the <code>set_&lt;component&gt;</code> methods is always preferred, as this prevents mistakes related to inserting similar, but incorrect types.</em></p>
</blockquote>
<h3 id="the-actual-code"><a class="header" href="#the-actual-code">The actual code</a></h3>
<p>The current implementation of <code>orchestrate</code> is defined <a href="https://github.com/smithy-lang/smithy-rs/blob/8bc93fc04dd8c8d7447bfe3f5196a75cba0b10ba/rust-runtime/aws-smithy-runtime/src/client/orchestrator.rs#L23">here</a>, in the <a href="https://github.com/smithy-lang/smithy-rs/tree/main/rust-runtime/aws-smithy-runtime"><code>aws-smithy-runtime</code> crate</a>. Related code can be found in the <a href="https://github.com/smithy-lang/smithy-rs/tree/main/rust-runtime/aws-smithy-runtime"><code>aws-smithy-runtime-api</code> crate</a>.</p>
<h2 id="frequently-asked-questions"><a class="header" href="#frequently-asked-questions">Frequently asked questions</a></h2>
<h3 id="why-cant-users-create-and-use-their-own-runtime-plugins"><a class="header" href="#why-cant-users-create-and-use-their-own-runtime-plugins">Why can't users create and use their own runtime plugins?</a></h3>
<p>We chose to hide the runtime plugin API from users because we are concerned that exposing it will cause more problems than it solves. Instead, we encourage users to use interceptors. This is because, when setting a runtime plugin, any existing runtime plugin with the same type will be replaced. For example, there can only be one retry strategy or response deserializer. Errors resulting from unintentionally overriding a plugin would be difficult for users to diagnose, and would consume valuable development time.</p>
<h3 id="why-does-the-orchestrator-exist"><a class="header" href="#why-does-the-orchestrator-exist">Why does the orchestrator exist?</a></h3>
<p>The orchestrator exists because there is an AWS-internal initiative to bring the architecture of all AWS SDKs closer to one another.</p>
<h3 id="why-does-this-document-exist-when-theres-already-an-orchestrator-rfc"><a class="header" href="#why-does-this-document-exist-when-theres-already-an-orchestrator-rfc">Why does this document exist when there's already an orchestrator RFC?</a></h3>
<p>Because RFCs become outdated as designs evolve. It is our intention to keep this document up to date with our current implementation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="identity-and-auth-in-clients"><a class="header" href="#identity-and-auth-in-clients">Identity and Auth in Clients</a></h1>
<p>The <a href="https://smithy.io/2.0/spec/authentication-traits.html">Smithy specification establishes several auth related modeling traits</a> that can be applied to
operation and service shapes. To briefly summarize:</p>
<ul>
<li>The auth schemes that are supported by a service are declared on the service shape</li>
<li>Operation shapes MAY specify the subset of service-defined auth schemes they support. If none are specified, then all service-defined auth schemes are supported.</li>
</ul>
<p>A smithy code generator MUST support at least one auth scheme for every modeled operation, but it need not support ALL modeled auth schemes.</p>
<p>This design document establishes how smithy-rs implements this specification.</p>
<h2 id="terminology"><a class="header" href="#terminology">Terminology</a></h2>
<ul>
<li><strong>Auth:</strong> Either a shorthand that represents both of the authentication and authorization terms below,
or an ambiguous representation of one of them. In this doc, this term will always refer to both.</li>
<li><strong>Authentication:</strong> The process of proving an entity is who they claim they are, sometimes referred to as AuthN.</li>
<li><strong>Authorization:</strong> The process of granting an authenticated entity the permission to
do something, sometimes referred to as AuthZ.</li>
<li><strong>Identity:</strong> The information required for authentication.</li>
<li><strong>Signing:</strong> The process of attaching metadata to a request that allows a server to authenticate that request.</li>
</ul>
<h2 id="overview-of-smithy-client-auth"><a class="header" href="#overview-of-smithy-client-auth">Overview of Smithy Client Auth</a></h2>
<p>There are two stages to identity and auth:</p>
<ol>
<li>Configuration</li>
<li>Execution</li>
</ol>
<h3 id="the-configuration-stage"><a class="header" href="#the-configuration-stage">The configuration stage</a></h3>
<p>First, let's establish the aspects of auth that can be configured from the model at codegen time.</p>
<ul>
<li><strong>Data</strong>
<ul>
<li><strong>AuthSchemeOptionResolverParams:</strong> parameters required to resolve auth scheme options. These parameters are allowed
to come from both the client config and the operation input structs.</li>
<li><strong>AuthSchemes:</strong> a list of auth schemes that can be used to sign HTTP requests. This information
comes directly from the service model.</li>
<li><strong>AuthSchemeProperties:</strong> configuration from the auth scheme for the signer.</li>
<li><strong>IdentityResolvers:</strong> list of available identity resolvers.</li>
</ul>
</li>
<li><strong>Implementations</strong>
<ul>
<li><strong>IdentityResolver:</strong> resolves an identity for use in authentication.
There can be multiple identity resolvers that need to be selected from.</li>
<li><strong>Signer:</strong> a signing implementation that signs a HTTP request.</li>
<li><strong>ResolveAuthSchemeOptions:</strong> resolves a list of auth scheme options for a given operation and its inputs.</li>
</ul>
</li>
</ul>
<p>As it is undocumented (at time of writing), this document assumes that the code generator
creates one service-level runtime plugin, and an operation-level runtime plugin per operation, hence
referred to as the service runtime plugin and operation runtime plugin.</p>
<p>The code generator emits code to add identity resolvers and HTTP auth schemes to the config bag
in the service runtime plugin. It then emits code to register an interceptor in the operation runtime
plugin that reads the operation input to generate the auth scheme option resolver params (which also get added
to the config bag).</p>
<h3 id="the-execution-stage"><a class="header" href="#the-execution-stage">The execution stage</a></h3>
<p>At a high-level, the process of resolving an identity and signing a request looks as follows:</p>
<ol>
<li>Retrieve the <code>AuthSchemeOptionResolverParams</code> from the config bag. The <code>AuthSchemeOptionResolverParams</code> allow client
config and operation inputs to play a role in which auth scheme option is selected.</li>
<li>Retrieve the <code>ResolveAuthSchemeOptions</code> impl from the config bag, and use it to resolve the auth scheme options available
with the <code>AuthSchemeOptionResolverParams</code>. The returned auth scheme options are in priority order.</li>
<li>Retrieve the <code>IdentityResolvers</code> list from the config bag.</li>
<li>For each auth scheme option:
<ol>
<li>Attempt to find an HTTP auth scheme for that auth scheme option in the config bag (from the <code>AuthSchemes</code> list).</li>
<li>If an auth scheme is found:
<ol>
<li>Use the auth scheme to extract the correct identity resolver from the <code>IdentityResolvers</code> list.</li>
<li>Retrieve the <code>Signer</code> implementation from the auth scheme.</li>
<li>Use the <code>IdentityResolver</code> to resolve the identity needed for signing.</li>
<li>Sign the request with the identity, and break out of the loop from step #4.</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>In general, it is assumed that if an HTTP auth scheme exists for an auth scheme option, then an identity resolver
also exists for that auth scheme option. Otherwise, the auth option was configured incorrectly during codegen.</p>
<h2 id="how-this-looks-in-rust"><a class="header" href="#how-this-looks-in-rust">How this looks in Rust</a></h2>
<p>The client will use trait objects and dynamic dispatch for the <code>IdentityResolver</code>,
<code>Signer</code>, and <code>AuthSchemeOptionResolver</code> implementations. Generics could potentially be used,
but the number of generic arguments and trait bounds in the orchestrator would balloon to
unmaintainable levels if each configurable implementation in it was made generic.</p>
<p>These traits look like this:</p>
<pre><code class="language-rust ignore">#[derive(Clone, Debug)]
pub struct AuthSchemeId {
    scheme_id: &amp;'static str,
}

pub trait ResolveAuthSchemeOptions: Send + Sync + Debug {
    fn resolve_auth_scheme_options&lt;'a&gt;(
        &amp;'a self,
        params: &amp;AuthSchemeOptionResolverParams,
    ) -&gt; Result&lt;Cow&lt;'a, [AuthSchemeId]&gt;, BoxError&gt;;
}

pub trait IdentityResolver: Send + Sync + Debug {
    fn resolve_identity(&amp;self, config: &amp;ConfigBag) -&gt; BoxFallibleFut&lt;Identity&gt;;
}

pub trait Signer: Send + Sync + Debug {
    /// Return a signed version of the given request using the given identity.
    ///
    /// If the provided identity is incompatible with this signer, an error must be returned.
    fn sign_http_request(
        &amp;self,
        request: &amp;mut HttpRequest,
        identity: &amp;Identity,
        auth_scheme_endpoint_config: AuthSchemeEndpointConfig&lt;'_&gt;,
        runtime_components: &amp;RuntimeComponents,
        config_bag: &amp;ConfigBag,
    ) -&gt; Result&lt;(), BoxError&gt;;
}</code></pre>
<p><code>IdentityResolver</code> and <code>Signer</code> implementations are both given an <code>Identity</code>, but
will need to understand what the concrete data type underlying that identity is. The <code>Identity</code> struct
uses a <code>Arc&lt;dyn Any&gt;</code> to represent the actual identity data so that generics are not needed in
the traits:</p>
<pre><code class="language-rust ignore">#[derive(Clone, Debug)]
pub struct Identity {
    data: Arc&lt;dyn Any + Send + Sync&gt;,
    expiration: Option&lt;SystemTime&gt;,
}</code></pre>
<p>Identities can often be cached and reused across several requests, which is why the <code>Identity</code> uses <code>Arc</code>
rather than <code>Box</code>. This also reduces the allocations required. The signer implementations
will use downcasting to access the identity data types they understand. For example, with AWS SigV4,
it might look like the following:</p>
<pre><code class="language-rust ignore">fn sign_http_request(
    &amp;self,
    request: &amp;mut HttpRequest,
    identity: &amp;Identity,
    auth_scheme_endpoint_config: AuthSchemeEndpointConfig&lt;'_&gt;,
    runtime_components: &amp;RuntimeComponents,
    config_bag: &amp;ConfigBag,
) -&gt; Result&lt;(), BoxError&gt; {
    let aws_credentials = identity.data::&lt;Credentials&gt;()
        .ok_or_else(|| "The SigV4 signer requires AWS credentials")?;
    let access_key = &amp;aws_credentials.secret_access_key;
    // -- snip --
}</code></pre>
<p>Also note that identity data structs are expected to censor their own sensitive fields, as
<code>Identity</code> implements the automatically derived <code>Debug</code> trait.</p>
<h3 id="challenges-with-this-identity-design"><a class="header" href="#challenges-with-this-identity-design">Challenges with this <code>Identity</code> design</a></h3>
<p>A keen observer would note that there is an <code>expiration</code> field on <code>Identity</code>, and may ask, "what about
non-expiring identities?" This is the result of a limitation on <code>Box&lt;dyn Any&gt;</code>, where it can only be
downcasted to concrete types. There is no way to downcast to a <code>dyn Trait</code> since the information required
to verify that that type is that trait is lost at compile time (a <code>std::any::TypeId</code> only encodes information
about the concrete type).</p>
<p>In an ideal world, it would be possible to extract the expiration like this:</p>
<pre><code class="language-rust ignore">pub trait ExpiringIdentity {
    fn expiration(&amp;self) -&gt; SystemTime;
}

let identity: Identity = some_identity();
if let Some(expiration) = identity.data::&lt;&amp;dyn ExpiringIdentity&gt;().map(ExpiringIdentity::expiration) {
    // make a decision based on that expiration
}</code></pre>
<p>Theoretically, you should be able to save off additional type information alongside the <code>Box&lt;dyn Any&gt;</code> and use
unsafe code to transmute to known traits, but it is difficult to implement in practice, and adds unsafe code
in a security critical piece of code that could otherwise be avoided.</p>
<p>The <code>expiration</code> field is a special case that is allowed onto the <code>Identity</code> struct directly since identity
cache implementations will always need to be aware of this piece of information, and having it as an <code>Option</code>
still allows for non-expiring identities.</p>
<p>Ultimately, this design constrains <code>Signer</code> implementations to concrete types. There is no world
where an <code>Signer</code> can operate across multiple unknown identity data types via trait, and that
should be OK since the signer implementation can always be wrapped with an implementation that is aware
of the concrete type provided by the identity resolver, and can do any necessary conversions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="detailed-error-explanations"><a class="header" href="#detailed-error-explanations">Detailed Error Explanations</a></h1>
<p>This page collects detailed explanations for some errors. If you encounter an
error and are interested in learning more about what it means and why it occurs,
check here.</p>
<p><strong>If you can't find the explanation on this page, please file an issue asking
for it to be added.</strong></p>
<h2 id="connection-encountered-an-issue-and-should-not-be-re-used-marking-it-for-closure"><a class="header" href="#connection-encountered-an-issue-and-should-not-be-re-used-marking-it-for-closure">"Connection encountered an issue and should not be re-used. Marking it for closure"</a></h2>
<p>The SDK clients each maintain their own connection pool (<em>except when they share
an <code>HttpClient</code></em>). By the convention of some services, when a request fails due
to a <a href="client/detailed_error_explanations.html#transient-errors">transient error</a>, that connection should not be re-used
for a retry. Instead, it should be dropped and a new connection created instead.
This prevents clients from repeatedly sending requests over a failed connection.</p>
<p>This feature is referred to as "connection poisoning" internally.</p>
<h2 id="transient-errors"><a class="header" href="#transient-errors">Transient Errors</a></h2>
<p>When requests to a service time out, or when a service responds with a 500, 502,
503, or 504 error, it's considered a 'transient error'. Transient errors are
often resolved by making another request.</p>
<p>When retrying transient errors, the SDKs may avoid re-using connections to
overloaded or otherwise unavailable service endpoints, choosing instead to
establish a new connection. This behavior is referred to internally as
"connection poisoning" and is configurable.</p>
<p>To configure this behavior, set the <a href="https://docs.rs/aws-types/latest/aws_types/sdk_config/struct.RetryConfig.html#method.with_reconnect_mode">reconnect_mode</a> in an SDK
client config's <a href="https://docs.rs/aws-types/latest/aws_types/sdk_config/struct.RetryConfig.html">RetryConfig</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smithy-server"><a class="header" href="#smithy-server">Smithy Server</a></h1>
<p>Smithy Rust provides the ability to generate a server whose operations are provided by the customer.</p>
<ul>
<li><a href="server/./middleware.html">Middleware</a></li>
<li><a href="server/./instrumentation.html">Instrumentation</a></li>
<li><a href="server/./from_parts.html">Accessing Un-modelled Data</a></li>
<li><a href="server/./anatomy.html">The Anatomy of a Service</a></li>
<li><a href="server/./code_generation.html">Generating Common Service Code</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="middleware"><a class="header" href="#middleware">Middleware</a></h1>
<p>The following document provides a brief survey of the various positions middleware can be inserted in Smithy Rust.</p>
<p>We use the <a href="https://github.com/smithy-lang/smithy-rs/blob/main/codegen-core/common-test-models/pokemon.smithy">Pokémon service</a> as a reference model throughout.</p>
<pre><code class="language-smithy">/// A Pokémon species forms the basis for at least one Pokémon.
@title("Pokémon Species")
resource PokemonSpecies {
    identifiers: {
        name: String
    },
    read: GetPokemonSpecies,
}

/// A users current Pokémon storage.
resource Storage {
    identifiers: {
        user: String
    },
    read: GetStorage,
}

/// The Pokémon Service allows you to retrieve information about Pokémon species.
@title("Pokémon Service")
@restJson1
service PokemonService {
    version: "2021-12-01",
    resources: [PokemonSpecies, Storage],
    operations: [
        GetServerStatistics,
        DoNothing,
        CapturePokemon,
        CheckHealth
    ],
}
</code></pre>
<h2 id="introduction-to-tower"><a class="header" href="#introduction-to-tower">Introduction to Tower</a></h2>
<p>Smithy Rust is built on top of <a href="https://github.com/tower-rs/tower"><code>tower</code></a>.</p>
<blockquote>
<p>Tower is a library of modular and reusable components for building robust networking clients and servers.</p>
</blockquote>
<p>The <code>tower</code> library is centered around two main interfaces, the <a href="https://docs.rs/tower/latest/tower/trait.Service.html"><code>Service</code></a> trait and the <a href="https://docs.rs/tower/latest/tower/trait.Layer.html"><code>Layer</code></a> trait.</p>
<p>The <code>Service</code> trait can be thought of as an asynchronous function from a request to a response, <code>async fn(Request) -&gt; Result&lt;Response, Error&gt;</code>, coupled with a mechanism to <a href="https://docs.rs/tower/latest/tower/trait.Service.html#backpressure">handle back pressure</a>, while the <code>Layer</code> trait can be thought of as a way of decorating a <code>Service</code>, transforming either the request or response.</p>
<p>Middleware in <code>tower</code> typically conforms to the following pattern, a <code>Service</code> implementation of the form</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct NewService&lt;S&gt; {
    inner: S,
    /* auxillary data */
}
<span class="boring">}</span></code></pre></pre>
<p>and a complementary</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate tower;
</span><span class="boring">pub struct NewService&lt;S&gt; { inner: S }
</span>use tower::{Layer, Service};

pub struct NewLayer {
    /* auxiliary data */
}

impl&lt;S&gt; Layer&lt;S&gt; for NewLayer {
    type Service = NewService&lt;S&gt;;

    fn layer(&amp;self, inner: S) -&gt; Self::Service {
        NewService {
            inner,
            /* auxiliary fields */
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p>The <code>NewService</code> modifies the behavior of the inner <code>Service</code> <code>S</code> while the <code>NewLayer</code> takes auxiliary data and constructs <code>NewService&lt;S&gt;</code> from <code>S</code>.</p>
<p>Customers are then able to stack middleware by composing <code>Layer</code>s using combinators such as <a href="https://docs.rs/tower/latest/tower/struct.ServiceBuilder.html#method.layer"><code>ServiceBuilder::layer</code></a> and <a href="https://docs.rs/tower/latest/tower/layer/util/struct.Stack.html"><code>Stack</code></a>.</p>
<!-- TODO(Update documentation): There's a `Layer` implementation on tuples about to be merged, give it as an example here. -->
<h2 id="applying-middleware"><a class="header" href="#applying-middleware">Applying Middleware</a></h2>
<p>One of the primary goals is to provide configurability and extensibility through the application of middleware. The customer is able to apply <code>Layer</code>s in a variety of key places during the request/response lifecycle. The following schematic labels each configurable middleware position from A to D:</p>
<pre class="mermaid">stateDiagram-v2
    state in &lt;&lt;fork&gt;&gt;
    state &quot;GetPokemonSpecies&quot; as C1
    state &quot;GetStorage&quot; as C2
    state &quot;DoNothing&quot; as C3
    state &quot;...&quot; as C4
    direction LR
    [*] --&gt; in : HTTP Request
    UpgradeLayer --&gt; [*]: HTTP Response
    state A {
        state PokemonService {
            state RoutingService {
                in --&gt; UpgradeLayer: HTTP Request
                in --&gt; C2: HTTP Request
                in --&gt; C3: HTTP Request
                in --&gt; C4: HTTP Request
                state B {
                    state C1 {
                        state C {
                            state UpgradeLayer {
                                direction LR
                                [*] --&gt; Handler: Model Input
                                Handler --&gt; [*] : Model Output
                                state D {
                                    Handler
                                }
                            }
                        }
                    }
                    C2
                    C3
                    C4
                }
            }
        }
    }
    C2 --&gt; [*]: HTTP Response
    C3 --&gt; [*]: HTTP Response
    C4 --&gt; [*]: HTTP Response
</pre>
<p>where <code>UpgradeLayer</code> is the <code>Layer</code> converting Smithy model structures to HTTP structures and the <code>RoutingService</code> is responsible for routing requests to the appropriate operation.</p>
<h3 id="a-outer-middleware"><a class="header" href="#a-outer-middleware">A. Outer Middleware</a></h3>
<p>The output of the Smithy service builder provides the user with a <code>Service&lt;http::Request, Response = http::Response&gt;</code> implementation. A <code>Layer</code> can be applied around the entire <code>Service</code>.</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate tower;
</span><span class="boring">use std::time::Duration;
</span><span class="boring">struct TimeoutLayer;
</span><span class="boring">impl TimeoutLayer { fn new(t: Duration) -&gt; Self { Self }}
</span><span class="boring">impl&lt;S&gt; Layer&lt;S&gt; for TimeoutLayer { type Service = S; fn layer(&amp;self, svc: S) -&gt; Self::Service { svc } }
</span><span class="boring">use pokemon_service_server_sdk::{input::*, output::*, error::*};
</span><span class="boring">let handler = |req: GetPokemonSpeciesInput| async { Result::&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;::Ok(todo!()) };
</span><span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span>use pokemon_service_server_sdk::{PokemonServiceConfig, PokemonService};
use tower::Layer;

let config = PokemonServiceConfig::builder().build();

// This is a HTTP `Service`.
let app = PokemonService::builder(config)
    .get_pokemon_species(handler)
    /* ... */
    .build()
    .unwrap();
<span class="boring">let app: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = app;
</span>
// Construct `TimeoutLayer`.
let timeout_layer = TimeoutLayer::new(Duration::from_secs(3));

// Apply a 3 second timeout to all responses.
let app = timeout_layer.layer(app);
<span class="boring">}</span></code></pre></pre>
<h3 id="b-route-middleware"><a class="header" href="#b-route-middleware">B. Route Middleware</a></h3>
<p>A <em>single</em> layer can be applied to <em>all</em> routes inside the <code>Router</code>. This
exists as a method on the <code>PokemonServiceConfig</code> builder object, which is passed into the
service builder.</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate tower;
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use tower::{util::service_fn, Layer};
</span><span class="boring">use std::time::Duration;
</span><span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span><span class="boring">use pokemon_service_server_sdk::{input::*, output::*, error::*};
</span><span class="boring">let handler = |req: GetPokemonSpeciesInput| async { Result::&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;::Ok(todo!()) };
</span><span class="boring">struct MetricsLayer;
</span><span class="boring">impl MetricsLayer { pub fn new() -&gt; Self { Self } }
</span><span class="boring">impl&lt;S&gt; Layer&lt;S&gt; for MetricsLayer { type Service = S; fn layer(&amp;self, svc: S) -&gt; Self::Service { svc } }
</span>use pokemon_service_server_sdk::{PokemonService, PokemonServiceConfig};

// Construct `MetricsLayer`.
let metrics_layer = MetricsLayer::new();

let config = PokemonServiceConfig::builder().layer(metrics_layer).build();

let app = PokemonService::builder(config)
    .get_pokemon_species(handler)
    /* ... */
    .build()
    .unwrap();
<span class="boring">let app: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = app;
</span><span class="boring">}</span></code></pre></pre>
<p>Note that requests pass through this middleware immediately <em>after</em> routing succeeds and therefore will <em>not</em> be encountered if routing fails. This means that the <a href="https://docs.rs/tower-http/latest/tower_http/trace/struct.TraceLayer.html">TraceLayer</a> in the example above does <em>not</em> provide logs unless routing has completed. This contrasts to <a href="server/middleware.html#a-outer-middleware">middleware A</a>, which <em>all</em> requests/responses pass through when entering/leaving the service.</p>
<h3 id="c-operation-specific-http-middleware"><a class="header" href="#c-operation-specific-http-middleware">C. Operation Specific HTTP Middleware</a></h3>
<p>A "HTTP layer" can be applied to specific operations.</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate tower;
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use tower::{util::service_fn, Layer};
</span><span class="boring">use std::time::Duration;
</span><span class="boring">use pokemon_service_server_sdk::{operation_shape::GetPokemonSpecies, input::*, output::*, error::*};
</span><span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span><span class="boring">use aws_smithy_http_server::{operation::OperationShapeExt, plugin::*, operation::*};
</span><span class="boring">let handler = |req: GetPokemonSpeciesInput| async { Result::&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;::Ok(todo!()) };
</span><span class="boring">struct LoggingLayer;
</span><span class="boring">impl LoggingLayer { pub fn new() -&gt; Self { Self } }
</span><span class="boring">impl&lt;S&gt; Layer&lt;S&gt; for LoggingLayer { type Service = S; fn layer(&amp;self, svc: S) -&gt; Self::Service { svc } }
</span>use pokemon_service_server_sdk::{PokemonService, PokemonServiceConfig, scope};

scope! {
    /// Only log on `GetPokemonSpecies` and `GetStorage`
    struct LoggingScope {
        includes: [GetPokemonSpecies, GetStorage]
    }
}

// Construct `LoggingLayer`.
let logging_plugin = LayerPlugin(LoggingLayer::new());
let logging_plugin = Scoped::new::&lt;LoggingScope&gt;(logging_plugin);
let http_plugins = HttpPlugins::new().push(logging_plugin);

let config = PokemonServiceConfig::builder().http_plugin(http_plugins).build();

let app = PokemonService::builder(config)
    .get_pokemon_species(handler)
    /* ... */
    .build()
    .unwrap();
<span class="boring">let app: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = app;
</span><span class="boring">}</span></code></pre></pre>
<p>This middleware transforms the operations HTTP requests and responses.</p>
<h3 id="d-operation-specific-model-middleware"><a class="header" href="#d-operation-specific-model-middleware">D. Operation Specific Model Middleware</a></h3>
<p>A "model layer" can be applied to specific operations.</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate tower;
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use tower::{util::service_fn, Layer};
</span><span class="boring">use pokemon_service_server_sdk::{operation_shape::GetPokemonSpecies, input::*, output::*, error::*};
</span><span class="boring">let handler = |req: GetPokemonSpeciesInput| async { Result::&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;::Ok(todo!()) };
</span><span class="boring">use aws_smithy_http_server::{operation::*, plugin::*};
</span><span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span><span class="boring">struct BufferLayer;
</span><span class="boring">impl BufferLayer { pub fn new(size: usize) -&gt; Self { Self } }
</span><span class="boring">impl&lt;S&gt; Layer&lt;S&gt; for BufferLayer { type Service = S; fn layer(&amp;self, svc: S) -&gt; Self::Service { svc } }
</span>use pokemon_service_server_sdk::{PokemonService, PokemonServiceConfig, scope};

scope! {
    /// Only buffer on `GetPokemonSpecies` and `GetStorage`
    struct BufferScope {
        includes: [GetPokemonSpecies, GetStorage]
    }
}

// Construct `BufferLayer`.
let buffer_plugin = LayerPlugin(BufferLayer::new(3));
let buffer_plugin = Scoped::new::&lt;BufferScope&gt;(buffer_plugin);
let config = PokemonServiceConfig::builder().model_plugin(buffer_plugin).build();

let app = PokemonService::builder(config)
    .get_pokemon_species(handler)
    /* ... */
    .build()
    .unwrap();
<span class="boring">let app: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = app;
</span><span class="boring">}</span></code></pre></pre>
<p>In contrast to <a href="server/middleware.html#c-operation-specific-http-middleware">position C</a>, this middleware transforms the operations modelled inputs to modelled outputs.</p>
<h2 id="plugin-system"><a class="header" href="#plugin-system">Plugin System</a></h2>
<p>Suppose we want to apply a different <code>Layer</code> to every operation. In this case, position B (<code>PokemonService::layer</code>) will not suffice because it applies a single <code>Layer</code> to all routes and while position C (<code>Operation::layer</code>) would work, it'd require the customer constructs the <code>Layer</code> by hand for every operation.</p>
<p>Consider the following middleware:</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate tower;
</span>use aws_smithy_http_server::shape_id::ShapeId;
use std::task::{Context, Poll};
use tower::Service;

/// A [`Service`] that adds a print log.
pub struct PrintService&lt;S&gt; {
    inner: S,
    operation_id: ShapeId,
    service_id: ShapeId
}

impl&lt;R, S&gt; Service&lt;R&gt; for PrintService&lt;S&gt;
where
    S: Service&lt;R&gt;,
{
    type Response = S::Response;
    type Error = S::Error;
    type Future = S::Future;

    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        self.inner.poll_ready(cx)
    }

    fn call(&amp;mut self, req: R) -&gt; Self::Future {
        println!("Hi {} in {}", self.operation_id.name(), self.service_id.name());
        self.inner.call(req)
    }
}
<span class="boring">}</span></code></pre></pre>
<p>The plugin system provides a way to construct then apply <code>Layer</code>s in position <a href="server/middleware.html#c-operation-specific-http-middleware">C</a> and <a href="server/middleware.html#d-operation-specific-model-middleware">D</a>, using the <a href="https://awslabs.github.io/smithy/2.0/aws/protocols/index.html">protocol</a> and <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#service-operations">operation shape</a> as parameters.</p>
<p>An example of a <code>PrintPlugin</code> which prints the operation name:</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::shape_id::ShapeId;
</span><span class="boring">pub struct PrintService&lt;S&gt; { inner: S, operation_id: ShapeId, service_id: ShapeId }
</span>use aws_smithy_http_server::{plugin::Plugin, operation::OperationShape, service::ServiceShape};

/// A [`Plugin`] for a service builder to add a [`PrintService`] over operations.
#[derive(Debug)]
pub struct PrintPlugin;

impl&lt;Ser, Op, T&gt; Plugin&lt;Ser, Op, T&gt; for PrintPlugin
where
    Ser: ServiceShape,
    Op: OperationShape,
{
    type Output = PrintService&lt;T&gt;;

    fn apply(&amp;self, inner: T) -&gt; Self::Output {
        PrintService {
            inner,
            operation_id: Op::ID,
            service_id: Ser::ID,
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p>You can provide a custom method to add your plugin to a collection of  <code>HttpPlugins</code> or <code>ModelPlugins</code> via an extension trait. For example, for <code>HttpPlugins</code>:</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">pub struct PrintPlugin;
</span><span class="boring">impl aws_smithy_http_server::plugin::HttpMarker for PrintPlugin { }
</span>use aws_smithy_http_server::plugin::{HttpPlugins, PluginStack};

/// This provides a [`print`](PrintExt::print) method on [`HttpPlugins`].
pub trait PrintExt&lt;ExistingPlugins&gt; {
    /// Causes all operations to print the operation name when called.
    ///
    /// This works by applying the [`PrintPlugin`].
    fn print(self) -&gt; HttpPlugins&lt;PluginStack&lt;PrintPlugin, ExistingPlugins&gt;&gt;;
}

impl&lt;ExistingPlugins&gt; PrintExt&lt;ExistingPlugins&gt; for HttpPlugins&lt;ExistingPlugins&gt; {
    fn print(self) -&gt; HttpPlugins&lt;PluginStack&lt;PrintPlugin, ExistingPlugins&gt;&gt; {
        self.push(PrintPlugin)
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This allows for:</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::plugin::{PluginStack, Plugin};
</span><span class="boring">struct PrintPlugin;
</span><span class="boring">impl&lt;Ser, Op, T&gt; Plugin&lt;Ser, Op, T&gt; for PrintPlugin { type Output = T; fn apply(&amp;self, svc: T) -&gt; Self::Output { svc }}
</span><span class="boring">impl aws_smithy_http_server::plugin::HttpMarker for PrintPlugin { }
</span><span class="boring">trait PrintExt&lt;EP&gt; { fn print(self) -&gt; HttpPlugins&lt;PluginStack&lt;PrintPlugin, EP&gt;&gt;; }
</span><span class="boring">impl&lt;EP&gt; PrintExt&lt;EP&gt; for HttpPlugins&lt;EP&gt; { fn print(self) -&gt; HttpPlugins&lt;PluginStack&lt;PrintPlugin, EP&gt;&gt; { self.push(PrintPlugin) }}
</span><span class="boring">use pokemon_service_server_sdk::{operation_shape::GetPokemonSpecies, input::*, output::*, error::*};
</span><span class="boring">let handler = |req: GetPokemonSpeciesInput| async { Result::&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;::Ok(todo!()) };
</span><span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span>use aws_smithy_http_server::plugin::{IdentityPlugin, HttpPlugins};
use pokemon_service_server_sdk::{PokemonService, PokemonServiceConfig};

let http_plugins = HttpPlugins::new()
    // [..other plugins..]
    // The custom method!
    .print();
let config = PokemonServiceConfig::builder().http_plugin(http_plugins).build();
let app /* : PokemonService&lt;Route&lt;B&gt;&gt; */ = PokemonService::builder(config)
    .get_pokemon_species(handler)
    /* ... */
    .build()
    .unwrap();
<span class="boring">let app: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = app;
</span><span class="boring">}</span></code></pre></pre>
<p>The custom <code>print</code> method hides the details of the <code>Plugin</code> trait from the average consumer.
They interact with the utility methods on <code>HttpPlugins</code> and enjoy the self-contained documentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="instrumentation"><a class="header" href="#instrumentation">Instrumentation</a></h1>
<p>A Smithy Rust server uses the <a href="https://github.com/tokio-rs/tracing"><code>tracing</code></a> crate to provide instrumentation. The customer is responsible for setting up a <a href="https://docs.rs/tracing/latest/tracing/subscriber/trait.Subscriber.html"><code>Subscriber</code></a> in order to ingest and process <a href="https://docs.rs/tracing/latest/tracing/struct.Event.html">events</a> - Smithy Rust makes no prescription on the choice of <code>Subscriber</code>. Common choices might include:</p>
<ul>
<li><a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/index.html"><code>tracing_subscriber::fmt</code></a> for printing to <code>stdout</code>.</li>
<li><a href="https://crates.io/crates/tracing-log"><code>tracing-log</code></a> to providing compatibility with the <a href="https://crates.io/crates/log"><code>log</code></a>.</li>
</ul>
<p>Events are emitted and <a href="https://docs.rs/tracing/latest/tracing/struct.Span.html">spans</a> are opened by the <code>aws-smithy-http-server</code>, <code>aws-smithy-http-server-python</code>, and generated crate. The <a href="https://docs.rs/tracing/latest/tracing/struct.Metadata.html">default</a> <a href="https://docs.rs/tracing/latest/tracing/struct.Metadata.html#method.target">target</a> is always used</p>
<blockquote>
<p>The tracing macros default to using the module path where the span or event originated as the target, but it may be overridden.</p>
</blockquote>
<p>and therefore spans and events be filtered using the <a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html"><code>EnvFilter</code></a> and/or <a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/targets/struct.Targets.html"><code>Targets</code></a> filters with crate and module paths.</p>
<p>For example,</p>
<pre><code class="language-bash">RUST_LOG=aws_smithy_http_server=warn,aws_smithy_http_server_python=error
</code></pre>
<p>and</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate tracing_subscriber;
</span><span class="boring">extern crate tracing;
</span><span class="boring">use tracing_subscriber::filter;
</span><span class="boring">use tracing::Level;
</span>let filter = filter::Targets::new().with_target("aws_smithy_http_server", Level::DEBUG);
<span class="boring">}</span></code></pre></pre>
<p>In general, Smithy Rust is conservative when using high-priority log levels:</p>
<ul>
<li>ERROR
<ul>
<li>Fatal errors, resulting in the termination of the service.</li>
<li>Requires immediate remediation.</li>
</ul>
</li>
<li>WARN
<ul>
<li>Non-fatal errors, resulting in incomplete operation.</li>
<li>Indicates service misconfiguration, transient errors, or future changes in behavior.</li>
<li>Requires inspection and remediation.</li>
</ul>
</li>
<li>INFO
<ul>
<li>Informative events, which occur inside normal operating limits.</li>
<li>Used for large state transitions, e.g. startup/shutdown.</li>
</ul>
</li>
<li>DEBUG
<ul>
<li>Informative and sparse events, which occur inside normal operating limits.</li>
<li>Used to debug coarse-grained progress of service.</li>
</ul>
</li>
<li>TRACE
<ul>
<li>Informative and frequent events, which occur inside normal operating limits.</li>
<li>Used to debug fine-grained progress of service.</li>
</ul>
</li>
</ul>
<h2 id="spans-over-the-requestresponse-lifecycle"><a class="header" href="#spans-over-the-requestresponse-lifecycle">Spans over the Request/Response lifecycle</a></h2>
<p>Smithy Rust is built on top of <a href="https://github.com/tower-rs/tower"><code>tower</code></a>, which means that middleware can be used to encompass different periods of the lifecycle of the request and response and identify them with a span.</p>
<p>An open-source example of such a middleware is <a href="https://docs.rs/tower-http/latest/tower_http/trace/struct.TraceLayer.html"><code>TraceLayer</code></a> provided by the <a href="https://docs.rs/tower-http/latest/tower_http/"><code>tower-http</code></a> crate.</p>
<p>Smithy provides an out-the-box middleware which:</p>
<ul>
<li>Opens a DEBUG level span, prior to request handling, including the operation name and request URI and headers.</li>
<li>Emits a DEBUG level event, after to request handling, including the response headers and status code.</li>
</ul>
<p>This is enabled via the <code>instrument</code> method provided by the <code>aws_smithy_http_server::instrumentation::InstrumentExt</code> trait.</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">use pokemon_service_server_sdk::{operation_shape::GetPokemonSpecies, input::*, output::*, error::*};
</span><span class="boring">let handler = |req: GetPokemonSpeciesInput| async { Result::&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;::Ok(todo!()) };
</span>use aws_smithy_http_server::{
  instrumentation::InstrumentExt,
  plugin::{IdentityPlugin, HttpPlugins}
};
<span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span>use pokemon_service_server_sdk::{PokemonServiceConfig, PokemonService};

let http_plugins = HttpPlugins::new().instrument();
let config = PokemonServiceConfig::builder().http_plugin(http_plugins).build();
let app = PokemonService::builder(config)
  .get_pokemon_species(handler)
  /* ... */
  .build()
  .unwrap();
<span class="boring">let app: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = app;
</span><span class="boring">}</span></code></pre></pre>
<!-- TODO: Link to it when the logging module is no longer `#[doc(hidden)]` -->
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<p>The Pokémon service example, located at <code>/examples/pokemon-service</code>, sets up a <code>tracing</code> <code>Subscriber</code> as follows:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate tracing_subscriber;
</span>use tracing_subscriber::{prelude::*, EnvFilter};

/// Setup `tracing::subscriber` to read the log level from RUST_LOG environment variable.
pub fn setup_tracing() {
    let format = tracing_subscriber::fmt::layer().pretty();
    let filter = EnvFilter::try_from_default_env()
        .or_else(|_| EnvFilter::try_new("info"))
        .unwrap();
    tracing_subscriber::registry().with(format).with(filter).init();
}
<span class="boring">}</span></code></pre></pre>
<p>Running the Pokémon service example using</p>
<pre><code class="language-bash">RUST_LOG=aws_smithy_http_server=debug,pokemon_service=debug cargo r
</code></pre>
<p>and then using <code>cargo t</code> to run integration tests against the server, yields the following logs:</p>
<pre><code class="language-text">  2022-09-27T09:13:35.372517Z DEBUG aws_smithy_http_server::instrumentation::service: response, headers: {"content-type": "application/json", "content-length": "17"}, status_code: 200 OK
    at /smithy-rs/rust-runtime/aws-smithy-http-server/src/logging/service.rs:47
    in aws_smithy_http_server::instrumentation::service::request with operation: get_server_statistics, method: GET, uri: /stats, headers: {"host": "localhost:13734"}

  2022-09-27T09:13:35.374104Z DEBUG pokemon_service: attempting to authenticate storage user
    at pokemon-service/src/lib.rs:184
    in aws_smithy_http_server::instrumentation::service::request with operation: get_storage, method: GET, uri: /pokedex/{redacted}, headers: {"passcode": "{redacted}", "host": "localhost:13734"}

  2022-09-27T09:13:35.374152Z DEBUG pokemon_service: authentication failed
    at pokemon-service/src/lib.rs:188
    in aws_smithy_http_server::instrumentation::service::request with operation: get_storage, method: GET, uri: /pokedex/{redacted}, headers: {"passcode": "{redacted}", "host": "localhost:13734"}

  2022-09-27T09:13:35.374230Z DEBUG aws_smithy_http_server::instrumentation::service: response, headers: {"content-type": "application/json", "x-amzn-errortype": "NotAuthorized", "content-length": "2"}, status_code: 401 Unauthorized
    at /smithy-rs/rust-runtime/aws-smithy-http-server/src/logging/service.rs:47
    in aws_smithy_http_server::instrumentation::service::request with operation: get_storage, method: GET, uri: /pokedex/{redacted}, headers: {"passcode": "{redacted}", "host": "localhost:13734"}
</code></pre>
<h2 id="interactions-with-sensitivity"><a class="header" href="#interactions-with-sensitivity">Interactions with Sensitivity</a></h2>
<p>Instrumentation interacts with Smithy's <a href="https://awslabs.github.io/smithy/2.0/spec/documentation-traits.html#sensitive-trait">sensitive trait</a>.</p>
<blockquote>
<p>Sensitive data MUST NOT be exposed in things like exception messages or log output. Application of this trait SHOULD NOT affect wire logging (i.e., logging of all data transmitted to and from servers or clients).</p>
</blockquote>
<p>For this reason, Smithy runtime will never use <code>tracing</code> to emit events or open spans that include any sensitive data. This means that the customer can ingest all logs from <code>aws-smithy-http-server</code> and <code>aws-smithy-http-server-*</code> without fear of violating the sensitive trait.</p>
<p>The Smithy runtime will not, and cannot, prevent the customer violating the sensitive trait within the operation handlers and custom middleware. It is the responsibility of the customer to not violate the sensitive contract of their own model, care must be taken.</p>
<p>Smithy shapes can be sensitive while being coupled to the HTTP request/responses via the <a href="https://awslabs.github.io/smithy/2.0/spec/http-bindings.html">HTTP binding traits</a>. This poses a risk when ingesting events which naively capture request/response information. The instrumentation middleware provided by Smithy Rust respects the sensitive trait and will replace sensitive data in its span and event with <code>{redacted}</code>. This feature can be seen in the <a href="server/instrumentation.html#example">Example</a> above. For debugging purposes these redactions can be prevented using the <code>aws-smithy-http-server</code> feature flag, <code>unredacted-logging</code>.</p>
<p>Some examples of inadvertently leaking sensitive information:</p>
<ul>
<li>Ingesting tracing events and spans from third-party crates which do not respect sensitivity.
<ul>
<li>An concrete example of this would be enabling events from <code>hyper</code> or <code>tokio</code>.</li>
</ul>
</li>
<li>Applying middleware which ingests events including HTTP payloads or any other part of the HTTP request/response which can be bound.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="accessing-un-modelled-data"><a class="header" href="#accessing-un-modelled-data">Accessing Un-modelled Data</a></h1>
<p>For every <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#operation">Smithy Operation</a> an input, output, and optional error are specified. This in turn constrains the function signature of the handler provided to the service builder - the input to the handler must be the input specified by the operation etc.</p>
<p>But what if we, the customer, want to access data in the handler which is <em>not</em> modelled by our Smithy model? Smithy Rust provides an escape hatch in the form of the <code>FromParts</code> trait. In <a href="https://docs.rs/axum/latest/axum/index.html"><code>axum</code></a> these are referred to as <a href="https://docs.rs/axum/latest/axum/extract/index.html">"extractors"</a>.</p>
<!-- TODO(IntoParts): Dually, what if we want to return data from the handler which is _not_ modelled by our Smithy model? -->
<pre><code class="language-rust ignore">/// Provides a protocol aware extraction from a [`Request`]. This borrows the
/// [`Parts`], in contrast to [`FromRequest`].
pub trait FromParts&lt;Protocol&gt;: Sized {
    /// The type of the failures yielded extraction attempts.
    type Rejection: IntoResponse&lt;Protocol&gt;;

    /// Extracts `self` from a [`Parts`] synchronously.
    fn from_parts(parts: &amp;mut Parts) -&gt; Result&lt;Self, Self::Rejection&gt;;
}</code></pre>
<p>Here <a href="https://docs.rs/http/latest/http/request/struct.Parts.html"><code>Parts</code></a> is the struct containing all items in a <a href="https://docs.rs/http/latest/http/request/struct.Request.html"><code>http::Request</code></a> except for the HTTP body.</p>
<p>A prolific example of a <code>FromParts</code> implementation is <code>Extension&lt;T&gt;</code>:</p>
<pre><code class="language-rust ignore">/// Generic extension type stored in and extracted from [request extensions].
///
/// This is commonly used to share state across handlers.
///
/// If the extension is missing it will reject the request with a `500 Internal
/// Server Error` response.
///
/// [request extensions]: https://docs.rs/http/latest/http/struct.Extensions.html
#[derive(Debug, Clone)]
pub struct Extension&lt;T&gt;(pub T);

/// The extension has not been added to the [`Request`](http::Request) or has been previously removed.
#[derive(Debug, Error)]
#[error("the `Extension` is not present in the `http::Request`")]
pub struct MissingExtension;

impl&lt;Protocol&gt; IntoResponse&lt;Protocol&gt; for MissingExtension {
    fn into_response(self) -&gt; http::Response&lt;BoxBody&gt; {
        let mut response = http::Response::new(empty());
        *response.status_mut() = StatusCode::INTERNAL_SERVER_ERROR;
        response
    }
}

impl&lt;Protocol, T&gt; FromParts&lt;Protocol&gt; for Extension&lt;T&gt;
where
    T: Send + Sync + 'static,
{
    type Rejection = MissingExtension;

    fn from_parts(parts: &amp;mut http::request::Parts) -&gt; Result&lt;Self, Self::Rejection&gt; {
        parts.extensions.remove::&lt;T&gt;().map(Extension).ok_or(MissingExtension)
    }
}</code></pre>
<p>This allows the service builder to accept the following handler</p>
<pre><code class="language-rust ignore">async fn handler(input: ModelInput, extension: Extension&lt;SomeStruct&gt;) -&gt; ModelOutput {
    /* ... */
}</code></pre>
<p>where <code>ModelInput</code> and <code>ModelOutput</code> are specified by the Smithy Operation and <code>SomeStruct</code> is a struct which has been inserted, by middleware, into the <a href="https://docs.rs/http/latest/http/request/struct.Request.html#method.extensions"><code>http::Request::extensions</code></a>.</p>
<p>Up to 32 structures implementing <code>FromParts</code> can be provided to the handler with the constraint that they <em>must</em> be provided <em>after</em> the <code>ModelInput</code>:</p>
<pre><code class="language-rust ignore">async fn handler(input: ModelInput, ext1: Extension&lt;SomeStruct1&gt;, ext2: Extension&lt;SomeStruct2&gt;, other: Other /* : FromParts */, /* ... */) -&gt; ModelOutput {
    /* ... */
}</code></pre>
<p>Note that the <code>parts.extensions.remove::&lt;T&gt;()</code> in <code>Extensions::from_parts</code> will cause multiple <code>Extension&lt;SomeStruct&gt;</code> arguments in the handler to fail. The first extraction failure to occur is serialized via the <code>IntoResponse</code> trait (notice <code>type Error: IntoResponse&lt;Protocol&gt;</code>) and returned.</p>
<p>The <code>FromParts</code> trait is public so customers have the ability specify their own implementations:</p>
<pre><code class="language-rust ignore">struct CustomerDefined {
    /* ... */
}

impl&lt;P&gt; FromParts&lt;P&gt; for CustomerDefined {
    type Error = /* ... */;

    fn from_parts(parts: &amp;mut Parts) -&gt; Result&lt;Self, Self::Error&gt; {
        // Construct `CustomerDefined` using the request headers.
        let header_value = parts.headers.get("header-name").ok_or(/* ... */)?;
        Ok(CustomerDefined { /* ... */ })
    }
}

async fn handler(input: ModelInput, arg: CustomerDefined) -&gt; ModelOutput {
    /* ... */
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-anatomy-of-a-service"><a class="header" href="#the-anatomy-of-a-service">The Anatomy of a Service</a></h1>
<p>What is <a href="https://awslabs.github.io/smithy/2.0/index.html">Smithy</a>? At a high-level, it's a grammar for specifying services while leaving the business logic undefined. A <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#service">Smithy Service</a> specifies a collection of function signatures in the form of <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#operation">Operations</a>, their purpose is to encapsulate business logic. A Smithy implementation should, for each Smithy Service, provide a builder, which accepts functions conforming to said signatures, and returns a service subject to the semantics specified by the model.</p>
<p>This survey is disinterested in the actual Kotlin implementation of the code generator, and instead focuses on the structure of the generated Rust code and how it relates to the Smithy model. The intended audience is new contributors and users interested in internal details.</p>
<p>During the survey we will use the <a href="https://github.com/smithy-lang/smithy-rs/blob/main/codegen-core/common-test-models/pokemon.smithy"><code>pokemon.smithy</code></a> model as a reference:</p>
<pre><code class="language-smithy">/// A Pokémon species forms the basis for at least one Pokémon.
@title("Pokémon Species")
resource PokemonSpecies {
    identifiers: {
        name: String
    },
    read: GetPokemonSpecies,
}

/// A users current Pokémon storage.
resource Storage {
    identifiers: {
        user: String
    },
    read: GetStorage,
}

/// The Pokémon Service allows you to retrieve information about Pokémon species.
@title("Pokémon Service")
@restJson1
service PokemonService {
    version: "2021-12-01",
    resources: [PokemonSpecies, Storage],
    operations: [
        GetServerStatistics,
        DoNothing,
        CapturePokemon,
        CheckHealth
    ],
}
</code></pre>
<p>Smithy Rust will use this model to produce the following API:</p>
<pre><pre class="playground"><code class="language-rust no_run edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::protocol::rest_json_1::{RestJson1, router::RestRouter};
</span><span class="boring">use aws_smithy_http_server::routing::{Route, RoutingService};
</span><span class="boring">use pokemon_service_server_sdk::{input::*, output::*, error::*, operation_shape::*, PokemonServiceConfig, PokemonService};
</span>// A handler for the `GetPokemonSpecies` operation (the `PokemonSpecies` resource).
async fn get_pokemon_species(input: GetPokemonSpeciesInput) -&gt; Result&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt; {
    todo!()
}

let config = PokemonServiceConfig::builder().build();

// Use the service builder to create `PokemonService`.
let pokemon_service = PokemonService::builder(config)
    // Pass the handler directly to the service builder...
    .get_pokemon_species(get_pokemon_species)
    /* other operation setters */
    .build()
    .expect("failed to create an instance of the Pokémon service");
<span class="boring">let pokemon_service: PokemonService&lt;RoutingService&lt;RestRouter&lt;Route&gt;, RestJson1&gt;&gt;  = pokemon_service;
</span><span class="boring">}</span></code></pre></pre>
<h2 id="operations"><a class="header" href="#operations">Operations</a></h2>
<p>A <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#operation">Smithy Operation</a> specifies the input, output, and possible errors of an API operation. One might characterize a Smithy Operation as syntax for specifying a function type.</p>
<p>We represent this in Rust using the <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/operation/trait.OperationShape.html"><code>OperationShape</code></a> trait:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::shape_id::ShapeId;
</span>pub trait OperationShape {
    /// The name of the operation.
    const ID: ShapeId;

    /// The operation input.
    type Input;
    /// The operation output.
    type Output;
    /// The operation error. [`Infallible`](std::convert::Infallible) in the case where no error
    /// exists.
    type Error;
}
<span class="boring">use aws_smithy_http_server::operation::OperationShape as OpS;
</span><span class="boring">impl&lt;T: OpS&gt; OperationShape for T {
</span><span class="boring">  const ID: ShapeId = &lt;T as OpS&gt;::ID;
</span><span class="boring">  type Input = &lt;T as OpS&gt;::Input;
</span><span class="boring">  type Output = &lt;T as OpS&gt;::Output;
</span><span class="boring">  type Error = &lt;T as OpS&gt;::Error;
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>For each Smithy Operation shape,</p>
<pre><code class="language-smithy">/// Retrieve information about a Pokémon species.
@readonly
@http(uri: "/pokemon-species/{name}", method: "GET")
operation GetPokemonSpecies {
    input: GetPokemonSpeciesInput,
    output: GetPokemonSpeciesOutput,
    errors: [ResourceNotFoundException],
}
</code></pre>
<p>the following implementation is generated</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::{operation::OperationShape, shape_id::ShapeId};
</span><span class="boring">use pokemon_service_server_sdk::{input::*, output::*, error::*};
</span>/// Retrieve information about a Pokémon species.
pub struct GetPokemonSpecies;

impl OperationShape for GetPokemonSpecies {
    const ID: ShapeId = ShapeId::new("com.aws.example#GetPokemonSpecies", "com.aws.example", "GetPokemonSpecies");

    type Input = GetPokemonSpeciesInput;
    type Output = GetPokemonSpeciesOutput;
    type Error = GetPokemonSpeciesError;
}
<span class="boring">}</span></code></pre></pre>
<p>where <code>GetPokemonSpeciesInput</code>, <code>GetPokemonSpeciesOutput</code> are both generated from the Smithy structures and <code>GetPokemonSpeciesError</code> is an enum generated from the <code>errors: [ResourceNotFoundException]</code>.</p>
<p>Note that the <code>GetPokemonSpecies</code> marker structure is a zero-sized type (ZST), and therefore does not exist at runtime - it is a way to attach operation-specific data on an entity within the type system.</p>
<p>The following nomenclature will aid us in our survey. We describe a <code>tower::Service</code> as a "model service" if its request and response are Smithy structures, as defined by the <code>OperationShape</code> trait - the <code>GetPokemonSpeciesInput</code>, <code>GetPokemonSpeciesOutput</code>, and <code>GetPokemonSpeciesError</code> described above. Similarly, we describe a <code>tower::Service</code> as a "HTTP service" if its request and response are <a href="https://github.com/hyperium/http"><code>http</code></a> structures - <code>http::Request</code> and <code>http::Response</code>.</p>
<p>The constructors exist on the marker ZSTs as an extension trait to <code>OperationShape</code>, namely <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/operation/trait.OperationShapeExt.html"><code>OperationShapeExt</code></a>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::operation::*;
</span>/// An extension trait over [`OperationShape`].
pub trait OperationShapeExt: OperationShape {
    /// Creates a new [`Service`] for well-formed [`Handler`]s.
    fn from_handler&lt;H, Exts&gt;(handler: H) -&gt; IntoService&lt;Self, H&gt;
    where
        H: Handler&lt;Self, Exts&gt;,
        Self: Sized;

    /// Creates a new [`Service`] for well-formed [`Service`](tower::Service)s.
    fn from_service&lt;S, Exts&gt;(svc: S) -&gt; Normalize&lt;Self, S&gt;
    where
        S: OperationService&lt;Self, Exts&gt;,
        Self: Sized;
}
<span class="boring">use aws_smithy_http_server::operation::OperationShapeExt as OpS;
</span><span class="boring">impl&lt;T: OpS&gt; OperationShapeExt for T {
</span><span class="boring">  fn from_handler&lt;H, Exts&gt;(handler: H) -&gt; IntoService&lt;Self, H&gt; where H: Handler&lt;Self, Exts&gt;, Self: Sized { &lt;T as OpS&gt;::from_handler(handler) }
</span><span class="boring">  fn from_service&lt;S, Exts&gt;(svc: S) -&gt; Normalize&lt;Self, S&gt; where S: OperationService&lt;Self, Exts&gt;, Self: Sized { &lt;T as OpS&gt;::from_service(svc) }
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>Observe that there are two constructors provided: <code>from_handler</code> which takes a <code>H: Handler</code> and <code>from_service</code> which takes a <code>S: OperationService</code>. In both cases <code>Self</code> is passed as a parameter to the traits - this constrains <code>handler: H</code> and <code>svc: S</code> to the signature given by the implementation of <code>OperationShape</code> on <code>Self</code>.</p>
<p>The <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/operation/trait.Handler.html"><code>Handler</code></a> and <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/operation/trait.OperationService.html"><code>OperationService</code></a> both serve a similar purpose - they provide a common interface for converting to a model service <code>S</code>.</p>
<ul>
<li>The <code>Handler&lt;GetPokemonSpecies&gt;</code> trait covers all async functions taking <code>GetPokemonSpeciesInput</code> and asynchronously returning a <code>Result&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt;</code>.</li>
<li>The <code>OperationService&lt;GetPokemonSpecies&gt;</code> trait covers all <code>tower::Service</code>s with request <code>GetPokemonSpeciesInput</code>, response <code>GetPokemonSpeciesOutput</code> and error <code>GetPokemonSpeciesOutput</code>.</li>
</ul>
<p>The <code>from_handler</code> constructor is used in the following way:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span>use pokemon_service_server_sdk::{
    input::GetPokemonSpeciesInput,
    output::GetPokemonSpeciesOutput,
    error::GetPokemonSpeciesError,
    operation_shape::GetPokemonSpecies
};
use aws_smithy_http_server::operation::OperationShapeExt;

async fn get_pokemon_service(input: GetPokemonSpeciesInput) -&gt; Result&lt;GetPokemonSpeciesOutput, GetPokemonSpeciesError&gt; {
    todo!()
}

let operation = GetPokemonSpecies::from_handler(get_pokemon_service);
<span class="boring">}</span></code></pre></pre>
<p>Alternatively, <code>from_service</code> constructor:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate pokemon_service_server_sdk;
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate tower;
</span>use pokemon_service_server_sdk::{
    input::GetPokemonSpeciesInput,
    output::GetPokemonSpeciesOutput,
    error::GetPokemonSpeciesError,
    operation_shape::GetPokemonSpecies
};
use aws_smithy_http_server::operation::OperationShapeExt;
use std::task::{Context, Poll};
use tower::Service;

struct Svc {
    /* ... */
}

impl Service&lt;GetPokemonSpeciesInput&gt; for Svc {
    type Response = GetPokemonSpeciesOutput;
    type Error = GetPokemonSpeciesError;
    type Future = /* Future&lt;Output = Result&lt;Self::Response, Self::Error&gt;&gt; */
<span class="boring">    std::future::Ready&lt;Result&lt;Self::Response, Self::Error&gt;&gt;;
</span>
    fn poll_ready(&amp;mut self, ctx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        todo!()
    }

    fn call(&amp;mut self, input: GetPokemonSpeciesInput) -&gt; Self::Future {
        todo!()
    }
}

let svc: Svc = Svc { /* ... */ };
let operation = GetPokemonSpecies::from_service(svc);
<span class="boring">}</span></code></pre></pre>
<p>To summarize a <em>model service</em> constructed can be constructed from a <code>Handler</code> or a <code>OperationService</code> subject to the constraints of an <code>OperationShape</code>. More detailed information on these conversions is provided in the <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/operation/index.html">Handler and OperationService section</a> Rust docs.</p>
<h2 id="serialization-and-deserialization"><a class="header" href="#serialization-and-deserialization">Serialization and Deserialization</a></h2>
<p>A <a href="https://awslabs.github.io/smithy/2.0/spec/protocol-traits.html#serialization-and-protocol-traits">Smithy protocol</a> specifies the serialization/deserialization scheme - how a HTTP request is transformed into a modelled input and a modelled output to a HTTP response. The is formalized using the <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/request/trait.FromRequest.html"><code>FromRequest</code></a> and <a href="https://github.com/smithy-lang/smithy-rs/blob/4c5cbc39384f0d949d7693eb87b5853fe72629cd/rust-runtime/aws-smithy-http-server/src/response.rs#L40-L44"><code>IntoResponse</code></a> traits:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate http;
</span><span class="boring">use aws_smithy_http_server::body::BoxBody;
</span><span class="boring">use std::future::Future;
</span>/// Provides a protocol aware extraction from a [`Request`]. This consumes the
/// [`Request`], in contrast to [`FromParts`].
pub trait FromRequest&lt;Protocol, B&gt;: Sized {
    type Rejection: IntoResponse&lt;Protocol&gt;;
    type Future: Future&lt;Output = Result&lt;Self, Self::Rejection&gt;&gt;;

    /// Extracts `self` from a [`Request`] asynchronously.
    fn from_request(request: http::Request&lt;B&gt;) -&gt; Self::Future;
}

/// A protocol aware function taking `self` to [`http::Response`].
pub trait IntoResponse&lt;Protocol&gt; {
    /// Performs a conversion into a [`http::Response`].
    fn into_response(self) -&gt; http::Response&lt;BoxBody&gt;;
}
<span class="boring">use aws_smithy_http_server::request::FromRequest as FR;
</span><span class="boring">impl&lt;P, B, T: FR&lt;P, B&gt;&gt; FromRequest&lt;P, B&gt; for T {
</span><span class="boring">  type Rejection = &lt;T as FR&lt;P, B&gt;&gt;::Rejection;
</span><span class="boring">  type Future = &lt;T as FR&lt;P, B&gt;&gt;::Future;
</span><span class="boring">  fn from_request(request: http::Request&lt;B&gt;) -&gt; Self::Future {
</span><span class="boring">      &lt;T as FR&lt;P, B&gt;&gt;::from_request(request)
</span><span class="boring">  }
</span><span class="boring">}
</span><span class="boring">use aws_smithy_http_server::response::IntoResponse as IR;
</span><span class="boring">impl&lt;P, T: IR&lt;P&gt;&gt; IntoResponse&lt;P&gt; for T {
</span><span class="boring">  fn into_response(self) -&gt; http::Response&lt;BoxBody&gt; { &lt;T as IR&lt;P&gt;&gt;::into_response(self) }
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>Note that both traits are parameterized by <code>Protocol</code>. These <a href="https://awslabs.github.io/smithy/2.0/aws/protocols/index.html">protocols</a> exist as ZST marker structs:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::protocol::{
</span><span class="boring">  aws_json_10::AwsJson1_0 as _,
</span><span class="boring">  aws_json_11::AwsJson1_1 as _,
</span><span class="boring">  rest_json_1::RestJson1 as _,
</span><span class="boring">  rest_xml::RestXml as _,
</span><span class="boring">};
</span>/// [AWS REST JSON 1.0 Protocol](https://awslabs.github.io/smithy/2.0/aws/protocols/aws-restjson1-protocol.html).
pub struct RestJson1;

/// [AWS REST XML Protocol](https://awslabs.github.io/smithy/2.0/aws/protocols/aws-restxml-protocol.html).
pub struct RestXml;

/// [AWS JSON 1.0 Protocol](https://awslabs.github.io/smithy/2.0/aws/protocols/aws-json-1_0-protocol.html).
pub struct AwsJson1_0;

/// [AWS JSON 1.1 Protocol](https://awslabs.github.io/smithy/2.0/aws/protocols/aws-json-1_1-protocol.html).
pub struct AwsJson1_1;
<span class="boring">}</span></code></pre></pre>
<h2 id="upgrading-a-model-service"><a class="header" href="#upgrading-a-model-service">Upgrading a Model Service</a></h2>
<p>We can "upgrade" a model service to a HTTP service using <code>FromRequest</code> and <code>IntoResponse</code> described in the prior section:</p>
<pre class="mermaid">stateDiagram-v2
    direction LR
    HttpService: HTTP Service
    [*] --&gt; from_request: HTTP Request
    state HttpService {
        direction LR
        ModelService: Model Service
        from_request --&gt; ModelService: Model Input
        ModelService --&gt; into_response: Model Output
    }
    into_response --&gt; [*]: HTTP Response
</pre>
<p>This is formalized by the <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/operation/struct.Upgrade.html"><code>Upgrade&lt;Protocol, Op, S&gt;</code></a> HTTP service. The <code>tower::Service</code> implementation is approximately:</p>
<pre><code class="language-rust ignore">impl&lt;P, Op, S&gt; Service&lt;http::Request&gt; for Upgrade&lt;P, Op, S&gt;
where
    Input: FromRequest&lt;P, B&gt;,
    S: Service&lt;Input&gt;,
    S::Response: IntoResponse&lt;P&gt;,
    S::Error: IntoResponse&lt;P&gt;,
{
    async fn call(&amp;mut self, request: http::Request) -&gt; http::Response {
        let model_request = match &lt;Op::Input as OperationShape&gt;::from_request(request).await {
            Ok(ok) =&gt; ok,
            Err(err) =&gt; return err.into_response()
        };
        let model_response = self.model_service.call(model_request).await;
        model_response.into_response()
    }
}</code></pre>
<p>When we <code>GetPokemonSpecies::from_handler</code> or <code>GetPokemonSpecies::from_service</code>, the model service produced, <code>S</code>, will meet the constraints above.</p>
<p>There is an associated <code>Plugin</code>, <code>UpgradePlugin</code> which constructs <code>Upgrade</code> from a service.</p>
<p>The upgrade procedure is finalized by the application of the <code>Layer</code> <code>L</code>, referenced in <code>Operation&lt;S, L&gt;</code>. In this way the entire upgrade procedure takes an <code>Operation&lt;S, L&gt;</code> and returns a HTTP service.</p>
<pre class="mermaid">stateDiagram-v2
    direction LR
    [*] --&gt; UpgradePlugin: HTTP Request
    state HttpPlugin {
        state UpgradePlugin {
            direction LR
            [*] --&gt; S: Model Input
            S --&gt; [*] : Model Output
            state ModelPlugin {
                S
            }
        }
    }
    UpgradePlugin --&gt; [*]: HTTP Response
</pre>
<p>Note that the <code>S</code> is specified by logic written, in Rust, by the customer, whereas <code>UpgradePlugin</code> is specified entirely by Smithy model via the protocol, <a href="https://awslabs.github.io/smithy/2.0/spec/http-bindings.html">HTTP bindings</a>, etc.</p>
<h2 id="routers"><a class="header" href="#routers">Routers</a></h2>
<p>Different protocols supported by Smithy enjoy different routing mechanisms, for example, <a href="https://awslabs.github.io/smithy/2.0/aws/protocols/aws-json-1_0-protocol.html#protocol-behaviors">AWS JSON 1.0</a> uses the <code>X-Amz-Target</code> header to select an operation, whereas <a href="https://awslabs.github.io/smithy/2.0/aws/protocols/aws-restxml-protocol.html">AWS REST XML</a> uses the <a href="https://awslabs.github.io/smithy/2.0/spec/http-bindings.html#httplabel-trait">HTTP label trait</a>.</p>
<p>Despite their differences, all routing mechanisms satisfy a common interface. This is formalized using the <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/routing/trait.Router.html">Router</a> trait:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate http;
</span>/// An interface for retrieving an inner [`Service`] given a [`http::Request`].
pub trait Router&lt;B&gt; {
    type Service;
    type Error;

    /// Matches a [`http::Request`] to a target [`Service`].
    fn match_route(&amp;self, request: &amp;http::Request&lt;B&gt;) -&gt; Result&lt;Self::Service, Self::Error&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>which provides the ability to determine an inner HTTP service from a collection using a <code>&amp;http::Request</code>.</p>
<p>Types which implement the <code>Router</code> trait are converted to a HTTP service via the <code>RoutingService</code> struct:</p>
<pre><code class="language-rust ignore">/// A [`Service`] using a [`Router`] `R` to redirect messages to specific routes.
///
/// The `Protocol` parameter is used to determine the serialization of errors.
pub struct RoutingService&lt;R, Protocol&gt; {
    router: R,
    _protocol: PhantomData&lt;Protocol&gt;,
}

impl&lt;R, P&gt; Service&lt;http::Request&gt; for RoutingService&lt;R, P&gt;
where
    R: Router&lt;B&gt;,
    R::Service: Service&lt;http::Request, Response = http::Response&gt;,
    R::Error: IntoResponse&lt;P&gt; + Error,
{
    type Response = http::Response;
    type Error = /* implementation detail */;

    async fn call(&amp;mut self, req: http::Request&lt;B&gt;) -&gt; Result&lt;Self::Response, Self::Error&gt; {
        match self.router.match_route(&amp;req) {
            // Successfully routed, use the routes `Service::call`.
            Ok(ok) =&gt; ok.oneshot(req).await,
            // Failed to route, use the `R::Error`s `IntoResponse&lt;P&gt;`.
            Err(error) =&gt; {
                debug!(%error, "failed to route");
                Err(Box::new(error.into_response()))
            }
        }
    }
}</code></pre>
<p>The <code>RouterService</code> is the final piece necessary to form a functioning composition - it is used to aggregate together the HTTP services, created via the upgrade procedure, into a single HTTP service which can be presented to the customer.</p>
<pre class="mermaid">stateDiagram
state in &lt;&lt;fork&gt;&gt;
    direction LR
    [*] --&gt; in
    state RouterService {
        direction LR
        in --&gt;  ServiceA
        in --&gt; ServiceB
        in --&gt; ServiceC
    }
    ServiceA --&gt; [*]
    ServiceB --&gt; [*]
    ServiceC --&gt; [*]
</pre>
<h2 id="plugins"><a class="header" href="#plugins">Plugins</a></h2>
<!-- TODO(missing_doc): Link to "Write a Plugin" documentation -->
<p>A <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/plugin/trait.Plugin.html"><code>Plugin</code></a> is a
[<code>tower::Layer</code>] with two extra type parameters, <code>Service</code> and <code>Operation</code>, corresponding to <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#service">Smithy Service</a> and <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#operation">Smithy Operation</a>. This allows the middleware to be
parameterized them and change behavior depending on the context in which it's applied.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span>pub trait Plugin&lt;Service, Operation, T&gt; {
    type Output;

    fn apply(&amp;self, input: T) -&gt; Self::Output;
}
<span class="boring">use aws_smithy_http_server::plugin::Plugin as Pl;
</span><span class="boring">impl&lt;Ser, Op, T, U: Pl&lt;Ser, Op, T&gt;&gt; Plugin&lt;Ser, Op, T&gt; for U {
</span><span class="boring">  type Output = &lt;U as Pl&lt;Ser, Op, T&gt;&gt;::Output;
</span><span class="boring">  fn apply(&amp;self, input: T) -&gt; Self::Output { &lt;U as Pl&lt;Ser, Op, T&gt;&gt;::apply(self, input) }
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>An example <code>Plugin</code> implementation can be found in <a href="https://github.com/smithy-lang/smithy-rs/blob/main/examples/pokemon-service/src/plugin.rs">/examples/pokemon-service/src/plugin.rs</a>.</p>
<p>Plugins can be applied in two places:</p>
<ul>
<li>HTTP plugins, which are applied pre-deserialization/post-serialization, acting on HTTP requests/responses.</li>
<li>Model plugins, which are applied post-deserialization/pre-serialization, acting on model inputs/outputs/errors.</li>
</ul>
<pre class="mermaid">stateDiagram-v2
    direction LR
    [*] --&gt; S: HTTP Request
    state HttpPlugin {
        state UpgradePlugin {
            state ModelPlugin {
                S
            }
        }
    }
    S --&gt; [*]: HTTP Response
</pre>
<p>The service builder API requires plugins to be specified upfront - they must be
registered in the config object, which is passed as an argument to <code>builder</code>.
Plugins cannot be modified afterwards.</p>
<p>You might find yourself wanting to apply <em>multiple</em> plugins to your service.
This can be accommodated via [<code>HttpPlugins</code>] and [<code>ModelPlugins</code>].</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span>use aws_smithy_http_server::plugin::HttpPlugins;
<span class="boring">use aws_smithy_http_server::plugin::IdentityPlugin as LoggingPlugin;
</span><span class="boring">use aws_smithy_http_server::plugin::IdentityPlugin as MetricsPlugin;
</span>
let http_plugins = HttpPlugins::new().push(LoggingPlugin).push(MetricsPlugin);
<span class="boring">}</span></code></pre></pre>
<p>The plugins' runtime logic is executed in registration order.
In the example above, <code>LoggingPlugin</code> would run first, while <code>MetricsPlugin</code> is executed last.</p>
<p>If you are vending a plugin, you can leverage <code>HttpPlugins</code> or <code>ModelPlugins</code> as an extension point: you can add custom methods to it using an extension trait.
For example:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span>use aws_smithy_http_server::plugin::{HttpPlugins, PluginStack};
<span class="boring">use aws_smithy_http_server::plugin::IdentityPlugin as LoggingPlugin;
</span><span class="boring">use aws_smithy_http_server::plugin::IdentityPlugin as AuthPlugin;
</span>
pub trait AuthPluginExt&lt;CurrentPlugins&gt; {
    fn with_auth(self) -&gt; HttpPlugins&lt;PluginStack&lt;AuthPlugin, CurrentPlugins&gt;&gt;;
}

impl&lt;CurrentPlugins&gt; AuthPluginExt&lt;CurrentPlugins&gt; for HttpPlugins&lt;CurrentPlugins&gt; {
    fn with_auth(self) -&gt; HttpPlugins&lt;PluginStack&lt;AuthPlugin, CurrentPlugins&gt;&gt; {
        self.push(AuthPlugin)
    }
}

let http_plugins = HttpPlugins::new()
    .push(LoggingPlugin)
    // Our custom method!
    .with_auth();
<span class="boring">}</span></code></pre></pre>
<h2 id="builders"><a class="header" href="#builders">Builders</a></h2>
<p>The service builder is the primary public API, generated for every <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html">Smithy Service</a>.
At a high-level, the service builder takes as input a function for each Smithy Operation and returns a single HTTP service. The signature of each function, also known as <em>handlers</em>, must match the constraints of the corresponding Smithy model.</p>
<p>You can create an instance of a service builder by calling <code>builder</code> on the corresponding service struct.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::routing::Route;
</span>/// The service builder for [`PokemonService`].
///
/// Constructed via [`PokemonService::builder`].
pub struct PokemonServiceBuilder&lt;Body, HttpPl, ModelPl&gt; {
    capture_pokemon_operation: Option&lt;Route&lt;Body&gt;&gt;,
    empty_operation: Option&lt;Route&lt;Body&gt;&gt;,
    get_pokemon_species: Option&lt;Route&lt;Body&gt;&gt;,
    get_server_statistics: Option&lt;Route&lt;Body&gt;&gt;,
    get_storage: Option&lt;Route&lt;Body&gt;&gt;,
    health_check_operation: Option&lt;Route&lt;Body&gt;&gt;,
    http_plugin: HttpPl,
    model_plugin: ModelPl,
}
<span class="boring">}</span></code></pre></pre>
<p>The builder has two setter methods for each <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#operation">Smithy Operation</a> in the <a href="https://awslabs.github.io/smithy/2.0/spec/service-types.html#service">Smithy Service</a>:</p>
<pre><code class="language-rust ignore">    pub fn get_pokemon_species&lt;HandlerType, HandlerExtractors, UpgradeExtractors&gt;(self, handler: HandlerType) -&gt; Self
    where
        HandlerType:Handler&lt;GetPokemonSpecies, HandlerExtractors&gt;,

        ModelPl: Plugin&lt;
            PokemonService,
            GetPokemonSpecies,
            IntoService&lt;GetPokemonSpecies, HandlerType&gt;
        &gt;,
        UpgradePlugin::&lt;UpgradeExtractors&gt;: Plugin&lt;
            PokemonService,
            GetPokemonSpecies,
            ModelPlugin::Output
        &gt;,
        HttpPl: Plugin&lt;
            PokemonService,
            GetPokemonSpecies,
            UpgradePlugin::&lt;UpgradeExtractors&gt;::Output
        &gt;,
    {
        let svc = GetPokemonSpecies::from_handler(handler);
        let svc = self.model_plugin.apply(svc);
        let svc = UpgradePlugin::&lt;UpgradeExtractors&gt;::new()
            .apply(svc);
        let svc = self.http_plugin.apply(svc);
        self.get_pokemon_species_custom(svc)
    }

    pub fn get_pokemon_species_service&lt;S, ServiceExtractors, UpgradeExtractors&gt;(self, service: S) -&gt; Self
    where
        S: OperationService&lt;GetPokemonSpecies, ServiceExtractors&gt;,

        ModelPl: Plugin&lt;
            PokemonService,
            GetPokemonSpecies,
            Normalize&lt;GetPokemonSpecies, S&gt;
        &gt;,
        UpgradePlugin::&lt;UpgradeExtractors&gt;: Plugin&lt;
            PokemonService,
            GetPokemonSpecies,
            ModelPlugin::Output
        &gt;,
        HttpPl: Plugin&lt;
            PokemonService,
            GetPokemonSpecies,
            UpgradePlugin::&lt;UpgradeExtractors&gt;::Output
        &gt;,
    {
        let svc = GetPokemonSpecies::from_service(service);
        let svc = self.model_plugin.apply(svc);
        let svc = UpgradePlugin::&lt;UpgradeExtractors&gt;::new().apply(svc);
        let svc = self.http_plugin.apply(svc);
        self.get_pokemon_species_custom(svc)
    }

    pub fn get_pokemon_species_custom&lt;S&gt;(mut self, svc: S) -&gt; Self
    where
        S: Service&lt;Request&lt;Body&gt;, Response = Response&lt;BoxBody&gt;, Error = Infallible&gt;,
    {
        self.get_pokemon_species = Some(Route::new(svc));
        self
    }</code></pre>
<p>Handlers and operations are upgraded to a <a href="https://github.com/smithy-lang/smithy-rs/blob/4c5cbc39384f0d949d7693eb87b5853fe72629cd/rust-runtime/aws-smithy-http-server/src/routing/route.rs#L49-L52"><code>Route</code></a> as soon as they are registered against the service builder. You can think of <code>Route</code> as a boxing layer in disguise.</p>
<p>You can transform a builder instance into a complete service (<code>PokemonService</code>) using one of the following methods:</p>
<ul>
<li><code>build</code>. The transformation fails if one or more operations do not have a registered handler;</li>
<li><code>build_unchecked</code>. The transformation never fails, but we return <code>500</code>s for all operations that do not have a registered handler.</li>
</ul>
<p>Both builder methods take care of:</p>
<ol>
<li>Pair each handler with the routing information for the corresponding operation;</li>
<li>Collect all <code>(routing_info, handler)</code> pairs into a <code>Router</code>;</li>
<li>Transform the <code>Router</code> implementation into a HTTP service via <code>RouterService</code>;</li>
<li>Wrap the <code>RouterService</code> in a newtype given by the service name, <code>PokemonService</code>.</li>
</ol>
<p>The final outcome, an instance of <code>PokemonService</code>, looks roughly like this:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">use aws_smithy_http_server::{routing::RoutingService, protocol::rest_json_1::{router::RestRouter, RestJson1}};
</span>/// The Pokémon Service allows you to retrieve information about Pokémon species.
#[derive(Clone)]
pub struct PokemonService&lt;S&gt; {
    router: RoutingService&lt;RestRouter&lt;S&gt;, RestJson1&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The following schematic summarizes the composition:</p>
<pre class="mermaid">stateDiagram-v2
    state in &lt;&lt;fork&gt;&gt;
    state &quot;GetPokemonSpecies&quot; as C1
    state &quot;GetStorage&quot; as C2
    state &quot;DoNothing&quot; as C3
    state &quot;...&quot; as C4
    direction LR
    [*] --&gt; in : HTTP Request
    UpgradePlugin --&gt; [*]: HTTP Response
    state PokemonService {
        state RoutingService {
            in --&gt; UpgradePlugin: HTTP Request
            in --&gt; C2: HTTP Request
            in --&gt; C3: HTTP Request
            in --&gt; C4: HTTP Request
            state C1 {
                state HttpPlugin {
                    state UpgradePlugin {
                        direction LR
                        [*] --&gt; S: Model Input
                        S --&gt; [*] : Model Output
                        state ModelPlugin {
                            S
                        }
                    }
                }
            }
            C2
            C3
            C4
        }

    }
    C2 --&gt; [*]: HTTP Response
    C3 --&gt; [*]: HTTP Response
    C4 --&gt; [*]: HTTP Response
</pre>
<h2 id="accessing-unmodelled-data"><a class="header" href="#accessing-unmodelled-data">Accessing Unmodelled Data</a></h2>
<p>An additional omitted detail is that we provide an "escape hatch" allowing <code>Handler</code>s and <code>OperationService</code>s to accept data that isn't modelled. In addition to accepting <code>Op::Input</code> they can accept additional arguments which implement the <a href="https://docs.rs/aws-smithy-http-server/latest/aws_smithy_http_server/request/trait.FromParts.html"><code>FromParts</code></a> trait:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate http;
</span><span class="boring">use http::request::Parts;
</span><span class="boring">use aws_smithy_http_server::response::IntoResponse;
</span>/// Provides a protocol aware extraction from a [`Request`]. This borrows the
/// [`Parts`], in contrast to [`FromRequest`].
pub trait FromParts&lt;Protocol&gt;: Sized {
    /// The type of the failures yielded extraction attempts.
    type Rejection: IntoResponse&lt;Protocol&gt;;

    /// Extracts `self` from a [`Parts`] synchronously.
    fn from_parts(parts: &amp;mut Parts) -&gt; Result&lt;Self, Self::Rejection&gt;;
}
<span class="boring">use aws_smithy_http_server::request::FromParts as FP;
</span><span class="boring">impl&lt;P, T: FP&lt;P&gt;&gt; FromParts&lt;P&gt; for T {
</span><span class="boring">  type Rejection = &lt;T as FP&lt;P&gt;&gt;::Rejection;
</span><span class="boring">  fn from_parts(parts: &amp;mut Parts) -&gt; Result&lt;Self, Self::Rejection&gt; { &lt;T as FP&lt;P&gt;&gt;::from_parts(parts) }
</span><span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<p>This differs from <code>FromRequest</code> trait, introduced in <a href="server/anatomy.html#serialization-and-deserialization">Serialization and Deserialization</a>, as it's synchronous and has non-consuming access to <a href="https://docs.rs/http/latest/http/request/struct.Parts.html"><code>Parts</code></a>, rather than the entire <a href="https://docs.rs/http/latest/http/request/struct.Request.html">Request</a>.</p>
<pre><code class="language-rust ignore">pub struct Parts {
    pub method: Method,
    pub uri: Uri,
    pub version: Version,
    pub headers: HeaderMap&lt;HeaderValue&gt;,
    pub extensions: Extensions,
    /* private fields */
}</code></pre>
<p>This is commonly used to access types stored within <a href="https://docs.rs/http/0.2.8/http/struct.Extensions.html"><code>Extensions</code></a> which have been inserted by a middleware. An <code>Extension</code> struct implements <code>FromParts</code> to support this use case:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">extern crate aws_smithy_http_server;
</span><span class="boring">extern crate http;
</span><span class="boring">extern crate thiserror;
</span><span class="boring">use aws_smithy_http_server::{body::BoxBody, request::FromParts, response::IntoResponse};
</span><span class="boring">use http::status::StatusCode;
</span><span class="boring">use thiserror::Error;
</span><span class="boring">fn empty() -&gt; BoxBody { todo!() }
</span>/// Generic extension type stored in and extracted from [request extensions].
///
/// This is commonly used to share state across handlers.
///
/// If the extension is missing it will reject the request with a `500 Internal
/// Server Error` response.
///
/// [request extensions]: https://docs.rs/http/latest/http/struct.Extensions.html
#[derive(Debug, Clone)]
pub struct Extension&lt;T&gt;(pub T);

impl&lt;Protocol, T&gt; FromParts&lt;Protocol&gt; for Extension&lt;T&gt;
where
    T: Clone + Send + Sync + 'static,
{
    type Rejection = MissingExtension;

    fn from_parts(parts: &amp;mut http::request::Parts) -&gt; Result&lt;Self, Self::Rejection&gt; {
        parts.extensions.remove::&lt;T&gt;().map(Extension).ok_or(MissingExtension)
    }
}

/// The extension has not been added to the [`Request`](http::Request) or has been previously removed.
#[derive(Debug, Error)]
#[error("the `Extension` is not present in the `http::Request`")]
pub struct MissingExtension;

impl&lt;Protocol&gt; IntoResponse&lt;Protocol&gt; for MissingExtension {
    fn into_response(self) -&gt; http::Response&lt;BoxBody&gt; {
        let mut response = http::Response::new(empty());
        *response.status_mut() = StatusCode::INTERNAL_SERVER_ERROR;
        response
    }
}
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generating-common-service-code"><a class="header" href="#generating-common-service-code">Generating Common Service Code</a></h1>
<p>This document introduces the project and how code is being generated. It is written for developers who want to start contributing to <code>smithy-rs</code>.</p>
<h2 id="folder-structure"><a class="header" href="#folder-structure">Folder structure</a></h2>
<p>The project is divided in:</p>
<ul>
<li><code>/codegen-core</code>: contains common code to be used for both client and server code generation</li>
<li><code>/codegen-client</code>: client code generation. Depends on <code>codegen-core</code></li>
<li><code>/codegen-server</code>: server code generation. Depends on <code>codegen-core</code></li>
<li><code>/aws</code>: the AWS Rust SDK, it deals with AWS services specifically. The folder structure reflects the project's, with the <code>rust-runtime</code> and the <code>codegen</code></li>
<li><code>/rust-runtime</code>: the generated client and server crates may depend on crates in this folder. Crates here are not code generated. The only crate that is not published is <code>inlineable</code>,
which contains common functions used by other crates, <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/CargoDependency.kt#L95-L95">copied into</a> the source crate</li>
</ul>
<p>Crates in <code>/rust-runtime</code> (informally referred to as "runtime crates") are added to a crate's dependency only when used.
For example, if a model uses event streams, the generated crates will depend on <a href="https://docs.rs/aws-smithy-eventstream"><code>aws-smithy-eventstream</code></a>.</p>
<h2 id="generating-code"><a class="header" href="#generating-code">Generating code</a></h2>
<p><code>smithy-rs</code>'s entry points are Smithy code-generation plugins, and is not a command. One entry point is in <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/RustCodegenPlugin.kt#L34">RustCodegenPlugin::execute</a> and
inherits from <code>SmithyBuildPlugin</code> in <a href="https://github.com/awslabs/smithy/tree/main/smithy-build">smithy-build</a>. Code generation is in Kotlin and shared common, non-Rust specific code with the <a href="https://github.com/awslabs/smithy"><code>smithy</code> Java repository</a>. They plug into the <a href="https://awslabs.github.io/smithy/1.0/guides/building-models/gradle-plugin.html">Smithy gradle</a> plugin, which is a gradle plugin.</p>
<p>The comment at the beginning of <code>execute</code> describes what a <code>Decorator</code> is and uses the following terms:</p>
<ul>
<li>Context: contains the model being generated, projection and settings for the build</li>
<li>Decorator: (also referred to as customizations) customizes how code is being generated. AWS services are required to sign with the SigV4 protocol, and <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/aws/sdk-codegen/src/main/kotlin/software/amazon/smithy/rustsdk/SigV4SigningDecorator.kt#L45">a decorator</a> adds Rust code to sign requests and responses.
Decorators are applied in reverse order of being added and have a priority order.</li>
<li>Writer: creates files and adds content; it supports templating, using <code>#</code> for substitutions</li>
<li>Location: the file where a symbol will be written to</li>
</ul>
<p>The only task of a <code>RustCodegenPlugin</code> is to construct a <code>CodegenVisitor</code> and call its <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenVisitor.kt#L115-L115">execute()</a> method.</p>
<p><code>CodegenVisitor::execute()</code> is given a <code>Context</code> and decorators, and calls a <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenVisitor.kt#L44">CodegenVisitor</a>.</p>
<p>CodegenVisitor, RustCodegenPlugin, and wherever there are different implementations between client and server, such as in generating error types,
have corresponding server versions.</p>
<p>Objects used throughout code generation are:</p>
<ul>
<li>Symbol: a node in a graph, an abstraction that represents the qualified name of a type; symbols reference and depend on other symbols, and have some common properties among languages (such as a namespace or a definition file). For Rust, we add properties to include more metadata about a symbol, such as its <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/SymbolVisitor.kt#L363-L363">type</a></li>
<li><a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/RustTypes.kt#L25-L25">RustType</a>: <code>Option&lt;T&gt;</code>, <code>HashMap</code>, ... along with their namespaces of origin such as <code>std::collections</code></li>
<li><a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/RuntimeTypes.kt#L113-L113">RuntimeType</a>: the information to locate a type, plus the crates it depends on</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#shape-id">ShapeId</a>: an immutable object that identifies a <code>Shape</code></li>
</ul>
<p>Useful conversions are:</p>
<pre><code class="language-kotlin">SymbolProvider.toSymbol(shape)
</code></pre>
<p>where <code>SymbolProvider</code> constructs symbols for shapes. Some symbols require to create other symbols and types;
<a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/EventStreamSymbolProvider.kt#L65-L65">event streams</a> and <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/StreamingTraitSymbolProvider.kt#L26-L26">other streaming shapes</a> are an example.
Symbol providers are all <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/RustCodegenPlugin.kt#L62-L62">applied</a> in order; if a shape uses a reserved keyword in Rust, its name is converted to a new name by a <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/RustReservedWords.kt#L26-L26">symbol provider</a>,
and all other providers will work with this <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/EventStreamSymbolProvider.kt#L38-L38">new</a> symbol.</p>
<pre><code class="language-kotlin">Model.expectShape(shapeId)
</code></pre>
<p>Each model has a <code>shapeId</code> to <code>shape</code> map; this method returns the shape associated with this shapeId.</p>
<p>Some objects implement a <code>transform</code> <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/transformers/OperationNormalizer.kt#L52-L52">method</a> that only change the input model, so that code generation will work on that new model. This is used to, for example, add a trait to a shape.</p>
<p><code>CodegenVisitor</code> is a <code>ShapeVisitor</code>. For all services in the input model, shapes are <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenVisitor.kt#L119-L119">converted into Rust</a>;
<a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenVisitor.kt#L150-L150">here</a> is how a service is constructed,
<a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenVisitor.kt#L172-L172">here</a> a structure and so on.</p>
<p>Code generation flows from writer to files and entities are (mostly) generated only on a <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenDelegator.kt#L119-L126">need-by-need basis</a>.
The complete result is a <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenDelegator.kt#L42-L42">Rust crate</a>,
in which all dependencies are written into their modules and <code>lib.rs</code> is generated (<a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenDelegator.kt#L96-L107">here</a>).
<code>execute()</code> ends by running <a href="https://github.com/smithy-lang/smithy-rs/blob/db48039065bec890ef387385773b37154b555b14/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/CodegenVisitor.kt#L133-L133">cargo fmt</a>,
to avoid having to format correctly Rust in <code>Writer</code>s and to be sure the generated code follows the styling rules.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfcs"><a class="header" href="#rfcs">RFCs</a></h1>
<p><strong>What is an RFC?:</strong> An RFC is a document that proposes a change to <code>smithy-rs</code> or the AWS Rust SDK. Request for Comments means a request for discussion and oversight about the future of the project from maintainers, contributors and users.</p>
<p><strong>When should I write an RFC?:</strong> The AWS Rust SDK team proactively decides to write RFCs for major features or complex changes that we feel require extra scrutiny. However, the process can be used to request feedback on any change. Even changes that seem obvious and simple at first glance can be improved once a group of interested and experienced people have a chance to weigh in.</p>
<p><strong>Who can submit an RFC?:</strong> An RFC can be submitted by anyone. In most cases, RFCs are authored by SDK maintainers, but everyone is welcome to submit RFCs.</p>
<p><strong>Where do I start?:</strong> If you're ready to write and submit an RFC, please start a GitHub discussion with a summary of what you're trying to accomplish first. That way, the AWS Rust SDK team can ensure they have the bandwidth to review and shepherd the RFC through the whole process before you've expended effort in writing it. Once you've gotten the go-ahead, start with the <a href="rfcs/./rfc_template.html">RFC template</a>.</p>
<h2 id="previously-submitted-rfcs"><a class="header" href="#previously-submitted-rfcs">Previously Submitted RFCs</a></h2>
<ul>
<li><a href="rfcs/./rfc0001_shared_config.html">RFC-0001: AWS Configuration</a></li>
<li><a href="rfcs/./rfc0002_http_versions.html">RFC-0002: Supporting multiple HTTP versions for SDKs that use Event Stream</a></li>
<li><a href="rfcs/./rfc0003_presigning_api.html">RFC-0003: API for Presigned URLs</a></li>
<li><a href="rfcs/./rfc0004_retry_behavior.html">RFC-0004: Retry Behavior</a></li>
<li><a href="rfcs/./rfc0005_service_generation.html">RFC-0005: Service Generation</a></li>
<li><a href="rfcs/./rfc0006_service_specific_middleware.html">RFC-0006: Service-specific middleware</a></li>
<li><a href="rfcs/./rfc0007_split_release_process.html">RFC-0007: Split Release Process</a></li>
<li><a href="rfcs/./rfc0008_paginators.html">RFC-0008: Paginators</a></li>
<li><a href="rfcs/./rfc0009_example_consolidation.html">RFC-0009: Example Consolidation</a></li>
<li><a href="rfcs/./rfc0010_waiters.html">RFC-0010: Waiters</a></li>
<li><a href="rfcs/./rfc0011_crates_io_alpha_publishing.html">RFC-0011: Publishing Alpha to Crates.io</a></li>
<li><a href="rfcs/./rfc0012_independent_crate_versioning.html">RFC-0012: Independent Crate Versioning</a></li>
<li><a href="rfcs/./rfc0013_body_callback_apis.html">RFC-0013: Body Callback APIs</a></li>
<li><a href="rfcs/./rfc0014_timeout_config.html">RFC-0014: Fine-grained timeout configuration</a></li>
<li><a href="rfcs/./rfc0015_using_features_responsibly.html">RFC-0015: How Cargo "features" should be used in the SDK and runtime crates</a></li>
<li><a href="rfcs/./rfc0016_flexible_checksum_support.html">RFC-0016: Supporting Flexible Checksums</a></li>
<li><a href="rfcs/./rfc0017_customizable_client_operations.html">RFC-0017: Customizable Client Operations</a></li>
<li><a href="rfcs/./rfc0018_logging_sensitive.html">RFC-0018: Logging in the Presence of Sensitive Data</a></li>
<li><a href="rfcs/./rfc0019_event_streams_errors.html">RFC-0019: Event Streams Errors</a></li>
<li><a href="rfcs/./rfc0020_service_builder.html">RFC-0020: Service Builder Improvements</a></li>
<li><a href="rfcs/./rfc0021_dependency_versions.html">RFC-0021: Dependency Versions</a></li>
<li><a href="rfcs/./rfc0022_error_context_and_compatibility.html">RFC-0022: Error Context and Compatibility</a></li>
<li><a href="rfcs/./rfc0023_refine_builder.html">RFC-0023: Evolving the new service builder API</a></li>
<li><a href="rfcs/./rfc0024_request_id.html">RFC-0024: RequestID</a></li>
<li><a href="rfcs/./rfc0025_constraint_traits.html">RFC-0025: Constraint traits</a></li>
<li><a href="rfcs/./rfc0026_client_crate_organization.html">RFC-0026: Client Crate Organization</a></li>
<li><a href="rfcs/./rfc0027_endpoints_20.html">RFC-0027: Endpoints 2.0</a></li>
<li><a href="rfcs/./rfc0028_sdk_credential_cache_type_safety.html">RFC-0028: SDK Credential Cache Type Safety</a></li>
<li><a href="rfcs/./rfc0029_new_home_for_cred_types.html">RFC-0029: Finding New Home for Credential Types</a></li>
<li><a href="rfcs/./rfc0030_serialization_and_deserialization.html">RFC-0030: Serialization And Deserialization</a></li>
<li><a href="rfcs/./rfc0031_providing_fallback_credentials_on_timeout.html">RFC-0031: Providing Fallback Credentials on Timeout</a></li>
<li><a href="rfcs/./rfc0032_better_constraint_violations.html">RFC-0032: Better Constraint Violations</a></li>
<li><a href="rfcs/./rfc0033_improve_sdk_request_id_access.html">RFC-0033: Improving access to request IDs in SDK clients</a></li>
<li><a href="rfcs/./rfc0034_smithy_orchestrator.html">RFC-0034: The Orchestrator Architecture</a></li>
<li><a href="rfcs/./rfc0035_collection_defaults.html">RFC-0035: Sensible Defaults for Collection Values</a></li>
<li><a href="rfcs/./rfc0036_http_dep_elimination.html">RFC-0036: Enabling HTTP crate upgrades in the future</a></li>
<li><a href="rfcs/./rfc0037_http_wrapper.html">RFC-0037: The HTTP wrapper type</a></li>
<li><a href="rfcs/./rfc0038_retry_classifier_customization.html">RFC-0038: Retry Classifier Customization</a></li>
<li><a href="rfcs/./rfc0039_forward_compatible_errors.html">RFC-0039: Forward Compatible Errors</a></li>
<li><a href="rfcs/./rfc0040_behavior_versions.html">RFC-0040: Behavior Versions</a></li>
<li><a href="rfcs/./rfc0041_improve_client_error_ergonomics.html">RFC-0041: Improve client error ergonomics</a></li>
<li><a href="rfcs/./rfc0042_file_per_change_changelog.html">RFC-0042: File-per-change changelog</a></li>
<li><a href="rfcs/./rfc0043_identity_cache_partitions.html">RFC-0043: Identity Cache Partitions</a></li>
</ul>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<blockquote>
<p>4a8757c23 (add RFC to fix identity cache partitioning and default cache behaviors)</p>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aws-configuration-rfc"><a class="header" href="#aws-configuration-rfc">AWS Configuration RFC</a></h1>
<blockquote>
<p>Status: Implemented. For an ordered list of proposed changes see: <a href="rfcs/rfc0001_shared_config.html#changes-checklist">Proposed changes</a>.</p>
</blockquote>
<p>An AWS SDK loads configuration from multiple locations. Some of these locations can be loaded synchronously. Some are
async. Others may actually use AWS services such as STS or SSO.</p>
<p>This document proposes an overhaul to the configuration design to facilitate three things:</p>
<ol>
<li>Future-proof: It should be easy to add additional sources of region and credentials, sync and async, from many
sources, including code-generated AWS services.</li>
<li>Ergonomic: There should be one obvious way to create an AWS service client. Customers should be able to easily
customize the client to make common changes. It should encourage sharing of things that are expensive to create.</li>
<li>Shareable: A config object should be usable to configure multiple AWS services.</li>
</ol>
<h2 id="usage-guide"><a class="header" href="#usage-guide">Usage Guide</a></h2>
<blockquote>
<p>The following is an imagined usage guide if this RFC where implemented.</p>
</blockquote>
<h3 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h3>
<p>Using the SDK requires two crates:</p>
<ol>
<li><code>aws-sdk-&lt;someservice&gt;</code>: The service you want to use (e.g. <code>dynamodb</code>, <code>s3</code>, <code>sesv2</code>)</li>
<li><code>aws-config</code>: AWS metaconfiguration. This crate contains all the of logic to load configuration for the SDK (regions,
credentials, retry configuration, etc.)</li>
</ol>
<p>Add the following to your Cargo.toml:</p>
<pre><code class="language-toml">[dependencies]
aws-sdk-dynamo = "0.1"
aws-config = "0.5"

tokio = { version = "1", features = ["full"] }
</code></pre>
<p>Let's write a small example project to list tables:</p>
<pre><code class="language-rust ignore">use aws_sdk_dynamodb as dynamodb;

#[tokio::main]
async fn main() -&gt; Result&lt;(), dynamodb::Error&gt; {
    let config = aws_config::load_from_env().await;
    let dynamodb = dynamodb::Client::new(&amp;config);
    let resp = dynamodb.list_tables().send().await;
    println!("my tables: {}", resp.tables.unwrap_or_default());
    Ok(())
}</code></pre>
<blockquote>
<p>Tip: Every AWS service exports a top level <code>Error</code> type (e.g. <a href="https://awslabs.github.io/aws-sdk-rust/aws_sdk_dynamodb/enum.Error.html">aws_sdk_dynamodb::Error</a>).
Individual operations return specific error types that contain only the <a href="https://awslabs.github.io/aws-sdk-rust/aws_sdk_dynamodb/error/struct.ListTablesError.html">error variants returned by the operation</a>.
Because all the individual errors implement <code>Into&lt;dynamodb::Error&gt;</code>, you can use <code>dynamodb::Error</code> as the return type along with <code>?</code>.</p>
</blockquote>
<p>Next, we'll explore some other ways to configure the SDK. Perhaps you want to override the region loaded from the
environment with your region. In this case, we'll want more control over how we load config,
using <code>aws_config::from_env()</code> directly:</p>
<pre><code class="language-rust ignore">use aws_sdk_dynamodb as dynamodb;

#[tokio::main]
async fn main() -&gt; Result&lt;(), dynamodb::Error&gt; {
    let region_provider = RegionProviderChain::default_provider().or_else("us-west-2");
    let config = aws_config::from_env().region(region_provider).load().await;
    let dynamodb = dynamodb::Client::new(&amp;config);
    let resp = dynamodb.list_tables().send().await;
    println!("my tables: {}", resp.tables.unwrap_or_default());
    Ok(())
}</code></pre>
<h3 id="sharing-configuration-between-multiple-services"><a class="header" href="#sharing-configuration-between-multiple-services">Sharing configuration between multiple services</a></h3>
<p>The <code>Config</code> produced by <code>aws-config</code> can be used with any AWS service. If we wanted to read our Dynamodb DB tables
aloud with Polly, we could create a Polly client as well. First, we'll need to add Polly to our <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
aws-sdk-dynamo = "0.1"
aws-sdk-polly = "0.1"
aws-config = "0.5"

tokio = { version = "1", features = ["full"] }
</code></pre>
<p>Then, we can use the shared configuration to build both service clients. The region override will apply to both clients:</p>
<pre><code class="language-rust ignore">use aws_sdk_dynamodb as dynamodb;
use aws_sdk_polly as polly;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; { // error type changed to `Box&lt;dyn Error&gt;` because we now have dynamo and polly errors
    let config = aws_config::env_loader().with_region(Region::new("us-west-2")).load().await;

    let dynamodb = dynamodb::Client::new(&amp;config);
    let polly = polly::Client::new(&amp;config);

    let resp = dynamodb.list_tables().send().await;
    let tables = resp.tables.unwrap_or_default();
    let table_sentence = format!("my dynamo DB tables are: {}", tables.join(", "));
    let audio = polly.synthesize_speech()
        .output_format(OutputFormat::Mp3)
        .text(table_sentence)
        .voice_id(VoiceId::Joanna)
        .send()
        .await?;

    // Get MP3 data from the response and save it
    let mut blob = resp
        .audio_stream
        .collect()
        .await
        .expect("failed to read data");

    let mut file = tokio::fs::File::create("tables.mp3")
        .await
        .expect("failed to create file");

    file.write_all_buf(&amp;mut blob)
        .await
        .expect("failed to write to file");
    Ok(())
}</code></pre>
<h3 id="specifying-a-custom-credential-provider"><a class="header" href="#specifying-a-custom-credential-provider">Specifying a custom credential provider</a></h3>
<p>If you have your own source of credentials, you may opt-out of the standard credential provider chain.</p>
<p>To do this, implement the <code>ProvideCredentials</code> trait.</p>
<blockquote>
<p>NOTE: <code>aws_types::Credentials</code> already implements <code>ProvideCredentials</code>. If you want to use the SDK with static credentials, you're already done!</p>
</blockquote>
<pre><code class="language-rust ignore">use aws_types::credentials::{ProvideCredentials, provide_credentials::future, Result};

struct MyCustomProvider;

impl MyCustomProvider {
    pub async fn load_credentials(&amp;self) -&gt; Result {
        todo!() // A regular async function
    }
}

impl ProvideCredentials for MyCustomProvider {
    fn provide_credentials&lt;'a&gt;(&amp;'a self) -&gt; future::ProvideCredentials&lt;'a&gt;
        where
            Self: 'a,
    {
        future::ProvideCredentials::new(self.load_credentials())
    }
}</code></pre>
<blockquote>
<p>Hint: If your credential provider is not asynchronous, you can use <code>ProvideCredentials::ready</code> instead to save an allocation.</p>
</blockquote>
<p>After writing your custom provider, you'll use it in when constructing the configuration:</p>
<pre><code class="language-rust ignore">#[tokio::main]
async fn main() {
    let config = aws_config::from_env().credentials_provider(MyCustomProvider).load().await;
    let dynamodb = dynamodb::new(&amp;config);
}</code></pre>
<h2 id="proposed-design"><a class="header" href="#proposed-design">Proposed Design</a></h2>
<p>Achieving this design consists of three major changes:</p>
<ol>
<li>Add a <code>Config</code> struct to <code>aws-types</code>. This contains a config, but with no logic to <em>construct</em> it. This represents
what configuration SDKS need, but <strong>not</strong> how to load the information from the environment.</li>
<li>Create the <code>aws-config</code> crate. <code>aws-config</code> contains the logic to load configuration from the environment. No
generated service clients will depend on <code>aws-config</code>. This is critical to avoid circular dependencies and to
allow <code>aws-config</code> to depend on other AWS services. <code>aws-config</code> contains individual providers as well as a
pre-assembled default provider chain for region and credentials. It will also contain crate features to automatically
bring in HTTPS and async-sleep implementations.</li>
<li>Remove all "business logic" from <code>aws-types</code>. <code>aws-types</code> should be an interface-only crate that is extremely stable.
The ProvideCredentials trait should move into <code>aws-types</code>. The region provider trait which only exists to support
region-chaining will move out of aws-types into aws-config.</li>
</ol>
<p>Services will continue to generate their own <code>Config</code> structs. These will continue to be customizable as they are today,
however, they won't have any default resolvers built in. Each AWS config will implement <code>From&lt;&amp;aws_types::SharedConfig&gt;</code>
. A convenience method to <code>new()</code> a fluent client directly from a shared config will also be generated.</p>
<h3 id="shared-config-implementation"><a class="header" href="#shared-config-implementation">Shared Config Implementation</a></h3>
<p>This RFC proposes adding region and credentials providers support to the shared config. A future RFC will propose
integration with HTTP settings, HTTPs connectors, and async sleep.</p>
<pre><code class="language-rust ignore">struct Config {
    // private fields
    ...
}

impl Config {
    pub fn region(&amp;self) -&gt; Option&lt;&amp;Region&gt; {
        self.region.as_ref()
    }

    pub fn credentials_provider(&amp;self) -&gt; Option&lt;SharedCredentialsProvider&gt; {
        self.credentials_provider.clone()
    }

    pub fn builder() -&gt; Builder {
        Builder::default()
    }
}
</code></pre>
<p>The <code>Builder</code> for <code>Config</code> allows customers to provide individual overrides and handles the insertion of the default
chain for regions and credentials.</p>
<h3 id="sleep--connectors"><a class="header" href="#sleep--connectors">Sleep + Connectors</a></h3>
<p>Sleep and Connector are both runtime dependent features. <code>aws-config</code> will define <code>rt-tokio</code> and <code>rustls</code>
and <code>native-tls</code> optional features. <strong>This centralizes the Tokio/Hyper dependency</strong> eventually removing the need for
each service to maintain their own Tokio/Hyper features.</p>
<p>Although not proposed in this RFC, shared config will eventually gain support for creating an HTTPs client from HTTP
settings.</p>
<h2 id="the-build-method-on-config"><a class="header" href="#the-build-method-on-config">The <code>.build()</code> method on <service>::Config</a></h2>
<p>Currently, the <code>.build()</code> method on service config will fill in defaults. As part of this change, <code>.build()</code> called on
the service config with missing properties will fill in "empty" defaults. If no credentials provider is given,
a <code>NoCredentials</code> provider will be set, and <code>Region</code> will remain as <code>None</code>.</p>
<h2 id="stability-and-versioning"><a class="header" href="#stability-and-versioning">Stability and Versioning</a></h2>
<p>The introduction of <code>Config</code> to aws-types is not without risks. If a customer depends on a version aws-config that
uses <code>Config</code> that is incompatible, they will get confusing compiler errors.</p>
<p>An example of a problematic set of dependent versions:</p>
<pre><code class="language-markdown">┌─────────────────┐                 ┌───────────────┐
│ aws-types = 0.1 │                 │aws-types= 0.2 │
└─────────────────┘                 └───────────────┘
           ▲                                 ▲
           │                                 │
           │                                 │
           │                                 │
 ┌─────────┴─────────────┐          ┌────────┴───────┐
 │aws-sdk-dynamodb = 0.5 │          │aws-config = 0.6│
 └───────────┬───────────┘          └───────┬────────┘
             │                              │
             │                              │
             │                              │
             │                              │
             │                              │
             ├─────────────────────┬────────┘
             │ my-lambda-function  │
             └─────────────────────┘
</code></pre>
<p>To mitigate this risk, we will need to make <code>aws-types</code> essentially permanently stable. Changes to <code>aws-types</code> need to
be made with extreme care. This will ensure that two versions of <code>aws-types</code> never end up in a customer's dependency
tree.</p>
<p>We will dramatically reduce the surface area of <code>aws-types</code> to contain only interfaces.</p>
<p>Several breaking changes will be made as part of this, notably, the profile file parsing will be moved out of aws-types.</p>
<p>Finally, to mitigate this risk even further, services will <code>pub use</code> items from <code>aws-types</code> directly which means that
even if a dependency mismatch exists, it is still possible for customers to work around it.</p>
<h2 id="changes-checklist"><a class="header" href="#changes-checklist">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
ProvideRegion becomes async using a newtype'd future.</li>
<li><input disabled="" type="checkbox" checked=""/>
AsyncProvideCredentials is removed. ProvideCredentials becomes async using a newtype'd future.</li>
<li><input disabled="" type="checkbox" checked=""/>
ProvideCredentials moved into <code>aws-types</code>. <code>Credentials</code> moved into <code>aws-types</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>aws-config</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Profile-file parsing moved into <code>aws-config</code>, region chain &amp; region environment loaders moved to <code>aws-config</code>.</li>
<li><input disabled="" type="checkbox"/>
os_shim_internal moved to ??? <code>aws-smithy-types</code>?</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>Config</code> to <code>aws-types</code>. Ensure that it's set up to add new members while remaining backwards
compatible.</li>
<li><input disabled="" type="checkbox" checked=""/>
Code generate <code>From&lt;&amp;SharedConfig&gt; for &lt;everyservice&gt;::Config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Code generate <code>&lt;everservice&gt;::Client::new(&amp;shared_config)</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Remove <code>&lt;everyservice&gt;::from_env</code></li>
</ul>
<h2 id="open-issues"><a class="header" href="#open-issues">Open Issues</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Connector construction needs to be a function of HTTP settings</li>
<li><input disabled="" type="checkbox"/>
An AsyncSleep should be added to <code>aws-types::Config</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-supporting-multiple-http-versions-for-sdks-that-use-event-stream"><a class="header" href="#rfc-supporting-multiple-http-versions-for-sdks-that-use-event-stream">RFC: Supporting multiple HTTP versions for SDKs that use Event Stream</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0002_http_versions.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Most AWS SDK operations use HTTP/1.1, but bi-directional streaming operations that use the Event Stream
message framing format need to use HTTP/2 (h2).</p>
<p>Smithy models can also customize which HTTP versions are used in each individual protocol trait.
For example,
<a href="https://awslabs.github.io/smithy/1.0/spec/aws/aws-restjson1-protocol.html#aws-protocols-restjson1-trait"><code>@restJson1</code> has attributes <code>http</code> and <code>eventStreamHttp</code></a>
to list out the versions that should be used in a priority order.</p>
<p>There are two problems in play that this doc attempts to solve:</p>
<ol>
<li><strong>Connector Creation</strong>: Customers need to be able to create connectors with the HTTP settings they desire,
and these custom connectors must align with what the Smithy model requires.</li>
<li><strong>Connector Selection</strong>: The generated code must be able to select the connector that best matches the requirements
from the Smithy model.</li>
</ol>
<h2 id="terminology-1"><a class="header" href="#terminology-1">Terminology</a></h2>
<p>Today, there are three layers of <code>Client</code> that are easy to confuse, so to make the following easier to follow,
the following terms will be used:</p>
<ul>
<li><strong>Connector</strong>: An implementor of Tower's <code>Service</code> trait that converts a request into a response. This is typically
a thin wrapper around a Hyper client.</li>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This isn't intended to be used directly.</li>
<li><strong>Fluent Client</strong>: A code generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that uses a <code>DynConnector</code>, <code>DefaultMiddleware</code>,
and <code>Standard</code> retry policy.</li>
</ul>
<p>All of these are just called <code>Client</code> in code today. This is something that could be clarified in a separate refactor.</p>
<h2 id="how-clients-work-today"><a class="header" href="#how-clients-work-today">How Clients Work Today</a></h2>
<p>Fluent clients currently keep a handle to a single Smithy client, which is a wrapper
around the underlying connector. When constructing operation builders, this handle is <code>Arc</code> cloned and
given to the new builder instances so that their <code>send()</code> calls can initiate a request.</p>
<p>The generated fluent client code ends up looking like this:</p>
<pre><code class="language-rust ignore">struct Handle&lt;C, M, R&gt; {
    client: aws_smithy_client::Client&lt;C, M, R&gt;,
    conf: crate::Config,
}

pub struct Client&lt;C, M, R = Standard&gt; {
    handle: Arc&lt;Handle&lt;C, M, R&gt;&gt;,
}</code></pre>
<p>Functions are generated per operation on the fluent client to gain access to the individual operation builders.
For example:</p>
<pre><code class="language-rust ignore">pub fn assume_role(&amp;self) -&gt; fluent_builders::AssumeRole&lt;C, M, R&gt; {
    fluent_builders::AssumeRole::new(self.handle.clone())
}</code></pre>
<p>The fluent operation builders ultimately implement <code>send()</code>, which chooses the one and only Smithy client out
of the handle to make the request with:</p>
<pre><code class="language-rust ignore">pub struct AssumeRole&lt;C, M, R&gt; {
    handle: std::sync::Arc&lt;super::Handle&lt;C, M, R&gt;&gt;,
    inner: crate::input::assume_role_input::Builder,
}

impl&lt;C, M, R&gt; AssumeRole&lt;C, M, R&gt; where ...{
    pub async fn send(self) -&gt; Result&lt;AssumeRoleOutput, SdkError&lt;AssumeRoleError&gt;&gt; where ... {
        // Setup code omitted ...

        // Make the actual request
        self.handle.client.call(op).await
    }
}</code></pre>
<p>Smithy clients are constructed from a connector, as shown:</p>
<pre><code class="language-rust ignore">let connector = Builder::new()
    .https()
    .middleware(...)
    .build();
let client = Client::with_config(connector, Config::builder().build());</code></pre>
<p>The <code>https()</code> method on the Builder constructs the actual Hyper client, and is driven off Cargo features to
select the correct TLS implementation. For example:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "rustls")]
pub fn https() -&gt; Https {
    let https = hyper_rustls::HttpsConnector::with_native_roots();
    let client = hyper::Client::builder().build::&lt;_, SdkBody&gt;(https);
    // HyperAdapter is a Tower `Service` request -&gt; response connector that just calls the Hyper client
    crate::hyper_impls::HyperAdapter::from(client)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="solving-the-connector-creation-problem"><a class="header" href="#solving-the-connector-creation-problem">Solving the Connector Creation Problem</a></h2>
<p>Customers need to be able to provide HTTP settings, such as timeouts, for all connectors that the clients use.
These should come out of the <code>SharedConfig</code> when it is used. Connector creation also needs to be customizable
so that alternate HTTP implementations can be used, or so that a fake implementation can be used for tests.</p>
<p>To accomplish this, <code>SharedConfig</code> will have a <code>make_connector</code> member. A customer would configure
it as such:</p>
<pre><code class="language-rust ignore">let config = some_shared_config_loader()
    .with_http_settings(my_http_settings)
    .with_make_connector(|reqs: &amp;MakeConnectorRequirements| {
        Some(MyCustomConnector::new(reqs))
    })
    .await;</code></pre>
<p>The passed in <code>MakeConnectorRequirements</code> will hold the customer-provided <code>HttpSettings</code> as well
as any Smithy-modeled requirements, which will just be <code>HttpVersion</code> for now. The <code>MakeConnectorRequirements</code>
struct will be marked <code>non_exhaustive</code> so that new requirements can be added to it as the SDK evolves.</p>
<p>A default <code>make_connector</code> implementation would be provided that creates a Hyper connector based on the
Cargo feature flags. This might look something like this:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "rustls")]
pub fn default_connector(reqs: &amp;HttpRequirements) -&gt; HyperAdapter {
    let https = hyper_rustls::HttpsConnector::with_native_roots();
    let mut builder = hyper::Client::builder();
    builder = configure_settings(builder, &amp;reqs.http_settings);
    if let Http2 = &amp;reqs.http_version {
        builder = builder.http2_only(true);
    }
    HyperAdapter::from(builder.build::&lt;_, SdkBody&gt;(https))
}
<span class="boring">}</span></code></pre></pre>
<p>For any given service, <code>make_connector</code> could be called multiple times to create connectors
for all required HTTP versions and settings.</p>
<p><strong>Note:</strong> the <code>make_connector</code> returns an <code>Option</code> since an HTTP version may not be required, but rather, preferred
according to a Smithy model. For operations that list out <code>["h2", "HTTP/1.1"]</code> as the desired versions,
a customer could choose to provide only an HTTP 1 connector, and the operation should still succeed.</p>
<h2 id="solving-the-connector-selection-problem"><a class="header" href="#solving-the-connector-selection-problem">Solving the Connector Selection Problem</a></h2>
<p>Each service operation needs to be able to select a connector that meets its requirements best
from the customer provided connectors. Initially, the only selection criteria will be the HTTP version,
but later when per-operation HTTP settings are implemented, the connector will also need to be keyed off of those
settings. Since connector creation is not a cheap process, connectors will need to be cached after they are
created.</p>
<p>This caching is currently handled by the <code>Handle</code> in the fluent client, which holds on to the
Smithy client. This cache needs to be adjusted to:</p>
<ul>
<li>Support multiple connectors, keyed off of the customer provided <code>HttpSettings</code>, and also off of the Smithy modeled requirements.</li>
<li>Be lazy initialized. Services that have a mix of Event Stream and non-streaming operations shouldn't create
an HTTP/2 client if the customer doesn't intend to use the Event Stream operations that require it.</li>
</ul>
<p>To accomplish this, the <code>Handle</code> will hold a cache that is optimized for many reads and few writes:</p>
<pre><code class="language-rust ignore">#[derive(Debug, Hash, Eq, PartialEq)]
struct ConnectorKey {
    http_settings: HttpSettings,
    http_version: HttpVersion,
}

struct Handle&lt;C, M, R&gt; {
    clients: RwLock&lt;HashMap&lt;HttpRequirements&lt;'static&gt;, aws_smithy_client::Client&lt;C, M, R&gt;&gt;&gt;,
    conf: crate::Config,
}

pub struct Client&lt;C, M, R = Standard&gt; {
    handle: Arc&lt;Handle&lt;C, M, R&gt;&gt;,
}</code></pre>
<p>With how the generics are organized, the connector type will have to be the same between HTTP implementations,
but this should be fine since it is generally a thin wrapper around a separate HTTP implementor.
For cases where it is not, the custom connector type can host its own <code>dyn Trait</code> solution.</p>
<p>The <code>HttpRequirements</code> struct will hold <code>HttpSettings</code> as copy-on-write so that it can be used
for cache lookup without having to clone <code>HttpSettings</code>:</p>
<pre><code class="language-rust ignore">struct HttpRequirements&lt;'a&gt; {
    http_settings: Cow&lt;'a, HttpSettings&gt;,
    http_version: HttpVersion,
}

impl&lt;'a&gt; HttpRequirements&lt;'a&gt; {
    // Needed for converting a borrowed HttpRequirements into an owned cache key for cache population
    pub fn into_owned(self) -&gt; HttpRequirements&lt;'static&gt; {
        Self {
            http_settings: Cow::Owned(self.http_settings.into_owned()),
            http_version: self.http_version,
        }
    }
}</code></pre>
<p>With the cache established, each operation needs to be aware of its requirements. The code generator will be
updated to store a prioritized list of <code>HttpVersion</code> in the property bag in an input's <code>make_operation()</code> method.
This prioritized list will come from the Smithy protocol trait's <code>http</code> or <code>eventStreamHttp</code> attribute, depending
on the operation. The fluent client will then pull this list out of the property bag so that it can determine which
connector to use. This indirection is necessary so that an operation still holds all information
needed to make a service call from the Smithy client directly.</p>
<p><strong>Note:</strong> This may be extended in the future to be more than just <code>HttpVersion</code>, for example, when per-operation
HTTP setting overrides are implemented. This doc is not attempting to solve that problem.</p>
<p>In the fluent client, this will look as follows:</p>
<pre><code class="language-rust ignore">impl&lt;C, M, R&gt; AssumeRole&lt;C, M, R&gt; where ... {
    pub async fn send(self) -&gt; Result&lt;AssumeRoleOutput, SdkError&lt;AssumeRoleError&gt;&gt; where ... {
        let input = self.create_input()?;
        let op = input.make_operation(&amp;self.handle.conf)?;

        // Grab the `make_connector` implementation
        let make_connector = self.config.make_connector();

        // Acquire the prioritized HttpVersion list
        let http_versions = op.properties().get::&lt;HttpVersionList&gt;();

        // Make the actual request (using default HttpSettings until modifying those is implemented)
        let client = self.handle
            .get_or_create_client(make_connector, &amp;default_http_settings(), &amp;http_versions)
            .await?;
        client.call(op).await
    }
}</code></pre>
<p>If an operation requires a specific protocol version, and if the <code>make_connection</code> implementation can't
provide that it, then the <code>get_or_create_client()</code> function will return <code>SdkError::ConstructionFailure</code>
indicating the error.</p>
<h2 id="changes-checklist-1"><a class="header" href="#changes-checklist-1">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Create <code>HttpVersion</code> in <code>aws-smithy-http</code> with <code>Http1_1</code> and <code>Http2</code></li>
<li><input disabled="" type="checkbox"/>
Refactor existing <code>https()</code> connector creation functions to take <code>HttpVersion</code></li>
<li><input disabled="" type="checkbox"/>
Add <code>make_connector</code> to <code>SharedConfig</code>, and wire up the <code>https()</code> functions as a default</li>
<li><input disabled="" type="checkbox"/>
Create <code>HttpRequirements</code> in <code>aws-smithy-http</code></li>
<li><input disabled="" type="checkbox"/>
Implement the connector cache on <code>Handle</code></li>
<li><input disabled="" type="checkbox"/>
Implement function to calculate a minimum required set of HTTP versions from a Smithy model in the code generator</li>
<li><input disabled="" type="checkbox"/>
Update the <code>make_operation</code> code gen to put an <code>HttpVersionList</code> into the operation property bag</li>
<li><input disabled="" type="checkbox"/>
Update the fluent client <code>send()</code> function code gen grab the HTTP version list and acquire the correct connector with it</li>
<li><input disabled="" type="checkbox"/>
Add required defaulting for models that don't set the optional <code>http</code> and <code>eventStreamHttp</code> protocol trait attributes</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-api-for-presigned-urls"><a class="header" href="#rfc-api-for-presigned-urls">RFC: API for Presigned URLs</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0003_presigning_api.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Several AWS services allow for presigned requests in URL form, which is described well by
<a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html">S3's documentation on authenticating requests using query parameters</a>.</p>
<p>This doc establishes the customer-facing API for creating these presigned URLs and how they will
be implemented in a generic fashion in the SDK codegen.</p>
<h2 id="terminology-2"><a class="header" href="#terminology-2">Terminology</a></h2>
<p>To differentiate between the clients that are present in the generated SDK today, the following
terms will be used throughout this doc:</p>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
</ul>
<h2 id="presigned-url-config"><a class="header" href="#presigned-url-config">Presigned URL config</a></h2>
<p>Today, presigned URLs take an expiration time that's not part of the service API.
The SDK will make this configurable as a separate struct so that there's no chance of name collisions, and so
that additional fields can be added in the future. Fields added later will require defaulting for
backwards compatibility.</p>
<p>Customers should also be able to set a start time on the presigned URL's expiration so that they can
generate URLs that become active in the future. An optional <code>start_time</code> option will be available and
default to <code>SystemTime::now()</code>.</p>
<p>Construction <code>PresigningConfig</code> can be done with a builder, but a <code>PresigningConfig::expires_in</code>
convenience function will be provided to bypass the builder for the most frequent use-case.</p>
<pre><code class="language-rust ignore">#[non_exhaustive]
#[derive(Debug, Clone)]
pub struct PresigningConfig {
    start_time: SystemTime,
    expires_in: Duration,
}

#[non_exhaustive]
#[derive(Debug)]
pub struct Builder {
    start_time: Option&lt;SystemTime&gt;,
    expires_in: Option&lt;Duration&gt;,
}

impl Builder {
    pub fn start_time(self, start_time: SystemTime) -&gt; Self { ... }
    pub fn set_start_time(&amp;mut self, start_time: Option&lt;SystemTime&gt;) { ... }

    pub fn expires_in(self, expires_in: Duration) -&gt; Self { ... }
    pub fn set_expires_in(&amp;mut self, expires_in: Option&lt;Duration&gt;) { ... }

    // Validates `expires_in` is no greater than one week
    pub fn build(self) -&gt; Result&lt;PresigningConfig, Error&gt; { ... }
}

impl PresigningConfig {
    pub fn expires_in(expires_in: Duration) -&gt; PresigningConfig {
        Self::builder().expires(expires).build().unwrap()
    }

    pub fn builder() -&gt; Builder { ... }
}</code></pre>
<p>Construction of <code>PresigningConfig</code> will validate that <code>expires_in</code> is no greater than one week, as this
is the longest supported expiration time for SigV4. This validation will result in a panic.</p>
<p>It's not inconceivable that <code>PresigningConfig</code> will need additional service-specific parameters as customizations,
so it will be code generated with each service rather than living a shared location.</p>
<h2 id="fluent-presigned-url-api"><a class="header" href="#fluent-presigned-url-api">Fluent Presigned URL API</a></h2>
<p>The generated fluent builders for operations that support presigning will have a <code>presigned()</code> method
in addition to <code>send()</code> that will return a presigned URL rather than sending the request. For S3's GetObject,
the usage of this will look as follows:</p>
<pre><code class="language-rust ignore">let config = aws_config::load_config_from_environment().await;
let client = s3::Client::new(&amp;config);
let presigning_config = PresigningConfig::expires_in(Duration::from_secs(86400));
let presigned: PresignedRequest = client.get_object()
    .bucket("example-bucket")
    .key("example-object")
    .presigned(presigning_config)
    .await?;</code></pre>
<p>This API requires a client, and for use-cases where no actual service calls need to be made,
customers should be able to create presigned URLs without the overhead of an HTTP client.
Once the <a href="rfcs/./rfc0002_http_versions.html">HTTP Versions RFC</a> is implemented, the underlying HTTP client
won't be created until the first service call, so there will be no HTTP client overhead to
this approach.</p>
<p>In a step away from the general pattern of keeping fluent client capabilities in line with Smithy client capabilities,
creating presigned URLs directly from the Smithy client will not be supported. This is for two reasons:</p>
<ul>
<li>The Smithy client is not code generated, so adding a method to do presigning would apply to all operations,
but not all operations can be presigned.</li>
<li>Presigned URLs are not currently a Smithy concept (<a href="https://github.com/awslabs/smithy/pull/897">although this may change soon</a>).</li>
</ul>
<p>The result of calling <code>presigned()</code> is a <code>PresignedRequest</code>, which is a wrapper with delegating functions
around <code>http::Request&lt;()&gt;</code> so that the request method and additional signing headers are also made available.
This is necessary since there are some presignable POST operations that require the signature to be in the
headers rather than the query.</p>
<p><strong>Note:</strong> Presigning <em>needs</em> to be <code>async</code> because the underlying credentials provider used to sign the
request <em>may</em> need to make service calls to acquire the credentials.</p>
<h2 id="input-presigned-url-api"><a class="header" href="#input-presigned-url-api">Input Presigned URL API</a></h2>
<p>Even though generating a presigned URL through the fluent client doesn't necessitate an HTTP client,
it will be clearer that this is the case by allowing the creation of presigned URLs directly from an input.
This would look as follows:</p>
<pre><code class="language-rust ignore">let config = aws_config::load_config_from_environment().await;
let presigning_config = PresigningConfig::expires_in(Duration::from_secs(86400));
let presigned: PresignedRequest = GetObjectInput::builder()
    .bucket("example-bucket")
    .key("example-bucket")
    .presigned(&amp;config, presigning_config)
    .await?;</code></pre>
<p>Creating the URL through the input will exercise the same code path as creating it through the client,
but it will be more apparent that the overhead of a client isn't present.</p>
<h2 id="behind-the-scenes"><a class="header" href="#behind-the-scenes">Behind the scenes</a></h2>
<p>From an SDK's perspective, the following are required to make a presigned URL:</p>
<ul>
<li>Valid request input</li>
<li>Endpoint</li>
<li>Credentials to sign with</li>
<li>Signing implementation</li>
</ul>
<p>The AWS middleware provides everything except the request, and the request is provided as part
of the fluent builder API. The generated code needs to be able to run the middleware to fully populate
a request property bag, but not actually dispatch it.  The <code>expires_in</code> value from the presigning config
needs to be piped all the way through to the signer. Additionally, the SigV4 signing needs to adjusted
to do query param signing, which is slightly different than its header signing.</p>
<p>Today, request dispatch looks as follows:</p>
<ol>
<li>The customer creates a new fluent builder by calling <code>client.operation_name()</code>, fills in inputs, and then calls <code>send()</code>.</li>
<li><code>send()</code>:
<ol>
<li>Builds the final input struct, and then calls its <code>make_operation()</code> method with the stored config to create a Smithy <code>Operation</code>.</li>
<li>Calls the underlying Smithy client with the operation.</li>
</ol>
</li>
<li>The Smithy client constructs a Tower Service with AWS middleware and a dispatcher at the bottom, and then executes it.</li>
<li>The middleware acquire and add required signing parameters (region, credentials, endpoint, etc) to the request property bag.</li>
<li>The SigV4 signing middleware signs the request by adding HTTP headers to it.</li>
<li>The dispatcher makes the actual HTTP request and returns the response all the way back up the Tower.</li>
</ol>
<p>Presigning will take advantage of a lot of these same steps, but will cut out the <code>Operation</code> and
replace the dispatcher with a presigned URL generator:</p>
<ol>
<li>The customer creates a new fluent builder by calling <code>client.operation_name()</code>, fills in inputs, and then calls <code>presigned()</code>.</li>
<li><code>presigned()</code>:
<ol>
<li>Builds the final input struct, calls the <code>make_operation()</code> method with the stored config, and then extracts
the request from the operation (discarding the rest).</li>
<li>Mutates the <code>OperationSigningConfig</code> in the property bag to:
<ul>
<li>Change the <code>signature_type</code> to <code>HttpRequestQueryParams</code> so that the signer runs the correct signing logic.</li>
<li>Set <code>expires_in</code> to the value given by the customer in the presigning config.</li>
</ul>
</li>
<li>Constructs a Tower Service with <code>AwsMiddleware</code> layered in, and a <code>PresignedUrlGeneratorLayer</code> at the bottom.</li>
<li>Calls the Tower Service and returns its result</li>
</ol>
</li>
<li>The <code>AwsMiddleware</code> will sign the request.</li>
<li>The <code>PresignedUrlGeneratorLayer</code> directly returns the request since all of the work is done by the middleware.</li>
</ol>
<p>It should be noted that the <code>presigned()</code> function above is on the generated input struct, so implementing this for
the input API is identical to implementing it for the fluent client.</p>
<p>All the code for the new <code>make_request()</code> is already in the existing <code>make_operation()</code> and will just need to be split out.</p>
<h3 id="modeling-presigning"><a class="header" href="#modeling-presigning">Modeling Presigning</a></h3>
<p>AWS models don't currently have any information about which operations can be presigned.
To work around this, the Rust SDK will create a synthetic trait to model presigning with, and
apply this trait to known presigned operations via customization. The code generator will
look for this synthetic trait when creating the fluent builders and inputs to know if a
<code>presigned()</code> method should be added.</p>
<h3 id="avoiding-name-collision"><a class="header" href="#avoiding-name-collision">Avoiding name collision</a></h3>
<p>If a presignable operation input has a member named <code>presigned</code>, then there will be a name collision with
the function to generate a presigned URL. To mitigate this, <code>RustReservedWords</code> will be updated
to rename the <code>presigned</code> member to <code>presigned_value</code>
<a href="https://github.com/smithy-lang/smithy-rs/blob/3d61226b5d446f4cc20bf4969f0e56d106cf478b/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/rustlang/RustReservedWords.kt#L28">similar to how <code>send</code> is renamed</a>.</p>
<h2 id="changes-checklist-2"><a class="header" href="#changes-checklist-2">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>aws-sigv4</code> to support query param signing</li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>PresignedOperationSyntheticTrait</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Customize models for known presigned operations</li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>PresigningConfig</code> and its builder</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>PresignedUrlGeneratorLayer</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create new AWS codegen decorator to:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>presigned()</code> method to input code generator</li>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>presigned()</code> method to fluent client generator</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>RustReservedWords</code> to reserve <code>presigned()</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add integration test to S3</li>
<li><input disabled="" type="checkbox" checked=""/>
Add integration test to Polly</li>
<li><input disabled="" type="checkbox" checked=""/>
Add examples for using presigning for:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
S3 GetObject and PutObject</li>
<li><input disabled="" type="checkbox" checked=""/>
Polly SynthesizeSpeech</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-retry-behavior"><a class="header" href="#rfc-retry-behavior">RFC: Retry Behavior</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0004_retry_behavior.html#changes-checklist">Changes Checklist</a> section.</p>
<p>It is not currently possible for users of the SDK to configure a client's maximum number of retry attempts. This RFC establishes a method for users to set the number of retries to attempt when calling a service and would allow users to disable retries entirely. This RFC would introduce breaking changes to the <code>retry</code> module of the <code>aws-smithy-client</code> crate.</p>
<h2 id="terminology-3"><a class="header" href="#terminology-3">Terminology</a></h2>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that defaults to using a <code>DynConnector</code>, <code>AwsMiddleware</code>,
and <code>Standard</code> retry policy.</li>
<li><strong>Shared Config</strong>: An <code>aws_types::Config</code> struct that is responsible for storing shared configuration data that is used across all services. This is not generated and lives in the <code>aws-types</code> crate.</li>
<li><strong>Service-specific Config</strong>: A code-generated <code>Config</code> that has methods for setting service-specific configuration. Each <code>Config</code> is defined in the <code>config</code> module of its parent service. For example, the S3-specific config struct is <code>use</code>able from <code>aws_sdk_s3::config::Config</code> and re-exported as <code>aws_sdk_s3::Config</code>.</li>
<li><strong>Standard retry behavior</strong>: The standard set of retry rules across AWS SDKs. This mode includes a standard set of errors that are retried, and support for retry quotas. The default maximum number of attempts with this mode is three, unless <code>max_attempts</code> is explicitly configured.</li>
<li><strong>Adaptive retry behavior</strong>: Adaptive retry mode dynamically limits the rate of AWS requests to maximize success rate. This may be at the expense of request latency. Adaptive retry mode is not recommended when predictable latency is important.
<ul>
<li><em>Note: supporting the "adaptive" retry behavior is considered outside the scope of this RFC</em></li>
</ul>
</li>
</ul>
<h2 id="configuring-the-maximum-number-of-retries"><a class="header" href="#configuring-the-maximum-number-of-retries">Configuring the maximum number of retries</a></h2>
<p>This RFC will demonstrate <em>(with examples)</em> the following ways that Users can set the maximum number of retry attempts:</p>
<ul>
<li>By calling the <code>Config::retry_config(..)</code> or <code>Config::disable_retries()</code> methods when building a service-specific config</li>
<li>By calling the <code>Config::retry_config(..)</code> or <code>Config::disable_retries()</code> methods when building a shared config</li>
<li>By setting the <code>AWS_MAX_ATTEMPTS</code> environment variable</li>
</ul>
<p>The above list is in order of decreasing precedence e.g. setting maximum retry attempts with the <code>max_attempts</code> builder method will override a value set by <code>AWS_MAX_ATTEMPTS</code>.</p>
<p><em>The default number of retries is 3 as specified in the <a href="https://docs.aws.amazon.com/sdkref/latest/guide/setting-global-max_attempts.html">AWS SDKs and Tools Reference Guide</a>.</em></p>
<h3 id="setting-an-environment-variable"><a class="header" href="#setting-an-environment-variable">Setting an environment variable</a></h3>
<p>Here's an example app that logs your AWS user's identity</p>
<pre><code class="language-rust ignore">use aws_sdk_sts as sts;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::load_from_env().await;

    let sts = sts::Client::new(&amp;config);
    let resp = sts.get_caller_identity().send().await?;
    println!("your user id: {}", resp.user_id.unwrap_or_default());
    Ok(())
}</code></pre>
<p>Then, in your terminal:</p>
<pre><code class="language-sh"># Set the env var before running the example program
export AWS_MAX_ATTEMPTS=5
# Run the example program
cargo run
</code></pre>
<h3 id="calling-a-method-on-an-aws-shared-config"><a class="header" href="#calling-a-method-on-an-aws-shared-config">Calling a method on an AWS shared config</a></h3>
<p>Here's an example app that creates a shared config with custom retry behavior and then logs your AWS user's identity</p>
<pre><code class="language-rust ignore">use aws_sdk_sts as sts;
use aws_types::retry_config::StandardRetryConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let retry_config = StandardRetryConfig::builder().max_attempts(5).build();
    let config = aws_config::from_env().retry_config(retry_config).load().await;

    let sts = sts::Client::new(&amp;config);
    let resp = sts.get_caller_identity().send().await?;
    println!("your user id: {}", resp.user_id.unwrap_or_default());
    Ok(())
}</code></pre>
<h3 id="calling-a-method-on-service-specific-config"><a class="header" href="#calling-a-method-on-service-specific-config">Calling a method on service-specific config</a></h3>
<p>Here's an example app that creates a service-specific config with custom retry behavior and then logs your AWS user's identity</p>
<pre><code class="language-rust ignore">use aws_sdk_sts as sts;
use aws_types::retry_config::StandardRetryConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::load_from_env().await;
    let retry_config = StandardRetryConfig::builder().max_attempts(5).build();
    let sts_config = sts::config::Config::from(&amp;config).retry_config(retry_config).build();

    let sts = sts::Client::new(&amp;sts_config);
    let resp = sts.get_caller_identity().send().await?;
    println!("your user id: {}", resp.user_id.unwrap_or_default());
    Ok(())
}</code></pre>
<h3 id="disabling-retries"><a class="header" href="#disabling-retries">Disabling retries</a></h3>
<p>Here's an example app that creates a shared config that disables retries and then logs your AWS user's identity</p>
<pre><code class="language-rust ignore">use aws_sdk_sts as sts;
use aws_types::config::Config;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::from_env().disable_retries().load().await;
    let sts_config = sts::config::Config::from(&amp;config).build();

    let sts = sts::Client::new(&amp;sts_config);
    let resp = sts.get_caller_identity().send().await?;
    println!("your user id: {}", resp.user_id.unwrap_or_default());
    Ok(())
}</code></pre>
<p>Retries can also be disabled by explicitly passing the <code>RetryConfig::NoRetries</code> enum variant to the <code>retry_config</code> builder method:</p>
<pre><code class="language-rust ignore">use aws_sdk_sts as sts;
use aws_types::retry_config::RetryConfig;

#[tokio::main]
async fn main() -&gt; Result&lt;(), sts::Error&gt; {
    let config = aws_config::load_from_env().await;
    let sts_config = sts::config::Config::from(&amp;config).retry_config(RetryConfig::NoRetries).build();

    let sts = sts::Client::new(&amp;sts_config);
    let resp = sts.get_caller_identity().send().await?;
    println!("your user id: {}", resp.user_id.unwrap_or_default());
    Ok(())
}</code></pre>
<h2 id="behind-the-scenes-1"><a class="header" href="#behind-the-scenes-1">Behind the scenes</a></h2>
<p>Currently, when users want to send a request, the following occurs:</p>
<ol>
<li>The user creates either a shared config or a service-specific config</li>
<li>The user creates a fluent client for the service they want to interact with and passes the config they created. Internally, this creates an AWS client with a default retry policy</li>
<li>The user calls an operation builder method on the client which constructs a request</li>
<li>The user sends the request by awaiting the <code>send()</code> method</li>
<li>The smithy client creates a new <code>Service</code> and attaches a copy of its retry policy</li>
<li>The <code>Service</code> is <code>call</code>ed, sending out the request and retrying it according to the retry policy</li>
</ol>
<p>After this change, the process will work like this:</p>
<ol>
<li>The user creates either a shared config or a service-specific config
<ul>
<li>If <code>AWS_MAX_ATTEMPTS</code> is set to zero, this is invalid and we will log it with <code>tracing::warn</code>. However, this will not error until a request is made</li>
<li>If <code>AWS_MAX_ATTEMPTS</code> is 1, retries will be disabled</li>
<li>If <code>AWS_MAX_ATTEMPTS</code> is greater than 1, retries will be attempted at most as many times as is specified</li>
<li>If the user creates the config with the <code>.disable_retries</code> builder method, retries will be disabled</li>
<li>If the user creates the config with the <code>retry_config</code> builder method, retry behavior will be set according to the <code>RetryConfig</code> they passed</li>
</ul>
</li>
<li>The user creates a fluent client for the service they want to interact with and passes the config they created
<ul>
<li>Provider precedence will determine what retry behavior is actually set, working like how <code>Region</code> is set</li>
</ul>
</li>
<li>The user calls an operation builder method on the client which constructs a request</li>
<li>The user sends the request by awaiting the <code>send()</code> method</li>
<li>The smithy client creates a new <code>Service</code> and attaches a copy of its retry policy</li>
<li>The <code>Service</code> is <code>call</code>ed, sending out the request and retrying it according to the retry policy</li>
</ol>
<p>These changes will be made in such a way that they enable us to add the "adaptive" retry behavior at a later date without introducing a breaking change.</p>
<h2 id="changes-checklist-3"><a class="header" href="#changes-checklist-3">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create new Kotlin decorator <code>RetryConfigDecorator</code>
<ul>
<li>Based on <a href="https://github.com/smithy-lang/smithy-rs/blob/main/aws/sdk-codegen/src/main/kotlin/software/amazon/smithy/rustsdk/RegionDecorator.kt">RegionDecorator.kt</a></li>
<li>This decorator will live in the <code>codegen</code> project because it has relevance outside the SDK</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
<strong>Breaking changes:</strong>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>aws_smithy_client::retry::Config</code> to <code>StandardRetryConfig</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>aws_smithy_client::retry::Config::with_max_retries</code> method to <code>with_max_attempts</code> in order to follow AWS convention</li>
<li><input disabled="" type="checkbox" checked=""/>
Passing 0 to <code>with_max_attempts</code> will panic with a helpful, descriptive error message</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Create non-exhaustive <code>aws_types::retry_config::RetryConfig</code> enum wrapping structs that represent specific retry behaviors
<ul>
<li><input disabled="" type="checkbox" checked=""/>
A <code>NoRetry</code> variant that disables retries. Doesn't wrap a struct since it doesn't need to contain any data</li>
<li><input disabled="" type="checkbox" checked=""/>
A <code>Standard</code> variant that enables the standard retry behavior. Wraps a <code>StandardRetryConfig</code> struct.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>aws_config::meta::retry_config::RetryConfigProviderChain</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>aws_config::meta::retry_config::ProvideRetryConfig</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>EnvironmentVariableMaxAttemptsProvider</code> struct
<ul>
<li>Setting AWS_MAX_ATTEMPTS=0 and trying to load from env will panic with a helpful, descriptive error message</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>retry_config</code> method to <code>aws_config::ConfigLoader</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>AwsFluentClientDecorator</code> to correctly configure the max retry attempts of its inner <code>aws_hyper::Client</code> based on the passed-in <code>Config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add tests
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Test that setting retry_config to 1 disables retries</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that setting retry_config to <code>n</code> limits retries to <code>n</code> where <code>n</code> is a non-zero integer</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that correct precedence is respected when overriding retry behavior in a service-specific config</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that correct precedence is respected when overriding retry behavior in a shared config</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that creating a config from env if AWS_MAX_ATTEMPTS=0 will panic with a helpful, descriptive error message</li>
<li><input disabled="" type="checkbox" checked=""/>
Test that setting invalid <code>max_attempts=0</code> with a <code>StandardRetryConfig</code> will panic with a helpful, descriptive error message</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-smithy-rust-service-framework"><a class="header" href="#rfc-smithy-rust-service-framework">RFC: Smithy Rust Service Framework</a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>The Rust Smithy Framework is a full-fledged service framework whose main
responsibility is to handle request lifecycles from beginning to end. It takes
care of input de-serialization, operation execution, output serialization,
error handling, and provides facilities to fulfill the requirements below.</p>
<h2 id="requirements"><a class="header" href="#requirements">Requirements</a></h2>
<h3 id="smithy-model-driven-code-generation"><a class="header" href="#smithy-model-driven-code-generation">Smithy model-driven code generation</a></h3>
<p>Server side code is generated from Smithy models and implements operations,
input and output structures, and errors defined in the service model.</p>
<h3 id="performance"><a class="header" href="#performance">Performance</a></h3>
<p>This new framework is built with performance in mind. It refrains from
allocating memory when not needed and tries to use a majority of
<a href="https://doc.rust-lang.org/std/borrow/trait.Borrow.html">borrowed</a> types,
handling their memory lifetimes so that a request body can be stored in memory
only once and not
<a href="https://doc.rust-lang.org/std/clone/trait.Clone.html">cloned</a> if possible.</p>
<p>The code is implemented on solid and widely used foundations. It uses
<a href="https://hyper.rs/">Hyper</a> to handle the HTTP requests, the
<a href="https://tokio.rs/">Tokio</a> ecosystem for asynchronous (non-blocking) operations
and <a href="https://docs.rs/tower/">Tower</a> to implement middleware such as timeouts,
rate limiting, retries, and more. CPU intensive operations are scheduled on a
separated thread-pool to avoid blocking the event loop.</p>
<p>It uses Tokio <a href="https://tokio.rs/blog/2021-07-announcing-axum">axum</a>, an HTTP
framework built on top of the technologies mentioned above which handles
routing, request extraction, response building, and workers lifecycle. Axum is
a relatively thin layer on top of Hyper and adds very little overhead, so its
<a href="https://github.com/programatik29/rust-web-benchmarks/blob/master/results/hello-world.md">performance is comparable</a>
to Hyper.</p>
<p>The framework should allow customers to use the built-in HTTP server or
select other transport implementations that can be more performant or better
suited than HTTP for their use case.</p>
<h3 id="extensibility"><a class="header" href="#extensibility">Extensibility</a></h3>
<p>We want to deliver an extensible framework that can plugin components possibly
during code generation and at runtime for specific scenarios that cannot be
covered during generation. These components are developed using a standard
<a href="https://doc.rust-lang.org/book/ch10-02-traits.html">interface</a> provided by the
framework itself.</p>
<h3 id="observability"><a class="header" href="#observability">Observability</a></h3>
<p>Being able to report and trace the status of the service is vital for the
success of any product. The framework is integrated with tracing and allows
non-blocking I/O through the asynchronous
<a href="https://tracing.rs/tracing_appender/index.html#non-blocking-writer">tracing appender</a>.</p>
<p>Metrics and logging are built with extensibility in mind, allowing customers to
plug their own handlers following a well defined interface provided by the
framework.</p>
<h3 id="client-generation"><a class="header" href="#client-generation">Client generation</a></h3>
<p>Client generation is deferred to the various Smithy implementations.</p>
<h3 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h3>
<p>Benchmarking the framework is key and customers can't use anything that
compromises the fundamental business objectives of latency and performance.</p>
<h3 id="model-validation"><a class="header" href="#model-validation">Model validation</a></h3>
<p>The generated service code is responsible for validating the model constraints of input structures.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-service-specific-middleware"><a class="header" href="#rfc-service-specific-middleware">RFC: Service-specific middleware</a></h1>
<blockquote>
<p>Status: <a href="https://github.com/smithy-lang/smithy-rs/pull/959">Implemented</a></p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0006_service_specific_middleware.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Currently, all services use a centralized <code>AwsMiddleware</code> that is defined in the (poorly named) <code>aws-hyper</code> crate. This
poses a number of long term risks and limitations:</p>
<ol>
<li>When creating a Smithy Client directly for a given service, customers are forced to implicitly assume that the
service uses stock <code>AwsMiddleware</code>. This prevents us from <em>ever</em> changing the middleware stack for a service in the
future.</li>
<li>It is impossible / impractical in the current situation to alter the middleware stack for a given service. For
services like S3, we will almost certainly want to customize endpoint middleware in a way that is currently
impossible.</li>
</ol>
<p>In light of these limitations, this RFC proposes moving middleware into each generated service. <code>aws-inlineable</code> will be
used to host and test the middleware stack. Each service will then define a public <code>middleware</code> module containing their
middleware stack.</p>
<h2 id="terminology-4"><a class="header" href="#terminology-4">Terminology</a></h2>
<ul>
<li><strong>Middleware</strong>: A tower layer that augments <code>operation::Request -&gt; operation::Response</code> for things like signing and
endpoint resolution.</li>
<li><strong>Aws Middleware</strong>: A specific middleware stack that meets the requirements for AWS services.</li>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together the
connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it. A fluent
builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that defaults to using a <code>DynConnector</code>, <code>AwsMiddleware</code>, and <code>Standard</code>
retry policy.</li>
<li><strong>Shared Config</strong>: An <code>aws_types::Config</code> struct that is responsible for storing shared configuration data that is
used across all services. This is not generated and lives in the <code>aws-types</code> crate.</li>
<li><strong>Service-specific Config</strong>: A code-generated <code>Config</code> that has methods for setting service-specific configuration.
Each <code>Config</code> is defined in the <code>config</code> module of its parent service. For example, the S3-specific config struct
is <code>use</code>able from <code>aws_sdk_s3::config::Config</code> and re-exported as <code>aws_sdk_s3::Config</code>.</li>
</ul>
<h1 id="detailed-design"><a class="header" href="#detailed-design">Detailed Design</a></h1>
<p>Currently, <code>AwsMiddleware</code> is defined in <code>aws-hyper</code>. As part of this change, an <code>aws-inlineable</code> dependency will be
added containing code that is largely identical. This will be exposed in a public <code>middleware</code> module in all generated
services. At some future point, we could even expose a baseline set of default middleware for whitelabel Smithy services
to make them easier to use out-of-the-box.</p>
<p>The <code>ClientGenerics</code> parameter of the <code>AwsFluentClientGenerator</code> will be updated to become a <code>RuntimeType</code>, enabling
loading the type directly. This has the advantage of making it fairly easy to do per-service middleware stacks since we
can easily configure <code>AwsFluentClientGenerator</code> to insert different types based on the service id.</p>
<h1 id="changes-checklist-4"><a class="header" href="#changes-checklist-4">Changes Checklist</a></h1>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Move aws-hyper into aws-inlineable. Update comments as needed including with a usage example about how customers can augment it.</li>
<li><input disabled="" type="checkbox" checked=""/>
Refactor <code>ClientGenerics</code> to contain a RuntimeType instead of a string and configure. Update <code>AwsFluentClientDecorator</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update all code and examples that use <code>aws-hyper</code> to use service-specific middleware.</li>
<li><input disabled="" type="checkbox" checked=""/>
Push an updated README to aws-hyper deprecating the package, explaining what happened. Do <em>not</em> yank previous versions since those will be relied on by older SDK versions.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-split-release-process"><a class="header" href="#rfc-split-release-process">RFC: Split Release Process</a></h1>
<blockquote>
<p>Status: Implemented in <a href="https://github.com/smithy-lang/smithy-rs/pull/986">smithy-rs#986</a> and <a href="https://github.com/awslabs/aws-sdk-rust/pull/351">aws-sdk-rust#351</a></p>
</blockquote>
<p>At the time of writing, the <code>aws-sdk-rust</code> repository is used exclusively
for the entire release process of both the Rust runtime crates from <code>smithy-rs</code> as
well as the AWS runtime crates and the AWS SDK. This worked well when <code>smithy-rs</code> was
only used for the AWS SDK, but now that it's also used for server codegen, there
are issues around publishing the server-specific runtime crates since they don't
belong to the SDK.</p>
<p>This RFC proposes a new split-release process so that the entire <code>smithy-rs</code> runtime
can be published separately before the AWS SDK is published.</p>
<h2 id="terminology-5"><a class="header" href="#terminology-5">Terminology</a></h2>
<ul>
<li><strong>Smithy Runtime Crate</strong>: A crate that gets published to crates.io and supports
the code generated by <code>smithy-rs</code>. These crates don't provide any SDK-only functionality.
These crates can support client and/or server code, and clients or servers may use
only a subset of them.</li>
<li><strong>AWS Runtime Crate</strong>: A crate of SDK-specific code that supports the code generated
by the <code>aws/codegen</code> module in <code>smithy-rs</code>. These also get published to crates.io.</li>
<li><strong>Publish-ready Bundle</strong>: A build artifact that is ready to publish to crates.io without
additional steps (such as running the publisher tool's <code>fix-manifests</code> subcommand). Publishing
one group of crates before another is not considered an additional step for this definition.</li>
<li><strong>Releaser</strong>: A developer, automated process, or combination of the two that performs the actual release.</li>
</ul>
<h2 id="requirements-1"><a class="header" href="#requirements-1">Requirements</a></h2>
<p>At a high level, the requirements are: publish from both <code>smithy-rs</code> and <code>aws-sdk-rust</code>
while preserving our current level of confidence in the quality of the release. This
can be enumerated as:</p>
<ol>
<li>All Smithy runtime crates must be published together from <code>smithy-rs</code></li>
<li>AWS runtime crates and the SDK must be published together from <code>aws-sdk-rust</code></li>
<li>CI on <code>smithy-rs</code> must give confidence that the Smithy runtime crates,
AWS runtime crates, and SDK are all at the right quality bar for publish.</li>
<li>CI on the <code>aws-sdk-rust</code> repository must give confidence that the AWS SDK and its
runtime crates are at the right quality bar for publish. To do this successfully,
it must run against the exact versions of the Smithy runtime crates the code was
generated against <em>both before AND after they have been published to crates.io</em>.</li>
</ol>
<h2 id="background-how-publishing-worked-before"><a class="header" href="#background-how-publishing-worked-before">Background: How Publishing Worked Before</a></h2>
<p>The publish process to crates.io relied on copying all the Smithy runtime crates
into the final <code>aws-sdk-rust</code> repository. Overall, the process looked as follows:</p>
<ol>
<li><code>smithy-rs</code> generates a complete <code>aws-sdk-rust</code> source bundle at CI time</li>
<li>The releaser copies the generated bundle over to <code>aws-sdk-rust</code></li>
<li>The releaser runs the <code>publisher fix-manifests</code> subcommand to correct the
<code>Cargo.toml</code> files generated by <code>smithy-rs</code></li>
<li>The <code>aws-sdk-rust</code> CI performs one last pass on the code to verify it's sound</li>
<li>The releaser runs the <code>publisher publish</code> subcommand to push all the crates up to crates.io</li>
</ol>
<h2 id="proposed-solution"><a class="header" href="#proposed-solution">Proposed Solution</a></h2>
<p>CI in <code>smithy-rs</code> will be revised to generate two separate build artifacts where it generates
just an SDK artifact previously. Now, it will have two build targets that get executed from CI
to generate these artifacts:</p>
<ul>
<li><code>rust-runtime:assemble</code> - Generates a publish-ready bundle of Smithy runtime crates.</li>
<li><code>aws:sdk:assemble</code> - Generates a publish-ready bundle of AWS runtime crates, SDK crates,
and just the Smithy runtime crates that are used by the SDK.</li>
</ul>
<p>The <code>aws-sdk-rust</code> repository will have a new <code>next</code> branch that has its own set of CI workflows
and branch protection rules. The releaser will take the <code>aws:sdk:assemble</code> artifact and apply it
directly to this <code>next</code> branch as would have previously been done against the <code>main</code> branch.
The <code>main</code> branch will continue to have the same CI as <code>next</code>.</p>
<p>When it's time to cut a release, the releaser will do the following:</p>
<ol>
<li>Tag <code>smithy-rs</code> with the desired version number</li>
<li>Wait for CI to build artifacts for the tagged release</li>
<li>Pull-request the SDK artifacts over to <code>aws-sdk-rust/next</code> (this will be automated in the future)</li>
<li>Pull-request merge <code>aws-sdk-rust/next</code> into <code>aws-sdk-rust/main</code></li>
<li>Wait for successful CI in <code>main</code></li>
<li>Tag release for <code>main</code></li>
<li>Publish SDK with publisher tool</li>
</ol>
<p>The server team can then download the <code>rust-runtime:assemble</code> build artifact for the tagged release
in <code>smithy-rs</code>, and publish the <code>aws-smithy-http-server</code> crate from there.</p>
<h3 id="avoiding-mistakes-by-disallowing-creation-of-publish-ready-bundles-outside-of-ci"><a class="header" href="#avoiding-mistakes-by-disallowing-creation-of-publish-ready-bundles-outside-of-ci">Avoiding mistakes by disallowing creation of publish-ready bundles outside of CI</a></h3>
<p>It should be difficult to accidentally publish a locally built set of crates. To add friction to this,
the <code>smithy-rs</code> build process will look for the existence of the <code>GITHUB_ACTIONS=true</code> environment variable.
If this environment variable is not set, then it will pass a flag to the Rust codegen plugin that tells it to
emit a <code>publish = false</code> under <code>[package]</code> in the generated <code>Cargo.toml</code>.</p>
<p>This could be easily circumvented, but the goal is to reduce the chances of accidentally publishing
crates rather than making it impossible.</p>
<h2 id="alternatives-considered"><a class="header" href="#alternatives-considered">Alternatives Considered</a></h2>
<h3 id="publish-smithy-runtime-crates-from-smithy-rs-build-artifacts"><a class="header" href="#publish-smithy-runtime-crates-from-smithy-rs-build-artifacts">Publish Smithy runtime crates from <code>smithy-rs</code> build artifacts</a></h3>
<p>This approach is similar to the proposed solution, except that the SDK would not publish
the Smithy runtime crates. The <code>aws-sdk-rust/main</code> branch would have a small tweak to its CI
so that the SDK is tested against the Smithy runtime crates that are published to crates.io
This CI process would look as follows:</p>
<ol>
<li>Shallow clone <code>aws-sdk-rust</code> with the revision being tested</li>
<li>Run a script to remove the <code>path</code> argument for the Smithy runtime crate dependencies for every crate
in <code>aws-sdk-rust</code>. For example,</li>
</ol>
<pre><code class="language-toml">aws-smithy-types = { version = "0.33.0", path = "../aws-smithy-types" }
</code></pre>
<p>Would become:</p>
<pre><code class="language-toml">aws-smithy-types = { version = "0.33.0" }
</code></pre>
<ol start="3">
<li>Run the tests as usual</li>
</ol>
<p>When it's time to cut a release, the releaser will do the following:</p>
<ol>
<li>Tag <code>smithy-rs</code> with the desired version number</li>
<li>Wait for CI to build artifacts for the tagged release</li>
<li>Pull-request the SDK artifacts over to <code>aws-sdk-rust/next</code></li>
<li>Wait for successful CI in <code>aws-sdk-rust/next</code></li>
<li>Download the Smithy runtime crates build artifact and publish it to crates.io</li>
<li>Pull-request merge <code>aws-sdk-rust/next</code> into <code>aws-sdk-rust/main</code></li>
<li>Wait for successful CI in <code>main</code> (this time actually running against the crates.io Smithy runtime crates)</li>
<li>Tag release for <code>main</code></li>
<li>Publish SDK with publisher tool</li>
</ol>
<h3 id="keep-smithy-runtime-crates-in-smithy-rs"><a class="header" href="#keep-smithy-runtime-crates-in-smithy-rs">Keep Smithy runtime crates in <code>smithy-rs</code></a></h3>
<p>This approach is similar to the previous alternative, except that the <code>aws-sdk-rust</code> repository
won't have a snapshot of the Smithy runtime crates, and an additional step needs to be performed
during CI for the <code>next</code> branch so that it looks as follows:</p>
<ol>
<li>Make a shallow clone of <code>aws-sdk-rust/next</code></li>
<li>Retrieve the <code>smithy-rs</code> commit hash that was used to generate the SDK from a file
that was generated alongside the rest of the build artifacts from <code>smithy-rs</code> and
copied into <code>aws-sdk-rust</code>.</li>
<li>Make a shallow clone of <code>smithy-rs</code> at the correct commit hash</li>
<li>Use a script to add a <code>[patch]</code> section to all the AWS SDK crates to point to the
Smithy runtime crates from the local clone of <code>smithy-rs</code>.
For example:</li>
</ol>
<pre><code class="language-toml"># The dependencies section is left alone, but is here for context
[dependencies]
# Some version of aws-smithy-types that isn't on crates.io yet, referred to as `&lt;unreleased&gt;` below
aws-smithy-types = "&lt;unreleased&gt;"

# This patch section gets added by the script
[patch.crates-io]
aws-smithy-types = { version = "&lt;unreleased&gt;", path = "path/to/local/smithy-rs/rust-runtime/aws-smithy-types"}
</code></pre>
<ol start="5">
<li>Run CI as normal.</li>
</ol>
<p><strong>Note:</strong> <code>smithy-rs</code> would need to do the same patching in CI as <code>aws-sdk-rust/next</code> since the generated
SDK would not have path dependencies for the Smithy runtime crates (since they are a publish-ready bundle
intended for landing in <code>aws-sdk-rust</code>). The script that does this patching could live in <code>smithy-rs</code> and be
reused by <code>aws-sdk-rust</code>.</p>
<p>The disadvantage of this approach is that a customer having an issue with the current release wouldn't be able
to get a fix sooner by patching their own project's crate manifest to use the <code>aws-sdk-rust/next</code> branch before
a release is cut since their project wouldn't be able to find the unreleased Smithy runtime crates.</p>
<h2 id="changes-checklist-5"><a class="header" href="#changes-checklist-5">Changes Checklist</a></h2>
<ul>
<li>In <code>smithy-rs</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Move publisher tool from <code>aws-sdk-rust</code> into <code>smithy-rs</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Modify <code>aws:sdk:assemble</code> target to run the publisher <code>fix-manifests</code> subcommand</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>rust-runtime:assemble</code> target that generates publish-ready Smithy runtime crates</li>
<li><input disabled="" type="checkbox" checked=""/>
Add CI step to create Smithy runtime bundle artifact</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>GITHUB_ACTIONS=true</code> env var check for setting the <code>publish</code> flag in generated AND runtime manifests</li>
<li><input disabled="" type="checkbox" checked=""/>
Revise publisher tool to publish from an arbitrary directory</li>
</ul>
</li>
<li>In <code>aws-sdk-rust</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement CI for the <code>aws-sdk-rust/next</code> branch</li>
<li><input disabled="" type="checkbox" checked=""/>
Remove the publisher tool</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Update release process documentation</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>Smithy <a href="https://awslabs.github.io/smithy/1.0/spec/core/behavior-traits.html#paginated-trait">models paginated responses</a>
. Customers of Smithy generated code &amp; the Rust SDK will have an improved user experience if code is generated to
support this. Fundamentally, paginators are a way to automatically make a series of requests with the SDK, where subsequent
requests automatically forward output from the previous responses. There is nothing a paginator does that a user could not do manually,
they merely simplify the common task of interacting with paginated APIs. **Specifically, a paginator will resend the orginal request
but with <code>inputToken</code> updated to the value of the previous <code>outputToken</code>.</p>
<p>In this RFC, we propose modeling paginated data as
a  <a href="https://docs.rs/tokio-stream/0.1.5/tokio_stream/#traits"><code>Stream</code></a> of output shapes.</p>
<ul>
<li>When an output is paginated, a <code>paginate()</code> method will be added to the high level builder</li>
<li>An <code>&lt;OperationName&gt;Paginator</code> struct will be generated into the <code>paginator</code> module.</li>
<li>If <code>items</code> is modeled, <code>paginate().items()</code> will be added to produce the paginated
items. <code>&lt;OperationName&gt;PaginatorItems</code> will be generated into the <code>paginator</code> module.</li>
</ul>
<p>The <a href="https://docs.rs/tokio-stream/latest/tokio_stream/index.html"><code>Stream</code></a> trait enables customers to use a number of
abstractions including simple looping, and <code>collect()</code>ing all data in a single call. A paginator will resend the
original input, but with the field marked <code>inputToken</code> to the value of <code>outputToken</code> in the previous output.</p>
<p>Usage example:</p>
<pre><code class="language-rust ignore">let paginator = client
    .list_tables()
    .paginate()
    .items()
    .page_size(10)
    .send()
    .await;
let tables: Result&lt;Vec&lt;_ &gt;, _ &gt; = paginator.collect().await;</code></pre>
<p>Paginators are lazy and only retrieve pages when polled by a client.</p>
<h3 id="details"><a class="header" href="#details">Details</a></h3>
<p>Paginators will be generated into the <code>paginator</code> module of service crates. Currently, paginators are <em>not</em> feature gated, but this
could be considered in the future. A <code>paginator</code> struct captures 2 pieces of data:</p>
<pre><code class="language-rust ignore">// dynamodb/src/paginator.rs
struct ListTablesPaginator&lt;C, M, R&gt; {
    // holds the low-level client and configuration
    handle: Arc&lt;Handle&lt;C, M, R&gt;&gt;,

    // input builder to construct the actual input on demand
    input: ListTablesInputBuilder
}</code></pre>
<p>In addition to the basic usage example above, when <code>pageSize</code> is modeled, customers can specify the page size during
pagination:</p>
<pre><code class="language-rust ignore">let mut tables = vec![];
let mut pages = client
    .list_tables()
    .paginate()
    .page_size(20)
    .send();
while let Some(next_page) = pages.try_next().await? {
    // pages of 20 items requested from DynamoDb
    tables.extend(next_page.table_names.unwrap_or_default().into_iter());
}</code></pre>
<p>Paginators define a public method <code>send()</code>. This method
returns <code>impl Stream&lt;Item=Result&lt;OperationOutput, OperationError&gt;</code>. This uses <code>FnStream</code> defined in the <code>aws-smithy-async</code> crate which
enables demand driven execution of a closure. A rendezvous channel is used which will block on <code>send</code> until demand exists.</p>
<p>When modeled by Smithy, <code>page_size</code> which automatically sets the appropriate page_size parameter and <code>items()</code> which returns an
automatically flattened paginator are also generated. <strong>Note</strong>: <code>page_size</code> directly sets the modeled parameter on the internal builder.
This means that a value set for page size will override any previously set value for that field.</p>
<pre><code class="language-rust ignore">// Generated paginator for ListTables
impl&lt;C, M, R&gt; ListTablesPaginator&lt;C, M, R&gt;
{
  /// Set the page size
  pub fn page_size(mut self, limit: i32) -&gt; Self {
    self.builder.limit = Some(limit);
    self
  }

  /// Create a flattened paginator
  ///
  /// This paginator automatically flattens results using `table_names`. Queries to the underlying service
  /// are dispatched lazily.
  pub fn items(self) -&gt; crate::paginator::ListTablesPaginatorItems&lt;C, M, R&gt; {
    crate::paginator::ListTablesPaginatorItems(self)
  }

  /// Create the pagination stream
  ///
  /// _Note:_ No requests will be dispatched until the stream is used (eg. with [`.next().await`](tokio_stream::StreamExt::next)).
  pub async fn send(
    self,
  ) -&gt; impl tokio_stream::Stream&lt;
    Item = std::result::Result&lt;
      crate::output::ListTablesOutput,
      aws_smithy_http::result::SdkError&lt;crate::error::ListTablesError&gt;,
    &gt;,
  &gt; + Unpin
  {
    // Move individual fields out of self for the borrow checker
    let builder = self.builder;
    let handle = self.handle;
    fn_stream::FnStream::new(move |tx| {
      Box::pin(async move {
        // Build the input for the first time. If required fields are missing, this is where we'll produce an early error.
        let mut input = match builder.build().map_err(|err| {
          SdkError::ConstructionFailure(err.into())
        }) {
          Ok(input) =&gt; input,
          Err(e) =&gt; {
            let _ = tx.send(Err(e)).await;
            return;
          }
        };
        loop {
          let op = match input.make_operation(&amp;handle.conf).await.map_err(|err| {
            SdkError::ConstructionFailure(err.into())
          }) {
            Ok(op) =&gt; op,
            Err(e) =&gt; {
              let _ = tx.send(Err(e)).await;
              return;
            }
          };
          let resp = handle.client.call(op).await;
          // If the input member is None or it was an error
          let done = match resp {
            Ok(ref resp) =&gt; {
              input.exclusive_start_table_name = crate::lens::reflens_structure_crate_output_list_tables_output_last_evaluated_table_name(resp).cloned();
              input.exclusive_start_table_name.is_none()
            }
            Err(_) =&gt; true,
          };
          if let Err(_) = tx.send(resp).await {
            // receiving end was dropped
            return;
          }
          if done {
            return;
          }
        }
      })
    })
  }
}</code></pre>
<p><strong>On Box::pin</strong>: The stream returned by <code>AsyncStream</code> does not implement <code>Unpin</code>. Unfortunately, this makes iteration
require an invocation of <code>pin_mut!</code> and generates several hundred lines of compiler errors. Box::pin seems a worthwhile
trade off to improve the user experience.</p>
<p><strong>On the <code>+ Unpin</code> bound</strong>: Because auto-traits leak across <code>impl Trait</code> boundaries, <code>+ Unpin</code> prevents accidental
regressions in the generated code which would break users.</p>
<p><strong>On the crate::reflens::...</strong>: We use <code>LensGenerator.kt</code> to generate potentially complex accessors to deeply nested fields.</p>
<h3 id="updates-to-ergonomic-clients"><a class="header" href="#updates-to-ergonomic-clients">Updates to ergonomic clients</a></h3>
<p>The <code>builders</code> generated by ergonomic clients will gain the following method, if they represent an operation that implements the <code>Paginated</code> trait:</p>
<pre><code class="language-rust ignore">/// Create a paginator for this request
///
/// Paginators are used by calling [`send().await`](crate::paginator::ListTablesPaginator::send) which returns a [`Stream`](tokio_stream::Stream).
pub fn paginate(self) -&gt; crate::paginator::ListTablesPaginator&lt;C, M, R&gt; {
  crate::paginator::ListTablesPaginator::new(self.handle, self.inner)
}</code></pre>
<h2 id="discussion-areas"><a class="header" href="#discussion-areas">Discussion Areas</a></h2>
<h3 id="on-sendawait"><a class="header" href="#on-sendawait">On <code>send().await</code></a></h3>
<p>Calling <code>send().await</code> is not necessary from an API perspective—we could have the paginators impl-stream directly. However,
it enables using <code>impl Trait</code> syntax and also makes the API consistent with other SDK APIs.</p>
<h3 id="on-tokio_streamstream"><a class="header" href="#on-tokio_streamstream">On <code>tokio_stream::Stream</code></a></h3>
<p>Currently, the core trait we use is <code>tokio_stream::Stream</code>. This is a re-export from futures-util. There are a few other choices:</p>
<ol>
<li>Re-export <code>Stream</code> from tokio_stream.</li>
<li>Use <code>futures_util</code> directly</li>
</ol>
<h3 id="on-generics"><a class="header" href="#on-generics">On Generics</a></h3>
<p>Currently, the paginators forward the generics from the client (<code>C, M, R</code>) along with their fairly annoying bounds.
However, if we wanted to we <em>could</em> simplify this and erase all the generics when the paginator was created. Since everything
is code generated, there isn't actually much duplicated code in the generator, just in the generated code.</p>
<h2 id="changes-checklist-6"><a class="header" href="#changes-checklist-6">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create and test <code>FnStream</code> abstraction</li>
<li><input disabled="" type="checkbox" checked=""/>
Generate page-level paginators</li>
<li><input disabled="" type="checkbox" checked=""/>
Generate <code>.items()</code> paginators</li>
<li><input disabled="" type="checkbox" checked=""/>
Generate doc hints pointing people to paginators</li>
<li><input disabled="" type="checkbox" checked=""/>
Integration test using mocked HTTP traffic against a generated paginator for a real service</li>
<li><input disabled="" type="checkbox"/>
Integration test using real traffic</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-examples-consolidation"><a class="header" href="#rfc-examples-consolidation">RFC: Examples Consolidation</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>Currently, the AWS Rust SDK's examples are duplicated across
<a href="https://github.com/awslabs/aws-sdk-rust"><code>awslabs/aws-sdk-rust</code></a>,
<a href="https://github.com/smithy-lang/smithy-rs"><code>smithy-lang/smithy-rs</code></a>,
and <a href="https://github.com/awsdocs/aws-doc-sdk-examples"><code>awsdocs/aws-doc-sdk-examples</code></a>.
The <code>smithy-rs</code> repository was formerly the source of truth for examples,
with the examples being copied over to <code>aws-sdk-rust</code> as part of the release
process, and examples were manually copied over to <code>aws-doc-sdk-examples</code> so that
they could be included in the developer guide.</p>
<p>Now that the SDK is more stable with less frequent breaking changes,
the <code>aws-doc-sdk-examples</code> repository can become the source of truth
so long as the examples are tested against <code>smithy-rs</code> and continue to be
copied into <code>aws-sdk-rust</code>.</p>
<h2 id="requirements-2"><a class="header" href="#requirements-2">Requirements</a></h2>
<ol>
<li>Examples are authored and maintained in <code>aws-doc-sdk-examples</code></li>
<li>Examples are no longer present in <code>smithy-rs</code></li>
<li>CI in <code>smithy-rs</code> checks out examples from <code>aws-doc-sdk-examples</code> and
builds them against the generated SDK. Success for this CI job is optional for merging
since there can be a time lag between identifying that examples are broken and fixing them.</li>
<li>Examples must be copied into <code>aws-sdk-rust</code> so that the examples for a specific
version of the SDK can be easily referenced.</li>
<li>Examples must be verified in <code>aws-sdk-rust</code> prior to merging into the <code>main</code> branch.</li>
</ol>
<h2 id="example-ci-in-smithy-rs"><a class="header" href="#example-ci-in-smithy-rs">Example CI in <code>smithy-rs</code></a></h2>
<p>A CI job will be added to <code>smithy-rs</code> that:</p>
<ol>
<li>Depends on the CI job that generates the full AWS SDK</li>
<li>Checks out the <code>aws-doc-sdk-examples</code> repository</li>
<li>Modifies example <strong>Cargo.toml</strong> files to point to the newly generated AWS SDK crates</li>
<li>Runs <code>cargo check</code> on each example</li>
</ol>
<p>This job will not be required to pass for branch protection, but will
let us know that examples need to be updated before the next release.</p>
<h2 id="auto-sync-to-aws-sdk-rust-from-smithy-rs-changes"><a class="header" href="#auto-sync-to-aws-sdk-rust-from-smithy-rs-changes">Auto-sync to <code>aws-sdk-rust</code> from <code>smithy-rs</code> changes</a></h2>
<p>The auto-sync job that copies generated code from <code>smithy-rs</code> into the
<code>aws-sdk-rust/next</code> branch will be updated to check out the <code>aws-doc-sdk-examples</code>
repository and copy the examples into <code>aws-sdk-rust</code>. The example <strong>Cargo.toml</strong> files
will also be updated to point to the local crate paths as part of this process.</p>
<p>The <code>aws-sdk-rust</code> CI already requires examples to compile, so merging <code>next</code> into <code>main</code>,
the step required to perform a release, will be blocked until the examples are fixed.</p>
<p>In the event the examples don't work on the <code>next</code> branch, developers and example writers
will need to be able to point the examples in <code>aws-doc-sdk-examples</code> to the generated
SDK in <code>next</code> so that they can verify their fixes. This can be done by hand, or a tool
can be written to automate it if a significant number of examples need to be fixed.</p>
<h2 id="process-risks"><a class="header" href="#process-risks">Process Risks</a></h2>
<p>There are a couple of risks with this approach:</p>
<ol>
<li>
<p><strong>Risk:</strong> Examples are broken and an urgent fix needs to be released.</p>
<p><strong>Possible mitigations:</strong></p>
<ol>
<li>Revert the change that broke the examples and then add the urgent fix</li>
<li>Create a patch branch in <code>aws-sdk-rust</code>, apply the fix to that based off an older
version of <code>smithy-rs</code> with the fix applied, and merge that into <code>main</code>.</li>
</ol>
</li>
<li>
<p><strong>Risk:</strong> A larger project requires changes to examples prior to GA, but multiple releases
need to occur before the project completion.</p>
<p><strong>Possible mitigations:</strong></p>
<ol>
<li>If the required changes compile against the older SDK, then just make the changes
to the examples.</li>
<li>Feature gate any incremental new functionality in <code>smithy-rs</code>, and work on example
changes on a branch in <code>aws-doc-sdk-examples</code>. When wrapping up the project,
remove the feature gating and merge the examples into the <code>main</code> branch.</li>
</ol>
</li>
</ol>
<h2 id="alternatives"><a class="header" href="#alternatives">Alternatives</a></h2>
<h3 id="aws-sdk-rust-as-the-source-of-truth"><a class="header" href="#aws-sdk-rust-as-the-source-of-truth"><code>aws-sdk-rust</code> as the source of truth</a></h3>
<p>Alternatively, the examples could reside in <code>aws-sdk-rust</code>, be referenced
from <code>smithy-rs</code> CI, and get copied into <code>aws-doc-sdk-examples</code> for inclusion
in the user guide.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Prior to GA, fixing examples after making breaking changes to the SDK would be easier.
Otherwise, <strong>Cargo.toml</strong> files have to be temporarily modified to point to the
<code>aws-sdk-rust/next</code> branch in order to make fixes.</li>
<li>If a customer discovers examples via the <code>aws-sdk-rust</code> repository rather than via the
SDK user guide, then it would be more obvious how to make changes to examples. At time
of writing, the examples in the user guide link to the <code>aws-doc-sdk-examples</code> repository,
so if the examples are discovered that way, then updating them should already be clear.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Tooling would need to be built to sync examples from <code>aws-sdk-rust</code> into
<code>aws-doc-sdk-examples</code> so that they could be incorporated into the user guide.</li>
<li>Creates a circular dependency between the <code>aws-sdk-rust</code> and <code>smithy-rs</code> repositories.
CI in <code>smithy-rs</code> needs to exercise examples, which would be in <code>aws-sdk-rust</code>, and
<code>aws-sdk-rust</code> has its code generated by <code>smithy-rs</code>. This is workable, but may lead
to problems later on.</li>
</ul>
<p>The tooling to auto-sync from <code>aws-sdk-rust</code> into <code>aws-doc-sdk-examples</code> will likely cost
more than tooling to temporarily update <strong>Cargo.toml</strong> files to make example fixes (if
that tooling is even necessary).</p>
<h2 id="changes-checklist-7"><a class="header" href="#changes-checklist-7">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add example CI job to <code>smithy-rs</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Diff examples in <code>smithy-rs</code> and <code>aws-doc-sdk-examples</code> and move desired differences into <code>aws-doc-sdk-examples</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Apply example fix PRs from <code>aws-sdk-rust</code> into <code>aws-doc-sdk-examples</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>smithy-rs</code> CI to copy examples from <code>aws-doc-sdk-examples</code> rather than from smithy-rs</li>
<li><input disabled="" type="checkbox" checked=""/>
Delete examples from <code>smithy-rs</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-waiters"><a class="header" href="#rfc-waiters">RFC: Waiters</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>Waiters are a convenient polling mechanism to wait for a resource to become available or to
be deleted. For example, a waiter could be used to wait for a S3 bucket to be created after
a call to the <code>CreateBucket</code> API, and this would only require a small amount of code rather
than building out an entire polling mechanism manually.</p>
<p>At the highest level, a waiter is a simple polling loop (pseudo-Rust):</p>
<pre><code class="language-rust ignore">// Track state that contains the number of attempts made and the previous delay
let mut state = initial_state();

loop {
    // Poll the service
    let result = poll_service().await;

    // Classify the action that needs to be taken based on the Smithy model
    match classify(result) {
        // If max attempts hasn't been exceeded, then retry after a delay. Otherwise, error.
        Retry =&gt; if state.should_retry() {
            let delay = state.next_retry();
            sleep(delay).await;
        } else {
            return error_max_attempts();
        }
        // Otherwise, if the termination condition was met, return the output
        Terminate(result) =&gt; return result,
    }
}</code></pre>
<p>In the AWS SDK for Rust, waiters can be added without making any backwards breaking changes
to the current API. This doc outlines the approach to add them in this fashion, but does <em>NOT</em>
examine code generating response classification from JMESPath expressions, which can be left
to the implementer without concern for the overall API.</p>
<h2 id="terminology-6"><a class="header" href="#terminology-6">Terminology</a></h2>
<p>Today, there are three layers of <code>Client</code> that are easy to confuse, so to make the following easier to follow,
the following terms will be used:</p>
<ul>
<li><strong>Connector</strong>: An implementor of Tower's <code>Service</code> trait that converts a request into a response. This is typically
a thin wrapper around a Hyper client.</li>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy. This isn't intended to be used directly.</li>
<li><strong>Fluent Client</strong>: A code generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that uses a <code>DynConnector</code>, <code>DefaultMiddleware</code>,
and <code>Standard</code> retry policy.</li>
</ul>
<p>All of these are just called <code>Client</code> in code today. This is something that could be clarified in a separate refactor.</p>
<h2 id="requirements-3"><a class="header" href="#requirements-3">Requirements</a></h2>
<p>Waiters must adhere to the <a href="https://awslabs.github.io/smithy/1.0/spec/waiters.html">Smithy waiter specification</a>. To summarize:</p>
<ol>
<li>Waiters are specified by the Smithy <code>@waitable</code> trait</li>
<li>Retry during polling must be exponential backoff with jitter, with the min/max delay times and
max attempts configured by the <code>@waitable</code> trait</li>
<li>The SDK's built-in retry needs to be replaced by the waiter's retry since the Smithy model
can specify retry conditions that are contrary to the defaults. For example, an error that
would otherwise be retried by default might be the termination condition for the waiter.</li>
<li>Classification of the response must be code generated based on the JMESPath expression in the model.</li>
</ol>
<h2 id="waiter-api"><a class="header" href="#waiter-api">Waiter API</a></h2>
<p>To invoke a waiter, customers will only need to invoke a single function on the AWS Client. For example,
if waiting for a S3 bucket to exist, it would look like the following:</p>
<pre><code class="language-rust ignore">// Request bucket creation
client.create_bucket()
    .bucket_name("my-bucket")
    .send()
    .await()?;

// Wait for it to be created
client.wait_until_bucket_exists()
    .bucket_name("my-bucket")
    .send()
    .await?;</code></pre>
<p>The call to <code>wait_until_bucket_exists()</code> will return a waiter-specific fluent builder with a <code>send()</code> function
that will start the polling and return a future.</p>
<p>To avoid name conflicts with other API methods, the waiter functions can be added to the client via trait:</p>
<pre><code class="language-rust ignore">pub trait WaitUntilBucketExists {
    fn wait_until_bucket_exists(&amp;self) -&gt; crate::waiter::bucket_exists::Builder;
}</code></pre>
<p>This trait would be implemented for the service's fluent client (which will necessitate making the fluent client's
<code>handle</code> field <code>pub(crate)</code>).</p>
<h2 id="waiter-implementation"><a class="header" href="#waiter-implementation">Waiter Implementation</a></h2>
<p>A waiter trait implementation will merely return a fluent builder:</p>
<pre><code class="language-rust ignore">impl WaitUntilBucketExists for Client {
    fn wait_until_bucket_exists(&amp;self) -&gt; crate::waiter::bucket_exists::Builder {
        crate::waiter::bucket_exists::Builder::new()
    }
}</code></pre>
<p>This builder will have a short <code>send()</code> function to kick off the actual waiter implementation:</p>
<pre><code class="language-rust ignore">impl Builder {
    // ... existing fluent builder codegen can be reused to create all the setters and constructor

    pub async fn send(self) -&gt; Result&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt; {
        // Builds an input from this builder
        let input = self.inner.build().map_err(|err| aws_smithy_http::result::SdkError::ConstructionFailure(err.into()))?;
        // Passes in the client's handle, which contains a Smithy client and client config
        crate::waiter::bucket_exists::wait(self.handle, input).await
    }
}</code></pre>
<p>This wait function needs to, in a loop similar to the pseudo-code in the beginning,
convert the given input into an operation, replace the default response classifier on it
with a no-retry classifier, and then determine what to do next based on that classification:</p>
<pre><code class="language-rust ignore">pub async fn wait(
    handle: Arc&lt;Handle&lt;DynConnector, DynMiddleware&lt;DynConnector&gt;, retry::Standard&gt;&gt;,
    input: HeadBucketInput,
) -&gt; Result&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt; {
    loop {
        let operation = input
            .make_operation(&amp;handle.conf)
            .await
            .map_err(|err| {
                aws_smithy_http::result::SdkError::ConstructionFailure(err.into())
            })?;
        // Assume `ClassifyRetry` trait is implemented for `NeverRetry` to always return `RetryKind::Unnecessary`
        let operation = operation.with_retry_classifier(NeverRetry::new());

        let result = handle.client.call(operation).await;
        match classify_result(&amp;input, result) {
            AcceptorState::Retry =&gt; {
                // The sleep implementation is available here from `handle.conf.sleep_impl`
                unimplemented!("Check if another attempt should be made and calculate delay time if so")
            }
            AcceptorState::Terminate(output) =&gt; return output,
        }
    }
}

fn classify_result(
    input: &amp;HeadBucketInput,
    result: Result&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt;,
) -&gt; AcceptorState&lt;HeadBucketOutput, SdkError&lt;HeadBucketError&gt;&gt; {
    unimplemented!(
        "The Smithy model would dictate conditions to check here to produce an `AcceptorState`"
    )
}</code></pre>
<p>The retry delay time should be calculated by the same exponential backoff with jitter code that the
<a href="https://github.com/smithy-lang/smithy-rs/blob/main/rust-runtime/aws-smithy-client/src/retry.rs#L252-L292">default <code>RetryHandler</code> uses in <code>aws-smithy-client</code></a>. This function will need to be split up and made
available to the waiter implementations so that just the delay can be calculated.</p>
<h2 id="changes-checklist-8"><a class="header" href="#changes-checklist-8">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Codegen fluent builders for waiter input and their <code>send()</code> functions</li>
<li><input disabled="" type="checkbox"/>
Codegen waiter invocation traits</li>
<li><input disabled="" type="checkbox"/>
Commonize exponential backoff with jitter delay calculation</li>
<li><input disabled="" type="checkbox"/>
Codegen <code>wait()</code> functions with delay and max attempts configuration from Smithy model</li>
<li><input disabled="" type="checkbox"/>
Codegen <code>classify_result()</code> functions based on JMESPath expressions in Smithy model</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-publishing-the-alpha-sdk-to-cratesio"><a class="header" href="#rfc-publishing-the-alpha-sdk-to-cratesio">RFC: Publishing the Alpha SDK to Crates.io</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>The AWS SDK for Rust and its supporting Smithy crates need to be published to <a href="https://crates.io/">crates.io</a>
so that customers can include them in their projects and also publish crates of their own that depend on them.</p>
<p>This doc proposes a short-term solution for publishing to crates.io. This approach is intended to be executed
manually by a developer using scripts and an SOP no more than once per week, and should require less than a
dev week to implement.</p>
<h2 id="terminology-7"><a class="header" href="#terminology-7">Terminology</a></h2>
<ul>
<li><strong>AWS SDK Crate</strong>: A crate that provides a client for calling a given AWS service, such as <code>aws-sdk-s3</code> for calling S3.</li>
<li><strong>AWS Runtime Crate</strong>: Any runtime crate that the AWS SDK generated code relies on, such as <code>aws-types</code>.</li>
<li><strong>Smithy Runtime Crate</strong>: Any runtime crate that the smithy-rs generated code relies on, such as <code>smithy-types</code>.</li>
</ul>
<h2 id="requirements-4"><a class="header" href="#requirements-4">Requirements</a></h2>
<h3 id="versioning"><a class="header" href="#versioning">Versioning</a></h3>
<p>Cargo uses <a href="https://github.com/dtolnay/semver#requirements">semver</a> for versioning,
with a <code>major.minor.patch-pre</code> format:</p>
<ul>
<li><code>major</code>: Incompatible API changes</li>
<li><code>minor</code>: Added functionality in backwards compatible manner</li>
<li><code>patch</code>: Backwards compatible bug fixes</li>
<li><code>pre</code>: Pre-release version tag (omitted for normal releases)</li>
</ul>
<p>For now, AWS SDK crates (including <code>aws-config</code>) will maintain a consistent <code>major</code> and <code>minor</code> version number
across all services. The latest version of <code>aws-sdk-s3</code> will always have the same <code>major.minor</code> version as the
latest <code>aws-sdk-dynamodb</code>, for example. The <code>patch</code> version is allowed to be different between service crates,
but it is unlikely that we will make use of <code>patch</code> versions throughout alpha and dev preview.
Smithy runtime crates will have different version numbers from the AWS SDK crates, but will also maintain
a consistent <code>major.minor</code>.</p>
<p>The <code>pre</code> version tag will be <code>alpha</code> during the Rust SDK alpha, and will be removed once the SDK is in
dev preview.</p>
<p>During alpha, the <code>major</code> version will always be 0, and the <code>minor</code> will be bumped for all published
crates for every release. A later RFC may change the process during dev preview.</p>
<h3 id="yanking"><a class="header" href="#yanking">Yanking</a></h3>
<p>Mistakes will inevitably be made, and a mechanism is needed to yank packages while keeping the latest version
of the SDK successfully consumable from crates.io. To keep this simple, the entire published batch of crates
will be yanked if any crate in that batch needs to be yanked. For example, if 260 crates were published in a batch,
and it turns out there's a problem that requires yanking one of them, then all 260 will be yanked. Attempting to do
partial yanking will require a lot of effort and be difficult to get right. Yanking should be a last resort.</p>
<h2 id="concrete-scenarios"><a class="header" href="#concrete-scenarios">Concrete Scenarios</a></h2>
<p>The following changes will be bundled together as a <code>minor</code> version bump during weekly releases:</p>
<ul>
<li>AWS model updates</li>
<li>New features</li>
<li>Bug fixes in runtime crates or codegen</li>
</ul>
<p>In exceptional circumstances, a <code>patch</code> version will be issued if the fix doesn't require API breaking changes:</p>
<ul>
<li>CVE discovered in a runtime crate</li>
<li>Buggy update to a runtime crate</li>
</ul>
<p>In the event of a CVE being discovered in an external dependency, if the external dependency is
internal to a crate, then a <code>patch</code> revision can be issued for that crate to correct it. Otherwise if the CVE
is in a dependency that is part of the public API, a <code>minor</code> revision will be issued with an expedited release.</p>
<p>For a CVE in generated code, a <code>minor</code> revision will be issued with an expedited release.</p>
<h2 id="proposal"><a class="header" href="#proposal">Proposal</a></h2>
<p>The short-term approach builds off our pre-crates.io weekly release process. That process was the following:</p>
<ol>
<li>Run script to update AWS models</li>
<li>Manually update AWS SDK version in <code>aws/sdk/gradle.properties</code> in smithy-rs</li>
<li>Tag smithy-rs</li>
<li>Wait for GitHub actions to generate AWS SDK using newly released smithy-rs</li>
<li>Check out aws-sdk-rust, delete existing SDK code, unzip generated SDK in place, and update readme</li>
<li>Tag aws-sdk-rust</li>
</ol>
<p>To keep things simple:</p>
<ul>
<li>The Smithy runtime crates will have the same smithy-rs version</li>
<li>All AWS crates will have the same AWS SDK version</li>
<li><code>patch</code> revisions are exceptional and will be one-off manually published by a developer</li>
</ul>
<p>All runtime crate version numbers in smithy-rs will be locked at <code>0.0.0-smithy-rs-head</code>. This is a fake
version number that gets replaced when generating the SDK.</p>
<p>The SDK generator script in smithy-rs will be updated to:</p>
<ul>
<li>Replace Smithy runtime crate versions with the smithy-rs version from <code>aws/sdk/gradle.properties</code></li>
<li>Replace AWS runtime crate versions with AWS SDK version from <code>aws/sdk/gradle.properties</code></li>
<li>Add correct version numbers to all path dependencies in all the final crates that end up in the build artifacts</li>
</ul>
<p>This will result in all the crates having the correct version and manifests when imported into aws-sdk-rust.
From there, a script needs to be written to determine crate dependency order, and publish crates (preferably
with throttling and retry) in the correct order. This script needs to be able to recover from an interruption
part way through publishing all the crates, and it also needs to output a list of all crate versions published
together. This crate list will be commented on the release issue so that yanking the batch can be done if
necessary.</p>
<p>The new release process would be:</p>
<ol>
<li>Run script to update AWS models</li>
<li>Manually update <em>both</em> the AWS SDK version <em>and</em> the smithy-rs version in <code>aws/sdk/gradle.properties</code> in smithy-rs</li>
<li>Tag smithy-rs</li>
<li>Wait for automation to sync changes to <code>aws-sdk-rust/next</code></li>
<li>Cut a PR to merge <code>aws-sdk-rust/next</code> into <code>aws-sdk-rust/main</code></li>
<li>Tag aws-sdk-rust</li>
<li>Run publish script</li>
</ol>
<h3 id="short-term-changes-checklist"><a class="header" href="#short-term-changes-checklist">Short-term Changes Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Prepare runtime crate manifests for publication to crates.io (https://github.com/smithy-lang/smithy-rs/pull/755)</li>
<li><input disabled="" type="checkbox" checked=""/>
Update SDK generator to set correct crate versions (https://github.com/smithy-lang/smithy-rs/pull/755)</li>
<li><input disabled="" type="checkbox" checked=""/>
Write bulk publish script</li>
<li><input disabled="" type="checkbox" checked=""/>
Write bulk yank script</li>
<li><input disabled="" type="checkbox" checked=""/>
Write automation to sync smithy-rs to aws-sdk-rust</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-independent-crate-versioning"><a class="header" href="#rfc-independent-crate-versioning">RFC: Independent Crate Versioning</a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>During its alpha and dev preview releases, the AWS SDK for Rust adopted <a href="rfcs/./rfc0011_crates_io_alpha_publishing.html">a short-term solution
for versioning and publishing to crates.io</a>.
This doc proposes a long-term versioning strategy that will carry the SDK from dev preview
into general availability.</p>
<p>This strategy will be implemented in two phases:</p>
<ol>
<li><strong>Dev Preview</strong>: The SDK will break with its current version strategy
of maintaining consistent <code>major.minor</code> version numbers.</li>
<li><strong>Stability and 1.x</strong>: This phase begins when the SDK becomes generally available. The
major version will be bumped to 1, and backwards breaking changes will no longer be allowed
without a major version bump to all crates in the SDK.</li>
</ol>
<h2 id="terminology-8"><a class="header" href="#terminology-8">Terminology</a></h2>
<ul>
<li><strong>AWS SDK Crate</strong>: A crate that provides a client for calling a given AWS service, such as <code>aws-sdk-s3</code> for calling S3.</li>
<li><strong>AWS Runtime Crate</strong>: Any runtime crate that the AWS SDK generated code relies on, such as <code>aws-types</code>.</li>
<li><strong>Smithy Runtime Crate</strong>: Any runtime crate that the <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> generated code relies on, such as <code>smithy-types</code>.</li>
</ul>
<h2 id="requirements-5"><a class="header" href="#requirements-5">Requirements</a></h2>
<h3 id="versioning-1"><a class="header" href="#versioning-1">Versioning</a></h3>
<p>Cargo uses <a href="https://semver.org/">semver</a> for versioning, with a <code>major.minor.patch-pre</code> format:</p>
<ul>
<li><code>major</code>: Incompatible API changes</li>
<li><code>minor</code>: Added functionality in backwards compatible manner</li>
<li><code>patch</code>: Backwards compatible bug fixes</li>
<li><code>pre</code>: Pre-release version tag (omitted for normal releases)</li>
</ul>
<p>In the new versioning strategy, the <code>minor</code> version number will no longer be coordinated across
all SDK and Smithy runtime crates.</p>
<p>During phases 1 and 2, the <code>major</code> version will always be 0, and the following scheme will be used:</p>
<ul>
<li><code>minor</code>:
<ul>
<li>New features</li>
<li>Breaking changes</li>
<li>Dependency updates for dependencies that are part of the public API</li>
<li>Model updates with API changes</li>
<li>For code-generated crates: when a newer version of <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> is used to generate the crate</li>
</ul>
</li>
<li><code>patch</code>:
<ul>
<li>Bug fixes that do not break backwards compatibility</li>
<li>Model updates that <em>only</em> have documentation changes</li>
</ul>
</li>
</ul>
<p>During phase 3:</p>
<ul>
<li><code>major</code>: Breaking changes</li>
<li><code>minor</code>:
<ul>
<li>Changes that aren't breaking</li>
<li>Dependency updates for dependencies that are part of the public API</li>
<li>Model updates with API changes</li>
<li>For code-generated crates: when a newer version of <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> is used to generate the crate</li>
</ul>
</li>
<li><code>patch</code>:
<ul>
<li>Bug fixes that do not break backwards compatibility</li>
<li>Model updates that <em>only</em> have documentation changes</li>
</ul>
</li>
</ul>
<p>During phase 3, bumps to the <code>major</code> version must be coordinated across all SDK and runtime crates.</p>
<h3 id="release-identification"><a class="header" href="#release-identification">Release Identification</a></h3>
<p>Since there will no longer be one SDK "version", release tags will be dates in <code>YYYY-MM-DD</code> format
rather than version numbers. Additionally, the SDK's user agent string will need to include a separate
service version number (this requirement has already been implemented).</p>
<h3 id="yanking-1"><a class="header" href="#yanking-1">Yanking</a></h3>
<p>It must be possible to yank an entire release with a single action. The publisher tool must
be updated to understand which crate versions were released with a given release tag, and be able to
yank all the crates published from that tag.</p>
<h2 id="phase-1-dev-preview"><a class="header" href="#phase-1-dev-preview">Phase 1: Dev Preview</a></h2>
<p>Phase 1 will address the following challenges introduced by uncoordinating the <code>major.minor</code> versions:</p>
<ul>
<li>Tracking of versions associated with a release tag</li>
<li>Creation of version bump process for code generated crates</li>
<li>Enforcement of version bump process in runtime crates</li>
<li>Yanking of versions associated with a release tag</li>
</ul>
<h3 id="version-tracking"><a class="header" href="#version-tracking">Version Tracking</a></h3>
<p>A new manifest file will be introduced in the root of <a href="https://github.com/awslabs/aws-sdk-rust">aws-sdk-rust</a> named <code>versions.toml</code> that describes
all versioning information for any given commit in the repository. In the main branch, the <code>versions.toml</code>
in tagged commits will become the source of truth for which crate versions belong to that release, as well
as additional metadata that's required for maintaining version process in the future.</p>
<p>The special <code>0.0.0-smithy-rs-head</code> version that is used prior to Phase 1 for maintaining the runtime crate
versions will no longer be used (as detailed in <a href="rfcs/rfc0012_independent_crate_versioning.html#versioning-for-runtime-crates">Versioning for Runtime Crates</a>).</p>
<p>This format will look as follows:</p>
<pre><code class="language-toml">smithy_rs_version = "&lt;release-tag|commit-hash&gt;"

[aws-smithy-types]
version = "0.50.1"

[aws-config]
version = "0.40.0"

[aws-sdk-s3]
version = "0.89.0"
model_hash = "&lt;hash&gt;"

# ...
</code></pre>
<p>The auto-sync tool is responsible for maintaining this file. When it generates a new SDK, it will take
the version numbers from runtime crates directly, and it will use the rules from the next section to determine
the version numbers for the generated crates.</p>
<h3 id="versioning-for-code-generated-sdk-service-crates"><a class="header" href="#versioning-for-code-generated-sdk-service-crates">Versioning for Code Generated (SDK Service) Crates</a></h3>
<p>Code generated crates will have their <code>minor</code> version bumped when the version of <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> used to generate
them changes, or when model updates with API changes are made. Three pieces of information are required to
handle this process: the previously released version number, the <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> version used to generate the code,
and the level of model updates being applied. For this last one, if there are multiple model updates that
affect only documentation, but then one model update that affects an API, then as a whole they will be
considered as affecting an API and require a <code>minor</code> version bump.</p>
<p>The previously released version number will be retrieved from crates.io using its API. The <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> version
used during code generation will become a build artifact that is saved to <code>versions.toml</code> in <a href="https://github.com/awslabs/aws-sdk-rust">aws-sdk-rust</a>.
During phase 1, the tooling required to know if a model is a documentation-only change will not be available,
so all model changes will result in a <code>minor</code> version bump during this phase.</p>
<p>Overall, determining a generated crate's version number looks as follows:</p>
<pre class="mermaid">flowchart TD
    start[Generate crate version] --&gt; smithyrschanged{A. smithy-rs changed?}
    smithyrschanged -- Yes --&gt; minor1[Minor version bump]
    smithyrschanged -- No --&gt; modelchanged{B. model changed?}
    modelchanged -- Yes --&gt; minor2[Minor version bump]
    modelchanged -- No --&gt; keep[Keep current version]
</pre>
<ul>
<li><strong>A: smithy-rs changed?</strong>: Compare the <code>smithy_rs_version</code> in the previous <code>versions.toml</code> with the
next <code>versions.toml</code> file, and if the values are different, consider <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> to have changed.</li>
<li><strong>B: model changed?</strong>: Similarly, compare the <code>model_hash</code> for the crate in <code>versions.toml</code>.</li>
</ul>
<h3 id="versioning-for-runtime-crates"><a class="header" href="#versioning-for-runtime-crates">Versioning for Runtime Crates</a></h3>
<p>The old scheme of all runtime crates in <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a> having a fake <code>0.0.0-smithy-rs-head</code> version number with
a build step to replace those with a consistent <code>major.minor</code> will be removed. These runtime crates will begin
having their actual next version number in the Cargo.toml file in smithy-rs.</p>
<p>This introduces a new problem where a developer can forget to bump a runtime crate version, so a method of
process enforcement needs to be introduced. This will be done through CI when merging into <code>smithy-rs/main</code>
and repeated when merging into <code>aws-sdk-rust/main</code>.</p>
<p>The following checks need to be run for runtime crates:</p>
<pre class="mermaid">flowchart TD
    A[Check runtime crate] --&gt; B{A. Crate has changed?}
    B -- Yes --&gt; C{B. Minor bumped?}
    B -- No --&gt; H{C. Version changed?}
    C -- Yes --&gt; K[Pass]
    C -- No --&gt; E{D. Patch bumped?}
    E -- Yes --&gt; F{E. Semverver passes?}
    E -- No --&gt; L[Fail]
    F -- Yes --&gt; D[Pass]
    F -- No --&gt; G[Fail]
    H -- Yes --&gt; I[Fail]
    H -- No --&gt; J[Pass]
</pre>
<ul>
<li><strong>A: Crate has changed?</strong> The crate's source files and manifest will be hashed for the previous version
and the next version. If these hashes match, then the crate is considered unchanged.</li>
<li><strong>B: Minor bumped?</strong> The previous version is compared against the next version to see if the minor version
number was bumped.</li>
<li><strong>C: Version changed?</strong> The previous version is compared against the next version to see if it changed.</li>
<li><strong>D: Patch bumped?</strong> The previous version is compared against the next version to see if the patch version
number was bumped.</li>
<li><strong>E: Semverver passes?</strong> Runs <a href="https://github.com/rust-lang/rust-semverver">rust-semverver</a> against the old and new versions of the crate.
<ul>
<li>If semverver fails to run (for example, if it needs to be updated to the latest nightly to succeed),
then fail CI saying that either semverver needs maintenance, or that a minor version bump is required.</li>
<li>If semverver results in errors, fail CI indicating a minor version bump is required.</li>
<li>If semverver passes, then pass CI.</li>
</ul>
</li>
</ul>
<p>When running semverver, the path dependencies of the crate under examination should be updated to be crates.io
references if there were no changes in those crates since the last public to crates.io. Otherwise, the types
referenced from those crates in the public API will always result in breaking changes since, as far as the Rust
compiler is concerned, they are different types originating from separate path-dependency crates.</p>
<p>For CI, the <code>aws-sdk-rust/main</code> branch's <code>versions.toml</code> file is the source of truth for the previous release's
crate versions and source code.</p>
<h3 id="yanking-2"><a class="header" href="#yanking-2">Yanking</a></h3>
<p>The publisher tool will be updated to read the <code>versions.toml</code> to yank all versions published in a release.
This process will look as follows:</p>
<ol>
<li>Take a path to a local clone of the <a href="https://github.com/awslabs/aws-sdk-rust">aws-sdk-rust</a> repository</li>
<li>Confirm the working tree is currently unmodified and on a release tag.</li>
<li>Read <code>versions.toml</code> and print out summary of crates to yank</li>
<li>Confirm with user before proceeding</li>
<li>Yank crates</li>
</ol>
<h3 id="changes-checklist-9"><a class="header" href="#changes-checklist-9">Changes Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Update <code>rust-semverver</code> to a newer nightly that can compile <code>aws-smithy-client</code></li>
<li><input disabled="" type="checkbox"/>
Establish initial <code>versions.toml</code> in <code>aws-sdk-rust/main</code></li>
<li><input disabled="" type="checkbox"/>
Set version numbers in runtime crates in <a href="https://github.com/smithy-lang/smithy-rs">smithy-rs</a></li>
<li><input disabled="" type="checkbox"/>
Update the auto-sync tool to generate <code>versions.toml</code></li>
<li><input disabled="" type="checkbox"/>
Create CI tool to check runtime crate version
<ul>
<li><input disabled="" type="checkbox"/>
Integrate with <code>smithy-rs/main</code> CI</li>
<li><input disabled="" type="checkbox"/>
Integrate with <code>aws-sdk-rust/main</code> CI</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Update CI to verify no older runtime crates are used. For example, if <code>aws-smithy-client</code> is bumped to
<code>0.50.0</code>, then verify no crates (generated or runtime) depend on <code>0.49.0</code> or lower.</li>
</ul>
<p><strong>Estimate:</strong> 2-4 dev weeks</p>
<h2 id="phase-2-stability-and-1x"><a class="header" href="#phase-2-stability-and-1x">Phase 2: Stability and 1.x</a></h2>
<p>When stabilizing to 1.x, the version process will stay the same, but the minor version bumps caused by version
bumping runtime crates, updating models, or changing the code generator will be candidate for automatic upgrade
per semver. At that point, no further API breaking changes can be made without a major version bump.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-callback-apis-for-bytestream-and-sdkbody"><a class="header" href="#rfc-callback-apis-for-bytestream-and-sdkbody">RFC: Callback APIs for <code>ByteStream</code> and <code>SdkBody</code></a></h1>
<blockquote>
<p>Status: RFC</p>
</blockquote>
<p>Adding a callback API to <code>ByteStream</code> and <code>SdkBody</code> will enable developers using the SDK to implement things like checksum validations and 'read progress' callbacks.</p>
<h2 id="the-implementation"><a class="header" href="#the-implementation">The Implementation</a></h2>
<p><em>Note that comments starting with '//' are not necessarily going to be included in the actual implementation and are intended as clarifying comments for the purposes of this RFC.</em></p>
<pre><code class="language-rust ignore">// in aws_smithy_http::callbacks...

/// A callback that, when inserted into a request body, will be called for corresponding lifecycle events.
trait BodyCallback: Send {
   /// This lifecycle function is called for each chunk **successfully** read. If an error occurs while reading a chunk,
   /// this method will not be called. This method takes `&amp;mut self` so that implementors may modify an implementing
   /// struct/enum's internal state. Implementors may return an error.
   fn update(&amp;mut self, #[allow(unused_variables)] bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; { Ok(()) }

   /// This callback is called once all chunks have been read. If the callback encountered one or more errors
   /// while running `update`s, this is how those errors are raised. Implementors may return a [`HeaderMap`][HeaderMap]
   /// that will be appended to the HTTP body as a trailer. This is only useful to do for streaming requests.
   fn trailers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; { Ok(None) }

   /// Create a new `BodyCallback` from an existing one. This is called when a `BodyCallback` needs to be
   /// re-initialized with default state. For example: when a request has a body that needs to be
   /// rebuilt, all callbacks for that body need to be run again but with a fresh internal state.
   fn make_new(&amp;self) -&gt; Box&lt;dyn BodyCallback&gt;;
}

impl BodyCallback for Box&lt;dyn BodyCallback&gt; {
   fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; { BodyCallback::update(self, bytes) }
   fn trailers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; { BodyCallback::trailers(self) }
   fn make_new(&amp;self) -&gt; Box&lt;dyn SendCallback&gt; { BodyCallback::make_new(self) }
}</code></pre>
<p>The changes we need to make to <code>ByteStream</code>:</p>
<p><em>(The current version of <code>ByteStream</code> and <code>Inner</code> can be seen <a href="https://github.com/smithy-lang/smithy-rs/blob/f76bc159bf16510a0873f5fba691cb05816f4192/rust-runtime/aws-smithy-http/src/byte_stream.rs#L205">here</a>.)</em></p>
<pre><code class="language-rust ignore">// in `aws_smithy_http::byte_stream`...

// We add a new method to `ByteStream` for inserting callbacks
impl ByteStream {
    // ...other impls omitted

    // A "builder-style" method for setting callbacks
    pub fn with_body_callback(&amp;mut self, body_callback: Box&lt;dyn BodyCallback&gt;) -&gt; &amp;mut Self {
        self.inner.with_body_callback(body_callback);
        self
    }
}

impl Inner&lt;SdkBody&gt; {
    // `Inner` wraps an `SdkBody` which has a "builder-style" function for adding callbacks.
    pub fn with_body_callback(&amp;mut self, body_callback: Box&lt;dyn BodyCallback&gt;) -&gt; &amp;mut Self {
        self.body.with_body_callback(body_callback);
        self
    }
}</code></pre>
<p>The changes we need to make to <code>SdkBody</code>:</p>
<p><em>(The current version of <code>SdkBody</code> can be seen <a href="https://github.com/smithy-lang/smithy-rs/blob/f76bc159bf16510a0873f5fba691cb05816f4192/rust-runtime/aws-smithy-http/src/body.rs#L71">here</a>.)</em></p>
<pre><code class="language-rust ignore">// In aws_smithy_http::body...

#[pin_project]
pub struct SdkBody {
    #[pin]
    inner: Inner,
    rebuild: Option&lt;Arc&lt;dyn (Fn() -&gt; Inner) + Send + Sync&gt;&gt;,
    // We add a `Vec` to store the callbacks
    #[pin]
    callbacks: Vec&lt;Box&lt;dyn BodyCallback&gt;&gt;,
}

impl SdkBody {
    // We update the various fns that create `SdkBody`s to create an empty `Vec` to store callbacks.
    // Those updates are very simple so I've omitted them from this code example.

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, Error&gt;&gt;&gt; {
        let mut this = self.project();
        // This block is old. I've included for context.
        let polling_result = match this.inner.project() {
            InnerProj::Once(ref mut opt) =&gt; {
                let data = opt.take();
                match data {
                    Some(bytes) if bytes.is_empty() =&gt; Poll::Ready(None),
                    Some(bytes) =&gt; Poll::Ready(Some(Ok(bytes))),
                    None =&gt; Poll::Ready(None),
                }
            }
            InnerProj::Streaming(body) =&gt; body.poll_data(cx).map_err(|e| e.into()),
            InnerProj::Dyn(box_body) =&gt; box_body.poll_data(cx),
            InnerProj::Taken =&gt; {
                Poll::Ready(Some(Err("A `Taken` body should never be polled".into())))
            }
        };

        // This block is new.
        match &amp;polling_result {
            // When we get some bytes back from polling, pass those bytes to each callback in turn
            Poll::Ready(Some(Ok(bytes))) =&gt; {
               for callback in this.callbacks.iter_mut() {
                  // Callbacks can run into errors when reading bytes. They'll be surfaced here
                  callback.update(bytes)?;
               }
            }
            // When we're done polling for bytes, run each callback's `trailers()` method. If any calls to
            // `trailers()` return an error, propagate that error up. Otherwise, continue.
            Poll::Ready(None) =&gt; {
                for callback_result in this.callbacks.iter().map(BodyCallback::trailers) {
                    if let Err(e) = callback_result {
                        return Poll::Ready(Some(Err(e)));
                    }
                }
            }
            _ =&gt; (),
        }

        // Now that we've inspected the polling result, all that's left to do is to return it.
        polling_result
    }

    // This function now has the added responsibility of cloning callback functions (but with fresh state)
    // in the case that the `SdkBody` needs to be rebuilt.
    pub fn try_clone(&amp;self) -&gt; Option&lt;Self&gt; {
        self.rebuild.as_ref().map(|rebuild| {
            let next = rebuild();
            let callbacks = self
                .callbacks
                .iter()
                .map(Callback::make_new)
                .collect();

            Self {
                inner: next,
                rebuild: self.rebuild.clone(),
                callbacks,
            }
        })
    }

    pub fn with_callback(&amp;mut self, callback: BodyCallback) -&gt; &amp;mut Self {
        self.callbacks.push(callback);
        self
    }
}

/// Given two [`HeaderMap`][HeaderMap]s, merge them together and return the merged `HeaderMap`. If the
/// two `HeaderMap`s share any keys, values from the right `HeaderMap` be appended to the left `HeaderMap`.
///
/// # Example
///
/// ```rust
/// let header_name = HeaderName::from_static("some_key");
///
/// let mut left_hand_side_headers = HeaderMap::new();
/// left_hand_side_headers.insert(
///     header_name.clone(),
///     HeaderValue::from_str("lhs value").unwrap(),
/// );
///
/// let mut right_hand_side_headers = HeaderMap::new();
/// right_hand_side_headers.insert(
///     header_name.clone(),
///     HeaderValue::from_str("rhs value").unwrap(),
/// );
///
/// let merged_header_map =
///     append_merge_header_maps(left_hand_side_headers, right_hand_side_headers);
/// let merged_values: Vec&lt;_&gt; = merged_header_map
///     .get_all(header_name.clone())
///     .into_iter()
///     .collect();
///
/// // Will print 'some_key: ["lhs value", "rhs value"]'
/// println!("{}: {:?}", header_name.as_str(), merged_values);
/// ```
fn append_merge_header_maps(
    mut lhs: HeaderMap&lt;HeaderValue&gt;,
    rhs: HeaderMap&lt;HeaderValue&gt;,
) -&gt; HeaderMap&lt;HeaderValue&gt; {
    let mut last_header_name_seen = None;
    for (header_name, header_value) in rhs.into_iter() {
        // For each yielded item that has None provided for the `HeaderName`,
        // then the associated header name is the same as that of the previously
        // yielded item. The first yielded item will have `HeaderName` set.
        // https://docs.rs/http/latest/http/header/struct.HeaderMap.html#method.into_iter-2
        match (&amp;mut last_header_name_seen, header_name) {
            (_, Some(header_name)) =&gt; {
                lhs.append(header_name.clone(), header_value);
                last_header_name_seen = Some(header_name);
            }
            (Some(header_name), None) =&gt; {
                lhs.append(header_name.clone(), header_value);
            }
            (None, None) =&gt; unreachable!(),
        };
    }

    lhs
}

impl http_body::Body for SdkBody {
    // The other methods have been omitted because they haven't changed

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        let header_map = self
            .callbacks
            .iter()
            .filter_map(|callback| {
                match callback.trailers() {
                    Ok(optional_header_map) =&gt; optional_header_map,
                    // early return if a callback encountered an error
                    Err(e) =&gt; { return e },
                }
            })
            // Merge any `HeaderMap`s from the last step together, one by one.
            .reduce(append_merge_header_maps);

        Poll::Ready(Ok(header_map))
    }
}</code></pre>
<h2 id="implementing-checksums"><a class="header" href="#implementing-checksums">Implementing Checksums</a></h2>
<p>What follows is a simplified example of how this API could be used to introduce checksum validation for outgoing request payloads. In this example, the checksum calculation is fallible and no validation takes place. All it does it calculate
the checksum of some data and then returns the checksum of that data when <code>trailers</code> is called. This is fine because it's
being used to calculate the checksum of a streaming body for a request.</p>
<pre><code class="language-rust ignore">#[derive(Default)]
struct Crc32cChecksumCallback {
    state: Option&lt;u32&gt;,
}

impl ReadCallback for Crc32cChecksumCallback {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.state = match self.state {
            Some(crc) =&gt; { self.state = Some(crc32c_append(crc, bytes)) }
            None =&gt; { Some(crc32c(&amp;bytes)) }
        };

       Ok(())
    }

    fn trailers(&amp;self) -&gt;
    Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;,
          Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
    {
        let mut header_map = HeaderMap::new();
        // This checksum name is an Amazon standard and would be a `const` in the real implementation
        let key = HeaderName::from_static("x-amz-checksum-crc32c");
        // If no data was provided to this callback and no CRC was ever calculated, we return zero as the checksum.
        let crc = self.state.unwrap_or_default();
        // Convert the CRC to a string, base 64 encode it, and then convert it into a `HeaderValue`.
        let value = HeaderValue::from_str(&amp;base64::encode(crc.to_string())).expect("base64 will always produce valid header values");

        header_map.insert(key, value);

        Some(header_map)
    }

    fn make_new(&amp;self) -&gt; Box&lt;dyn ReadCallback&gt; {
        Box::new(Crc32cChecksumCallback::default())
    }
}</code></pre>
<p><em>NOTE: If <code>Crc32cChecksumCallback</code> needed to validate a response, then we could modify it to check its internal state against a target checksum value and calling <code>trailers</code> would produce an error if the values didn't match.</em></p>
<p>In order to use this in a request, we'd modify codegen for that request's service.</p>
<ol>
<li>We'd check if the user had requested validation and also check if they'd pre-calculated a checksum.</li>
<li>If validation was requested but no pre-calculated checksum was given, we'd create a callback similar to the one above</li>
<li>Then, we'd create a new checksum callback and:
<ul>
<li>(if streaming) we'd set the checksum callback on the request body object</li>
<li>(if non-streaming) we'd immediately read the body and call <code>BodyCallback::update</code> manually. Once all data was read, we'd get the checksum by calling <code>trailers</code> and insert that data as a request header.</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-fine-grained-timeout-configuration"><a class="header" href="#rfc-fine-grained-timeout-configuration">RFC: Fine-grained timeout configuration</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0014_timeout_config.html#changes-checklist">Changes Checklist</a> section.</p>
<p>While it is currently possible for users to implement request timeouts by racing operation send futures against timeout futures, this RFC proposes a more ergonomic solution that would also enable users to set timeouts for things like TLS negotiation and "time to first byte".</p>
<h2 id="terminology-9"><a class="header" href="#terminology-9">Terminology</a></h2>
<p>There's a lot of terminology to define, so I've broken it up into three sections.</p>
<h3 id="general-terms"><a class="header" href="#general-terms">General terms</a></h3>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together the connector, middleware, and retry policy. This is not generated and lives in the <code>aws-smithy-client</code> crate.</li>
<li><strong>Fluent Client</strong>: A code-generated <code>Client&lt;C, M, R&gt;</code> that has methods for each service operation on it. A fluent builder is generated alongside it to make construction easier.</li>
<li><strong>AWS Client</strong>: A specialized Fluent Client that defaults to using a <code>DynConnector</code>, <code>AwsMiddleware</code>, and <code>Standard</code> retry policy.</li>
<li><strong>Shared Config</strong>: An <code>aws_types::Config</code> struct that is responsible for storing shared configuration data that is used across all services. This is not generated and lives in the <code>aws-types</code> crate.</li>
<li><strong>Service-specific Config</strong>: A code-generated <code>Config</code> that has methods for setting service-specific configuration. Each <code>Config</code> is defined in the <code>config</code> module of its parent service. For example, the S3-specific config struct  is <code>use</code>able from <code>aws_sdk_s3::config::Config</code> and re-exported as <code>aws_sdk_s3::Config</code>. In this case, "service" refers to an AWS offering like S3.</li>
</ul>
<h3 id="http-stack-terms"><a class="header" href="#http-stack-terms">HTTP stack terms</a></h3>
<ul>
<li><strong>Service</strong>: A trait defined in the <a href="https://docs.rs/tower-service/0.3.1/tower_service/trait.Service.html"><code>tower-service</code> crate</a>. The lowest level of abstraction we deal with when making HTTP requests. Services act directly on data to transform and modify that data. A Service is what eventually turns a request into a response.</li>
<li><strong>Layer</strong>: Layers are a higher-order abstraction over services that is used to compose multiple services together, creating a new service from that combination. Nothing prevents us from manually wrapping services within services, but Layers allow us to do it in a flexible and generic manner. Layers don't directly act on data but instead can wrap an existing service with additional functionality, creating a new service. Layers can be thought of as middleware. <em>NOTE: The use of <a href="https://github.com/smithy-lang/smithy-rs/issues/634">Layers can produce compiler errors</a> that are difficult to interpret and defining a layer requires a large amount of boilerplate code.</em></li>
<li><strong>Middleware</strong>: a term with several meanings,
<ul>
<li>Generically speaking, middleware are similar to Services and Layers in that they modify requests and responses.</li>
<li>In the SDK, "Middleware" refers to a layer that can be wrapped around a <code>DispatchService</code>. In practice, this means that the resulting <code>Service</code> (and the inner service) must meet the bound <code>T: where T: Service&lt;operation::Request, Response=operation::Response, Error=SendOperationError&gt;</code>.
<ul>
<li><em>Note: This doesn't apply to the middlewares we use when generating presigned request because those don't wrap a <code>DispatchService</code>.</em></li>
</ul>
</li>
<li>The most notable example of a Middleware is the <a href="https://github.com/smithy-lang/smithy-rs/blob/1aa59693eed10713dec0f3774a8a25ca271dbf39/aws/rust-runtime/aws-hyper/src/lib.rs#L29">AwsMiddleware</a>. Other notable examples include <a href="https://github.com/smithy-lang/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-http-tower/src/map_request.rs#L122">MapRequest</a>, <a href="https://github.com/smithy-lang/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-http-tower/src/map_request.rs#L42">AsyncMapRequest</a>, and <a href="https://github.com/smithy-lang/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-http-tower/src/parse_response.rs#L27">ParseResponse</a>.</li>
</ul>
</li>
<li><strong>DispatchService</strong>: The innermost part of a group of nested services. The Service that actually makes an HTTP call on behalf of a request. Responsible for parsing success and error responses.</li>
<li><strong>Connector</strong>: a term with several meanings,
<ul>
<li>DynConnectors (a struct that implements <a href="https://github.com/smithy-lang/smithy-rs/blob/1aa59693eed10713dec0f3774a8a25ca271dbf39/rust-runtime/aws-smithy-client/src/erase.rs#L139">DynConnect</a>) are Services with their specific type erased so that we can do dynamic dispatch.</li>
<li>A term from <code>hyper</code> for any object that implements the <a href="https://docs.rs/hyper/0.14.14/hyper/client/connect/trait.Connect.html">Connect</a> trait. Really just an alias for <a href="https://docs.rs/tower-service/0.3.1/tower_service/trait.Service.html">tower_service::Service</a>. Sometimes referred to as a <code>Connection</code>.</li>
</ul>
</li>
<li><strong>Stage</strong>: A form of middleware that's not related to <code>tower</code>. These currently function as a way of transforming requests and don't have the ability to transform responses.</li>
<li><strong>Stack</strong>: higher order abstraction over Layers defined in the <a href="https://docs.rs/tower/0.4.10/tower/layer/util/struct.Stack.html">tower crate</a> e.g. Layers wrap services in one another and Stacks wrap layers within one another.</li>
</ul>
<h3 id="timeout-terms"><a class="header" href="#timeout-terms">Timeout terms</a></h3>
<ul>
<li><strong>Connect Timeout</strong>: A limit on the amount of time after making an initial connect attempt on a socket to complete the
connect-handshake.
<ul>
<li><em>TODO: the runtime is based on Hyper which reuses connection and doesn't currently have a way of guaranteeing that
a fresh connection will be use for a given request.</em></li>
</ul>
</li>
<li><strong>TLS Negotiation Timeout</strong>: A limit on the amount of time a TLS handshake takes from when the CLIENT HELLO message is
sent to the time the client and server have fully negotiated ciphers and exchanged keys.</li>
<li><strong>Time to First Byte Timeout</strong>: <em>Sometimes referred to as a "read timeout."</em> A limit on the amount of time an application takes to attempt to read the first byte over
an established, open connection after write request.</li>
<li><strong>HTTP Request Timeout For A Single Attempt</strong>: A limit on the amount of time it takes for the first byte to be sent over
an established, open connection and when the last byte is received from the service.</li>
<li><strong>HTTP Request Timeout For Multiple Attempts</strong>: This timeout acts like the previous timeout but constrains the total time
it takes to make a request plus any retries.
<ul>
<li><em>NOTE: In a way, this is already possible in that users are free to race requests against timer futures with
the <a href="https://docs.rs/futures/0.3.17/futures/future/fn.select.html">futures::future::select</a> macro or to use <a href="https://docs.rs/tokio/1.12.0/tokio/time/fn.timeout.html">tokio::time::timeout</a>. See relevant discussion in <a href="https://github.com/hyperium/hyper/issues/1097">hyper#1097</a></em></li>
</ul>
</li>
</ul>
<h2 id="configuring-timeouts"><a class="header" href="#configuring-timeouts">Configuring timeouts</a></h2>
<p>Just like with <a href="rfcs/./rfc0004_retry_behavior.html">Retry Behavior Configuration</a>, these settings can be configured in several places and have the same
precedence rules <em>(paraphrased here for clarity)</em>.</p>
<ol>
<li>Service-specific config builders</li>
<li>Shared config builders</li>
<li>Environment variables</li>
<li>Profile config file (e.g., <code>~/.aws/credentials</code>)</li>
</ol>
<p>The above list is in order of decreasing precedence e.g. configuration set in an app will override values from
environment variables.</p>
<h3 id="configuration-options"><a class="header" href="#configuration-options">Configuration options</a></h3>
<p>The table below details the specific ways each timeout can be configured. In all cases, valid values are non-negative floats representing the number of seconds before a timeout is triggered.</p>
<div class="table-wrapper"><table><thead><tr><th>Timeout</th><th>Environment Variable</th><th>AWS Config Variable</th><th>Builder Method</th></tr></thead><tbody>
<tr><td>Connect</td><td>AWS_CONNECT_TIMEOUT</td><td>connect_timeout</td><td>connect_timeout</td></tr>
<tr><td>TLS Negotiation</td><td>AWS_TLS_NEGOTIATION_TIMEOUT</td><td>tls_negotiation_timeout</td><td>tls_negotiation_timeout</td></tr>
<tr><td>Time To First Byte</td><td>AWS_READ_TIMEOUT</td><td>read_timeout</td><td>read_timeout</td></tr>
<tr><td>HTTP Request - single attempt</td><td>AWS_API_CALL_ATTEMPT_TIMEOUT</td><td>api_call_attempt_timeout</td><td>api_call_attempt_timeout</td></tr>
<tr><td>HTTP Request - all attempts</td><td>AWS_API_CALL_TIMEOUT</td><td>api_call_timeout</td><td>api_call_timeout</td></tr>
</tbody></table>
</div>
<h3 id="sdk-specific-defaults-set-by-aws-service-teams"><a class="header" href="#sdk-specific-defaults-set-by-aws-service-teams">SDK-specific defaults set by AWS service teams</a></h3>
<p><em>QUESTION: How does the SDK currently handle these defaults?</em></p>
<h2 id="prior-art"><a class="header" href="#prior-art">Prior Art</a></h2>
<ul>
<li><a href="https://github.com/hjr3/hyper-timeout">hjr3/hyper-timeout</a> is a <code>Connector</code> for hyper that enables setting connect, read, and write timeouts</li>
<li><a href="https://github.com/sfackler/tokio-io-timeout">sfackler/tokio-io-timeout</a> provides timeouts for tokio IO operations. Used within <code>hyper-timeout</code>.</li>
<li>[tokio::time::sleep_until] creates a <code>Future</code> that completes after some time has elapsed. Used within <code>tokio-io-timeout</code>.</li>
</ul>
<h2 id="behind-the-scenes-2"><a class="header" href="#behind-the-scenes-2">Behind the scenes</a></h2>
<p>Timeouts are achieved by racing a future against a <code>tokio::time::Sleep</code> future. The question, then, is "how can I create a future that represents a condition I want to watch for?". For example, in the case of a <code>ConnectTimeout</code>, how do we watch an ongoing request to see if it's completed the connect-handshake? Our current stack of Middleware acts on requests at different levels of granularity. The timeout Middlewares will be no different.</p>
<h3 id="middlewares-for-aws-client-requests"><a class="header" href="#middlewares-for-aws-client-requests">Middlewares for AWS Client requests</a></h3>
<p><em>View <a href="https://github.com/smithy-lang/smithy-rs/blob/1aa59693eed10713dec0f3774a8a25ca271dbf39/aws/rust-runtime/aws-hyper/src/lib.rs#L29">AwsMiddleware</a> in GitHub</em></p>
<pre><code class="language-rust ignore">#[derive(Debug, Default)]
#[non_exhaustive]
pub struct AwsMiddleware;
impl&lt;S&gt; tower::Layer&lt;S&gt; for AwsMiddleware {
  type Service = &lt;AwsMiddlewareStack as tower::Layer&lt;S&gt;&gt;::Service;

  fn layer(&amp;self, inner: S) -&gt; Self::Service {
    let credential_provider = AsyncMapRequestLayer::for_mapper(CredentialsStage::new());
    let signer = MapRequestLayer::for_mapper(SigV4SigningStage::new(SigV4Signer::new()));
    let endpoint_resolver = MapRequestLayer::for_mapper(AwsAuthStage);
    let user_agent = MapRequestLayer::for_mapper(UserAgentStage::new());
    ServiceBuilder::new()
            .layer(endpoint_resolver)
            .layer(user_agent)
            .layer(credential_provider)
            .layer(signer)
            .service(inner)
  }
}</code></pre>
<p>The above code is only included for context. This RFC doesn't define any timeouts specific to AWS so <code>AwsMiddleware</code> won't require any changes.</p>
<h3 id="middlewares-for-smithy-client-requests"><a class="header" href="#middlewares-for-smithy-client-requests">Middlewares for Smithy Client requests</a></h3>
<p><em>View <a href="https://github.com/smithy-lang/smithy-rs/blob/841f51113fb14e2922793951ce16bda3e16cb51f/rust-runtime/aws-smithy-client/src/lib.rs#L175">aws_smithy_client::Client::call_raw</a> in GitHub</em></p>
<pre><code class="language-rust ignore">impl&lt;C, M, R&gt; Client&lt;C, M, R&gt;
  where
          C: bounds::SmithyConnector,
          M: bounds::SmithyMiddleware&lt;C&gt;,
          R: retry::NewRequestPolicy,
{
  // ...other methods omitted
  pub async fn call_raw&lt;O, T, E, Retry&gt;(
    &amp;self,
    input: Operation&lt;O, Retry&gt;,
  ) -&gt; Result&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;
    where
            R::Policy: bounds::SmithyRetryPolicy&lt;O, T, E, Retry&gt;,
            bounds::Parsed&lt;&lt;M as bounds::SmithyMiddleware&lt;C&gt;&gt;::Service, O, Retry&gt;:
            Service&lt;Operation&lt;O, Retry&gt;, Response=SdkSuccess&lt;T&gt;, Error=SdkError&lt;E&gt;&gt; + Clone,
  {
    let connector = self.connector.clone();

    let mut svc = ServiceBuilder::new()
            // Create a new request-scoped policy
            .retry(self.retry_policy.new_request_policy())
            .layer(ParseResponseLayer::&lt;O, Retry&gt;::new())
            // These layers can be considered as occurring in order. That is, first invoke the
            // customer-provided middleware, then dispatch dispatch over the wire.
            .layer(&amp;self.middleware)
            .layer(DispatchLayer::new())
            .service(connector);

    svc.ready().await?.call(input).await
  }
}</code></pre>
<p>The Smithy Client creates a new <code>Stack</code> of services to handle each request it sends. Specifically:</p>
<ul>
<li>A method <code>retry</code> is used set the retry handler. The configuration for this was set during creation of the <code>Client</code>.</li>
<li><code>ParseResponseLayer</code> inserts a service for transforming responses into operation-specific outputs or errors. The <code>O</code> generic parameter of <code>input</code> is what decides exactly how the transformation is implemented.</li>
<li>A middleware stack that was included during <code>Client</code> creation is inserted into the stack. In the case of the AWS SDK, this would be <code>AwsMiddleware</code>.</li>
<li><code>DispatchLayer</code> inserts a service for transforming an <code>http::Request</code> into an <code>operation::Request</code>. It's also responsible for re-attaching the property bag from the Operation that triggered the request.</li>
<li>The innermost <code>Service</code> is a <code>DynConnector</code> wrapping a <code>hyper</code> client (which one depends on the TLS implementation was enabled by cargo features.)</li>
</ul>
<p>The <strong>HTTP Request Timeout For A Single Attempt</strong> and <strong>HTTP Request Timeout For Multiple Attempts</strong> can be implemented at this level. The same <code>Layer</code> can be used to create both <code>TimeoutService</code>s. The <code>TimeoutLayer</code> would require two inputs:</p>
<ul>
<li><code>sleep_fn</code>: A runtime-specific implementation of <code>sleep</code>. The SDK is currently <code>tokio</code>-based and would default to <code>tokio::time::sleep</code> (this default is set in the <code>aws_smithy_async::rt::sleep</code> module.)</li>
<li>The duration of the timeout as a <code>std::time::Duration</code></li>
</ul>
<p>The resulting code would look like this:</p>
<pre><code class="language-rust ignore">impl&lt;C, M, R&gt; Client&lt;C, M, R&gt;
  where
          C: bounds::SmithyConnector,
          M: bounds::SmithyMiddleware&lt;C&gt;,
          R: retry::NewRequestPolicy,
{
  // ...other methods omitted
  pub async fn call_raw&lt;O, T, E, Retry&gt;(
    &amp;self,
    input: Operation&lt;O, Retry&gt;,
  ) -&gt; Result&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt;
    where
            R::Policy: bounds::SmithyRetryPolicy&lt;O, T, E, Retry&gt;,
            bounds::Parsed&lt;&lt;M as bounds::SmithyMiddleware&lt;C&gt;&gt;::Service, O, Retry&gt;:
            Service&lt;Operation&lt;O, Retry&gt;, Response=SdkSuccess&lt;T&gt;, Error=SdkError&lt;E&gt;&gt; + Clone,
  {
    let connector = self.connector.clone();
    let sleep_fn = aws_smithy_async::rt::sleep::default_async_sleep();

    let mut svc = ServiceBuilder::new()
            .layer(TimeoutLayer::new(
              sleep_fn,
              self.timeout_config.api_call_timeout(),
            ))
            // Create a new request-scoped policy
            .retry(self.retry_policy.new_request_policy())
            .layer(TimeoutLayer::new(
              sleep_fn,
              self.timeout_config.api_call_attempt_timeout(),
            ))
            .layer(ParseResponseLayer::&lt;O, Retry&gt;::new())
            // These layers can be considered as occurring in order. That is, first invoke the
            // customer-provided middleware, then dispatch dispatch over the wire.
            .layer(&amp;self.middleware)
            .layer(DispatchLayer::new())
            .service(connector);

    svc.ready().await?.call(input).await
  }
}</code></pre>
<!-- TODO where should this note live? -->
<p><em>Note: Our HTTP client supports multiple TLS implementations. We'll likely have to implement this feature once per library.</em></p>
<p>Timeouts will be implemented in the following places:</p>
<ul>
<li>HTTP request timeout for multiple requests will be implemented as the outermost Layer in <code>Client::call_raw</code>.</li>
<li>HTTP request timeout for a single request will be implemented within <code>RetryHandler::retry</code>.</li>
<li>Time to first byte, TLS negotiation, and connect timeouts will be implemented within the central <code>hyper</code> connector.</li>
</ul>
<h2 id="changes-checklist-10"><a class="header" href="#changes-checklist-10">Changes checklist</a></h2>
<p>Changes are broken into to sections:</p>
<ul>
<li>HTTP requests (single or multiple) are implementable as layers within our current stack</li>
<li>Other timeouts will require changes to our dependencies and may be slower to implement</li>
</ul>
<h3 id="implementing-http-request-timeouts"><a class="header" href="#implementing-http-request-timeouts">Implementing HTTP request timeouts</a></h3>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>TimeoutConfig</code> to <code>smithy-types</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>TimeoutConfigProvider</code> to <code>aws-config</code>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add provider that fetches config from environment variables</li>
<li><input disabled="" type="checkbox" checked=""/>
Add provider that fetches config from profile</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>timeout</code> method to <code>aws_types::Config</code> for setting timeout configuration</li>
<li><input disabled="" type="checkbox" checked=""/>
Add <code>timeout</code> method to generated <code>Config</code>s too</li>
<li><input disabled="" type="checkbox" checked=""/>
Create a generic <code>TimeoutService</code> and accompanying <code>Layer</code>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
<code>TimeoutLayer</code> should accept a <code>sleep</code> function so that it doesn't have a hard dependency on <code>tokio</code></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
insert a <code>TimeoutLayer</code> before the <code>RetryPolicy</code> to handle timeouts for multiple-attempt requests</li>
<li><input disabled="" type="checkbox" checked=""/>
insert a <code>TimeoutLayer</code> after the <code>RetryPolicy</code> to handle timeouts for single-attempt requests</li>
<li><input disabled="" type="checkbox" checked=""/>
Add tests for timeout behavior
<ul>
<li><input disabled="" type="checkbox" checked=""/>
test multi-request timeout triggers after 3 slow retries</li>
<li><input disabled="" type="checkbox" checked=""/>
test single-request timeout triggers correctly</li>
<li><input disabled="" type="checkbox" checked=""/>
test single-request timeout doesn't trigger if request completes in time</li>
</ul>
</li>
</ul>
<!--- Links -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-how-cargo-features-should-be-used-in-the-sdk-and-runtime-crates"><a class="header" href="#rfc-how-cargo-features-should-be-used-in-the-sdk-and-runtime-crates">RFC: How Cargo "features" should be used in the SDK and runtime crates</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<h2 id="some-background-on-features"><a class="header" href="#some-background-on-features">Some background on features</a></h2>
<p>What is a feature? Here's a definition from the <a href="https://doc.rust-lang.org/cargo/reference/features.html">Cargo Book section on features</a>:</p>
<blockquote>
<p>Cargo "features" provide a mechanism to express conditional compilation and optional dependencies. A package defines a set of named features in the <code>[features]</code> table of <code>Cargo.toml</code>, and each feature can either be enabled or disabled. Features for the package being built can be enabled on the command-line with flags such as <code>--features</code>. Features for dependencies can be enabled in the dependency declaration in <code>Cargo.toml</code>.</p>
</blockquote>
<p>We use features in a majority of our runtime crates and in all of our SDK crates. For example, <a href="https://github.com/smithy-lang/smithy-rs/blob/5a1990791d727652587df51b77df4d1df9058252/aws/rust-runtime/aws-sigv4/Cargo.toml">aws-sigv4</a> uses them to enable event streams. Another common use case is exhibited by <a href="https://github.com/awslabs/aws-sdk-rust/blob/f2b4361b004ee822960ea9791f566fd4eb6d1aba/sdk/s3/Cargo.toml">aws-sdk-s3</a> which uses them to enable the <code>tokio</code> runtime and the TLS implementation used when making requests.</p>
<h3 id="features-should-be-additive"><a class="header" href="#features-should-be-additive">Features should be additive</a></h3>
<p>The Cargo book has this to say:</p>
<blockquote>
<p>When a dependency is used by multiple packages, Cargo will use the union of all features enabled on that dependency when building it. This helps ensure that only a single copy of the dependency is used.</p>
</blockquote>
<blockquote>
<p>A consequence of this is that features should be <em>additive</em>. That is, enabling a feature should not disable functionality, and it should usually be safe to enable any combination of features. <strong>A feature should not introduce a <a href="https://doc.rust-lang.org/cargo/reference/features.html#semver-compatibility">SemVer-incompatible change</a>.</strong></p>
</blockquote>
<h2 id="what-does-this-mean-for-the-sdk"><a class="header" href="#what-does-this-mean-for-the-sdk">What does this mean for the SDK?</a></h2>
<p>Despite the constraints outlined above, we should use features in the SDKs because of the benefits they bring:</p>
<ul>
<li>Features enable users to avoid compiling code that they won't be using. Additionally, features allow both general and specific control of compiled code, serving the needs of both novice and expert users.</li>
<li>A single feature in a crate can activate or deactivate multiple features exposed by that crate's dependencies, freeing the user from having to specifically activate or deactivate them.</li>
<li>Features can help users understand what a crate is capable of in the same way that looking at a graph of a crate's modules can.</li>
</ul>
<p>When using features, we should adhere to the guidelines outlined below.</p>
<h3 id="avoid-writing-code-that-relies-on-only-activating-one-feature-from-a-set-of-mutually-exclusive-features"><a class="header" href="#avoid-writing-code-that-relies-on-only-activating-one-feature-from-a-set-of-mutually-exclusive-features">Avoid writing code that relies on only activating one feature from a set of mutually exclusive features.</a></h3>
<p>As noted earlier in an excerpt from the Cargo book:</p>
<blockquote>
<p>enabling a feature should not disable functionality, and it should usually be safe to enable any combination of features. A feature should not introduce a <a href="https://doc.rust-lang.org/cargo/reference/features.html#semver-compatibility">SemVer-incompatible change</a>.</p>
</blockquote>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "rustls")]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using Rustls.
    pub fn tls_adapter(self) -&gt; ClientBuilder&lt;Adapter&lt;crate::conns::Https&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::https()))
    }
}

#[cfg(feature = "native-tls")]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using the native TLS library on your platform.
    pub fn tls_adapter(
        self,
    ) -&gt; ClientBuilder&lt;Adapter&lt;hyper_tls::HttpsConnector&lt;hyper::client::HttpConnector&gt;&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::native_tls()))
    }
}
<span class="boring">}</span></code></pre></pre>
<p>When the example code above is compiled with both features enabled, compilation will fail with a "duplicate definitions with name <code>tls_adapter</code>" error. Also, note that the return type of the function differs between the two versions. This is a SemVer-incompatible change.</p>
<p>Here's an updated version of the example that fixes these issues:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "rustls")]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using Rustls.
    pub fn rustls(self) -&gt; ClientBuilder&lt;Adapter&lt;crate::conns::Https&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::https()))
    }
}

#[cfg(feature = "native-tls")]
impl&lt;M, R&gt; ClientBuilder&lt;(), M, R&gt; {
    /// Connect to the service over HTTPS using the native TLS library on your platform.
    pub fn native_tls(
        self,
    ) -&gt; ClientBuilder&lt;Adapter&lt;hyper_tls::HttpsConnector&lt;hyper::client::HttpConnector&gt;&gt;, M, R&gt; {
        self.connector(Adapter::builder().build(crate::conns::native_tls()))
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Both features can now be enabled at once without creating a conflict. Since both methods have different names, it's now Ok for them to have different return types.</p>
<p><a href="https://github.com/smithy-lang/smithy-rs/blob/2e7ed943513203f1472f2490866dc4fb8a392bd3/rust-runtime/aws-smithy-client/src/hyper_ext.rs#L303"><em>This is real code, see it in context</em></a></p>
<h3 id="we-should-avoid-using-cfgnotfeature--some-feature"><a class="header" href="#we-should-avoid-using-cfgnotfeature--some-feature">We should avoid using <code>#[cfg(not(feature = "some-feature"))]</code></a></h3>
<p>At the risk of seeming repetitive, the Cargo book says:</p>
<blockquote>
<p>enabling a feature should not disable functionality, and it should usually be safe to enable any combination of features</p>
</blockquote>
<p>Conditionally compiling code when a feature is <strong>not</strong> activated can make it hard for users and maintainers to reason about what will happen when they activate a feature. This is also a sign that a feature may not be "additive".</p>
<p><em><strong>NOTE</strong></em>: It's ok to use <code>#[cfg(not())]</code> to conditionally compile code based on a user's OS. It's also useful when controlling what code gets rendered when testing or when generating docs.</p>
<p>One case where using <code>not</code> is acceptable is when providing a fallback when no features are set:</p>
<pre><code class="language-rust ignore">#[cfg(feature = "rt-tokio")]
pub fn default_async_sleep() -&gt; Option&lt;Arc&lt;dyn AsyncSleep&gt;&gt; {
    Some(sleep_tokio())
}

#[cfg(not(feature = "rt-tokio"))]
pub fn default_async_sleep() -&gt; Option&lt;Arc&lt;dyn AsyncSleep&gt;&gt; {
    None
}</code></pre>
<h3 id="dont-default-to-defining-default-features"><a class="header" href="#dont-default-to-defining-default-features">Don't default to defining "default features"</a></h3>
<p>Because Cargo will use the union of all features enabled on a dependency when building it, we should be wary of marking features as default. Once we do mark features as default, users that want to exclude code and dependencies brought in by those features will have a difficult time doing so. One need look no further than <a href="https://github.com/awslabs/aws-sdk-rust/issues/304">this issue</a> submitted by a user that wanted to use Native TLS and struggled to make sure that Rustls was actually disabled <em>(This issue was resolved in <a href="https://github.com/smithy-lang/smithy-rs/pull/935">this PR</a> which removed default features from our runtime crates.)</em> This is not to say that we should never use them, as having defaults for the most common use cases means less work for those users.</p>
<h4 id="when-a-default-feature-providing-some-functionality-is-disabled-active-features-must-not-automatically-replace-that-functionality"><a class="header" href="#when-a-default-feature-providing-some-functionality-is-disabled-active-features-must-not-automatically-replace-that-functionality">When a default feature providing some functionality is disabled, active features must not automatically replace that functionality</a></h4>
<p>As the SDK is currently designed, the TLS implementation in use can change depending on what features are pulled in. Currently, if a user disables <code>default-features</code> (which include <code>rustls</code>) and activates the <code>native-tls</code> feature, then we automatically use <code>native-tls</code> when making requests. For an example of what this looks like from the user's perspective, <a href="https://github.com/smithy-lang/smithy-rs/tree/bc316a0b81b75a00c389f6281a66eb0f5357172a/aws/sdk/examples/using_native_tls_instead_of_rustls">see this example</a>.</p>
<p>This RFC proposes that we should have a single default for any configurable functionality and that that functionality depends on a corresponding default feature being active. If <code>default-features</code> are disabled, then so is the corresponding default functionality. In its place would be functionality that fails fast with a message describing why it failed <em>(a default was deactivated but the user didn't set a replacement)</em>, and what the user should do to fix it <em>(with links to documentation and examples where necessary)</em>. We should use <a href="https://doc.rust-lang.org/stable/std/macro.compile_error.html">compile-time errors</a> to communicate failures with users, or <code>panic</code>s for cases that can't be evaluated at compile-time.</p>
<p>For an example: Say you have a crate with features <code>a</code>, <code>b</code>, <code>c</code> that all provide some version of functionality <code>foo</code>. Feature <code>a</code> is part of <code>default-features</code>. When <code>no-default-features = true</code> but features <code>b</code> and <code>c</code> are active, don't automatically fall back to <code>b</code> or <code>c</code>. Instead, emit an error with a message like this:</p>
<blockquote>
<p>"When default features are disabled, you must manually set <code>foo</code>. Features <code>b</code> and <code>c</code> active; You can use one of those. See an example of setting a custom <code>foo</code> here: <em>link-to-docs.amazon.com/setting-foo</em>"</p>
</blockquote>
<h2 id="further-reading"><a class="header" href="#further-reading">Further reading</a></h2>
<ul>
<li><a href="https://stackoverflow.com/questions/59761045/how-to-tell-what-features-are-available-per-crate">How to tell what "features" are available per crate?</a></li>
<li><a href="https://stackoverflow.com/questions/40021555/how-do-i-pass-down-feature-flags-to-subdependencies-in-cargo">How do I 'pass down' feature flags to subdependencies in Cargo?</a></li>
<li>A small selection of feature-related GitHub issues submitted for popular crates
<ul>
<li><a href="https://github.com/chyh1990/yaml-rust/issues/44">The feature <code>preserve_order</code> is not "purely additive," which makes it impossible to use <code>serde_yaml</code> 0.5.0 and <code>clap</code> in the same program</a></li>
<li><a href="https://github.com/Geal/nom/issues/544">cargo features (verbose-errors may be other?) should be additive</a></li>
<li><a href="https://github.com/aclysma/profiling/issues/32">Mutually exclusive features are present in profiling-procmacros</a></li>
<li><a href="https://github.com/KyleMayes/clang-sys/issues/128">Clang-sys features not additive</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-supporting-flexible-checksums"><a class="header" href="#rfc-supporting-flexible-checksums">RFC: Supporting Flexible Checksums</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>We can't currently update the S3 SDK because we don't support the new "Flexible Checksums" feature. This RFC describes this new feature and details how we should implement it in <code>smithy-rs</code>.</p>
<h2 id="what-is-the-flexible-checksums-feature"><a class="header" href="#what-is-the-flexible-checksums-feature">What is the "Flexible Checksums" feature?</a></h2>
<p>S3 has previously supported MD5 checksum validation of data. Now, it supports more checksum algorithms like CRC32, CRC32C, SHA-1, and SHA-256. This validation is available when putting objects to S3 and when getting them from S3. For more information, see <a href="https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/">this AWS News Blog post</a>.</p>
<h2 id="implementing-checksums-1"><a class="header" href="#implementing-checksums-1">Implementing Checksums</a></h2>
<p>Checksum callbacks were introduced as a result of the acceptance of <a href="rfcs/./rfc0013_body_callback_apis.html">RFC0013</a> and this RFC proposes a refactor to those callbacks, as well as several new wrappers for <code>SdkBody</code> that will provide new functionality.</p>
<h3 id="refactoring-aws-smithy-checksums"><a class="header" href="#refactoring-aws-smithy-checksums">Refactoring aws-smithy-checksums</a></h3>
<p>TLDR; This refactor of aws-smithy-checksums:</p>
<ul>
<li>
<p><strong>Removes the "callback" terminology:</strong> As a word, "callback" doesn't carry any useful information, and doesn't aid in understanding.</p>
</li>
<li>
<p><strong>Removes support for the <code>BodyCallback</code> API:</strong> Instead of adding checksum callbacks to a body, we're going to use a "body wrapping" instead. "Body wrapping" is demonstrated in the <a href="rfcs/rfc0016_flexible_checksum_support.html#checksumbody"><code>ChecksumBody</code></a>, <a href="rfcs/rfc0016_flexible_checksum_support.html#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code></a>, and <a href="rfcs/rfc0016_flexible_checksum_support.html#checksumvalidatedbody"><code>ChecksumValidatedBody</code></a> sections.</p>
<p><em>NOTE: This doesn't remove the <code>BodyCallback</code> trait. That will still exist, we just won't use it.</em></p>
</li>
<li>
<p><strong>Updates terminology to focus on "headers" instead of "trailers":</strong> Because the types we deal with in this module are named for HTTP headers, I chose to use that terminology instead. My hope is that this will be less strange to people reading this code.</p>
</li>
<li>
<p><strong>Adds <code>fn checksum_algorithm_to_checksum_header_name</code>:</strong> a function that's used in generated code to set a checksum request header.</p>
</li>
<li>
<p><strong>Adds <code>fn checksum_header_name_to_checksum_algorithm</code>:</strong> a function that's used in generated code when creating a checksum-validating response body.</p>
</li>
<li>
<p><strong>Add new checksum-related "body wrapping" HTTP body types</strong>: These are defined in the <code>body</code> module and will be shown later in this RFC.</p>
</li>
</ul>
<pre><code class="language-rust ignore">// In aws-smithy-checksums/src/lib.rs
//! Checksum calculation and verification callbacks

use aws_smithy_types::base64;

use bytes::Bytes;
use http::header::{HeaderMap, HeaderName, HeaderValue};
use sha1::Digest;
use std::io::Write;

pub mod body;

// Valid checksum algorithm names
pub const CRC_32_NAME: &amp;str = "crc32";
pub const CRC_32_C_NAME: &amp;str = "crc32c";
pub const SHA_1_NAME: &amp;str = "sha1";
pub const SHA_256_NAME: &amp;str = "sha256";

pub const CRC_32_HEADER_NAME: HeaderName = HeaderName::from_static("x-amz-checksum-crc32");
pub const CRC_32_C_HEADER_NAME: HeaderName = HeaderName::from_static("x-amz-checksum-crc32c");
pub const SHA_1_HEADER_NAME: HeaderName = HeaderName::from_static("x-amz-checksum-sha1");
pub const SHA_256_HEADER_NAME: HeaderName = HeaderName::from_static("x-amz-checksum-sha256");

// Preserved for compatibility purposes. This should never be used by users, only within smithy-rs
const MD5_NAME: &amp;str = "md5";
const MD5_HEADER_NAME: HeaderName = HeaderName::from_static("content-md5");

/// Given a `&amp;str` representing a checksum algorithm, return the corresponding `HeaderName`
/// for that checksum algorithm.
pub fn checksum_algorithm_to_checksum_header_name(checksum_algorithm: &amp;str) -&gt; HeaderName {
    if checksum_algorithm.eq_ignore_ascii_case(CRC_32_NAME) {
        CRC_32_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(CRC_32_C_NAME) {
        CRC_32_C_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_1_NAME) {
        SHA_1_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_256_NAME) {
        SHA_256_HEADER_NAME
    } else if checksum_algorithm.eq_ignore_ascii_case(MD5_NAME) {
        MD5_HEADER_NAME
    } else {
        // TODO what's the best way to handle this case?
        HeaderName::from_static("x-amz-checksum-unknown")
    }
}

/// Given a `HeaderName` representing a checksum algorithm, return the name of that algorithm
/// as a `&amp;'static str`.
pub fn checksum_header_name_to_checksum_algorithm(
    checksum_header_name: &amp;HeaderName,
) -&gt; &amp;'static str {
    if checksum_header_name == CRC_32_HEADER_NAME {
        CRC_32_NAME
    } else if checksum_header_name == CRC_32_C_HEADER_NAME {
        CRC_32_C_NAME
    } else if checksum_header_name == SHA_1_HEADER_NAME {
        SHA_1_NAME
    } else if checksum_header_name == SHA_256_HEADER_NAME {
        SHA_256_NAME
    } else if checksum_header_name == MD5_HEADER_NAME {
        MD5_NAME
    } else {
        // TODO what's the best way to handle this case?
        "unknown-checksum-algorithm"
    }
}

/// When a response has to be checksum-verified, we have to check possible headers until we find the
/// header with the precalculated checksum. Because a service may send back multiple headers, we have
/// to check them in order based on how fast each checksum is to calculate.
pub const CHECKSUM_HEADERS_IN_PRIORITY_ORDER: [HeaderName; 4] = [
    CRC_32_C_HEADER_NAME,
    CRC_32_HEADER_NAME,
    SHA_1_HEADER_NAME,
    SHA_256_HEADER_NAME,
];

type BoxError = Box&lt;dyn std::error::Error + Send + Sync&gt;;

/// Checksum algorithms are use to validate the integrity of data. Structs that implement this trait
/// can be used as checksum calculators. This trait requires Send + Sync because these checksums are
/// often used in a threaded context.
pub trait Checksum: Send + Sync {
    /// Given a slice of bytes, update this checksum's internal state.
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt;;
    /// Either return this checksum as a `HeaderMap` containing one HTTP header, or return an error
    /// describing why checksum calculation failed.
    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt;;
    /// Return the `HeaderName` used to represent this checksum algorithm
    fn header_name(&amp;self) -&gt; HeaderName;
    /// "Finalize" this checksum, returning the calculated value as `Bytes` or an error that
    /// occurred during checksum calculation. To print this value in a human-readable hexadecimal
    /// format, you can print it using Rust's builtin [formatter].
    ///
    /// _**NOTE:** typically, "finalizing" a checksum in Rust will take ownership of the checksum
    /// struct. In this method, we clone the checksum's state before finalizing because checksums
    /// may be used in a situation where taking ownership is not possible._
    ///
    /// [formatter]: https://doc.rust-lang.org/std/fmt/trait.UpperHex.html
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt;;
    /// Return the size of this checksum algorithms resulting checksum, in bytes. For example, the
    /// CRC32 checksum algorithm calculates a 32 bit checksum, so a CRC32 checksum struct
    /// implementing this trait method would return 4.
    fn size(&amp;self) -&gt; u64;
}

/// Create a new `Box&lt;dyn Checksum&gt;` from an algorithm name. Valid algorithm names are defined as
/// `const`s in this module.
pub fn new_checksum(checksum_algorithm: &amp;str) -&gt; Box&lt;dyn Checksum&gt; {
    if checksum_algorithm.eq_ignore_ascii_case(CRC_32_NAME) {
        Box::new(Crc32::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(CRC_32_C_NAME) {
        Box::new(Crc32c::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_1_NAME) {
        Box::new(Sha1::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(SHA_256_NAME) {
        Box::new(Sha256::default())
    } else if checksum_algorithm.eq_ignore_ascii_case(MD5_NAME) {
        // It's possible to create an MD5 and we do this in some situations for compatibility.
        // We deliberately hide this from users so that they don't go using it.
        Box::new(Md5::default())
    } else {
        panic!("unsupported checksum algorithm '{}'", checksum_algorithm)
    }
}

#[derive(Debug, Default)]
struct Crc32 {
    hasher: crc32fast::Hasher,
}

impl Crc32 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.update(bytes);

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            &amp;self.hasher.clone().finalize().to_be_bytes(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        4
    }

    fn header_name() -&gt; HeaderName {
        CRC_32_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(u32::to_be_bytes(hash)))
            .expect("will always produce a valid header value from a CRC32 checksum")
    }
}

impl Checksum for Crc32 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Crc32c {
    state: Option&lt;u32&gt;,
}

impl Crc32c {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.state = match self.state {
            Some(crc) =&gt; Some(crc32c::crc32c_append(crc, bytes)),
            None =&gt; Some(crc32c::crc32c(bytes)),
        };

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            &amp;self.state.unwrap_or_default().to_be_bytes(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        4
    }

    fn header_name() -&gt; HeaderName {
        CRC_32_C_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // If no data was provided to this callback and no CRC was ever calculated, return zero as the checksum.
        let hash = self.state.unwrap_or_default();
        HeaderValue::from_str(&amp;base64::encode(u32::to_be_bytes(hash)))
            .expect("will always produce a valid header value from a CRC32C checksum")
    }
}

impl Checksum for Crc32c {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Sha1 {
    hasher: sha1::Sha1,
}

impl Sha1 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        20
    }

    fn header_name() -&gt; HeaderName {
        SHA_1_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect("will always produce a valid header value from a SHA-1 checksum")
    }
}

impl Checksum for Sha1 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Sha256 {
    hasher: sha2::Sha256,
}

impl Sha256 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        32
    }

    fn header_name() -&gt; HeaderName {
        SHA_256_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect("will always produce a valid header value from a SHA-256 checksum")
    }
}

impl Checksum for Sha256 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

#[derive(Debug, Default)]
struct Md5 {
    hasher: md5::Md5,
}

impl Md5 {
    fn update(&amp;mut self, bytes: &amp;[u8]) -&gt; Result&lt;(), BoxError&gt; {
        self.hasher.write_all(bytes)?;

        Ok(())
    }

    fn headers(&amp;self) -&gt; Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, BoxError&gt; {
        let mut header_map = HeaderMap::new();
        header_map.insert(Self::header_name(), self.header_value());

        Ok(Some(header_map))
    }

    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Ok(Bytes::copy_from_slice(
            self.hasher.clone().finalize().as_slice(),
        ))
    }

    // Size of the checksum in bytes
    fn size() -&gt; u64 {
        16
    }

    fn header_name() -&gt; HeaderName {
        MD5_HEADER_NAME
    }

    fn header_value(&amp;self) -&gt; HeaderValue {
        // We clone the hasher because `Hasher::finalize` consumes `self`
        let hash = self.hasher.clone().finalize();
        HeaderValue::from_str(&amp;base64::encode(&amp;hash[..]))
            .expect("will always produce a valid header value from an MD5 checksum")
    }
}

impl Checksum for Md5 {
    fn update(
        &amp;mut self,
        bytes: &amp;[u8],
    ) -&gt; Result&lt;(), Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::update(self, bytes)
    }
    fn headers(
        &amp;self,
    ) -&gt; Result&lt;Option&lt;HeaderMap&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt; {
        Self::headers(self)
    }
    fn header_name(&amp;self) -&gt; HeaderName {
        Self::header_name()
    }
    fn finalize(&amp;self) -&gt; Result&lt;Bytes, BoxError&gt; {
        Self::finalize(self)
    }
    fn size(&amp;self) -&gt; u64 {
        Self::size()
    }
}

// We have existing tests for the checksums, those don't require an update</code></pre>
<h3 id="checksumbody"><a class="header" href="#checksumbody"><code>ChecksumBody</code></a></h3>
<p>When creating a checksum-validated request with an in-memory request body, we can read the body, calculate a checksum, and insert the checksum header, all before sending the request. When creating a checksum-validated request with a streaming request body, we don't have that luxury. Instead, we must calculate a checksum while sending the body, and append that checksum as a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Trailer">trailer</a>.</p>
<p>We will accomplish this by wrapping the <code>SdkBody</code> that requires validation within a <code>ChecksumBody</code>. Afterwards, we'll need to wrap the <code>ChecksumBody</code> in yet another layer which we'll discuss in the <a href="rfcs/rfc0016_flexible_checksum_support.html#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code> and <code>AwsChunkedBodyOptions</code></a> section.</p>
<pre><code class="language-rust ignore">// In aws-smithy-checksums/src/body.rs
use crate::{new_checksum, Checksum};

use aws_smithy_http::body::SdkBody;
use aws_smithy_http::header::append_merge_header_maps;
use aws_smithy_types::base64;

use bytes::{Buf, Bytes};
use http::header::HeaderName;
use http::{HeaderMap, HeaderValue};
use http_body::{Body, SizeHint};
use pin_project::pin_project;

use std::fmt::Display;
use std::pin::Pin;
use std::task::{Context, Poll};

/// A `ChecksumBody` will read and calculate a request body as it's being sent. Once the body has
/// been completely read, it'll append a trailer with the calculated checksum.
#[pin_project]
pub struct ChecksumBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    checksum: Box&lt;dyn Checksum&gt;,
}

impl ChecksumBody&lt;SdkBody&gt; {
    /// Given an `SdkBody` and the name of a checksum algorithm as a `&amp;str`, create a new
    /// `ChecksumBody&lt;SdkBody&gt;`. Valid checksum algorithm names are defined in this crate's
    /// [root module](super).
    ///
    /// # Panics
    ///
    /// This will panic if the given checksum algorithm is not supported.
    pub fn new(body: SdkBody, checksum_algorithm: &amp;str) -&gt; Self {
        Self {
            checksum: new_checksum(checksum_algorithm),
            inner: body,
        }
    }

    /// Return the name of the trailer that will be emitted by this `ChecksumBody`
    pub fn trailer_name(&amp;self) -&gt; HeaderName {
        self.checksum.header_name()
    }

    /// Calculate and return the sum of the:
    /// - checksum when base64 encoded
    /// - trailer name
    /// - trailer separator
    ///
    /// This is necessary for calculating the true size of the request body for certain
    /// content-encodings.
    pub fn trailer_length(&amp;self) -&gt; u64 {
        let trailer_name_size_in_bytes = self.checksum.header_name().as_str().len() as u64;
        let base64_encoded_checksum_size_in_bytes = base64::encoded_length(self.checksum.size());

        (trailer_name_size_in_bytes
            // HTTP trailer names and values may be separated by either a single colon or a single
            // colon and a whitespace. In the AWS Rust SDK, we use a single colon.
            + ":".len() as u64
            + base64_encoded_checksum_size_in_bytes)
    }

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, aws_smithy_http::body::Error&gt;&gt;&gt; {
        let this = self.project();
        let inner = this.inner;
        let mut checksum = this.checksum;

        match inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let len = data.chunk().len();
                let bytes = data.copy_to_bytes(len);

                if let Err(e) = checksum.update(&amp;bytes) {
                    return Poll::Ready(Some(Err(e)));
                }

                Poll::Ready(Some(Ok(bytes)))
            }
            Poll::Ready(None) =&gt; Poll::Ready(None),
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}

impl http_body::Body for ChecksumBody&lt;SdkBody&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        self.poll_inner(cx)
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        let this = self.project();
        match (
            this.checksum.headers(),
            http_body::Body::poll_trailers(this.inner, cx),
        ) {
            // If everything is ready, return trailers, merging them if we have more than one map
            (Ok(outer_trailers), Poll::Ready(Ok(inner_trailers))) =&gt; {
                let trailers = match (outer_trailers, inner_trailers) {
                    // Values from the inner trailer map take precedent over values from the outer map
                    (Some(outer), Some(inner)) =&gt; Some(append_merge_header_maps(inner, outer)),
                    // If only one or neither produced trailers, just combine the `Option`s with `or`
                    (outer, inner) =&gt; outer.or(inner),
                };
                Poll::Ready(Ok(trailers))
            }
            // If the inner poll is Ok but the outer body's checksum callback encountered an error,
            // return the error
            (Err(e), Poll::Ready(Ok(_))) =&gt; Poll::Ready(Err(e)),
            // Otherwise return the result of the inner poll.
            // It may be pending or it may be ready with an error.
            (_, inner_poll) =&gt; inner_poll,
        }
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.inner.is_end_stream()
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        let body_size_hint = self.inner.size_hint();
        match body_size_hint.exact() {
            Some(size) =&gt; {
                let checksum_size_hint = self.checksum.size();
                SizeHint::with_exact(size + checksum_size_hint)
            }
            // TODO is this the right behavior?
            None =&gt; {
                let checksum_size_hint = self.checksum.size();
                let mut summed_size_hint = SizeHint::new();
                summed_size_hint.set_lower(body_size_hint.lower() + checksum_size_hint);

                if let Some(body_size_hint_upper) = body_size_hint.upper() {
                    summed_size_hint.set_upper(body_size_hint_upper + checksum_size_hint);
                }

                summed_size_hint
            }
        }
    }
}

// The tests I have written are omitted from this RFC for brevity. The request body checksum calculation and trailer size calculations are all tested.</code></pre>
<h3 id="checksumvalidatedbody"><a class="header" href="#checksumvalidatedbody"><code>ChecksumValidatedBody</code></a></h3>
<p>Users may request checksum validation for response bodies. That capability is provided by <code>ChecksumValidatedBody</code>, which will calculate a checksum as the response body is being read. Once all data has been read, the calculated checksum is compared to a precalculated checksum set during body creation. If the checksums don't match, then the body will emit an error.</p>
<pre><code class="language-rust ignore">// In aws-smithy-checksums/src/body.rs
/// A response body that will calculate a checksum as it is read. If all data is read and the
/// calculated checksum doesn't match a precalculated checksum, this body will emit an
/// [asw_smithy_http::body::Error].
#[pin_project]
pub struct ChecksumValidatedBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    checksum: Box&lt;dyn Checksum&gt;,
    precalculated_checksum: Bytes,
}

impl ChecksumValidatedBody&lt;SdkBody&gt; {
    /// Given an `SdkBody`, the name of a checksum algorithm as a `&amp;str`, and a precalculated
    /// checksum represented as `Bytes`, create a new `ChecksumValidatedBody&lt;SdkBody&gt;`.
    /// Valid checksum algorithm names are defined in this crate's [root module](super).
    ///
    /// # Panics
    ///
    /// This will panic if the given checksum algorithm is not supported.
    pub fn new(body: SdkBody, checksum_algorithm: &amp;str, precalculated_checksum: Bytes) -&gt; Self {
        Self {
            checksum: new_checksum(checksum_algorithm),
            inner: body,
            precalculated_checksum,
        }
    }

    fn poll_inner(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Bytes, aws_smithy_http::body::Error&gt;&gt;&gt; {
        let this = self.project();
        let inner = this.inner;
        let mut checksum = this.checksum;

        match inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let len = data.chunk().len();
                let bytes = data.copy_to_bytes(len);

                if let Err(e) = checksum.update(&amp;bytes) {
                    return Poll::Ready(Some(Err(e)));
                }

                Poll::Ready(Some(Ok(bytes)))
            }
            // Once the inner body has stopped returning data, check the checksum
            // and return an error if it doesn't match.
            Poll::Ready(None) =&gt; {
                let actual_checksum = {
                    match checksum.finalize() {
                        Ok(checksum) =&gt; checksum,
                        Err(err) =&gt; {
                            return Poll::Ready(Some(Err(err)));
                        }
                    }
                };
                if *this.precalculated_checksum == actual_checksum {
                    Poll::Ready(None)
                } else {
                    // So many parens it's starting to look like LISP
                    Poll::Ready(Some(Err(Box::new(Error::checksum_mismatch(
                        this.precalculated_checksum.clone(),
                        actual_checksum,
                    )))))
                }
            }
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}

/// Errors related to checksum calculation and validation
#[derive(Debug, Eq, PartialEq)]
#[non_exhaustive]
pub enum Error {
    /// The actual checksum didn't match the expected checksum. The checksummed data has been
    /// altered since the expected checksum was calculated.
    ChecksumMismatch { expected: Bytes, actual: Bytes },
}

impl Error {
    /// Given an expected checksum and an actual checksum in `Bytes` form, create a new
    /// `Error::ChecksumMismatch`.
    pub fn checksum_mismatch(expected: Bytes, actual: Bytes) -&gt; Self {
        Self::ChecksumMismatch { expected, actual }
    }
}

impl Display for Error {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; Result&lt;(), std::fmt::Error&gt; {
        match self {
            Error::ChecksumMismatch { expected, actual } =&gt; write!(
                f,
                "body checksum mismatch. expected body checksum to be {:x} but it was {:x}",
                expected, actual
            ),
        }
    }
}

impl std::error::Error for Error {}

impl http_body::Body for ChecksumValidatedBody&lt;SdkBody&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        self.poll_inner(cx)
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        self.project().inner.poll_trailers(cx)
    }

    // Once the inner body returns true for is_end_stream, we still need to
    // verify the checksum; Therefore, we always return false here.
    fn is_end_stream(&amp;self) -&gt; bool {
        false
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        self.inner.size_hint()
    }
}

// The tests I have written are omitted from this RFC for brevity. The response body checksum verification is tested.</code></pre>
<h3 id="awschunkedbody-and-awschunkedbodyoptions"><a class="header" href="#awschunkedbody-and-awschunkedbodyoptions"><code>AwsChunkedBody</code> and <code>AwsChunkedBodyOptions</code></a></h3>
<p>In order to send a request with checksum trailers, we must use an AWS-specific content encoding called <code>aws-chunked</code>. This encoding requires that we:</p>
<ul>
<li>Divide the original body content into one or more chunks. For our purposes we only ever use one chunk.</li>
<li>Append a hexadecimal chunk size header to each chunk.</li>
<li>Suffix each chunk with a <a href="https://developer.mozilla.org/en-US/docs/Glossary/CRLF">CRLF (carriage return line feed)</a>.</li>
<li>Send a 0 and CRLF to close the original body content section.</li>
<li>Send trailers as part of the request body, suffixing each with a CRLF.</li>
<li>Send a final CRLF to close the request body.</li>
</ul>
<p>As an example, Sending a regular request body with a SHA-256 checksum would look similar to this:</p>
<pre><code class="language-HTTP">PUT SOMEURL HTTP/1.1
x-amz-checksum-sha256: ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=
Content-Length: 11
...

Hello world
</code></pre>
<p>and the <code>aws-chunked</code> version would look like this:</p>
<pre><code class="language-HTTP">PUT SOMEURL HTTP/1.1
x-amz-trailer: x-amz-checksum-sha256
x-amz-decoded-content-length: 11
Content-Encoding: aws-chunked
Content-Length: 87
...

B\r\n
Hello world\r\n
0\r\n
x-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=\r\n
\r\n
</code></pre>
<p><em><strong>NOTES:</strong></em></p>
<ul>
<li><em>In the second example, <code>B</code> is the hexadecimal representation of 11.</em></li>
<li><em>Authorization and other headers are omitted from the examples above for brevity.</em></li>
<li><em>When using <code>aws-chunked</code> content encoding, S3 requires that we send the <code>x-amz-decoded-content-length</code> with the length of the original body content.</em></li>
</ul>
<p>This encoding scheme is performed by <code>AwsChunkedBody</code> and configured with <code>AwsChunkedBodyOptions</code>.</p>
<pre><code class="language-rust ignore">// In aws-http/src/content_encoding.rs
use aws_smithy_checksums::body::ChecksumBody;
use aws_smithy_http::body::SdkBody;

use bytes::{Buf, Bytes, BytesMut};
use http::{HeaderMap, HeaderValue};
use http_body::{Body, SizeHint};
use pin_project::pin_project;

use std::pin::Pin;
use std::task::{Context, Poll};

const CRLF: &amp;str = "\r\n";
const CHUNK_TERMINATOR: &amp;str = "0\r\n";

/// Content encoding header value constants
pub mod header_value {
    /// Header value denoting "aws-chunked" encoding
    pub const AWS_CHUNKED: &amp;str = "aws-chunked";
}

/// Options used when constructing an [`AwsChunkedBody`][AwsChunkedBody].
#[derive(Debug, Default)]
#[non_exhaustive]
pub struct AwsChunkedBodyOptions {
    /// The total size of the stream. For unsigned encoding this implies that
    /// there will only be a single chunk containing the underlying payload,
    /// unless ChunkLength is also specified.
    pub stream_length: Option&lt;u64&gt;,
    /// The maximum size of each chunk to be sent.
    ///
    /// If ChunkLength and stream_length are both specified, the stream will be
    /// broken up into chunk_length chunks. The encoded length of the aws-chunked
    /// encoding can still be determined as long as all trailers, if any, have a
    /// fixed length.
    pub chunk_length: Option&lt;u64&gt;,
    /// The length of each trailer sent within an `AwsChunkedBody`. Necessary in
    /// order to correctly calculate the total size of the body accurately.
    pub trailer_lens: Vec&lt;u64&gt;,
}

impl AwsChunkedBodyOptions {
    /// Create a new [`AwsChunkedBodyOptions`][AwsChunkedBodyOptions]
    pub fn new() -&gt; Self {
        Self::default()
    }

    /// Set stream length
    pub fn with_stream_length(mut self, stream_length: u64) -&gt; Self {
        self.stream_length = Some(stream_length);
        self
    }

    /// Set chunk length
    pub fn with_chunk_length(mut self, chunk_length: u64) -&gt; Self {
        self.chunk_length = Some(chunk_length);
        self
    }

    /// Set a trailer len
    pub fn with_trailer_len(mut self, trailer_len: u64) -&gt; Self {
        self.trailer_lens.push(trailer_len);
        self
    }
}

#[derive(Debug, PartialEq, Eq)]
enum AwsChunkedBodyState {
    WritingChunkSize,
    WritingChunk,
    WritingTrailers,
    Closed,
}

/// A request body compatible with `Content-Encoding: aws-chunked`
///
/// Chunked-Body grammar is defined in [ABNF] as:
///
/// ```txt
/// Chunked-Body    = *chunk
///                   last-chunk
///                   chunked-trailer
///                   CRLF
///
/// chunk           = chunk-size CRLF chunk-data CRLF
/// chunk-size      = 1*HEXDIG
/// last-chunk      = 1*("0") CRLF
/// chunked-trailer = *( entity-header CRLF )
/// entity-header   = field-name ":" OWS field-value OWS
/// ```
/// For more info on what the abbreviations mean, see https://datatracker.ietf.org/doc/html/rfc7230#section-1.2
///
/// [ABNF]:https://en.wikipedia.org/wiki/Augmented_Backus%E2%80%93Naur_form
#[derive(Debug)]
#[pin_project]
pub struct AwsChunkedBody&lt;InnerBody&gt; {
    #[pin]
    inner: InnerBody,
    #[pin]
    state: AwsChunkedBodyState,
    options: AwsChunkedBodyOptions,
}

// Currently, we only use this in terms of a streaming request body with checksum trailers
type Inner = ChecksumBody&lt;SdkBody&gt;;

impl AwsChunkedBody&lt;Inner&gt; {
    /// Wrap the given body in an outer body compatible with `Content-Encoding: aws-chunked`
    pub fn new(body: Inner, options: AwsChunkedBodyOptions) -&gt; Self {
        Self {
            inner: body,
            state: AwsChunkedBodyState::WritingChunkSize,
            options,
        }
    }

    fn encoded_length(&amp;self) -&gt; Option&lt;u64&gt; {
        if self.options.chunk_length.is_none() &amp;&amp; self.options.stream_length.is_none() {
            return None;
        }

        let mut length = 0;
        let stream_length = self.options.stream_length.unwrap_or_default();
        if stream_length != 0 {
            if let Some(chunk_length) = self.options.chunk_length {
                let num_chunks = stream_length / chunk_length;
                length += num_chunks * get_unsigned_chunk_bytes_length(chunk_length);
                let remainder = stream_length % chunk_length;
                if remainder != 0 {
                    length += get_unsigned_chunk_bytes_length(remainder);
                }
            } else {
                length += get_unsigned_chunk_bytes_length(stream_length);
            }
        }

        // End chunk
        length += CHUNK_TERMINATOR.len() as u64;

        // Trailers
        for len in self.options.trailer_lens.iter() {
            length += len + CRLF.len() as u64;
        }

        // Encoding terminator
        length += CRLF.len() as u64;

        Some(length)
    }
}

fn prefix_with_chunk_size(data: Bytes, chunk_size: u64) -&gt; Bytes {
    // Len is the size of the entire chunk as defined in `AwsChunkedBodyOptions`
    let mut prefixed_data = BytesMut::from(format!("{:X?}\r\n", chunk_size).as_bytes());
    prefixed_data.extend_from_slice(&amp;data);

    prefixed_data.into()
}

fn get_unsigned_chunk_bytes_length(payload_length: u64) -&gt; u64 {
    let hex_repr_len = int_log16(payload_length);
    hex_repr_len + CRLF.len() as u64 + payload_length + CRLF.len() as u64
}

fn trailers_as_aws_chunked_bytes(
    total_length_of_trailers_in_bytes: u64,
    trailer_map: Option&lt;HeaderMap&gt;,
) -&gt; Bytes {
    use std::fmt::Write;

    // On 32-bit operating systems, we might not be able to convert the u64 to a usize, so we just
    // use `String::new` in that case.
    let mut trailers = match usize::try_from(total_length_of_trailers_in_bytes) {
        Ok(total_length_of_trailers_in_bytes) =&gt; {
            String::with_capacity(total_length_of_trailers_in_bytes)
        }
        Err(_) =&gt; String::new(),
    };
    let mut already_wrote_first_trailer = false;

    if let Some(trailer_map) = trailer_map {
        for (header_name, header_value) in trailer_map.into_iter() {
            match header_name {
                // New name, new value
                Some(header_name) =&gt; {
                    if already_wrote_first_trailer {
                        // First trailer shouldn't have a preceding CRLF, but every trailer after it should
                        trailers.write_str(CRLF).unwrap();
                    } else {
                        already_wrote_first_trailer = true;
                    }

                    trailers.write_str(header_name.as_str()).unwrap();
                    trailers.write_char(':').unwrap();
                }
                // Same name, new value
                None =&gt; {
                    trailers.write_char(',').unwrap();
                }
            }
            trailers.write_str(header_value.to_str().unwrap()).unwrap();
        }
    }

    // Write CRLF to end the body
    trailers.write_str(CRLF).unwrap();
    // If we wrote at least one trailer, we need to write an extra CRLF
    if total_length_of_trailers_in_bytes != 0 {
        trailers.write_str(CRLF).unwrap();
    }

    trailers.into()
}

impl Body for AwsChunkedBody&lt;Inner&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        tracing::info!("polling AwsChunkedBody");
        let mut this = self.project();

        match *this.state {
            AwsChunkedBodyState::WritingChunkSize =&gt; match this.inner.poll_data(cx) {
                Poll::Ready(Some(Ok(data))) =&gt; {
                    // A chunk must be prefixed by chunk size in hexadecimal
                    tracing::info!("writing chunk size and start of chunk");
                    *this.state = AwsChunkedBodyState::WritingChunk;
                    let total_chunk_size = this
                        .options
                        .chunk_length
                        .or(this.options.stream_length)
                        .unwrap_or_default();
                    Poll::Ready(Some(Ok(prefix_with_chunk_size(data, total_chunk_size))))
                }
                Poll::Ready(None) =&gt; {
                    tracing::info!("chunk was empty, writing last-chunk");
                    *this.state = AwsChunkedBodyState::WritingTrailers;
                    Poll::Ready(Some(Ok(Bytes::from("0\r\n"))))
                }
                Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
                Poll::Pending =&gt; Poll::Pending,
            },
            AwsChunkedBodyState::WritingChunk =&gt; match this.inner.poll_data(cx) {
                Poll::Ready(Some(Ok(mut data))) =&gt; {
                    tracing::info!("writing rest of chunk data");
                    Poll::Ready(Some(Ok(data.copy_to_bytes(data.len()))))
                }
                Poll::Ready(None) =&gt; {
                    tracing::info!("no more chunk data, writing CRLF and last-chunk");
                    *this.state = AwsChunkedBodyState::WritingTrailers;
                    Poll::Ready(Some(Ok(Bytes::from("\r\n0\r\n"))))
                }
                Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
                Poll::Pending =&gt; Poll::Pending,
            },
            AwsChunkedBodyState::WritingTrailers =&gt; {
                return match this.inner.poll_trailers(cx) {
                    Poll::Ready(Ok(trailers)) =&gt; {
                        *this.state = AwsChunkedBodyState::Closed;
                        let total_length_of_trailers_in_bytes =
                            this.options.trailer_lens.iter().fold(0, |acc, n| acc + n);

                        Poll::Ready(Some(Ok(trailers_as_aws_chunked_bytes(
                            total_length_of_trailers_in_bytes,
                            trailers,
                        ))))
                    }
                    Poll::Pending =&gt; Poll::Pending,
                    Poll::Ready(Err(e)) =&gt; Poll::Ready(Some(Err(e))),
                };
            }
            AwsChunkedBodyState::Closed =&gt; {
                return Poll::Ready(None);
            }
        }
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        // Trailers were already appended to the body because of the content encoding scheme
        Poll::Ready(Ok(None))
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.state == AwsChunkedBodyState::Closed
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        SizeHint::with_exact(
            self.encoded_length()
                .expect("Requests made with aws-chunked encoding must have known size")
                as u64,
        )
    }
}

// Used for finding how many hexadecimal digits it takes to represent a base 10 integer
fn int_log16&lt;T&gt;(mut i: T) -&gt; u64
where
    T: std::ops::DivAssign + PartialOrd + From&lt;u8&gt; + Copy,
{
    let mut len = 0;
    let zero = T::from(0);
    let sixteen = T::from(16);

    while i &gt; zero {
        i /= sixteen;
        len += 1;
    }

    len
}

#[cfg(test)]
mod tests {
    use super::AwsChunkedBody;
    use crate::content_encoding::AwsChunkedBodyOptions;
    use aws_smithy_checksums::body::ChecksumBody;
    use aws_smithy_http::body::SdkBody;
    use bytes::Buf;
    use bytes_utils::SegmentedBuf;
    use http_body::Body;
    use std::io::Read;

    #[tokio::test]
    async fn test_aws_chunked_encoded_body() {
        let input_text = "Hello world";
        let sdk_body = SdkBody::from(input_text);
        let checksum_body = ChecksumBody::new(sdk_body, "sha256");
        let aws_chunked_body_options = AwsChunkedBodyOptions {
            stream_length: Some(input_text.len() as u64),
            chunk_length: None,
            trailer_lens: vec![
                "x-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=".len() as u64,
            ],
        };
        let mut aws_chunked_body = AwsChunkedBody::new(checksum_body, aws_chunked_body_options);

        let mut output = SegmentedBuf::new();
        while let Some(buf) = aws_chunked_body.data().await {
            output.push(buf.unwrap());
        }

        let mut actual_output = String::new();
        output
            .reader()
            .read_to_string(&amp;mut actual_output)
            .expect("Doesn't cause IO errors");

        let expected_output = "B\r\nHello world\r\n0\r\nx-amz-checksum-sha256:ZOyIygCyaOW6GjVnihtTFtIS9PNmskdyMlNKiuyjfzw=\r\n\r\n";

        // Verify data is complete and correctly encoded
        assert_eq!(expected_output, actual_output);

        assert!(
            aws_chunked_body
                .trailers()
                .await
                .expect("checksum generation was without error")
                .is_none(),
            "aws-chunked encoded bodies don't have normal HTTP trailers"
        );
    }

    #[tokio::test]
    async fn test_empty_aws_chunked_encoded_body() {
        let sdk_body = SdkBody::from("");
        let checksum_body = ChecksumBody::new(sdk_body, "sha256");
        let aws_chunked_body_options = AwsChunkedBodyOptions {
            stream_length: Some(0),
            chunk_length: None,
            trailer_lens: vec![
                "x-amz-checksum-sha256:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=".len() as u64,
            ],
        };
        let mut aws_chunked_body = AwsChunkedBody::new(checksum_body, aws_chunked_body_options);

        let mut output = SegmentedBuf::new();
        while let Some(buf) = aws_chunked_body.data().await {
            output.push(buf.unwrap());
        }

        let mut actual_output = String::new();
        output
            .reader()
            .read_to_string(&amp;mut actual_output)
            .expect("Doesn't cause IO errors");

        let expected_output =
            "0\r\nx-amz-checksum-sha256:47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU=\r\n\r\n";

        // Verify data is complete and correctly encoded
        assert_eq!(expected_output, actual_output);

        assert!(
            aws_chunked_body
                .trailers()
                .await
                .expect("checksum generation was without error")
                .is_none(),
            "aws-chunked encoded bodies don't have normal HTTP trailers"
        );
    }
}</code></pre>
<h3 id="sigv4-update"><a class="header" href="#sigv4-update">Sigv4 Update</a></h3>
<p>When sending checksum-verified requests with a streaming body, we must update the usual signing process. Instead of signing the request based on the request body's checksum, we must sign it with a special header instead:</p>
<pre><code class="language-HTTP">Authorization: &lt;computed authorization header value using "STREAMING-UNSIGNED-PAYLOAD-TRAILER"&gt;
x-amz-content-sha256: STREAMING-UNSIGNED-PAYLOAD-TRAILER
</code></pre>
<p>Setting <code>STREAMING-UNSIGNED-PAYLOAD-TRAILER</code> tells the signer that we're sending an unsigned streaming body that will be followed by trailers.</p>
<p>We can achieve this by:</p>
<ul>
<li>Adding a new variant to <code>SignableBody</code>:
<pre><code class="language-rust ignore">/// A signable HTTP request body
#[derive(Debug, Clone, Eq, PartialEq)]
#[non_exhaustive]
pub enum SignableBody&lt;'a&gt; {
    // existing variants have been omitted for brevity...

    /// An unsigned payload with trailers
    ///
    /// StreamingUnsignedPayloadTrailer is used for streaming requests where the contents of the
    /// body cannot be known prior to signing **AND** which include HTTP trailers.
    StreamingUnsignedPayloadTrailer,
}</code></pre>
</li>
<li>Updating the <code>CanonicalRequest::payload_hash</code> method to include the new <code>SignableBody</code> variant:
<pre><code class="language-rust ignore">fn payload_hash&lt;'b&gt;(body: &amp;'b SignableBody&lt;'b&gt;) -&gt; Cow&lt;'b, str&gt; {
    // Payload hash computation
    //
    // Based on the input body, set the payload_hash of the canonical request:
    // Either:
    // - compute a hash
    // - use the precomputed hash
    // - use `UnsignedPayload`
    // - use `StreamingUnsignedPayloadTrailer`
    match body {
        SignableBody::Bytes(data) =&gt; Cow::Owned(sha256_hex_string(data)),
        SignableBody::Precomputed(digest) =&gt; Cow::Borrowed(digest.as_str()),
        SignableBody::UnsignedPayload =&gt; Cow::Borrowed(UNSIGNED_PAYLOAD),
        SignableBody::StreamingUnsignedPayloadTrailer =&gt; {
            Cow::Borrowed(STREAMING_UNSIGNED_PAYLOAD_TRAILER)
        }
    }
}</code></pre>
</li>
<li><em>(in generated code)</em> Inserting the <code>SignableBody</code> into the request property bag when making a checksum-verified streaming request:
<pre><code class="language-rust ignore">if self.checksum_algorithm.is_some() {
    request
        .properties_mut()
        .insert(aws_sig_auth::signer::SignableBody::StreamingUnsignedPayloadTrailer);
}</code></pre>
</li>
</ul>
<p>It's possible to send <code>aws-chunked</code> requests where each chunk is signed individually. Because this feature isn't strictly necessary for flexible checksums, I've avoided implementing it.</p>
<h3 id="inlineables"><a class="header" href="#inlineables">Inlineables</a></h3>
<p>In order to avoid writing lots of Rust in Kotlin, I have implemented request and response building functions as inlineables:</p>
<ul>
<li>Building checksum-validated requests with in-memory request bodies:
<pre><code class="language-rust ignore">// In aws/rust-runtime/aws-inlineable/src/streaming_body_with_checksum.rs
/// Given a `&amp;mut http::request::Request`, and checksum algorithm name, calculate a checksum and
/// then modify the request to include the checksum as a header.
pub fn build_checksum_validated_request(
    request: &amp;mut http::request::Request&lt;aws_smithy_http::body::SdkBody&gt;,
    checksum_algorithm: &amp;str,
) -&gt; Result&lt;(), aws_smithy_http::operation::BuildError&gt; {
    let data = request.body().bytes().unwrap_or_default();

    let mut checksum = aws_smithy_checksums::new_checksum(checksum_algorithm);
    checksum
        .update(data)
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(err))?;
    let checksum = checksum
        .finalize()
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(err))?;

    request.headers_mut().insert(
        aws_smithy_checksums::checksum_algorithm_to_checksum_header_name(checksum_algorithm),
        aws_smithy_types::base64::encode(&amp;checksum[..])
            .parse()
            .expect("base64-encoded checksums are always valid header values"),
    );

    Ok(())
}</code></pre>
</li>
<li>Building checksum-validated requests with streaming request bodies:
<pre><code class="language-rust ignore">/// Given an `http::request::Builder`, `SdkBody`, and a checksum algorithm name, return a
/// `Request&lt;SdkBody&gt;` with checksum trailers where the content is `aws-chunked` encoded.
pub fn build_checksum_validated_request_with_streaming_body(
    request_builder: http::request::Builder,
    body: aws_smithy_http::body::SdkBody,
    checksum_algorithm: &amp;str,
) -&gt; Result&lt;http::Request&lt;aws_smithy_http::body::SdkBody&gt;, aws_smithy_http::operation::BuildError&gt; {
    use http_body::Body;

    let original_body_size = body
        .size_hint()
        .exact()
        .expect("body must be sized if checksum is requested");
    let body = aws_smithy_checksums::body::ChecksumBody::new(body, checksum_algorithm);
    let checksum_trailer_name = body.trailer_name();
    let aws_chunked_body_options = aws_http::content_encoding::AwsChunkedBodyOptions::new()
        .with_stream_length(original_body_size as usize)
        .with_trailer_len(body.trailer_length() as usize);

    let body = aws_http::content_encoding::AwsChunkedBody::new(body, aws_chunked_body_options);
    let encoded_content_length = body
        .size_hint()
        .exact()
        .expect("encoded_length must return known size");
    let request_builder = request_builder
        .header(
            http::header::CONTENT_LENGTH,
            http::HeaderValue::from(encoded_content_length),
        )
        .header(
            http::header::HeaderName::from_static("x-amz-decoded-content-length"),
            http::HeaderValue::from(original_body_size),
        )
        .header(
            http::header::HeaderName::from_static("x-amz-trailer"),
            checksum_trailer_name,
        )
        .header(
            http::header::CONTENT_ENCODING,
            aws_http::content_encoding::header_value::AWS_CHUNKED.as_bytes(),
        );

    let body = aws_smithy_http::body::SdkBody::from_dyn(http_body::combinators::BoxBody::new(body));

    request_builder
        .body(body)
        .map_err(|err| aws_smithy_http::operation::BuildError::Other(Box::new(err)))
}</code></pre>
</li>
<li>Building checksum-validated responses:
<pre><code class="language-rust ignore">/// Given a `Response&lt;SdkBody&gt;`, checksum algorithm name, and pre-calculated checksum, return a
/// `Response&lt;SdkBody&gt;` where the body will processed with the checksum algorithm and checked
/// against the pre-calculated checksum.
pub fn build_checksum_validated_sdk_body(
    body: aws_smithy_http::body::SdkBody,
    checksum_algorithm: &amp;str,
    precalculated_checksum: bytes::Bytes,
) -&gt; aws_smithy_http::body::SdkBody {
    let body = aws_smithy_checksums::body::ChecksumValidatedBody::new(
        body,
        checksum_algorithm,
        precalculated_checksum.clone(),
    );
    aws_smithy_http::body::SdkBody::from_dyn(http_body::combinators::BoxBody::new(body))
}

/// Given the name of a checksum algorithm and a `HeaderMap`, extract the checksum value from the
/// corresponding header as `Some(Bytes)`. If the header is unset, return `None`.
pub fn check_headers_for_precalculated_checksum(
    headers: &amp;http::HeaderMap&lt;http::HeaderValue&gt;,
) -&gt; Option&lt;(&amp;'static str, bytes::Bytes)&gt; {
    for header_name in aws_smithy_checksums::CHECKSUM_HEADERS_IN_PRIORITY_ORDER {
        if let Some(precalculated_checksum) = headers.get(&amp;header_name) {
            let checksum_algorithm =
                aws_smithy_checksums::checksum_header_name_to_checksum_algorithm(&amp;header_name);
            let precalculated_checksum =
                bytes::Bytes::copy_from_slice(precalculated_checksum.as_bytes());

            return Some((checksum_algorithm, precalculated_checksum));
        }
    }

    None
}</code></pre>
</li>
</ul>
<h2 id="codegen"><a class="header" href="#codegen">Codegen</a></h2>
<p>Codegen will be updated to insert the appropriate inlineable functions for operations that are tagged with the <code>@httpchecksum</code> trait. Some operations will require an MD5 checksum fallback if the user hasn't set a checksum themselves.</p>
<p>Users also have the option of supplying a precalculated checksum of their own. This is already handled by our current header insertion logic and won't require updating the existing implementation. Because this checksum validation behavior is AWS-specific, it will be defined in SDK codegen.</p>
<h2 id="implementation-checklist"><a class="header" href="#implementation-checklist">Implementation Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Implement codegen for building checksum-validated requests:
<ul>
<li><input disabled="" type="checkbox"/>
In-memory request bodies
<ul>
<li><input disabled="" type="checkbox"/>
Support MD5 fallback behavior for services that enable it.</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Streaming request bodies</li>
</ul>
</li>
<li><input disabled="" type="checkbox"/>
Implement codegen for building checksum-validated responses:</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-customizable-client-operations"><a class="header" href="#rfc-customizable-client-operations">RFC: Customizable Client Operations</a></h1>
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0017_customizable_client_operations.html#changes-checklist">Changes Checklist</a> section.</p>
<p>SDK customers occasionally need to add additional HTTP headers to requests, and currently,
the SDK has no easy way to accomplish this. At time of writing, the lower level Smithy
client has to be used to create an operation, and then the HTTP request augmented on
that operation type. For example:</p>
<pre><code class="language-rust ignore">let input = SomeOperationInput::builder().some_value(5).build()?;

let operation = {
    let op = input.make_operation(&amp;service_config).await?;
    let (request, response) = op.into_request_response();

    let request = request.augment(|req, _props| {
        req.headers_mut().insert(
            HeaderName::from_static("x-some-header"),
            HeaderValue::from_static("some-value")
        );
        Result::&lt;_, Infallible&gt;::Ok(req)
    })?;

    Operation::from_parts(request, response)
};

let response = smithy_client.call(operation).await?;</code></pre>
<p>This approach is both difficult to discover and implement since it requires acquiring
a Smithy client rather than the generated fluent client, and it's anything but ergonomic.</p>
<p>This RFC proposes an easier way to augment requests that is compatible with the fluent
client.</p>
<h2 id="terminology-10"><a class="header" href="#terminology-10">Terminology</a></h2>
<ul>
<li><strong>Smithy Client</strong>: A <code>aws_smithy_client::Client&lt;C, M, R&gt;</code> struct that is responsible for gluing together
the connector, middleware, and retry policy.</li>
<li><strong>Fluent Client</strong>: A code generated <code>Client</code> that has methods for each service operation on it.
A fluent builder is generated alongside it to make construction easier.</li>
</ul>
<h2 id="proposal-1"><a class="header" href="#proposal-1">Proposal</a></h2>
<p>The code generated fluent builders returned by the fluent client should have a method added to them,
similar to <code>send</code>, but that returns a customizable request. The customer experience should look as
follows:</p>
<pre><code class="language-rust ignore">let response = client.some_operation()
    .some_value(5)
    .customize()
    .await?
    .mutate_request(|mut req| {
        req.headers_mut().insert(
            HeaderName::from_static("x-some-header"),
            HeaderValue::from_static("some-value")
        );
    })
    .send()
    .await?;</code></pre>
<p>This new async <code>customize</code> method would return the following:</p>
<pre><code class="language-rust ignore">pub struct CustomizableOperation&lt;O, R&gt; {
    handle: Arc&lt;Handle&gt;,
    operation: Operation&lt;O, R&gt;,
}

impl&lt;O, R&gt; CustomizableOperation&lt;O, R&gt; {
    // Allows for customizing the operation's request
    fn map_request&lt;E&gt;(
        mut self,
        f: impl FnOnce(Request&lt;SdkBody&gt;) -&gt; Result&lt;Request&lt;SdkBody&gt;, E&gt;,
    ) -&gt; Result&lt;Self, E&gt; {
        let (request, response) = self.operation.into_request_response();
        let request = request.augment(|req, _props| f(req))?;
        self.operation = Operation::from_parts(request, response);
        Ok(self)
    }

    // Convenience for `map_request` where infallible direct mutation of request is acceptable
    fn mutate_request&lt;E&gt;(
        mut self,
        f: impl FnOnce(&amp;mut Request&lt;SdkBody&gt;) -&gt; (),
    ) -&gt; Self {
        self.map_request(|mut req| {
            f(&amp;mut req);
            Result::&lt;_, Infallible&gt;::Ok(req)
        }).expect("infallible");
        Ok(self)
    }

    // Allows for customizing the entire operation
    fn map_operation&lt;E&gt;(
        mut self,
        f: impl FnOnce(Operation&lt;O, R&gt;) -&gt; Result&lt;Operation&lt;O, R&gt;, E&gt;,
    ) -&gt; Result&lt;Self, E&gt; {
        self.operation = f(self.operation)?;
        Ok(self)
    }

    // Direct access to read the request
    fn request(&amp;self) -&gt; &amp;Request&lt;SdkBody&gt; {
        self.operation.request()
    }

    // Direct access to mutate the request
    fn request_mut(&amp;mut self) -&gt; &amp;mut Request&lt;SdkBody&gt; {
        self.operation.request_mut()
    }

    // Sends the operation's request
    async fn send&lt;T, E&gt;(self) -&gt; Result&lt;T, SdkError&lt;E&gt;&gt;
    where
        O: ParseHttpResponse&lt;Output = Result&lt;T, E&gt;&gt; + Send + Sync + Clone + 'static,
        E: std::error::Error,
        R: ClassifyResponse&lt;SdkSuccess&lt;T&gt;, SdkError&lt;E&gt;&gt; + Send + Sync,
    {
        self.handle.client.call(self.operation).await
    }
}</code></pre>
<p>Additionally, for those who want to avoid closures, the <code>Operation</code> type will have
<code>request</code> and <code>request_mut</code> methods added to it to get direct access to its underlying
HTTP request.</p>
<p>The <code>CustomizableOperation</code> type will then mirror these functions so that the experience
can look as follows:</p>
<pre><code class="language-rust ignore">let mut operation = client.some_operation()
    .some_value(5)
    .customize()
    .await?;
operation.request_mut()
    .headers_mut()
    .insert(
        HeaderName::from_static("x-some-header"),
        HeaderValue::from_static("some-value")
    );
let response = operation.send().await?;</code></pre>
<h3 id="why-not-remove-async-from-customize-to-make-this-more-ergonomic"><a class="header" href="#why-not-remove-async-from-customize-to-make-this-more-ergonomic">Why not remove <code>async</code> from <code>customize</code> to make this more ergonomic?</a></h3>
<p>In the proposal above, customers must <code>await</code> the result of <code>customize</code> in order
to get the <code>CustomizableOperation</code>. This is a result of the underlying <code>map_operation</code>
function that <code>customize</code> needs to call being async, which was made async during
the implementation of customizations for Glacier (see #797, #801, and #1474). It
is possible to move these Glacier customizations into middleware to make <code>map_operation</code>
sync, but keeping it async is much more future-proof since if a future customization
or feature requires it to be async, it won't be a breaking change in the future.</p>
<h3 id="why-the-name-customize"><a class="header" href="#why-the-name-customize">Why the name <code>customize</code>?</a></h3>
<p>Alternatively, the name <code>build</code> could be used, but this increases the odds that
customers won't realize that they can call <code>send</code> directly, and then call a longer
<code>build</code>/<code>send</code> chain when customization isn't needed:</p>
<pre><code class="language-rust ignore">client.some_operation()
    .some_value()
    .build() // Oops, didn't need to do this
    .send()
    .await?;</code></pre>
<p>vs.</p>
<pre><code class="language-rust ignore">client.some_operation()
    .some_value()
    .send()
    .await?;</code></pre>
<p>Additionally, no AWS services at time of writing have a member named <code>customize</code>
that would conflict with the new function, so adding it would not be a breaking change.</p>
<h2 id="changes-checklist-11"><a class="header" href="#changes-checklist-11">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>CustomizableOperation</code> as an inlinable, and code generate it into <code>client</code> so that it has access to <code>Handle</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Code generate the <code>customize</code> method on fluent builders</li>
<li><input disabled="" type="checkbox" checked=""/>
Update the <code>RustReservedWords</code> class to include <code>customize</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add ability to mutate the HTTP request on <code>Operation</code></li>
<li><input disabled="" type="checkbox"/>
Add examples for both approaches</li>
<li><input disabled="" type="checkbox"/>
Comment on older discussions asking about how to do this with this improved approach</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-logging-in-the-presence-of-sensitive-data"><a class="header" href="#rfc-logging-in-the-presence-of-sensitive-data">RFC: Logging in the Presence of Sensitive Data</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>Smithy provides a <a href="https://awslabs.github.io/smithy/1.0/spec/core/documentation-traits.html#sensitive-trait">sensitive trait</a> which exists as a <code>@sensitive</code> field annotation syntactically and has the following semantics:</p>
<blockquote>
<p>Sensitive data MUST NOT be exposed in things like exception messages or log output. Application of this trait SHOULD NOT affect wire logging (i.e., logging of all data transmitted to and from servers or clients).</p>
</blockquote>
<p>This RFC is concerned with solving the problem of honouring this specification in the context of logging.</p>
<p>Progress has been made towards this goal in the form of the <a href="https://github.com/smithy-lang/smithy-rs/pull/229">Sensitive Trait PR</a>, which uses code generation to remove sensitive fields from <code>Debug</code> implementations.</p>
<p>The problem remains open due to the existence of HTTP binding traits and a lack of clearly defined user guidelines which customers may follow to honour the specification.</p>
<p>This RFC proposes:</p>
<ul>
<li>A new logging middleware is generated and applied to each <code>OperationHandler</code> <code>Service</code>.</li>
<li>A developer guideline is provided on how to avoid violating the specification.</li>
</ul>
<h2 id="terminology-11"><a class="header" href="#terminology-11">Terminology</a></h2>
<ul>
<li><strong>Model</strong>: A <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html">Smithy Model</a>, usually pertaining to the one in use by the customer.</li>
<li><strong>Runtime crate</strong>: A crate existing within the <code>rust-runtime</code> folder, used to implement shared functionalities that do not have to be code-generated.</li>
<li><strong>Service</strong>: The <a href="https://docs.rs/tower-service/latest/tower_service/trait.Service.html">tower::Service</a> trait. The lowest level of abstraction we deal with when making HTTP requests. Services act directly on data to transform and modify that data. A Service is what eventually turns a request into a response.</li>
<li><strong>Middleware</strong>: Broadly speaking, middleware modify requests and responses. Concretely, these are exist as implementations of <a href="https://docs.rs/tower/latest/tower/layer/trait.Layer.html">Layer</a>/a <code>Service</code> wrapping an inner <code>Service</code>.</li>
<li><strong>Potentially sensitive</strong>: Data that <em>could</em> be bound to a sensitive field of a structure, for example via the <a href="rfcs/rfc0018_logging_sensitive.html#http-binding-traits">HTTP Binding Traits</a>.</li>
</ul>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<h3 id="http-binding-traits"><a class="header" href="#http-binding-traits">HTTP Binding Traits</a></h3>
<p>Smithy provides various HTTP binding traits. These allow protocols to configure a HTTP request by way of binding fields to parts of the request. For this reason sensitive data might be unintentionally leaked through logging of a bound request.</p>
<div class="table-wrapper"><table><thead><tr><th>Trait</th><th>Configurable</th></tr></thead><tbody>
<tr><td><a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#httpheader-trait">httpHeader</a></td><td>Headers</td></tr>
<tr><td><a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#httpprefixheaders-trait">httpPrefixHeaders</a></td><td>Headers</td></tr>
<tr><td><a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#httplabel-trait">httpLabel</a></td><td>URI</td></tr>
<tr><td><a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#httppayload-trait">httpPayload</a></td><td>Payload</td></tr>
<tr><td><a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#httpquery-trait">httpQuery</a></td><td>Query Parameters</td></tr>
<tr><td><a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#httpresponsecode-trait">httpResponseCode</a></td><td>Status Code</td></tr>
</tbody></table>
</div>
<p>Each of these configurable parts must therefore be logged cautiously.</p>
<h3 id="scope-and-guidelines"><a class="header" href="#scope-and-guidelines">Scope and Guidelines</a></h3>
<p>It would be unfeasible to forbid the logging of sensitive data all together using the type system. With the current API, the customer will always have an opportunity to log a request containing sensitive data before it enters the <code>Service&lt;Request&lt;B&gt;&gt;</code> that we provide to them.</p>
<pre><code class="language-rust ignore">// The API provides us with a `Service&lt;Request&lt;B&gt;&gt;`
let app: Router = OperationRegistryBuilder::default().build().expect("unable to build operation registry").into();

// We can `ServiceExt::map_request` log a request with potentially sensitive data
let app = app.map_request(|request| {
        info!(?request);
        request
    });</code></pre>
<p>A more subtle violation of the specification may occur when the customer enables verbose logging - a third-party dependency might simply log data marked as sensitive, for example <code>tokio</code> or <code>hyper</code>.</p>
<p>These two cases illustrate that <code>smithy-rs</code> can only prevent violation of the specification in a restricted scope - logs emitted from generated code and the runtime crates. A <code>smithy-rs</code> specific guideline should be available to the customer which outlines how to avoid violating the specification in areas outside of our control.</p>
<h3 id="routing"><a class="header" href="#routing">Routing</a></h3>
<p>The sensitivity and HTTP bindings are declared within specific structures/operations. For this reason, in the general case, it's unknowable whether or not any given part of a request is sensitive until we determine which operation is tasked with handling the request and hence which fields are bound. Implementation wise, this means that any middleware applied <em>before</em> routing has taken place cannot log anything potentially sensitive without performing routing logic itself.</p>
<p>Note that:</p>
<ul>
<li>We are not required to deserialize the entire request before we can make judgments on what data is sensitive or not - only which operation it has been routed to.</li>
<li>We are permitted to emit logs prior to routing when:
<ul>
<li>they contain no potentially sensitive data, or</li>
<li>the request failed to route, in which case it's not subject to the constraints of an operation.</li>
</ul>
</li>
</ul>
<h3 id="runtime-crates"><a class="header" href="#runtime-crates">Runtime Crates</a></h3>
<p>The crates existing in <code>rust-runtime</code> are not code generated - their source code is agnostic to the specific model in use. For this reason, if such a crate wanted to log potentially sensitive data then there must be a way to conditionally toggle that log without manipulation of the source code. Any proposed solution must acknowledge this concern.</p>
<h2 id="proposal-2"><a class="header" href="#proposal-2">Proposal</a></h2>
<p>This proposal serves to honor the sensitivity specification via code generation of a logging middleware which is aware of the sensitivity, together with a developer contract disallowing logging potentially sensitive data in the runtime crates. A developer guideline should be provided in addition to the middleware.</p>
<p>All data known to be sensitive should be replaced with <code>"{redacted}"</code> when logged. Implementation wise this means that <a href="https://docs.rs/tracing/latest/tracing/struct.Event.html">tracing::Event</a>s and <a href="https://docs.rs/tracing/latest/tracing/struct.Span.html">tracing::Span</a>s of the form <code>debug!(field = "sensitive data")</code> and <code>span!(..., field = "sensitive data")</code> must become <code>debug!(field = "{redacted}")</code> and <code>span!(..., field = "{redacted}")</code>.</p>
<h3 id="debug-logging"><a class="header" href="#debug-logging">Debug Logging</a></h3>
<p>Developers might want to observe sensitive data for debugging purposes. It should be possible to opt-out of the redactions by enabling a feature flag <code>unredacted-logging</code> (which is disabled by default).</p>
<p>To prevent excessive branches such as</p>
<pre><code class="language-rust ignore">if cfg!(feature = "unredacted-logging") {
    debug!(%data, "logging here");
} else {
    debug!(data = "{redacted}", "logging here");
}</code></pre>
<p>the following wrapper should be provided from a runtime crate:</p>
<pre><code class="language-rust ignore">pub struct Sensitive&lt;T&gt;(T);

impl&lt;T&gt; Debug for Sensitive&lt;T&gt;
where
    T: Debug
{
    fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; Result&lt;(), Error&gt; {
        if cfg!(feature = "unredacted-logging") {
            self.0.fmt(f)
        } else {
            "{redacted}".fmt(f)
        }
    }
}

impl&lt;T&gt; Display for Sensitive&lt;T&gt;
where
    T: Display
{
    fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; Result&lt;(), Error&gt; {
        if cfg!(feature = "unredacted-logging") {
            self.0.fmt(f)
        } else {
            "{redacted}".fmt(f)
        }
    }
}</code></pre>
<p>In which case the branch above becomes</p>
<pre><code class="language-rust ignore">debug!(sensitive_data = %Sensitive(data));</code></pre>
<h3 id="code-generated-logging-middleware"><a class="header" href="#code-generated-logging-middleware">Code Generated Logging Middleware</a></h3>
<p>Using the smithy model, for each operation, a logging middleware should be generated. Through the model, the code generation knows which fields are sensitive and which HTTP bindings exist, therefore the logging middleware can be carefully crafted to avoid leaking sensitive data.</p>
<p>As a request enters this middleware it should record the method, HTTP headers, status code, and URI in a <code>tracing::span</code>. As a response leaves this middleware it should record the HTTP headers and status code in a <code>tracing::debug</code>.</p>
<p>The following model</p>
<pre><code class="language-smithy">@readonly
@http(uri: "/inventory/{name}", method: "GET")
operation Inventory {
    input: Product,
    output: Stocked
}

@input
structure Product {
    @required
    @sensitive
    @httpLabel
    name: String
}

@output
structure Stocked {
    @sensitive
    @httpResponseCode
    code: String,
}
</code></pre>
<p>should generate the following</p>
<pre><code class="language-rust ignore">// NOTE: This code is intended to show behavior - it does not compile

pub struct InventoryLogging&lt;S&gt; {
    inner: S,
    operation_name: &amp;'static str
}

impl&lt;S&gt; InventoryLogging&lt;S&gt; {
    pub fn new(inner: S) -&gt; Self {
        Self {
            inner
        }
    }
}

impl&lt;B, S&gt; Service&lt;Request&lt;B&gt;&gt; for InventoryLogging&lt;S&gt;
where
    S: Service&lt;Request&lt;B&gt;&gt;
{
    type Response = Response&lt;BoxBody&gt;;
    type Error = S::Error;
    type Future = /* Implementation detail */;

    fn call(&amp;mut self, request: Request&lt;B&gt;) -&gt; Self::Future {
        // Remove sensitive data from parts of the HTTP
        let uri = /* redact {name} from URI */;
        let headers = /* no redactions */;

        let fut = async {
            let response = self.inner.call(request).await;
            let status_code = /* redact status code */;
            let headers = /* no redactions */;

            debug!(%status_code, ?headers, "response");

            response
        };

        // Instrument the future with a span
        let span = debug_span!("request", operation = %self.operation_name, method = %request.method(), %uri, ?headers);
        fut.instrument(span)
    }
}</code></pre>
<h3 id="http-debugdisplay-wrappers"><a class="header" href="#http-debugdisplay-wrappers">HTTP Debug/Display Wrappers</a></h3>
<p>The <code>Service::call</code> path, seen in <a href="rfcs/rfc0018_logging_sensitive.html#code-generated-logging-middleware">Code Generated Logging Middleware</a>, is latency-sensitive. Careful implementation is required to avoid excess allocations during redaction of sensitive data. Wrapping <a href="https://docs.rs/http/latest/http/uri/struct.Uri.html">Uri</a> and <a href="https://docs.rs/http/latest/http/header/struct.HeaderMap.html">HeaderMap</a> then providing a new <a href="https://doc.rust-lang.org/std/fmt/trait.Display.html">Display</a>/<a href="https://doc.rust-lang.org/std/fmt/trait.Debug.html">Debug</a> implementation which skips over the sensitive data is preferable over allocating a new <code>String</code>/<code>HeaderMap</code> and then mutating it.</p>
<p>These wrappers should be provided alongside the <code>Sensitive</code> struct described in <a href="rfcs/rfc0018_logging_sensitive.html#debug-logging">Debug Logging</a>. If they are implemented on top of <code>Sensitive</code>, they will inherit the same behavior - allowing redactions to be toggled using <code>unredacted-logging</code> feature flag.</p>
<h3 id="middleware-position"><a class="header" href="#middleware-position">Middleware Position</a></h3>
<p>This logging middleware should be applied outside of the <a href="https://github.com/smithy-lang/smithy-rs/blob/cd0563020abcde866a741fa123e3f2e18e1be1c9/rust-runtime/inlineable/src/server_operation_handler_trait.rs#L17-L21">OperationHandler</a> after its construction in the (generated) <code>operation_registry.rs</code> file. The middleware should preserve the associated types of the <code>OperationHandler</code> (<code>Response = Response&lt;BoxBody&gt;</code>, <code>Error = Infallible</code>) to cause minimal disruption.</p>
<p>An easy position to apply the logging middleware is illustrated below in the form of <code>Logging{Operation}::new</code>:</p>
<pre><code class="language-rust ignore">let empty_operation = LoggingEmptyOperation::new(operation(registry.empty_operation));
let get_pokemon_species = LoggingPokemonSpecies::new(operation(registry.get_pokemon_species));
let get_server_statistics = LoggingServerStatistics::new(operation(registry.get_server_statistics));
let routes = vec![
    (BoxCloneService::new(empty_operation), empty_operation_request_spec),
    (BoxCloneService::new(get_pokemon_species), get_pokemon_species_request_spec),
    (BoxCloneService::new(get_server_statistics), get_server_statistics_request_spec),
];
let router = aws_smithy_http_server::routing::Router::new_rest_json_router(routes);</code></pre>
<p>Although an acceptable first step, putting logging middleware here is suboptimal - the <code>Router</code> allows a <code>tower::Layer</code> to be applied to the operation by using the <a href="https://github.com/smithy-lang/smithy-rs/blob/main/rust-runtime/aws-smithy-http-server/src/routing/mod.rs#L146">Router::layer</a> method. This middleware will be applied <em>outside</em> of the logging middleware and, as a result, will not be subject to the span of any middleware. Therefore, the <code>Router</code> must be changed to allow for middleware to be applied within the logging middleware rather than outside of it.</p>
<p>This is a general problem, not specific to this proposal. For example, <a href="rfcs/rfc0018_logging_sensitive.html#use-request-extensions">Use Request Extensions</a> must also solve this problem.</p>
<p>Fortunately, this problem is separable from the actual implementation of the logging middleware and we can get immediate benefit by application of it in the suboptimal position described above.</p>
<h3 id="logging-within-the-router"><a class="header" href="#logging-within-the-router">Logging within the Router</a></h3>
<p>There is need for logging within the <code>Router</code> implementation - this is a crucial area of business logic. As mentioned in the <a href="rfcs/rfc0018_logging_sensitive.html#routing">Routing</a> section, we are permitted to log potentially sensitive data in cases where requests fail to get routed to an operation.</p>
<p>In the case of AWS JSON 1.0 and 1.1 protocols, the request URI is always <code>/</code>, putting it outside of the reach of the <code>@sensitive</code> trait. We therefore have the option to log it before routing occurs. We make a choice not to do this in order to remove the special case - relying on the logging layer to log URIs when appropriate.</p>
<h3 id="developer-guideline"><a class="header" href="#developer-guideline">Developer Guideline</a></h3>
<p>A guideline should be made available, which includes:</p>
<ul>
<li>The <a href="rfcs/rfc0018_logging_sensitive.html#http-binding-traits">HTTP bindings traits</a> and why they are of concern in the presence of <code>@sensitive</code>.</li>
<li>The <a href="https://github.com/smithy-lang/smithy-rs/pull/229">Debug implementation</a> on structures.</li>
<li>How to use the <code>Sensitive</code> struct, HTTP wrappers, and the <code>unredacted-logging</code> feature flag described in <a href="rfcs/rfc0018_logging_sensitive.html#debug-logging">Debug Logging</a> and <a href="rfcs/rfc0018_logging_sensitive.html#http-debugdisplay-wrappers">HTTP Debug/Display Wrappers</a>.</li>
<li>A warning against the two potential leaks described in <a href="rfcs/rfc0018_logging_sensitive.html#scope-and-guidelines">Scope and Guidelines</a>:
<ul>
<li>Sensitive data leaking from third-party dependencies.</li>
<li>Sensitive data leaking from middleware applied to the <code>Router</code>.</li>
</ul>
</li>
</ul>
<h2 id="alternative-proposals"><a class="header" href="#alternative-proposals">Alternative Proposals</a></h2>
<p>All of the following proposals are compatible with, and benefit from, <a href="rfcs/rfc0018_logging_sensitive.html#debug-logging">Debug Logging</a>, <a href="rfcs/rfc0018_logging_sensitive.html#http-debugdisplay-wrappers">HTTP Debug/Display Wrappers</a>, and <a href="rfcs/rfc0018_logging_sensitive.html#developer-guideline">Developer Guideline</a> portions of the main proposal.</p>
<p>The main proposal disallows the logging of potentially sensitive data in the runtime crates, instead opting for a dedicated code generated logging middleware. In contrast, the following proposals all seek ways to accommodate logging of potentially sensitive data in the runtime crates.</p>
<h3 id="use-request-extensions"><a class="header" href="#use-request-extensions">Use Request Extensions</a></h3>
<p>Request extensions can be used to adjoin data to a Request as it passes through the middleware. Concretely, they exist as the type map <a href="https://docs.rs/http/latest/http/struct.Extensions.html">http::Extensions</a> accessed via <a href="https://docs.rs/http/latest/http/request/struct.Request.html#method.extensions">http::extensions</a> and <a href="https://docs.rs/http/latest/http/request/struct.Request.html#method.extensions_mut">http::extensions_mut</a>.</p>
<p>These can be used to provide data to middleware interested in logging potentially sensitive data.</p>
<pre><code class="language-rust ignore">struct Sensitivity {
    /* Data concerning which parts of the request are sensitive */
}

struct Middleware&lt;S&gt; {
    inner: S
}

impl&lt;B, S&gt; Service&lt;Request&lt;B&gt;&gt; for Middleware&lt;S&gt; {
    /* ... */

    fn call(&amp;mut self, request: Request&lt;B&gt;) -&gt; Self::Future {
        if let Some(sensitivity) = request.extensions().get::&lt;Sensitivity&gt;() {
            if sensitivity.is_method_sensitive() {
                debug!(method = %request.method());
            }
        }

        /* ... */

        self.inner.call(request)
    }
}</code></pre>
<p>A middleware layer must be code generated (much in the same way as the logging middleware) which is dedicated to inserting the <code>Sensitivity</code> struct into the extensions of each incoming request.</p>
<pre><code class="language-rust ignore">impl&lt;B, S&gt; Service&lt;Request&lt;B&gt;&gt; for SensitivityInserter&lt;S&gt;
where
    S: Service&lt;Request&lt;B&gt;&gt;
{
    /* ... */

    fn call(&amp;mut self, request: Request&lt;B&gt;) -&gt; Self::Future {
        let sensitivity = Sensitivity {
            /* .. */
        };
        request.extensions_mut().insert(sensitivity);

        self.inner.call(request)
    }
}</code></pre>
<h4 id="advantages"><a class="header" href="#advantages">Advantages</a></h4>
<ul>
<li>Applicable to <em>all</em> middleware which takes <code>http::Request&lt;B&gt;</code>.</li>
<li>Does not pollute the API of the middleware - code internal to middleware simply inspects the request's extensions and performs logic based on its value.</li>
</ul>
<h4 id="disadvantages"><a class="header" href="#disadvantages">Disadvantages</a></h4>
<ul>
<li>The sensitivity and HTTP bindings are known at compile time whereas the insertion/retrieval of the extension data is done at runtime.
<ul>
<li><a href="https://docs.rs/http/latest/http/struct.Extensions.html">http::Extensions</a> is approximately a <code>HashMap&lt;u64, Box&lt;dyn Any&gt;&gt;</code> so lookup/insertion involves indirection/cache misses/heap allocation.</li>
</ul>
</li>
</ul>
<h3 id="accommodate-the-sensitivity-in-middleware-api"><a class="header" href="#accommodate-the-sensitivity-in-middleware-api">Accommodate the Sensitivity in Middleware API</a></h3>
<p>It is possible that sensitivity is a parameter passed to middleware during construction. This is similar in nature to <a href="rfcs/rfc0018_logging_sensitive.html#use-request-extensions">Use Request Extensions</a> except that the <code>Sensitivity</code> is passed to middleware during construction.</p>
<pre><code class="language-rust ignore">struct Middleware&lt;S&gt; {
    inner: S,
    sensitivity: Sensitivity
}

impl Middleware&lt;S&gt; {
    pub fn new(inner: S) -&gt; Self { /* ... */ }

    pub fn new_with_sensitivity(inner: S, sensitivity: Sensitivity) -&gt; Self { /* ... */ }
}

impl&lt;B, S&gt; Service&lt;Request&lt;B&gt;&gt; for Middleware&lt;S&gt; {
    /* ... */

    fn call(&amp;mut self, request: Request&lt;B&gt;) -&gt; Self::Future {
        if self.sensitivity.is_method_sensitive() {
            debug!(method = %Sensitive(request.method()));
        }

        /* ... */

        self.inner.call(request)
    }
}</code></pre>
<p>It would then be required that the code generation responsible constructing a <code>Sensitivity</code> for each operation. Additionally, if any middleware is being applied to a operation then the code generation would be responsible for passing that middleware the appropriate <code>Sensitivity</code> before applying it.</p>
<h4 id="advantages-1"><a class="header" href="#advantages-1">Advantages</a></h4>
<ul>
<li>Applicable to <em>all</em> middleware.</li>
<li>As the <code>Sensitivity</code> struct will be known statically, the compiler will remove branches, making it cheap.</li>
</ul>
<h4 id="disadvantages-1"><a class="header" href="#disadvantages-1">Disadvantages</a></h4>
<ul>
<li>Pollutes the API of middleware.</li>
</ul>
<h3 id="redact-values-using-a-tracing-layer"><a class="header" href="#redact-values-using-a-tracing-layer">Redact values using a tracing Layer</a></h3>
<p>Distinct from <code>tower::Layer</code>, a <a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/layer/trait.Layer.html">tracing::Layer</a> is a "composable handler for <code>tracing</code> events". It would be possible to write an implementation which would filter out events which contain sensitive data.</p>
<p>Examples of filtering <code>tracing::Layer</code>s already exist in the form of the <a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html">EnvFilter</a> and <a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/targets/struct.Targets.html">Targets</a>. It is unlikely that we'll be able to leverage them for our use, but the underlying principle remains the same - the <code>tracing::Layer</code> inspects <code>tracing::Event</code>s/<code>tracing::Span</code>s, filtering them based on some criteria.</p>
<p>Code generation would be need to be used in order to produce the filtering criteria from the models. Internal developers would need to adhere to a common set of field names in order for them to be subject to the filtering. Spans would need to be opened after routing occurs in order for the <code>tracing::Layer</code> to know which operation <code>Event</code>s are being produced within and hence which filtering rules to apply.</p>
<h4 id="advantages-2"><a class="header" href="#advantages-2">Advantages</a></h4>
<ul>
<li>Applicable to <em>all</em> middleware.</li>
<li>Good separation of concerns:
<ul>
<li>Does not pollute the API of the middleware</li>
<li>No specific logic required within middleware.</li>
</ul>
</li>
</ul>
<h4 id="disadvantages-2"><a class="header" href="#disadvantages-2">Disadvantages</a></h4>
<ul>
<li>Complex implementation.</li>
<li>Not necessarily fast.</li>
<li><code>tracing::Layer</code>s seem to only support filtering entire <code>Event</code>s, rather than more fine grained removal of fields.</li>
</ul>
<h2 id="changes-checklist-12"><a class="header" href="#changes-checklist-12">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement and integrate code generated logging middleware.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1550">https://github.com/smithy-lang/smithy-rs/pull/1550</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add logging to <code>Router</code> implementation.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/issues/1666">https://github.com/smithy-lang/smithy-rs/issues/1666</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Write developer guideline.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1772">https://github.com/smithy-lang/smithy-rs/pull/1772</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Refactor <code>Router</code> to allow for better positioning described in <a href="rfcs/rfc0018_logging_sensitive.html#middleware-position">Middleware Position</a>.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1620">https://github.com/smithy-lang/smithy-rs/pull/1620</a></li>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1679">https://github.com/smithy-lang/smithy-rs/pull/1679</a></li>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1693">https://github.com/smithy-lang/smithy-rs/pull/1693</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-errors-for-event-streams"><a class="header" href="#rfc-errors-for-event-streams">RFC: Errors for event streams</a></h1>
<!-- RFCs start with the "RFC" status and are then either "Implemented" or "Rejected".  -->
<blockquote>
<p>Status: Implemented</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0019_event_streams_errors.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC defines how client and server will use errors defined in <code>@streaming</code> unions (event streams).</p>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented">The user experience if this RFC is implemented</a></h2>
<p>In the current version of smithy-rs, customers who want to use errors in event streams need to use them as so:</p>
<pre><code class="language-rust ignore">stream! {
    yield Ok(EventStreamUnion::ErrorVariant ...)
}</code></pre>
<p>Furthermore, there is no support for <code>@error</code>s in event streams being terminal; that is, when an error is sent,
it does not signal termination and thus does not complete the stream.</p>
<p>This RFC proposes to make changes to:</p>
<ul>
<li>terminate the stream upon receiving a modeled error</li>
<li>change the API so that customers will write their business logic in a more Rust-like experience:</li>
</ul>
<pre><code class="language-rust ignore">stream! {
    yield Err(EventStreamUnionError::ErrorKind ...)
}</code></pre>
<p>Thus any <code>Err(_)</code> from the stream is terminal, rather than any <code>Ok(x)</code> with <code>x</code> being matched against the set of modeled variant errors in the union.</p>
<!-- Explain the implementation of this new feature -->
<h2 id="how-to-actually-implement-this-rfc"><a class="header" href="#how-to-actually-implement-this-rfc">How to actually implement this RFC</a></h2>
<p>In order to implement this feature:</p>
<ul>
<li>Errors modeled in streaming unions are going to be treated like operation errors
<ul>
<li>They are in the <code>error::</code> namespace</li>
<li>They have the same methods operation errors have (<code>name</code> on the server, <code>metadata</code> on the client and so on)</li>
<li>They are not variants in the corresponding error structure</li>
</ul>
</li>
<li>Errors need to be marshalled and unmarshalled</li>
<li><code>Receiver</code> must treat any error coming from the other end as terminal</li>
</ul>
<p>The code examples below have been generated using the <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/codegen-server-test/model/pokemon.smithy#L27">following model</a>:</p>
<pre><code class="language-smithy">@http(uri: "/capture-pokemon-event/{region}", method: "POST")
operation CapturePokemonOperation {
    input: CapturePokemonOperationEventsInput,
    output: CapturePokemonOperationEventsOutput,
    errors: [UnsupportedRegionError, ThrottlingError]
}

@input
structure CapturePokemonOperationEventsInput {
    @httpPayload
    events: AttemptCapturingPokemonEvent,

    @httpLabel
    @required
    region: String,
}

@output
structure CapturePokemonOperationEventsOutput {
    @httpPayload
    events: CapturePokemonEvents,
}

@streaming
union AttemptCapturingPokemonEvent {
    event: CapturingEvent,
    masterball_unsuccessful: MasterBallUnsuccessful,
}

structure CapturingEvent {
    @eventPayload
    payload: CapturingPayload,
}

structure CapturingPayload {
    name: String,
    pokeball: String,
}

@streaming
union CapturePokemonEvents {
    event: CaptureEvent,
    invalid_pokeball: InvalidPokeballError,
    throttlingError: ThrottlingError,
}

structure CaptureEvent {
    @eventHeader
    name: String,
    @eventHeader
    captured: Boolean,
    @eventHeader
    shiny: Boolean,
    @eventPayload
    pokedex_update: Blob,
}

@error("server")
structure UnsupportedRegionError {
    @required
    region: String,
}
@error("client")
structure InvalidPokeballError {
    @required
    pokeball: String,
}
@error("server")
structure MasterBallUnsuccessful {
    @required
    message: String,
}
@error("client")
structure ThrottlingError {}
</code></pre>
<p>Wherever irrelevant, documentation and other lines are stripped out from the code examples below.</p>
<h4 id="errors-in-streaming-unions"><a class="header" href="#errors-in-streaming-unions">Errors in streaming unions</a></h4>
<p>The error in <code>AttemptCapturingPokemonEvent</code> is modeled as follows.</p>
<p>On the client,</p>
<pre><code class="language-rust ignore">pub struct AttemptCapturingPokemonEventError {
    pub kind: AttemptCapturingPokemonEventErrorKind,
    pub(crate) meta: aws_smithy_types::Error,
}
pub enum AttemptCapturingPokemonEventErrorKind {
    MasterBallUnsuccessful(crate::error::MasterBallUnsuccessful),
    Unhandled(Box&lt;dyn std::error::Error + Send + Sync + 'static&gt;),
}</code></pre>
<p>On the server,</p>
<pre><code class="language-rust ignore">pub enum AttemptCapturingPokemonEventError {
    MasterBallUnsuccessful(crate::error::MasterBallUnsuccessful),
}</code></pre>
<p>Both are modeled as normal errors, where the <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/generators/error/CombinedErrorGenerator.kt#L50">name</a> comes from <code>Error</code> with a prefix of the union's name.
In fact, both the <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/generators/error/CombinedErrorGenerator.kt#L71">client</a> and <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/ServerCombinedErrorGenerator.kt#L46">server</a>
generate operation errors and event stream errors the same way.</p>
<p>Event stream errors have their own <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/codegen/src/main/kotlin/software/amazon/smithy/rust/codegen/smithy/protocols/serialize/EventStreamErrorMarshallerGenerator.kt#L39">marshaller</a>.
To make it work for users to stream errors, <code>EventStreamSender&lt;&gt;</code>, in addition to the union type <code>T</code>, takes an error type <code>E</code>; that is, the <code>AttemptCapturingPokemonEventError</code> in the example.
This means that an error from the stream is <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/rust-runtime/aws-smithy-http/src/event_stream/sender.rs#L137">marshalled and sent</a> as a data structure similarly to the union's non-error members.</p>
<p>On the other side, the <code>Receiver&lt;&gt;</code> needs to terminate the stream upon <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/rust-runtime/aws-smithy-http/src/event_stream/receiver.rs#L249">receiving any error</a>.
A terminated stream has <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/rust-runtime/aws-smithy-http/src/event_stream/receiver.rs#L38">no more data</a> and will always be a <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/rust-runtime/aws-smithy-http/src/event_stream/receiver.rs#L54">bug</a> to use it.</p>
<p>An example of how errors can be used on clients, extracted from <a href="https://github.com/smithy-lang/smithy-rs/blob/8f7e03ff8a84236955a65dba3d21c4bdbf17a9f4/rust-runtime/aws-smithy-http-server/examples/pokemon_service/tests/simple_integration_test.rs#L100">this test</a>:</p>
<pre><code class="language-rust ignore">yield Err(AttemptCapturingPokemonEventError::new(
    AttemptCapturingPokemonEventErrorKind::MasterBallUnsuccessful(MasterBallUnsuccessful::builder().build()),
    Default::default()
));</code></pre>
<p>Because unions can be used in input or output of more than one operation, errors must be generated once as they are in the <code>error::</code> namespace.</p>
<!-- Include a checklist of all the things that need to happen for this RFC's implementation to be considered complete -->
<h2 id="changes-checklist-13"><a class="header" href="#changes-checklist-13">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Errors are in the <code>error::</code> namespace and created as operation errors</li>
<li><input disabled="" type="checkbox" checked=""/>
Errors can be sent to the stream</li>
<li><input disabled="" type="checkbox" checked=""/>
Errors terminate the stream</li>
<li><input disabled="" type="checkbox" checked=""/>
Customers' experience using errors mirrors the Rust way: <code>Err(error::StreamingError ...)</code></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-service-builder-improvements"><a class="header" href="#rfc-service-builder-improvements">RFC: Service Builder Improvements</a></h1>
<blockquote>
<p>Status: Accepted</p>
</blockquote>
<p>One might characterize <code>smithy-rs</code> as a tool for transforming a <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#service">Smithy service</a> into a <a href="https://docs.rs/tower-service/latest/tower_service/trait.Service.html">tower::Service</a> builder. A Smithy model defines behavior of the generated service partially - handlers must be passed to the builder before the <code>tower::Service</code> is fully specified. This builder structure is the primary API surface we provide to the customer, as a result, it is important that it meets their needs.</p>
<p>This RFC proposes a new builder, deprecating the existing one, which addresses API deficiencies and takes steps to improve performance.</p>
<h2 id="terminology-12"><a class="header" href="#terminology-12">Terminology</a></h2>
<ul>
<li><strong>Model</strong>: A <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html">Smithy Model</a>, usually pertaining to the one in use by the customer.</li>
<li><strong>Smithy Service</strong>: The entry point of an API that aggregates <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#resource">resources</a> and <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#operation">operations</a> together within a Smithy model. Described in detail <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#service">here</a>.</li>
<li><strong>Service</strong>: The <code>tower::Service</code> trait is an interface for writing network applications in a modular and reusable way. <code>Service</code>s act on requests to produce responses.</li>
<li><strong>Service Builder</strong>: A <code>tower::Service</code> builder, generated from a Smithy service, by <code>smithy-rs</code>.</li>
<li><strong>Middleware</strong>: Broadly speaking, middleware modify requests and responses. Concretely, these are exist as implementations of <a href="https://docs.rs/tower/latest/tower/layer/trait.Layer.html">Layer</a>/a <code>Service</code> wrapping an inner <code>Service</code>.</li>
<li><strong>Handler</strong>: A closure defining the behavior of a particular request after routing. These are provided to the service builder to complete the description of the service.</li>
</ul>
<h2 id="background-1"><a class="header" href="#background-1">Background</a></h2>
<p>To provide context for the proposal we perform a survey of the current state of affairs.</p>
<p>The following is a reference model we will use throughout the RFC:</p>
<pre><code class="language-smithy">operation Operation0 {
    input: Input0,
    output: Output0
}

operation Operation1 {
    input: Input1,
    output: Output1
}

@restJson1
service Service0 {
    operations: [
        Operation0,
        Operation1,
    ]
}
</code></pre>
<p>We have purposely omitted details from the model that are unimportant to describing the proposal. We also omit distracting details from the Rust snippets. Code generation is linear in the sense that, code snippets can be assumed to extend to multiple operations in a predictable way. In the case where we do want to speak generally about an operation and its associated types, we use <code>{Operation}</code>, for example <code>{Operation}Input</code> is the input type of an unspecified operation.</p>
<p>Here is a quick example of what a customer might write when using the service builder:</p>
<pre><code class="language-rust ignore">async fn handler0(input: Operation0Input) -&gt; Operation0Output {
    todo!()
}

async fn handler1(input: Operation1Input) -&gt; Operation1Output {
    todo!()
}

let app: Router = OperationRegistryBuilder::default()
    // Use the setters
    .operation0(handler0)
    .operation1(handler1)
    // Convert to `OperationRegistry`
    .build()
    .unwrap()
    // Convert to `Router`
    .into();</code></pre>
<p>During the survey we touch on the major mechanisms used to achieve this API.</p>
<h3 id="handlers"><a class="header" href="#handlers">Handlers</a></h3>
<p>A core concept in the service builder is the <code>Handler</code> trait:</p>
<pre><code class="language-rust ignore">pub trait Handler&lt;T, Input&gt; {
    async fn call(self, req: http::Request) -&gt; http::Response;
}</code></pre>
<p>Its purpose is to provide an even interface over closures of the form <code>FnOnce({Operation}Input) -&gt; impl Future&lt;Output = {Operation}Output&gt;</code> and <code>FnOnce({Operation}Input, State) -&gt; impl Future&lt;Output = {Operation}Output&gt;</code>. It's this abstraction which allows the customers to supply both <code>async fn handler(input: {Operation}Input) -&gt; {Operation}Output</code> and <code>async fn handler(input: {Operation}Input, state: Extension&lt;S&gt;) -&gt; {Operation}Output</code> to the service builder.</p>
<p>We generate <code>Handler</code> implementations for said closures in <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/ServerOperationHandlerGenerator.kt">ServerOperationHandlerGenerator.kt</a>:</p>
<pre><code class="language-rust ignore">impl&lt;Fun, Fut&gt; Handler&lt;(), Operation0Input&gt; for Fun
where
    Fun: FnOnce(Operation0Input) -&gt; Fut,
    Fut: Future&lt;Output = Operation0Output&gt;,
{
    async fn call(self, request: http::Request) -&gt; http::Response {
        let input = /* Create `Operation0Input` from `request: http::Request` */;

        // Use closure on the input
        let output = self(input).await;

        let response = /* Create `http::Response` from `output: Operation0Output` */
        response
    }
}

impl&lt;Fun, Fut&gt; Handler&lt;Extension&lt;S&gt;, Operation0Input&gt; for Fun
where
    Fun: FnOnce(Operation0Input, Extension&lt;S&gt;) -&gt; Fut,
    Fut: Future&lt;Output = Operation0Output&gt;,
{
    async fn call(self, request: http::Request) -&gt; http::Response {
        let input = /* Create `Operation0Input` from `request: http::Request` */;

        // Use closure on the input and fetched extension data
        let extension = Extension(request.extensions().get::&lt;T&gt;().clone());
        let output = self(input, extension).await;

        let response = /* Create `http::Response` from `output: Operation0Output` */
        response
    }
}</code></pre>
<p>Creating <code>{Operation}Input</code> from a <code>http::Request</code> and <code>http::Response</code> from a <code>{Operation}Output</code> involves protocol aware serialization/deserialization, for example, it can involve the <a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html">HTTP binding traits</a>. The <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/rust-runtime/aws-smithy-http-server/src/runtime_error.rs#L53-L5">RuntimeError</a> enumerates error cases such as serialization/deserialization failures, <code>extensions().get::&lt;T&gt;()</code> failures, etc. We omit error handling in the snippet above, but, in full, it also involves protocol aware conversions from the <code>RuntimeError</code> to <code>http::Response</code>. The reader should make note of the influence of the model on the different sections of this procedure.</p>
<p>The <code>request.extensions().get::&lt;T&gt;()</code> present in the <code>Fun: FnOnce(Operation0Input, Extension&lt;S&gt;) -&gt; Fut</code> implementation is the current approach to injecting state into handlers. The customer is required to apply a <a href="https://docs.rs/tower-http/latest/tower_http/add_extension/struct.AddExtensionLayer.html">AddExtensionLayer</a> to the output of the service builder so that, when the request reaches the handler, the <code>extensions().get::&lt;T&gt;()</code> will succeed.</p>
<p>To convert the closures described above into a <code>Service</code> an <code>OperationHandler</code> is used:</p>
<pre><code class="language-rust ignore">pub struct OperationHandler&lt;H, T, Input&gt; {
    handler: H,
}

impl&lt;H, T, Input&gt; Service&lt;Request&lt;B&gt;&gt; for OperationHandler&lt;H, T, Input&gt;
where
    H: Handler&lt;T, I&gt;,
{
    type Response = http::Response;
    type Error = Infallible;

    #[inline]
    fn poll_ready(&amp;mut self, _cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        Poll::Ready(Ok(()))
    }

    async fn call(&amp;mut self, req: Request&lt;B&gt;) -&gt; Result&lt;Self::Response, Self::Error&gt; {
        self.handler.call(req).await.map(Ok)
    }
}</code></pre>
<h3 id="builder"><a class="header" href="#builder">Builder</a></h3>
<p>The service builder we provide to the customer is the <code>OperationRegistryBuilder</code>, generated from <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/ServerOperationRegistryGenerator.kt">ServerOperationRegistryGenerator.kt</a>.</p>
<p>Currently, the reference model would generate the following <code>OperationRegistryBuilder</code> and <code>OperationRegistry</code>:</p>
<pre><code class="language-rust ignore">pub struct OperationRegistryBuilder&lt;Op0, In0, Op1, In1&gt; {
    operation1: Option&lt;Op0&gt;,
    operation2: Option&lt;Op1&gt;,
}

pub struct OperationRegistry&lt;Op0, In0, Op1, In1&gt; {
    operation1: Op0,
    operation2: Op1,
}</code></pre>
<p>The <code>OperationRegistryBuilder</code> includes a setter per operation, and a fallible <code>build</code> method:</p>
<pre><code class="language-rust ignore">impl&lt;Op0, In0, Op1, In1&gt; OperationRegistryBuilder&lt;Op0, In0, Op1, In1&gt; {
    pub fn operation0(mut self, value: Op0) -&gt; Self {
        self.operation0 = Some(value);
        self
    }
    pub fn operation1(mut self, value: Op1) -&gt; Self {
        self.operation1 = Some(value);
        self
    }
    pub fn build(
        self,
    ) -&gt; Result&lt;OperationRegistry&lt;Op0, In0, Op1, In1&gt;, OperationRegistryBuilderError&gt; {
        Ok(OperationRegistry {
            operation0: self.operation0.ok_or(/* OperationRegistryBuilderError */)?,
            operation1: self.operation1.ok_or(/* OperationRegistryBuilderError */)?,
        })
    }
}</code></pre>
<p>The <code>OperationRegistry</code> does not include any methods of its own, however it does enjoy a <code>From&lt;OperationRegistry&gt; for Router&lt;B&gt;</code> implementation:</p>
<pre><code class="language-rust ignore">impl&lt;B, Op0, In0, Op1, In1&gt; From&lt;OperationRegistry&lt;B, Op0, In0, Op1, In1&gt;&gt; for Router&lt;B&gt;
where
    Op0: Handler&lt;B, In0, Operation0Input&gt;,
    Op1: Handler&lt;B, In1, Operation1Input&gt;,
{
    fn from(registry: OperationRegistry&lt;B, Op0, In0, Op1, In1&gt;) -&gt; Self {
        let operation0_request_spec = /* Construct Operation0 routing information */;
        let operation1_request_spec = /* Construct Operation1 routing information */;

        // Convert handlers into boxed services
        let operation0_svc = Box::new(OperationHandler::new(registry.operation0));
        let operation1_svc = Box::new(OperationHandler::new(registry.operation1));

        // Initialize the protocol specific router
        // We demonstrate it here with `new_rest_json_router`, but note that there is a different router constructor
        // for each protocol.
        aws_smithy_http_server::routing::Router::new_rest_json_router(vec![
            (
                operation0_request_spec,
                operation0_svc
            ),
            (
                operation1_request_spec,
                operation1_svc
            )
        ])
    }
}</code></pre>
<h3 id="router"><a class="header" href="#router">Router</a></h3>
<p>The <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/rust-runtime/aws-smithy-http-server/src/routing/mod.rs#L58-L60">aws_smithy_http::routing::Router</a> provides the protocol aware routing of requests to their target , it exists as</p>
<pre><code class="language-rust ignore">pub struct Route {
    service: Box&lt;dyn Service&lt;http::Request, Response = http::Response&gt;&gt;,
}

enum Routes {
    RestXml(Vec&lt;(Route, RequestSpec)&gt;),
    RestJson1(Vec&lt;(Route, RequestSpec)&gt;),
    AwsJson1_0(TinyMap&lt;String, Route&gt;),
    AwsJson11(TinyMap&lt;String, Route&gt;),
}

pub struct Router {
    routes: Routes,
}</code></pre>
<p>and enjoys the following <code>Service&lt;http::Request&gt;</code> implementation:</p>
<pre><code class="language-rust ignore">impl Service&lt;http::Request&gt; for Router
{
    type Response = http::Response;
    type Error = Infallible;

    fn poll_ready(&amp;mut self, _: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        Poll::Ready(Ok(()))
    }

    async fn call(&amp;mut self, request: http::Request) -&gt; Result&lt;Self::Response, Self::Error&gt; {
        match &amp;self.routes {
            Routes::/* protocol */(routes) =&gt; {
                let route: Result&lt;Route, _&gt; = /* perform route matching logic */;
                match route {
                    Ok(ok) =&gt; ok.oneshot().await,
                    Err(err) =&gt; /* Convert routing error into http::Response */
                }
            }
        }
    }
}</code></pre>
<p>Along side the protocol specific constructors, <code>Router</code> includes a <code>layer</code> method. This provides a way for the customer to apply a <code>tower::Layer</code> to all routes. For every protocol, <code>Router::layer</code> has the approximately the same behavior:</p>
<pre><code class="language-rust ignore">let new_routes = old_routes
    .into_iter()
    // Apply the layer
    .map(|route| layer.layer(route))
    // Re-box the service, to restore `Route` type
    .map(|svc| Box::new(svc))
    // Collect the iterator back into a collection (`Vec` or `TinyMap`)
    .collect();</code></pre>
<h3 id="comparison-to-axum"><a class="header" href="#comparison-to-axum">Comparison to Axum</a></h3>
<p>Historically, <code>smithy-rs</code> has borrowed from <a href="https://github.com/tokio-rs/axum">axum</a>. Despite various divergences the code bases still have much in common:</p>
<ul>
<li>Reliance on <code>Handler</code> trait to abstract over different closure signatures:
<ul>
<li><a href="https://docs.rs/axum/latest/axum/handler/trait.Handler.html">axum::handler::Handler</a></li>
<li><a href="rfcs/rfc0020_service_builder.html#handlers">Handlers</a></li>
</ul>
</li>
<li>A mechanism for turning <code>H: Handler</code> into a <code>tower::Service</code>:
<ul>
<li><a href="https://docs.rs/axum/latest/axum/handler/struct.IntoService.html">axum::handler::IntoService</a></li>
<li><a href="rfcs/rfc0020_service_builder.html#handlers">OperationHandler</a></li>
</ul>
</li>
<li>A <code>Router</code> to route requests to various handlers:
<ul>
<li><a href="https://docs.rs/axum/latest/axum/struct.Router.html">axum::Router</a></li>
<li><a href="rfcs/rfc0020_service_builder.html#router">aws_smithy_http_server::routing::Router</a></li>
</ul>
</li>
</ul>
<p>To identify where the implementations should differ we should classify in what ways the use cases differ. There are two primary areas which we describe below.</p>
<h4 id="extractors-and-responses"><a class="header" href="#extractors-and-responses">Extractors and Responses</a></h4>
<p>In <code>axum</code> there is a notion of <a href="https://docs.rs/axum/latest/axum/extract/index.html">Extractor</a>, which allows the customer to easily define a decomposition of an incoming <code>http::Request</code> by specifying the arguments to the handlers. For example,</p>
<pre><code class="language-rust ignore">async fn request(Json(payload): Json&lt;Value&gt;, Query(params): Query&lt;HashMap&lt;String, String&gt;&gt;, headers: HeaderMap) {
    todo!()
}</code></pre>
<p>is a valid handler - each argument satisfies the <a href="https://docs.rs/axum/latest/axum/extract/trait.FromRequest.html">axum::extract::FromRequest</a> trait, therefore satisfies one of <code>axum</code>s blanket <code>Handler</code> implementations:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>macro_rules! impl_handler {
    ( $($ty:ident),* $(,)? ) =&gt; {
        impl&lt;F, Fut, Res, $($ty,)*&gt; Handler&lt;($($ty,)*)&gt; for F
        where
            F: FnOnce($($ty,)*) -&gt; Fut + Clone + Send + 'static,
            Fut: Future&lt;Output = Res&gt; + Send,
            Res: IntoResponse,
            $( $ty: FromRequest + Send,)*
        {
            fn call(self, req: http::Request) -&gt; Self::Future {
                async {
                    let mut req = RequestParts::new(req);

                    $(
                        let $ty = match $ty::from_request(&amp;mut req).await {
                            Ok(value) =&gt; value,
                            Err(rejection) =&gt; return rejection.into_response(),
                        };
                    )*

                    let res = self($($ty,)*).await;

                    res.into_response()
                }
            }
        }
    };
}
<span class="boring">}</span></code></pre></pre>
<p>The implementations of <code>Handler</code> in <code>axum</code> and <code>smithy-rs</code> follow a similar pattern - convert <code>http::Request</code> into the closure's input, run the closure, convert the output of the closure to <code>http::Response</code>.</p>
<p>In <code>smithy-rs</code> we do not need a general notion of "extractor" - the <code>http::Request</code> decomposition is specified by the Smithy model, whereas in <code>axum</code> it's defined by the handlers signature. Despite the Smithy specification the customer may still want an "escape hatch" to allow them access to data outside of the Smithy service inputs, for this reason we should continue to support a restricted notion of extractor. This will help support use cases such as passing <a href="https://docs.rs/lambda_http/latest/lambda_http/struct.Context.html">lambda_http::Context</a> through to the handler despite it not being modeled in the Smithy model.</p>
<p>Dual to <code>FromRequest</code> is the <a href="https://docs.rs/axum/latest/axum/response/trait.IntoResponse.html">axum::response::IntoResponse</a> trait. This plays the role of converting the output of the handler to <code>http::Response</code>. Again, the difference between <code>axum</code> and <code>smithy-rs</code> is that <code>smithy-rs</code> has the conversion from <code>{Operation}Output</code> to <code>http::Response</code> specified by the Smithy model, whereas in <code>axum</code> the customer is free to specify a return type which implements <code>axum::response::IntoResponse</code>.</p>
<h4 id="routing-1"><a class="header" href="#routing-1">Routing</a></h4>
<p>The Smithy model not only specifies the <code>http::Request</code> decomposition and <code>http::Response</code> composition for a given service, it also determines the routing. The <code>From&lt;OperationRegistry&gt;</code> implementation, described in <a href="rfcs/rfc0020_service_builder.html#builder">Builder</a>, yields a fully formed router based on the protocol and <a href="https://awslabs.github.io/smithy/1.0/spec/core/http-traits.html#http-trait">http traits</a> specified.</p>
<p>This is in contrast to <code>axum</code>, where the user specifies the routing by use of various combinators included on the <code>axum::Router</code>, applied to other <code>tower::Service</code>s. In an <code>axum</code> application one might encounter the following code:</p>
<pre><code class="language-rust ignore">let user_routes = Router::new().route("/:id", /* service */);

let team_routes = Router::new().route("/", /* service */);

let api_routes = Router::new()
    .nest("/users", user_routes)
    .nest("/teams", team_routes);

let app = Router::new().nest("/api", api_routes);</code></pre>
<p>Note that, in <code>axum</code> handlers are eagerly converted to a <code>tower::Service</code> (via <code>IntoService</code>) before they are passed into the <code>Router</code>. In contrast, in <code>smithy-rs</code>, handlers are passed into a builder and then the conversion to <code>tower::Service</code> is performed (via <code>OperationHandler</code>).</p>
<p>Introducing state to handlers in <code>axum</code> is done in the same way as <code>smithy-rs</code>, described briefly in <a href="rfcs/rfc0020_service_builder.html#handlers">Handlers</a> - a layer is used to insert state into incoming <code>http::Request</code>s and the <code>Handler</code> implementation pops it out of the type map layer. In <code>axum</code>, if a customer wanted to scope state to all routes within <code>/users/</code> they are able to do the following:</p>
<pre><code class="language-rust ignore">async fn handler(Extension(state): Extension&lt;/* State */&gt;) -&gt; /* Return Type */ {}

let api_routes = Router::new()
    .nest("/users", user_routes.layer(Extension(/* state */)))
    .nest("/teams", team_routes);</code></pre>
<p>In <code>smithy-rs</code> a customer is only able to apply a layer around the <code>aws_smithy_http::routing::Router</code> or around every route via the <a href="rfcs/rfc0020_service_builder.html#router">layer method</a> described above.</p>
<h2 id="proposal-3"><a class="header" href="#proposal-3">Proposal</a></h2>
<p>The proposal is presented as a series of compatible transforms to the existing service builder, each paired with a motivation. Most of these can be independently implemented, and it is stated in the cases where an interdependency exists.</p>
<p>Although presented as a mutation to the existing service builder, the actual implementation should exist as an entirely separate builder, living in a separate namespace, reusing code generation from the old builder, while exposing a new Rust API. Preserving the old API surface will prevent breakage and make it easier to perform comparative benchmarks and testing.</p>
<h3 id="remove-two-step-build-procedure"><a class="header" href="#remove-two-step-build-procedure">Remove two-step build procedure</a></h3>
<p>As described in <a href="rfcs/rfc0020_service_builder.html#builder">Builder</a>, the customer is required to perform two conversions. One from <code>OperationRegistryBuilder</code> via <code>OperationRegistryBuilder::build</code>, the second from <code>OperationRegistryBuilder</code> to <code>Router</code> via the <code>From&lt;OperationRegistry&gt; for Router</code> implementation. The intermediary stop at <code>OperationRegistry</code> is not required and can be removed.</p>
<h3 id="statically-check-for-missing-handlers"><a class="header" href="#statically-check-for-missing-handlers">Statically check for missing Handlers</a></h3>
<p>As described in <a href="rfcs/rfc0020_service_builder.html#builder">Builder</a>, the <code>OperationRegistryBuilder::build</code> method is fallible - it yields a runtime error when one of the handlers has not been set.</p>
<pre><code class="language-rust ignore">    pub fn build(
        self,
    ) -&gt; Result&lt;OperationRegistry&lt;Op0, In0, Op1, In1&gt;, OperationRegistryBuilderError&gt; {
        Ok(OperationRegistry {
            operation0: self.operation0.ok_or(/* OperationRegistryBuilderError */)?,
            operation1: self.operation1.ok_or(/* OperationRegistryBuilderError */)?,
        })
    }</code></pre>
<p>We can do away with fallibility if we allow for on <code>Op0</code>, <code>Op1</code> to switch types during build and remove the <code>Option</code> from around the fields. The <code>OperationRegistryBuilder</code> then becomes</p>
<pre><code class="language-rust ignore">struct OperationRegistryBuilder&lt;Op0, Op1&gt; {
    operation_0: Op0,
    operation_1: Op1
}

impl OperationRegistryBuilder&lt;Op0, In0, Op1, In1&gt; {
    pub fn operation0&lt;NewOp0&gt;(mut self, value: NewOp0) -&gt; OperationRegistryBuilder&lt;NewOp0, In0, Op1, In1&gt; {
        OperationRegistryBuilder {
            operation0: value,
            operation1: self.operation1
        }
    }
    pub fn operation1&lt;NewOp1&gt;(mut self, value: NewOp1) -&gt; OperationRegistryBuilder&lt;Op0, In0, NewOp1, In1&gt; {
        OperationRegistryBuilder {
            operation0: self.operation0,
            operation1: value
        }
    }
}

impl OperationRegistryBuilder&lt;Op0, In0, Op1, In1&gt;
where
    Op0: Handler&lt;B, In0, Operation0Input&gt;,
    Op1: Handler&lt;B, In1, Operation1Input&gt;,
{
    pub fn build(self) -&gt; OperationRegistry&lt;Op0, In0, Op1, In1&gt; {
        OperationRegistry {
            operation0: self.operation0,
            operation1: self.operation1,
        }
    }
}</code></pre>
<p>The customer will now get a compile time error rather than a runtime error when they fail to specify a handler.</p>
<h3 id="switch-fromoperationregistry-for-router-to-an-operationregistrybuild-method"><a class="header" href="#switch-fromoperationregistry-for-router-to-an-operationregistrybuild-method">Switch <code>From&lt;OperationRegistry&gt; for Router</code> to an <code>OperationRegistry::build</code> method</a></h3>
<p>To construct a <code>Router</code>, the customer must either give a type ascription</p>
<pre><code class="language-rust ignore">let app: Router = /* Service builder */.into();</code></pre>
<p>or be explicit about the <code>Router</code> namespace</p>
<pre><code class="language-rust ignore">let app = Router::from(/* Service builder */);</code></pre>
<p>If we switch from a <code>From&lt;OperationRegistry&gt; for Router</code> to a <code>build</code> method on <code>OperationRegistry</code> the customer may simply</p>
<pre><code class="language-rust ignore">let app = /* Service builder */.build();</code></pre>
<p>There already exists a <code>build</code> method taking <code>OperationRegistryBuilder</code> to <code>OperationRegistry</code>, this is removed in <a href="rfcs/rfc0020_service_builder.html#remove-two-step-build-procedure">Remove two-step build procedure</a>. These two transforms pair well together for this reason.</p>
<h3 id="operations-as-middleware-constructors"><a class="header" href="#operations-as-middleware-constructors">Operations as Middleware Constructors</a></h3>
<p>As mentioned in <a href="rfcs/rfc0020_service_builder.html#routing">Comparison to Axum: Routing</a> and <a href="rfcs/rfc0020_service_builder.html#handlers">Handlers</a>, the <code>smithy-rs</code> service builder accepts handlers and only converts them into a <code>tower::Service</code> during the final conversion into a <code>Router</code>. There are downsides to this:</p>
<ol>
<li>The customer has no opportunity to apply middleware to a specific operation before they are all collected into <code>Router</code>. The <code>Router</code> does have a <code>layer</code> method, described in <a href="rfcs/rfc0020_service_builder.html#router">Router</a>, but this applies the middleware uniformly across all operations.</li>
<li>The builder has no way to apply middleware around customer applied middleware. A concrete example of where this would be useful is described in the <a href="rfcs/rfc0018_logging_sensitive.html#middleware-position">Middleware Position</a> section of <a href="rfcs/rfc0018_logging_sensitive.html">RFC: Logging in the Presence of Sensitive Data</a>.</li>
<li>The customer has no way of expressing readiness of the underlying operation - all handlers are converted to services with <a href="https://docs.rs/tower/latest/tower/trait.Service.html#tymethod.poll_ready">Service::poll_ready</a> returning <code>Poll::Ready(Ok(()))</code>.</li>
</ol>
<p>The three use cases described above are supported by <code>axum</code> by virtue of the <a href="https://docs.rs/axum/latest/axum/routing/struct.Router.html#method.route">Router::route</a> method accepting a <code>tower::Service</code>. The reader should consider a similar approach where the service builder setters accept a <code>tower::Service&lt;http::Request, Response = http::Response&gt;</code> rather than the <code>Handler</code>.</p>
<p>Throughout this section we purposely ignore the existence of handlers accepting state alongside the <code>{Operation}Input</code>, this class of handlers serve as a distraction and can be accommodated with small perturbations from each approach.</p>
<h4 id="approach-a-customer-uses-operationhandlernew"><a class="header" href="#approach-a-customer-uses-operationhandlernew">Approach A: Customer uses <code>OperationHandler::new</code></a></h4>
<p>It's possible to make progress with a small changeset, by requiring the customer eagerly uses <code>OperationHandler::new</code> rather than it being applied internally within <code>From&lt;OperationRegistry&gt; for Router</code> (see <a href="rfcs/rfc0020_service_builder.html#handlers">Handlers</a>). The setter would then become:</p>
<pre><code class="language-rust ignore">pub struct OperationRegistryBuilder&lt;Op0, Op1&gt; {
    operation1: Option&lt;Op0&gt;,
    operation2: Option&lt;Op1&gt;
}

impl&lt;Op0, Op1&gt; OperationRegistryBuilder&lt;Op0, Op1&gt; {
    pub fn operation0(self, value: Op0) -&gt; Self {
        self.operation1 = Some(value);
        self
    }
}</code></pre>
<p>The API usage would then become</p>
<pre><code class="language-rust ignore">async fn handler0(input: Operation0Input) -&gt; Operation0Output {
    todo!()
}

// Create a `Service&lt;http::Request, Response = http::Response, Error = Infallible&gt;` eagerly
let svc = OperationHandler::new(handler0);

// Middleware can be applied at this point
let operation0 = /* A HTTP `tower::Layer` */.layer(op1_svc);

OperationRegistryBuilder::default()
    .operation0(operation0)
    /* ... */</code></pre>
<p>Note that this requires that the <code>OperationRegistryBuilder</code> stores services, rather than <code>Handler</code>s. An unintended and superficial benefit of this is that we are able to drop <code>In{n}</code> from the <code>OperationRegistryBuilder&lt;Op0, In0, Op1, In1&gt;</code> - only <code>Op{n}</code> remains and it parametrizes each operation's <code>tower::Service</code>.</p>
<p>It is still possible to retain the original API which accepts <code>Handler</code> by introducing the following setters:</p>
<pre><code class="language-rust ignore">impl&lt;Op1, Op2&gt; OperationRegistryBuilder&lt;Op1, Op2&gt; {
    fn operation0_handler&lt;H: Handler&gt;(self, handler: H) -&gt; OperationRegistryBuilder&lt;OperationHandler&lt;H&gt;, Op2&gt; {
        OperationRegistryBuilder {
            operation0: OperationHandler::new(handler),
            operation1: self.operation1
        }
    }
}</code></pre>
<p>There are two points at which the customer might want to apply middleware: around <code>tower::Service&lt;{Operation}Input, Response = {Operation}Output&gt;</code> and <code>tower::Service&lt;http::Request, Response = http::Response&gt;</code>, that is, before and after the serialization/deserialization is performed. The change described only succeeds in the latter, and therefore is only a partial solution to (1).</p>
<p>This solves (2), the service builder may apply additional middleware around the service.</p>
<p>This does not solve (3), as the customer is not able to provide a <code>tower::Service&lt;{Operation}Input, Response = {Operation}Output&gt;</code>.</p>
<h4 id="approach-b-operations-as-middleware"><a class="header" href="#approach-b-operations-as-middleware">Approach B: Operations as Middleware</a></h4>
<p>In order to achieve all three we model operations as middleware:</p>
<pre><code class="language-rust ignore">pub struct Operation0&lt;S&gt; {
    inner: S,
}

impl&lt;S&gt; Service&lt;http::Request&gt; for Operation0&lt;S&gt;
where
    S: Service&lt;Operation0Input, Response = Operation0Output, Error = Infallible&gt;
{
    type Response = http::Response;
    type Error = Infallible;

    fn poll_ready(&amp;mut self, cx: &amp;mut Context) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        // We defer to the inner service for readiness
        self.inner.poll_ready(cx)
    }

    async fn call(&amp;mut self, request: http::Request) -&gt; Result&lt;Self::Response, Self::Error&gt; {
        let input = /* Create `Operation0Input` from `request: http::Request` */;

        self.inner.call(input).await;

        let response = /* Create `http::Response` from `output: Operation0Output` */
        response
    }
}</code></pre>
<p>Notice the similarity between this and the <code>OperationHandler</code>, the only real difference being that we hold an inner service rather than a closure. In this way we have separated all model aware serialization/deserialization, we noted in <a href="rfcs/rfc0020_service_builder.html#handlers">Handlers</a>, into this middleware.</p>
<p>A consequence of this is that the user <code>Operation0</code> must have two constructors:</p>
<ul>
<li><code>from_service</code>, which takes a <code>tower::Service&lt;Operation0Input, Response = Operation0Output&gt;</code>.</li>
<li><code>from_handler</code>, which takes an async <code>Operation0Input -&gt; Operation0Output</code>.</li>
</ul>
<p>A brief example of how this might look:</p>
<pre><code class="language-rust ignore">use tower::util::{ServiceFn, service_fn};

impl&lt;S&gt; Operation0&lt;S&gt; {
    pub fn from_service(inner: S) -&gt; Self {
        Self {
            inner,
        }
    }
}

impl&lt;F&gt; Operation0&lt;ServiceFn&lt;F&gt;&gt; {
    pub fn from_handler(inner: F) -&gt; Self {
        // Using `service_fn` here isn't strictly correct - there is slight misalignment of closure signatures. This
        // still serves to illustrate the proposal.
        Operation0::from_service(service_fn(inner))
    }
}</code></pre>
<p>The API usage then becomes:</p>
<pre><code class="language-rust ignore">async fn handler(input: Operation0Input) -&gt; Operation0Output {
    todo!()
}

// These are both `tower::Service` and hence can have middleware applied to them
let operation_0 = Operation0::from_handler(handler);
let operation_1 = Operation1::from_service(/* some service */);

OperationRegistryBuilder::default()
    .operation0(operation_0)
    .operation1(operation_1)
    /* ... */</code></pre>
<h4 id="approach-c-operations-as-middleware-constructors"><a class="header" href="#approach-c-operations-as-middleware-constructors">Approach C: Operations as Middleware Constructors</a></h4>
<p>While <a href="rfcs/rfc0020_service_builder.html#approach-b-operations-as-middleware">Attempt B</a> solves all three problems, it fails to adequately model the Smithy semantics. An operation cannot uniquely define a <code>tower::Service</code> without reference to a parent Smithy service - information concerning the serialization/deserialization, error modes are all inherited from the Smithy service an operation is used within. In this way, <code>Operation0</code> should not be a standalone middleware, but become middleware once accepted by the service builder.</p>
<p>Any solution which provides an <code>{Operation}</code> structure and wishes it to be accepted by multiple service builders must deal with this problem. We currently build one library per service and hence have duplicate structures when <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#service-closure">service closures</a> overlap. This means we wouldn't run into this problem today, but it would be a future obstruction if we wanted to reduce the amount of generated code.</p>
<pre><code class="language-rust ignore">use tower::layer::util::{Stack, Identity};
use tower::util::{ServiceFn, service_fn};

// This takes the same form as `Operation0` defined in the previous attempt. The difference being that this is now
// private.
struct Service0Operation0&lt;S&gt; {
    inner: S
}

impl&lt;S&gt; Service&lt;http::Request&gt; for ServiceOperation0&lt;S&gt;
where
    S: Service&lt;Operation0Input, Response = Operation0Output, Error = Infallible&gt;
{
    /* Same as above */
}

pub struct Operation0&lt;S, L&gt; {
    inner: S,
    layer: L
}

impl&lt;S&gt; Operation0&lt;S, Identity&gt; {
    pub fn from_service(inner: S) -&gt; Self {
        Self {
            inner,
            layer: Identity
        }
    }
}

impl&lt;F&gt; Operation0&lt;ServiceFn&lt;F&gt;, Identity&gt; {
    pub fn from_handler(inner: F) -&gt; Self {
        Operation0::from_service(service_fn(inner))
    }
}

impl&lt;S, L&gt; Operation0&lt;S, L&gt; {
    pub fn layer&lt;NewL&gt;(self, layer: L) -&gt; Operation0&lt;S, Stack&lt;L, NewL&gt;&gt; {
        Operation0 {
            inner: self.inner,
            layer: Stack::new(self.layer, layer)
        }
    }

    pub fn logging(self, /* args */) -&gt; Operation0&lt;S, Stack&lt;L, LoggingLayer&gt;&gt; {
        Operation0 {
            inner: self.inner,
            layer: Stack::new(self.layer, LoggingLayer::new(/* args */))
        }
    }

    pub fn auth(self, /* args */) -&gt; Operation0&lt;S, Stack&lt;L, AuthLayer&gt;&gt; {
        Operation0 {
            inner: self.inner,
            layer: Stack::new(self.layer, /* Construct auth middleware */)
        }

    }
}

impl&lt;Op1, Op2&gt; OperationRegistryBuilder&lt;Op1, Op2&gt; {
    pub fn operation0&lt;S, L&gt;(self, operation: Operation0&lt;S, L&gt;) -&gt; OperationRegistryBuilder&lt;&lt;L as Layer&lt;Service0Operation0&lt;S&gt;&gt;::Service, Op2&gt;
    where
        L: Layer&lt;Service0Operation0&lt;S&gt;&gt;
    {
        // Convert `Operation0` to a `tower::Service`.
        let http_svc = Service0Operation0 { inner: operation.inner };
        // Apply the layers
        operation.layer(http_svc)
    }
}</code></pre>
<p>Notice that we get some additional type safety here when compared to <a href="rfcs/rfc0020_service_builder.html#approach-a-customer-uses-operationhandlernew">Approach A</a> and <a href="rfcs/rfc0020_service_builder.html#approach-b-operations-as-middleware">Approach B</a> - <code>operation0</code> accepts a <code>Operation0</code> rather than a general <code>tower::Service</code>. We also get a namespace to include utility methods - notice the <code>logging</code> and <code>auth</code> methods.</p>
<p>The RFC favours this approach out of all those presented.</p>
<h4 id="approach-d-add-more-methods-to-the-service-builder"><a class="header" href="#approach-d-add-more-methods-to-the-service-builder">Approach D: Add more methods to the Service Builder</a></h4>
<p>An alternative to <a href="rfcs/rfc0020_service_builder.html#approach-c-operations-as-middleware-constructors">Approach C</a> is to simply add more methods to the service builder while internally storing a <code>tower::Service</code>:</p>
<ul>
<li><code>operation0_from_service</code>, accepts a <code>tower::Service&lt;Operation0Input, Response = Operation0Output&gt;</code>.</li>
<li><code>operation0_from_handler</code>, accepts an async <code>Fn(Operation0Input) -&gt; Operation0Output</code>.</li>
<li><code>operation0_layer</code>, accepts a <code>tower::Layer&lt;Op0&gt;</code>.</li>
</ul>
<p>This is functionally similar to <a href="rfcs/rfc0020_service_builder.html#approach-c-operations-as-middleware-constructors">Attempt C</a> except that all composition is done internal to the service builder and the namespace exists in the method name, rather than the <code>{Operation}</code> struct.</p>
<h3 id="service-parameterized-routers"><a class="header" href="#service-parameterized-routers">Service parameterized Routers</a></h3>
<p>Currently the <code>Router</code> stores <code>Box&lt;dyn tower::Service&lt;http::Request, Response = http::Response&gt;</code>. As a result the <code>Router::layer</code> method, seen in <a href="rfcs/rfc0020_service_builder.html#router">Router</a>, must re-box a service after every <code>tower::Layer</code> applied. The heap allocation <code>Box::new</code> itself is not cause for concern because <code>Router</code>s are typically constructed once at startup, however one might expect the indirection to regress performance when the server is running.</p>
<p>Having the service type parameterized as <code>Router&lt;S&gt;</code>, allows us to write:</p>
<pre><code class="language-rust ignore">impl&lt;S&gt; Router&lt;S&gt; {
    fn layer&lt;L&gt;(self, layer: &amp;L) -&gt; Router&lt;L::Service&gt;
    where
        L: Layer&lt;S&gt;
    {
        /* Same internal implementation without boxing */
    }
}</code></pre>
<h3 id="protocol-specific-routers"><a class="header" href="#protocol-specific-routers">Protocol specific Routers</a></h3>
<p>Currently there is a single <code>Router</code> structure, described in <a href="rfcs/rfc0020_service_builder.html#router">Router</a>, situated in the <code>rust-runtime/aws-smithy-http-server</code> crate, which is output by the service builder. This, roughly, takes the form of an <code>enum</code> listing the different protocols.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug)]
enum Routes {
    RestXml(/* Container */),
    RestJson1(/* Container */),
    AwsJson1_0(/* Container */),
    AwsJson1_1(/* Container */),
}
<span class="boring">}</span></code></pre></pre>
<p>Recall the form of the <code>Service::call</code> method, given in <a href="rfcs/rfc0020_service_builder.html#router">Router</a>, which involved matching on the protocol and then performing protocol specific logic.</p>
<p>Two downsides of modelling <code>Router</code> in this way are:</p>
<ul>
<li><code>Router</code> is larger and has more branches than a protocol specific implementation.</li>
<li>If a third-party wanted to extend <code>smithy-rs</code> to additional protocols <code>Routes</code> would have to be extended. A synopsis of this obstruction is presented in <a href="https://github.com/smithy-lang/smithy-rs/issues/1606">Should we generate the <code>Router</code> type</a> issue.</li>
</ul>
<p>After taking the <a href="rfcs/rfc0020_service_builder.html#switch-fromoperationregistry-for-router-to-an-operationregistrybuild-method">Switch <code>From&lt;OperationRegistry&gt; for Router</code> to an <code>OperationRegistry::build</code> method</a> transform, code generation is free to switch between return types based on the model. This allows for a scenario where a <code>@restJson1</code> causes the service builder to output a specific <code>RestJson1Router</code>.</p>
<h3 id="protocol-specific-errors"><a class="header" href="#protocol-specific-errors">Protocol specific Errors</a></h3>
<p>Currently, protocol specific routing errors are either:</p>
<ul>
<li>Converted to <code>RuntimeError</code>s and then <code>http::Response</code> (see <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/rust-runtime/aws-smithy-http-server/src/routing/mod.rs#L106-L118">unknown_operation</a>).</li>
<li>Converted directly to a <code>http::Response</code> (see <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/rust-runtime/aws-smithy-http-server/src/routing/mod.rs#L121-L127">method_not_allowed</a>). This is an outlier to the common pattern.</li>
</ul>
<p>The <code>from_request</code> functions yield protocol specific errors which are converted to <code>RequestRejection</code>s then <code>RuntimeError</code>s (see <a href="https://github.com/smithy-lang/smithy-rs/blob/458eeb63b95e6e1e26de0858457adbc0b39cbe4e/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/protocols/ServerHttpBoundProtocolGenerator.kt#L194-L210">ServerHttpBoundProtocolGenerator.kt</a>).</p>
<p>In these scenarios protocol specific errors are converted into <code>RuntimeError</code> before being converted to a <code>http::Response</code> via <code>into_response</code> method.</p>
<p>Two downsides of this are:</p>
<ul>
<li><code>RuntimeError</code> enumerates all possible errors across all existing protocols, so is larger than modelling the errors for a specific protocol.</li>
<li>If a third-party wanted to extend <code>smithy-rs</code> to additional protocols with differing failure modes <code>RuntimeError</code> would have to be extended. As in <a href="rfcs/rfc0020_service_builder.html#protocol-specific-errors">Protocol specific Errors</a>, a synopsis of this obstruction is presented in <a href="https://github.com/smithy-lang/smithy-rs/issues/1606">Should we generate the <code>Router</code> type</a> issue.</li>
</ul>
<p>Switching from using <code>RuntimeError</code> to protocol specific errors which satisfy a common interface, <code>IntoResponse</code>, would resolve these problem.</p>
<h3 id="type-erasure-with-the-name-of-the-smithy-service"><a class="header" href="#type-erasure-with-the-name-of-the-smithy-service">Type erasure with the name of the Smithy service</a></h3>
<p>Currently the service builder is named <code>OperationRegistryBuilder</code>. Despite the name being model agnostic, the <code>OperationRegistryBuilder</code> mutates when the associated service mutates. Renaming <code>OperationRegistryBuilder</code> to <code>{Service}Builder</code> would reflect the relationship between the builder and the Smithy service and prevent naming conflicts if multiple service builders are to exist in the same namespace.</p>
<p>Similarly, the output of the service builder is <code>Router</code>. This ties the output of the service builder to a structure in <code>rust-runtime</code>. Introducing a type erasure here around <code>Router</code> using a newtype named <code>{Service}</code> would:</p>
<ul>
<li>Ensure we are free to change the implementation of <code>{Service}</code> without changing the <code>Router</code> implementation.</li>
<li>Hide the router type, which is determined by the protocol specified in the model.</li>
<li>Allow us to put a <code>builder</code> method on <code>{Service}</code> which returns <code>{Service}Builder</code>.</li>
</ul>
<p>This is compatible with <a href="rfcs/rfc0020_service_builder.html#protocol-specific-routers">Protocol specific Routers</a>, we simply newtype the protocol specific router rather than <code>Router</code>.</p>
<p>With both of these changes the API would take the form:</p>
<pre><code class="language-rust ignore">let service_0: Service0 = Service0::builder()
    /* use the setters */
    .build()
    .unwrap()
    .into();</code></pre>
<p>With <a href="rfcs/rfc0020_service_builder.html#remove-two-step-build-procedure">Remove two-step build procedure</a>, <a href="rfcs/rfc0020_service_builder.html#switch-fromoperationregistry-for-router-to-an-operationregistrybuild-method">Switch <code>From&lt;OperationRegistry&gt; for Router</code> to a <code>OperationRegistry::build</code> method</a>, and <a href="rfcs/rfc0020_service_builder.html#statically-check-for-missing-handlers">Statically check for missing Handlers</a> we obtain the following API:</p>
<pre><code class="language-rust ignore">let service_0: Service0 = Service0::builder()
    /* use the setters */
    .build();</code></pre>
<h3 id="combined-proposal"><a class="header" href="#combined-proposal">Combined Proposal</a></h3>
<p>A combination of all the proposed transformations results in the following API:</p>
<pre><code class="language-rust ignore">struct Context {
    /* fields */
}

async fn handler(input: Operation0Input) -&gt; Operation0Output {
    todo!()
}

async fn handler_with_ext(input: Operation0Input, extension: Extension&lt;Context&gt;) -&gt; Operation0Output {
    todo!()
}

struct Operation1Service {
    /* fields */
}

impl Service&lt;Operation1Input&gt; for Operation1Service {
    type Response = Operation1Output;

    /* implementation */
}

struct Operation1ServiceWithExt {
    /* fields */
}

impl Service&lt;(Operation1Input, Extension&lt;Context&gt;)&gt; for Operation1Service {
    type Response = Operation1Output;

    /* implementation */
}

// Create an operation from a handler
let operation_0 = Operation0::from_handler(handler);

// Create an operation from a handler with extension
let operation_0 = Operation::from_handler(handler_with_ext);

// Create an operation from a `tower::Service`
let operation_1_svc = Operation1Service { /* initialize */ };
let operation_1 = Operation::from_service(operation_1_svc);

// Create an operation from a `tower::Service` with extension
let operation_1_svc = Operation1ServiceWithExtension { /* initialize */ };
let operation_1 = Operation::from_service(operation_1_svc);

// Apply a layer
let operation_0 = operation_0.layer(/* layer */);

// Use the service builder
let service_0 = Service0::builder()
    .operation_0(operation_0)
    .operation_1(operation_1)
    .build();</code></pre>
<p>A toy implementation of the combined proposal is presented in <a href="https://github.com/hlbarber/service-builder/pull/1">this PR</a>.</p>
<h2 id="changes-checklist-14"><a class="header" href="#changes-checklist-14">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add protocol specific routers to <code>rust-runtime/aws-smithy-http-server</code>.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1666">https://github.com/smithy-lang/smithy-rs/pull/1666</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add middleware primitives and error types to <code>rust-runtime/aws-smithy-http-server</code>.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1679">https://github.com/smithy-lang/smithy-rs/pull/1679</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add code generation which outputs new service builder.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1693">https://github.com/smithy-lang/smithy-rs/pull/1693</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Deprecate <code>OperationRegistryBuilder</code>, <code>OperationRegistry</code> and <code>Router</code>.
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1886">https://github.com/smithy-lang/smithy-rs/pull/1886</a></li>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/2161">https://github.com/smithy-lang/smithy-rs/pull/2161</a></li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-dependency-versions"><a class="header" href="#rfc-dependency-versions">RFC: Dependency Versions</a></h1>
<blockquote>
<p>Status: Accepted</p>
<p>Applies to: Client and Server</p>
</blockquote>
<p>This RFC outlines how Rust dependency versions are selected for the smithy-rs project, and
strives to meet the following semi-conflicting goals:</p>
<ul>
<li>Dependencies are secure</li>
<li>Vended libraries have dependency ranges that overlap other Rust libraries as much as possible</li>
</ul>
<p>When in conflict, the security goal takes priority over the compatibility goal.</p>
<h2 id="categorization-of-crates"><a class="header" href="#categorization-of-crates">Categorization of Crates</a></h2>
<p>The Rust crates within smithy-rs can be divided up into two categories:</p>
<ol>
<li><strong>Library Crates:</strong> Crates that are published to crates.io with the intention that other projects
will depend on them via their <code>Cargo.toml</code> files. This category does NOT include binaries that
are published to crates.io with the intention of being installed with <code>cargo install</code>.</li>
<li><strong>Application Crates:</strong> All examples, binaries, tools, standalone tests, or other crates that are
not published to crates.io with the intent of being depended on by other projects.</li>
</ol>
<p>All generated crates must be considered library crates even if they're not published since they are intended
to be pulled into other Rust projects with other dependencies.</p>
<h3 id="support-crates-for-applications"><a class="header" href="#support-crates-for-applications">Support crates for Applications</a></h3>
<p>The <code>aws-smithy-http-server-python</code> crate doesn't fit the categorization rules well since
it is a runtime crate for a generated Rust application with bindings to Python. This RFC
establishes this crate as an application crate since it needs to pull in application-specific
dependencies such as <code>tracing-subscriber</code> in order to implement its full feature set.</p>
<h2 id="dependency-version-rules"><a class="header" href="#dependency-version-rules">Dependency Version Rules</a></h2>
<p>Application crates <em>should</em> use the latest versions of dependencies, but <em>must</em> use a version greater than or equal
to the minimum secure version as determined by the <a href="https://rustsec.org/advisories/">RUSTSEC advisories database</a>. Library crates <em>must</em> use the
minimum secure version. This is illustrated at a high level below:</p>
<pre class="mermaid">graph TD
    S[Add Dependency] --&gt; T{Crate Type?}
    T --&gt;|Application Crate?| A[Use latest version]
    T --&gt;|Library Crate?| L[Use minimum secure version]
</pre>
<h3 id="what-is-a-minimum-secure-version-when-there-are-multiple-major-versions"><a class="header" href="#what-is-a-minimum-secure-version-when-there-are-multiple-major-versions">What is a minimum secure version when there are multiple major versions?</a></h3>
<p>If a dependency has multiple supported major versions, then the latest major version must be selected unless
there is a compelling reason to do otherwise (such as the previous major version having been previously
exposed in our public API). Choosing newer major versions will reduce the amount of upgrade work that
needs to be done at a later date when support for the older version is inevitably dropped.</p>
<h2 id="changes-checklist-15"><a class="header" href="#changes-checklist-15">Changes Checklist</a></h2>
<p>Some work needs to be done to establish these guidelines:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Establish automation for enforcing minimum secure versions for the direct dependencies of library crates</li>
</ul>
<!-- # Links -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-error-context-and-compatibility"><a class="header" href="#rfc-error-context-and-compatibility">RFC: Error Context and Compatibility</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: Generated clients and shared rust-runtime crates</p>
</blockquote>
<p>This RFC proposes a pattern for writing Rust errors to provide consistent
error context AND forwards/backwards compatibility. The goal is to strike
a balance between these four goals:</p>
<ol>
<li>Errors are forwards compatible, and changes to errors are backwards compatible</li>
<li>Errors are idiomatic and ergonomic. It is easy to match on them and extract additional
information for cases where that's useful. The type system prevents errors from being used
incorrectly (for example, incorrectly retrieving context for a different error variant)</li>
<li>Error messages are easy to debug</li>
<li>Errors implement best practices with Rust's <code>Error</code> trait (for example, implementing the optional <code>source()</code> function where possible)</li>
</ol>
<p><em>Note:</em> This RFC is <em>not</em> about error backwards compatibility when it comes to error serialization/deserialization
for transfer over the wire. The Smithy protocols cover that aspect.</p>
<h2 id="past-approaches-in-smithy-rs"><a class="header" href="#past-approaches-in-smithy-rs">Past approaches in smithy-rs</a></h2>
<p>This section examines some examples found in <code>aws-config</code> that illustrate different problems
that this RFC will attempt to solve, and calls out what was done well, and what could be improved upon.</p>
<h3 id="case-study-invalidfullurierror"><a class="header" href="#case-study-invalidfullurierror">Case study: <code>InvalidFullUriError</code></a></h3>
<p>To start, let's examine <code>InvalidFullUriError</code> (doc comments omitted):</p>
<pre><code class="language-rust ignore">#[derive(Debug)]
#[non_exhaustive]
pub enum InvalidFullUriError {
    #[non_exhaustive] InvalidUri(InvalidUri),
    #[non_exhaustive] NoDnsService,
    #[non_exhaustive] MissingHost,
    #[non_exhaustive] NotLoopback,
    DnsLookupFailed(io::Error),
}

impl Display for InvalidFullUriError {
    fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; std::fmt::Result {
        match self {
            InvalidFullUriError::InvalidUri(err) =&gt; write!(f, "URI was invalid: {}", err),
            InvalidFullUriError::MissingHost =&gt; write!(f, "URI did not specify a host"),
            // ... omitted ...
        }
    }
}

impl Error for InvalidFullUriError {
    fn source(&amp;self) -&gt; Option&lt;&amp;(dyn Error + 'static)&gt; {
        match self {
            InvalidFullUriError::InvalidUri(err) =&gt; Some(err),
            InvalidFullUriError::DnsLookupFailed(err) =&gt; Some(err),
            _ =&gt; None,
        }
    }
}</code></pre>
<p>This error does a few things well:</p>
<ol>
<li>Using <code>#[non_exhaustive]</code> on the enum allows new errors to be added in the future.</li>
<li>Breaking out different error types allows for more useful error messages, potentially with error-specific context.
Customers can match on these different error variants to change their program flow, although it's not immediately
obvious if such use cases exist for this error.</li>
<li>The error cause is available through the <code>Error::source()</code> impl for variants that have a cause.</li>
</ol>
<p>However, there are also a number of things that could be improved:</p>
<ol>
<li>All tuple/struct enum members are public, and <code>InvalidUri</code> is an error from the <code>http</code> crate.
Exposing a type from another crate can potentially lock the GA SDK into a specific crate version
if breaking changes are ever made to the exposed types. In this specific case, it prevents
using alternate HTTP implementations that don't use the <code>http</code> crate.</li>
<li><code>DnsLookupFailed</code> is missing <code>#[non_exhaustive]</code>, so new members can never be added to it.</li>
<li>Use of enum tuples, even with <code>#[non_exhaustive]</code>, adds friction to evolving the API since the
tuple members cannot be named.</li>
<li>Printing the source error in the <code>Display</code> impl leads to error repetition by reporters
that examine the full source chain.</li>
<li>The <code>source()</code> impl has a <code>_</code> match arm, which means future implementers could forget to propagate
a source when adding new error variants.</li>
<li>The error source can be downcasted to <code>InvalidUri</code> type from <code>http</code> in customer code. This is
a leaky abstraction where customers can start to rely on the underlying library the SDK uses
in its implementation, and if that library is replaced/changed, it can silently break the
customer's application. <em>Note:</em> later in the RFC, I'll demonstrate why fixing this issue is not practical.</li>
</ol>
<h3 id="case-study-profileparseerror"><a class="header" href="#case-study-profileparseerror">Case study: <code>ProfileParseError</code></a></h3>
<p>Next, let's look at a much simpler error. The <code>ProfileParseError</code> is focused purely on the parsing
logic for the SDK config file:</p>
<pre><code class="language-rust ignore">#[derive(Debug, Clone)]
pub struct ProfileParseError {
    location: Location,
    message: String,
}

impl Display for ProfileParseError {
    fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; fmt::Result {
        write!(
            f,
            "error parsing {} on line {}:\n  {}",
            self.location.path, self.location.line_number, self.message
        )
    }
}

impl Error for ProfileParseError {}</code></pre>
<p>What this error does well:</p>
<ul>
<li>The members are private, so <code>#[non_exhaustive]</code> isn't even necessary</li>
<li>The error is completely opaque (maximizing compatibility) while still being
debuggable thanks to the flexible messaging</li>
</ul>
<p>What could be improved:</p>
<ul>
<li>It needlessly implements <code>Clone</code>, which may prevent it from holding
an error source in the future since errors are often not <code>Clone</code>.</li>
<li>In the future, if more error variants are needed, a private inner error
kind enum could be added to change messaging, but there's not a <em>nice</em> way to
expose new variant-specific information to the customer.</li>
<li>Programmatic access to the error <code>Location</code> may be desired, but
this can be trivially added in the future without a breaking change by
adding an accessor method.</li>
</ul>
<h3 id="case-study-code-generated-client-errors"><a class="header" href="#case-study-code-generated-client-errors">Case study: code generated client errors</a></h3>
<p>The SDK currently generates errors such as the following (from S3):</p>
<pre><code class="language-rust ignore">#[non_exhaustive]
pub enum Error {
    BucketAlreadyExists(BucketAlreadyExists),
    BucketAlreadyOwnedByYou(BucketAlreadyOwnedByYou),
    InvalidObjectState(InvalidObjectState),
    NoSuchBucket(NoSuchBucket),
    NoSuchKey(NoSuchKey),
    NoSuchUpload(NoSuchUpload),
    NotFound(NotFound),
    ObjectAlreadyInActiveTierError(ObjectAlreadyInActiveTierError),
    ObjectNotInActiveTierError(ObjectNotInActiveTierError),
    Unhandled(Box&lt;dyn Error + Send + Sync + 'static&gt;),
}</code></pre>
<p>Each error variant gets its own struct, which can hold error-specific contextual information.
Except for the <code>Unhandled</code> variant, both the error enum and the details on each variant are extensible.
The <code>Unhandled</code> variant should move the error source into a struct so that its type can be hidden.
Otherwise, the code generated errors are already aligned with the goals of this RFC.</p>
<h2 id="approaches-from-other-projects"><a class="header" href="#approaches-from-other-projects">Approaches from other projects</a></h2>
<h3 id="stdioerror"><a class="header" href="#stdioerror"><code>std::io::Error</code></a></h3>
<p>The standard library uses an <code>Error</code> struct with an accompanying <code>ErrorKind</code> enum
for its IO error. Roughly:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Debug)]
#[non_exhaustive]
pub enum ErrorKind {
    NotFound,
    // ... omitted ...
    Other,
}

#[derive(Debug)]
pub struct Error {
    kind: ErrorKind,
    source: Box&lt;dyn std::error::Error + Send + Sync&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>What this error does well:</p>
<ul>
<li>It is extensible since the <code>ErrorKind</code> is non-exhaustive</li>
<li>It has an <code>Other</code> error type that can be instantiated by users in unit tests,
making it easier to unit test error handling</li>
</ul>
<p>What could be improved:</p>
<ul>
<li>There isn't an ergonomic way to add programmatically accessible error-specific context
to this error in the future</li>
<li>The source error can be downcasted, which could be a trap for backwards compatibility.</li>
</ul>
<h3 id="hyper-10"><a class="header" href="#hyper-10">Hyper 1.0</a></h3>
<p>Hyper has outlined <a href="https://github.com/hyperium/hyper/blob/bd7928f3dd6a8461f0f0fdf7ee0fd95c2f156f88/docs/ROADMAP.md#errors">some problems they want to address with errors</a>
for the coming 1.0 release. To summarize:</p>
<ul>
<li>It's difficult to match on specific errors (Hyper 0.x's <code>Error</code> relies
on <code>is_x</code> methods for error matching rather than enum matching).</li>
<li>Error reporters duplicate information since the hyper 0.x errors include the display of their error sources</li>
<li><code>Error::source()</code> can leak internal dependencies</li>
</ul>
<h2 id="opaque-error-sources"><a class="header" href="#opaque-error-sources">Opaque Error Sources</a></h2>
<p>There is <a href="https://github.com/rust-lang/project-error-handling/issues/53">discussion in the errors working group</a>
about how to avoid leaking internal dependency error types through error source downcasting. One option is to
create an opaque error wrapping new-type that removes the ability to downcast to the other library's error.
This, however, can be circumvented via unsafe code, and also breaks the ability for error reporters to
properly display the error (for example, if the error has backtrace information, that would be
inaccessible to the reporter).</p>
<p>This situation might improve if the nightly <code>request_value</code>/<code>request_ref</code>/<code>provide</code> functions on
<code>std::error::Error</code> are stabilized, since then contextual information needed for including things
such as a backtrace could still be retrieved through the opaque error new-type.</p>
<p>This RFC proposes that error types from other libraries not be directly exposed in the API, but rather,
be exposed indirectly through <code>Error::source</code> as <code>&amp;dyn Error + 'static</code>.</p>
<p>Errors should not require downcasting to be useful. Downcasting the error's source should be
a last resort, and with the understanding that the type could change at a later date with no
compile-time guarantees.</p>
<h2 id="error-proposal"><a class="header" href="#error-proposal">Error Proposal</a></h2>
<p>Taking a customer's perspective, there are two broad categories of errors:</p>
<ol>
<li><strong>Actionable:</strong> Errors that can/should influence program flow; where it's useful to
do different work based on additional error context or error variant information</li>
<li><strong>Informative:</strong> Errors that inform that something went wrong, but where
it's not useful to match on the error to change program flow</li>
</ol>
<p>This RFC proposes that a consistent pattern be introduced to cover these two use cases for
all errors in the public API for the Rust runtime crates and generated client crates.</p>
<h3 id="actionable-error-pattern"><a class="header" href="#actionable-error-pattern">Actionable error pattern</a></h3>
<p>Actionable errors are represented as enums. If an error variant has an error source or additional contextual
information, it must use a separate context struct that is referenced via tuple in the enum. For example:</p>
<pre><code class="language-rust ignore">// Good: new error types can be added in the future
#[non_exhaustive]
pub enum Error {
    // Good: This is exhaustive and uses a tuple, but its sole member is an extensible struct with private fields
    VariantA(VariantA),

    // Bad: The fields are directly exposed and can't have accessor methods. The error
    // source type also can't be changed at a later date since.
    #[non_exhaustive]
    VariantB {
        some_additional_info: u32,
        source: AnotherError // AnotherError is from this crate
    },

    // Bad: There's no way to add additional contextual information to this error in the future, even
    // though it is non-exhaustive. Changing it to a tuple or struct later leads to compile errors in existing
    // match statements.
    #[non_exhaustive]
    VariantC,

    // Bad: Not extensible if additional context is added later (unless that context can be added to `AnotherError`)
    #[non_exhaustive]
    VariantD(AnotherError),

    // Bad: Not extensible. If new context is added later (for example, a second endpoint), there's no way to name it.
    #[non_exhaustive]
    VariantE(Endpoint, AnotherError),

    // Bad: Exposes another library's error type in the public API,
    // which makes upgrading or replacing that library a breaking change
    #[non_exhaustive]
    VariantF {
        source: http::uri::InvalidUri
    },

    // Bad: The error source type is public, and even though its a boxed error, it won't
    // be possible to change it to an opaque error type later (for example, if/when
    // opaque errors become practical due to standard library stabilizations).
    #[non_exhaustive]
    VariantG {
        source: Box&lt;dyn Error + Send + Sync + 'static&gt;,
    }
}

pub struct VariantA {
    some_field: u32,
    // This is private, so it's fine to reference the external library's error type
    source: http::uri::InvalidUri
}

impl VariantA {
    fn some_field(&amp;self) -&gt; u32 {
        self.some_field
    }
}</code></pre>
<p>Error variants that contain a source must return it from the <code>Error::source</code> method.
The <code>source</code> implementation <em>should not</em> use the catch all (<code>_</code>) match arm, as this makes it easy to miss
adding a new error variant's source at a later date.</p>
<p>The error <code>Display</code> implementation <em>must not</em> include the source in its output:</p>
<pre><code class="language-rust ignore">// Good
impl fmt::Display for Error {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        match self {
            Self::VariantA =&gt; write!(f, "variant a"),
            Self::VariantB { some_additional_info, .. } =&gt; write!(f, "variant b ({some_additional_info})"),
            // ... and so on
        }
    }
}

// Bad
impl fmt::Display for Error {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        match self {
            Self::VariantA =&gt; write!(f, "variant a"),
            // Bad: includes the source in the `Display` output, which leads to duplicate error information
            Self::VariantB { some_additional_info, source } =&gt; write!(f, "variant b ({some_additional_info}): {source}"),
            // ... and so on
        }
    }
}</code></pre>
<h3 id="informative-error-pattern"><a class="header" href="#informative-error-pattern">Informative error pattern</a></h3>
<p>Informative errors must be represented as structs. If error messaging changes based on an underlying cause, then a
private error kind enum can be used internally for this purpose. For example:</p>
<pre><code class="language-rust ignore">#[derive(Debug)]
pub struct InformativeError {
    some_additional_info: u32,
    source: AnotherError,
}

impl fmt::Display for InformativeError {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        write!(f, "some informative message with {}", self.some_additional_info)
    }
}

impl Error for InformativeError {
    fn source(&amp;self) -&gt; Option&lt;&amp;(dyn Error + 'static)&gt; {
        Some(&amp;self.source)
    }
}</code></pre>
<p>In general, informative errors should be referenced by variants in actionable errors since they cannot be converted
to actionable errors at a later date without a breaking change. This is not a hard rule, however. Use your best judgement
for the situation.</p>
<h3 id="displaying-full-error-context"><a class="header" href="#displaying-full-error-context">Displaying full error context</a></h3>
<p>In code where errors are logged rather than returned to the customer, the full error source chain
must be displayed. This will be made easy by placing a <code>DisplayErrorContext</code> struct in <code>aws-smithy-types</code> that
is used as a wrapper to get the better error formatting:</p>
<pre><code class="language-rust ignore">tracing::warn!(err = %DisplayErrorContext(err), "some message");</code></pre>
<p>This might be implemented as follows:</p>
<pre><code class="language-rust ignore">#[derive(Debug)]
pub struct DisplayErrorContext&lt;E: Error&gt;(pub E);

impl&lt;E: Error&gt; fmt::Display for DisplayErrorContext&lt;E&gt; {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        write_err(f, &amp;self.0)?;
        // Also add a debug version of the error at the end
        write!(f, " ({:?})", self)
    }
}

fn write_err(f: &amp;mut fmt::Formatter&lt;'_&gt;, err: &amp;dyn Error) -&gt; fmt::Result {
    write!(f, "{}", err)?;
    if let Some(source) = err.source() {
        write!(f, ": ")?;
        write_err(f, source)?;
    }
    Ok(())
}</code></pre>
<h2 id="changes-checklist-16"><a class="header" href="#changes-checklist-16">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Update every struct/enum that implements <code>Error</code> in all the non-server Rust runtime crates</li>
<li><input disabled="" type="checkbox" checked=""/>
Hide error source type in <code>Unhandled</code> variant in code generated errors</li>
<li><input disabled="" type="checkbox" checked=""/>
Remove <code>Clone</code> from <code>ProfileParseError</code> and any others that have it</li>
</ul>
<h2 id="error-code-review-checklist"><a class="header" href="#error-code-review-checklist">Error Code Review Checklist</a></h2>
<p>This is a checklist meant to aid code review of new errors:</p>
<ul>
<li><input disabled="" type="checkbox"/>
The error fits either the actionable or informative pattern</li>
<li><input disabled="" type="checkbox"/>
If the error is informative, it's clear that it will never be expanded with additional variants in the future</li>
<li><input disabled="" type="checkbox"/>
The <code>Display</code> impl does not write the error source to the formatter</li>
<li><input disabled="" type="checkbox"/>
The catch all <code>_</code> match arm is not used in the <code>Display</code> or <code>Error::source</code> implementations</li>
<li><input disabled="" type="checkbox"/>
Error types from external libraries are not exposed in the public API</li>
<li><input disabled="" type="checkbox"/>
Error enums are <code>#[non_exhaustive]</code></li>
<li><input disabled="" type="checkbox"/>
Error enum variants that don't have a separate error context struct are <code>#[non_exhaustive]</code></li>
<li><input disabled="" type="checkbox"/>
Error context is exposed via accessors rather than by public fields</li>
<li><input disabled="" type="checkbox"/>
Actionable errors and their context structs are in an <code>error</code> submodule for any given module. They are not mixed with other non-error code</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-evolving-the-new-service-builder-api"><a class="header" href="#rfc-evolving-the-new-service-builder-api">RFC: Evolving the new service builder API</a></h1>
<blockquote>
<p>Status: Accepted</p>
<p>Applies to: Server</p>
</blockquote>
<p><a href="rfcs/rfc0020_service_builder.html">RFC 20</a> introduced a new service builder API.
It supports fine-grained configuration at multiple levels (per-handler middlewares, router middlewares, plugins) while trying to prevent some misconfiguration issues at compile-time (i.e. missing operation handlers).
There is consensus that the new API is an improvement over the pre-existing <code>OperationRegistryBuilder</code>/<code>OperationRegistry</code>, which is now on its way to deprecation in one of the next releases.</p>
<p>This RFC builds on top of <a href="rfcs/rfc0020_service_builder.html">RFC 20</a> to explore an alternative API design prior to its stabilisation.
The API proposed in this RFC has been manually implemented for the Pokemon service. You can find the code <a href="https://github.com/LukeMathWalker/builder-experiments">here</a>.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Type-heavy builders can lead to a poor developer experience when it comes to writing function signatures, conditional branches and clarity of error messages.
This RFC provides examples for the issues we are trying to mitigate and showcases an alternative design for the service builder, cutting generic parameters from 2*(N+1) to 2, where <code>N</code> is the number of operations on the service.
We rely on eagerly upgrading the registered handlers and operations to <code>Route&lt;B&gt;</code> to achieve this reduction.</p>
<p>Goals:</p>
<ul>
<li>Maximise API ergonomics, with a particular focus on the developer experience for Rust beginners.</li>
</ul>
<p>Strategy:</p>
<ul>
<li>Reduce type complexity, exposing a less generic API;</li>
<li>Provide clearer errors when the service builder is misconfigured.</li>
</ul>
<p>Trade-offs:</p>
<ul>
<li>Reduce compile-time safety. Missing handlers will be detected at runtime instead of compile-time.</li>
</ul>
<p>Constraints:</p>
<ul>
<li>There should be no significant degradation in runtime performance (i.e. startup time for applications).</li>
</ul>
<h2 id="handling-missing-operations"><a class="header" href="#handling-missing-operations">Handling missing operations</a></h2>
<p>Let's start by reviewing the API proposed in <a href="rfcs/rfc0020_service_builder.html">RFC 20</a>. We will use the <a href="https://github.com/smithy-lang/smithy-rs/blob/c7ddb164b28b920313432789cfe05d8112a035cc/codegen-core/common-test-models/pokemon.smithy">Pokemon service</a> as our driving example throughout the RFC.
This is what the startup code looks like:</p>
<pre><code class="language-rust ignore">#[tokio::main]
pub async fn main() {
    // [...]
    let app = PokemonService::builder()
        .get_pokemon_species(get_pokemon_species)
        .get_storage(get_storage)
        .get_server_statistics(get_server_statistics)
        .capture_pokemon(capture_pokemon)
        .do_nothing(do_nothing)
        .check_health(check_health)
        .build();

    // Setup shared state and middlewares.
    let shared_state = Arc::new(State::default());
    let app = app.layer(&amp;AddExtensionLayer::new(shared_state));

    // Start the [`hyper::Server`].
    let bind: SocketAddr = /* */;
    let server = hyper::Server::bind(&amp;bind).serve(app.into_make_service());
    // [...]
}</code></pre>
<p>The builder is infallible: we are able to verify at compile-time that all handlers have been provided using the <a href="https://www.greyblake.com/blog/builder-with-typestate-in-rust/">typestate builder pattern</a>.</p>
<h3 id="compiler-errors-cannot-be-tuned"><a class="header" href="#compiler-errors-cannot-be-tuned">Compiler errors cannot be tuned</a></h3>
<p>What happens if we stray away from the happy path? We might forget, for example, to add the <code>check_health</code> handler.
The compiler greets us with this error:</p>
<pre><code class="language-text">error[E0277]: the trait bound `MissingOperation: Upgradable&lt;AwsRestJson1, CheckHealth, (), _, IdentityPlugin&gt;` is not satisfied
  --&gt; pokemon-service/src/bin/pokemon-service.rs:38:10
   |
38 |         .build();
   |          ^^^^^ the trait `Upgradable&lt;AwsRestJson1, CheckHealth, (), _, IdentityPlugin&gt;` is not implemented for `MissingOperation`
   |
   = help: the following other types implement trait `Upgradable&lt;Protocol, Operation, Exts, B, Plugin&gt;`:
             FailOnMissingOperation
             Operation&lt;S, L&gt;
</code></pre>
<p>The compiler complains that <code>MissingOperation</code> does not implement the <code>Upgradable</code> trait. Neither <code>MissingOperation</code> nor <code>Upgradable</code> appear in the startup code we looked at. This is likely to be the first time the developer sees those traits, assuming they haven't spent time getting familiar with <code>aws-smithy-http-server</code>'s internals.
The <code>help</code> section is unhelpful, if not actively misdirecting.
How can the developer figure out that the issue lies with <code>check_health</code>?
They need to inspect the generic parameters attached to <code>Upgradable</code> in the code label or the top-level error message - we see, among other things, a <code>CheckHealth</code> parameter. That is the hint they need to follow to move forward.</p>
<p>We unfortunately do not have agency on the compiler error we just examined. Rust does not expose hooks for crate authors to tweak the errors returned when a type does not implement a trait we defined.
All implementations of the <a href="https://www.greyblake.com/blog/builder-with-typestate-in-rust/">typestate builder pattern</a> accept this shortcoming in exchange for compile-time safety.</p>
<p>Is it a good tradeoff in our case?</p>
<h3 id="the-cost-of-a-runtime-error"><a class="header" href="#the-cost-of-a-runtime-error">The cost of a runtime error</a></h3>
<p>If <code>build</code> returns an error, the HTTP server is never launched. The application fails to start.</p>
<p>Let's examine the cost of this runtime error along two dimensions:</p>
<ul>
<li>Impact on developer productivity;</li>
<li>Impact on end users.</li>
</ul>
<p>We'd love for this issue to be caught on the developer machine - it provides the shortest feedback loop.
The issue won't be surfaced by a <code>cargo check</code> or <code>cargo build</code> invocation, as it happens with the typestate builder approach.
It should be surfaced by executing the application test suite, assuming that the developer has written at least a single integration test - e.g. a test that passes a request to the <code>call</code> method exposed by <code>PokemonService</code> or launches a full-blown instance of the application which is then probed via an HTTP client.</p>
<p>If there are no integration tests, the issue won't be detected on the developer machine nor in CI.
Nonetheless, it is unlikely to cause any end-user impact even if it manages to escape detection and reach production. The deployment will never complete if they are using a progressive rollout strategy: instances of the new version will crash as soon as they are launched, never getting a chance to mark themselves as healthy; all traffic will keep being handled by the old version, with no visible impact on end users of the application.</p>
<p>Given the above, we think that the impact of a runtime error is low enough to be worth exploring designs that do not guarantee compile-safety for the builder API<sup class="footnote-reference"><a href="#further-dev-productivity-improvements">1</a></sup>.</p>
<h3 id="providing-clear-feedback"><a class="header" href="#providing-clear-feedback">Providing clear feedback</a></h3>
<p>Moving from a compile-time error to a runtime error does not require extensive refactoring.
The definition of <code>PokemonServiceBuilder</code> goes from:</p>
<pre><code class="language-rust ignore">pub struct PokemonServiceBuilder&lt;
    Op1,
    Op2,
    Op3,
    Op4,
    Op5,
    Op6,
    Exts1 = (),
    Exts2 = (),
    Exts3 = (),
    Exts4 = (),
    Exts5 = (),
    Exts6 = (),
    Pl = aws_smithy_http_server::plugin::IdentityPlugin,
&gt; {
    check_health: Op1,
    do_nothing: Op2,
    get_pokemon_species: Op3,
    get_server_statistics: Op4,
    capture_pokemon: Op5,
    get_storage: Op6,
    #[allow(unused_parens)]
    _exts: std::marker::PhantomData&lt;(Exts1, Exts2, Exts3, Exts4, Exts5, Exts6)&gt;,
    plugin: Pl,
}</code></pre>
<p>to:</p>
<pre><code class="language-rust ignore">pub struct PokemonServiceBuilder&lt;
    Op1,
    Op2,
    Op3,
    Op4,
    Op5,
    Op6,
    Exts1 = (),
    Exts2 = (),
    Exts3 = (),
    Exts4 = (),
    Exts5 = (),
    Exts6 = (),
    Pl = aws_smithy_http_server::plugin::IdentityPlugin,
&gt; {
    check_health: Option&lt;Op1&gt;,
    do_nothing: Option&lt;Op2&gt;,
    get_pokemon_species: Option&lt;Op3&gt;,
    get_server_statistics: Option&lt;Op4&gt;,
    capture_pokemon: Option&lt;Op5&gt;,
    get_storage: Option&lt;Op6&gt;,
    #[allow(unused_parens)]
    _exts: std::marker::PhantomData&lt;(Exts1, Exts2, Exts3, Exts4, Exts5, Exts6)&gt;,
    plugin: Pl,
}</code></pre>
<p>All operation fields are now <code>Option</code>-wrapped.
We introduce a new <code>MissingOperationsError</code> error to hold the names of the missing operations and their respective setter methods:</p>
<pre><code class="language-rust ignore">#[derive(Debug)]
pub struct MissingOperationsError {
    service_name: &amp;'static str,
    operation_names2setter_methods: HashMap&lt;&amp;'static str, &amp;'static str&gt;,
}

impl Display for MissingOperationsError { /* */ }
impl std::error::Error for MissingOperationsError {}</code></pre>
<p>which is then used in <code>build</code> as error type <em>(not shown here for brevity)</em>.
We can now try again to stray away from the happy path by forgetting to register a handler for the <code>CheckHealth</code> operation.
The code compiles just fine this time, but the application fails when launched via <code>cargo run</code>:</p>
<pre><code class="language-text">&lt;timestamp&gt; ERROR pokemon_service: You must specify a handler for all operations attached to the `Pokemon` service.
We are missing handlers for the following operations:
- com.aws.example#CheckHealth

Use the dedicated methods on `PokemonServiceBuilder` to register the missing handlers:
- PokemonServiceBuilder::check_health
</code></pre>
<p>The error speaks the language of the domain, Smithy's interface definition language: it mentions operations, services, handlers.
Understanding the error requires no familiarity with <code>smithy-rs</code>' internal type machinery or advanced trait patterns in Rust.
We can also provide actionable suggestions: Rust beginners should be able to easily process the information, rectify the mistake and move on quickly.</p>
<h2 id="simplifying-pokemonservicebuilders-signature"><a class="header" href="#simplifying-pokemonservicebuilders-signature">Simplifying <code>PokemonServiceBuilder</code>'s signature</a></h2>
<p>Let's take a second look at the (updated) definition of <code>PokemonServiceBuilder</code>:</p>
<pre><code class="language-rust ignore">pub struct PokemonServiceBuilder&lt;
    Op1,
    Op2,
    Op3,
    Op4,
    Op5,
    Op6,
    Exts1 = (),
    Exts2 = (),
    Exts3 = (),
    Exts4 = (),
    Exts5 = (),
    Exts6 = (),
    Pl = aws_smithy_http_server::plugin::IdentityPlugin,
&gt; {
    check_health: Option&lt;Op1&gt;,
    do_nothing: Option&lt;Op2&gt;,
    get_pokemon_species: Option&lt;Op3&gt;,
    get_server_statistics: Option&lt;Op4&gt;,
    capture_pokemon: Option&lt;Op5&gt;,
    get_storage: Option&lt;Op6&gt;,
    #[allow(unused_parens)]
    _exts: std::marker::PhantomData&lt;(Exts1, Exts2, Exts3, Exts4, Exts5, Exts6)&gt;,
    plugin: Pl,
}</code></pre>
<p>We have 13 generic parameters:</p>
<ul>
<li>1 for plugins (<code>Pl</code>);</li>
<li>2 for each operation (<code>OpX</code> and <code>ExtsX</code>);</li>
</ul>
<p>All those generic parameters were necessary when we were using the <a href="https://www.greyblake.com/blog/builder-with-typestate-in-rust/">typestate builder pattern</a>. They kept track of which operation handlers were missing: if any <code>OpX</code> was set to <code>MissingOperation</code> when calling <code>build</code> -&gt; compilation error!</p>
<p>Do we still need all those generic parameters if we move forward with this RFC?
You might be asking yourselves: why do those generics bother us? Is there any harm in keeping them around?
We'll look at the impact of those generic parameters on two scenarios:</p>
<ul>
<li>Branching in startup logic;</li>
<li>Breaking down a monolithic startup function into multiple smaller functions.</li>
</ul>
<h3 id="branching---incompatible-types"><a class="header" href="#branching---incompatible-types">Branching -&gt; "Incompatible types"</a></h3>
<p>Conditional statements appear quite often in the startup logic for an application (or in the setup code for its integration tests).
Let's consider a toy example: if a <code>check_database</code> flag is set to <code>true</code>, we want to register a different <code>check_health</code> handler - one that takes care of pinging the database to make sure it's up.</p>
<p>The "obvious" solution would look somewhat like this:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let app = if check_database {
    app.check_health(check_health)
} else {
    app.check_health(check_health_with_database)
};
app.build();</code></pre>
<p>The compiler is not pleased:</p>
<pre><code class="language-text">error[E0308]: `if` and `else` have incompatible types
  --&gt; pokemon-service/src/bin/pokemon-service.rs:39:9
   |
36 |       let app = if check_database {
   |  _______________-
37 | |         app.check_health(check_health)
   | |         ------------------------------ expected because of this
38 | |     } else {
39 | |         app.check_health(check_health_with_database)
   | |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected fn item, found a different fn item
40 | |     };
   | |_____- `if` and `else` have incompatible types
   |
   = note: expected struct `PokemonServiceBuilder&lt;Operation&lt;IntoService&lt;_, fn(CheckHealthInput) -&gt; impl Future&lt;Output =
    CheckHealthOutput&gt; {check_health}&gt;&gt;, _, _, _, _, _, _, _, _, _, _, _&gt;`
              found struct `PokemonServiceBuilder&lt;Operation&lt;IntoService&lt;_, fn(CheckHealthInput) -&gt; impl Future&lt;Output =
    CheckHealthOutput&gt; {check_health_with_database}&gt;&gt;, _, _, _, _, _, _, _, _, _, _, _&gt;`
</code></pre>
<p>The developer must be aware of the following facts to unpack the error message:</p>
<ol>
<li>The two branches of an <code>if</code>/<code>else</code> statement need to return the same type.</li>
<li>Each function closure has a new unique type (represented as <code>fn(CheckHealthInput) -&gt; impl Future&lt;Output =  CheckHealthOutput&gt; {check_health}</code> for <code>check_health</code>);</li>
<li>The handler function type becomes part of the overall <code>PokemonServiceBuilder</code> type, a cog in the larger <code>Op1</code> generic parameter used to hold the handler for the <code>CheckHealth</code> operation (i.e. <code>Operation&lt;IntoService&lt;_, fn(CheckHealthInput) -&gt; impl Future&lt;Output =  CheckHealthOutput&gt; {check_health}&gt;&gt;</code>);</li>
</ol>
<p>The second fact requires an intermediate understanding of Rust's closures and opaque types (<code>impl Trait</code>). It's quite likely to confuse Rust beginners.</p>
<p>The developer has three options to move forward:</p>
<ol>
<li>Convert <code>check_health</code> and <code>check_health_with_database</code> into a common type that can be passed as a handler to <code>PokemonServiceBuilder::check_health</code>;</li>
<li>Invoke the <code>build</code> method inside the two branches in order to return a "plain" <code>PokemonService&lt;Route&lt;B&gt;&gt;</code> from both branches.</li>
<li>Embed the configuration parameter (<code>check_database</code>) in the application state, retrieve it inside <code>check_health</code> and perform the branching there.</li>
</ol>
<p>I can't easily see a way to accomplish 1) using the current API. Pursuing 2) is straight-forward with a single conditional:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let app = if check_database {
    app.check_health(check_health).build()
} else {
    app.check_health(check_health_with_database).build()
};</code></pre>
<p>It becomes more cumbersome when we have more than a single conditional:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let include_cpu_statics: bool = /* */;
match (check_database, include_cpu_statics) {
    (true, true) =&gt; app
        .check_health(check_health_with_database)
        .get_server_statistics(get_server_statistics_with_cpu)
        .build(),
    (true, false) =&gt; app
        .check_health(check_health_with_database)
        .get_server_statistics(get_server_statistics)
        .build(),
    (false, true) =&gt; app
        .check_health(check_health)
        .get_server_statistics(get_server_statistics_with_cpu())
        .build(),
    (false, false) =&gt; app
        .check_health(check_health)
        .get_server_statistics(get_server_statistics)
        .build(),
}</code></pre>
<p>A lot of repetition compared to the code for the "obvious" approach:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let include_cpu_statics: bool = /* */;
let app = if check_database {
    app.check_health(check_health)
} else {
    app.check_health(check_health_with_database)
};
let app = if include_cpu_statistics {
    app.get_server_statistics(get_server_statistics_with_cpu)
} else {
    app.get_server_statistics(get_server_statistics)
};
app.build();</code></pre>
<p>The obvious approach becomes viable if we stop embedding the handler function type in <code>PokemonServiceBuilder</code>'s overall type.</p>
<h3 id="refactoring-into-smaller-functions---prepare-for-some-type-juggling"><a class="header" href="#refactoring-into-smaller-functions---prepare-for-some-type-juggling">Refactoring into smaller functions -&gt; Prepare for some type juggling!</a></h3>
<p>Services with a high number of routes can lead to fairly long startup routines.
Developers might be tempted to break down the startup routine into smaller functions, grouping together operations with common requirements (similar domain, same middlewares, etc.).</p>
<p>What does the signature of those smaller functions look like?
The service builder must be one of the arguments if we want to register handlers. We must also return it to allow the orchestrating function to finish the application setup (our setters take ownership of <code>self</code>).</p>
<p>A first sketch:</p>
<pre><code class="language-rust ignore">fn partial_setup(builder: PokemonServiceBuilder) -&gt; PokemonServiceBuilder {
    /* */
}</code></pre>
<p>The compiler demands to see those generic parameters in the signature:</p>
<pre><code class="language-text">error[E0107]: missing generics for struct `PokemonServiceBuilder`
  --&gt; pokemon-service/src/bin/pokemon-service.rs:28:27
   |
28 | fn partial_setup(builder: PokemonServiceBuilder) -&gt; PokemonServiceBuilder {
   |                           ^^^^^^^^^^^^^^^^^^^^^ expected at least 6 generic arguments
   |
note: struct defined here, with at least 6 generic parameters: `Op1`, `Op2`, `Op3`, `Op4`, `Op5`, `Op6`

error[E0107]: missing generics for struct `PokemonServiceBuilder`
  --&gt; pokemon-service/src/bin/pokemon-service.rs:28:53
   |
28 | fn partial_setup(builder: PokemonServiceBuilder) -&gt; PokemonServiceBuilder {
   |                                                     ^^^^^^^^^^^^^^^^^^^^^ expected at least 6 generic arguments
   |
note: struct defined here, with at least 6 generic parameters: `Op1`, `Op2`, `Op3`, `Op4`, `Op5`, `Op6`
</code></pre>
<p>We could try to nudge the compiler into inferring them:</p>
<pre><code class="language-rust ignore">fn partial_setup(
    builder: PokemonServiceBuilder&lt;_, _, _, _, _, _&gt;,
) -&gt; PokemonServiceBuilder&lt;_, _, _, _, _, _&gt; {
    /* */
}</code></pre>
<p>but that won't fly either:</p>
<pre><code class="language-text">error[E0121]: the placeholder `_` is not allowed within types on item signatures for return types
  --&gt; pokemon-service/src/bin/pokemon-service.rs:30:28
   |
30 | ) -&gt; PokemonServiceBuilder&lt;_, _, _, _, _, _&gt; {
   |                            ^  ^  ^  ^  ^  ^ not allowed in type signatures
   |                            |  |  |  |  |
   |                            |  |  |  |  not allowed in type signatures
   |                            |  |  |  not allowed in type signatures
   |                            |  |  not allowed in type signatures
   |                            |  not allowed in type signatures
   |                            not allowed in type signatures
</code></pre>
<p>We must type it all out:</p>
<pre><code class="language-rust ignore">fn partial_setup&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;(
    builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;,
) -&gt; PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt; {
    builder
}</code></pre>
<p>That compiles, at last.
Let's try to register an operation handler now:</p>
<pre><code class="language-rust ignore">fn partial_setup&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;(
    builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;,
) -&gt; PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt; {
    builder.get_server_statistics(get_server_statistics)
}</code></pre>
<p>That looks innocent, but it doesn't fly:</p>
<pre><code class="language-text">error[E0308]: mismatched types
  --&gt; pokemon-service/src/bin/pokemon-service.rs:31:5
   |
28 | fn partial_setup&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;(
   |                                 --- this type parameter
29 |     builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;,
30 | ) -&gt; PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt; {
   |      --------------------------------------------------- expected `PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;` because of return type
31 |     builder.get_server_statistics(get_server_statistics)
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected type parameter `Op4`, found struct `Operation`
   |
   = note: expected struct `PokemonServiceBuilder&lt;_, _, _, Op4, _, _, _&gt;`
              found struct `PokemonServiceBuilder&lt;_, _, _, Operation&lt;IntoService&lt;GetServerStatistics, fn(GetServerStatisticsInput, Extension&lt;Arc&lt;State&gt;&gt;) -&gt; impl Future&lt;Output = GetServerStatisticsOutput&gt; {get_server_statistics}&gt;&gt;, _, _, _&gt;
</code></pre>
<p>By registering a handler we have changed the corresponding <code>OpX</code> generic parameter.
Fixing this error requires some non-trivial type gymnastic - I gave up after trying for ~15 minutes.</p>
<h3 id="cut-them-down-going-from-2n1-to-2-generic-parameters"><a class="header" href="#cut-them-down-going-from-2n1-to-2-generic-parameters">Cut them down: going from 2N+1 to 2 generic parameters</a></h3>
<p>The previous two examples should have convinced you that the 2N+1 generic parameters on <code>PokemonServiceBuilder</code> harm the ergonomics of our API.
Can we get rid of them?</p>
<p>Yes! Let's look at one possible approach:</p>
<pre><code class="language-rust ignore">pub struct PokemonServiceBuilder&lt;Body, Plugin&gt; {
    check_health: Option&lt;Route&lt;Body&gt;&gt;,
    do_nothing: Option&lt;Route&lt;Body&gt;&gt;,
    get_pokemon_species: Option&lt;Route&lt;Body&gt;&gt;,
    get_server_statistics: Option&lt;Route&lt;Body&gt;&gt;,
    capture_pokemon: Option&lt;Route&lt;Body&gt;&gt;,
    get_storage: Option&lt;Route&lt;Body&gt;&gt;,
    plugin: Plugin,
}</code></pre>
<p>We no longer store the raw handlers inside <code>PokemonServiceBuilder</code>.
We eagerly upgrade the operation handlers to a <code>Route</code> instance when they are registered with the builder.</p>
<pre><code class="language-rust ignore">impl&lt;Body, Plugin&gt; PokemonServiceBuilder&lt;Body, Plugin&gt; {
    pub fn get_pokemon_species&lt;Handler, Extensions&gt;(mut self, handler: Handler) -&gt; Self
    /* Complex trait bounds */
    {
        let route = Route::new(Operation::from_handler(handler).upgrade(&amp;self.plugin));
        self.get_pokemon_species = Some(route);
        self
    }

    /* other setters and methods */
}</code></pre>
<p>The existing API performs the upgrade when <code>build</code> is called, forcing <code>PokemonServiceBuilder</code> to store the raw handlers and keep two generic parameters around (<code>OpX</code> and <code>ExtsX</code>) for each operation.
The proposed API requires plugins to be specified upfront, when creating an instance of the builder. They cannot be modified after a <code>PokemonServiceBuilder</code> instance has been built:</p>
<pre><code class="language-rust ignore">impl PokemonService&lt;()&gt; {
    /// Constructs a builder for [`PokemonService`].
    pub fn builder&lt;Body, Plugin&gt;(plugin: Plugin) -&gt; PokemonServiceBuilder&lt;Body, Plugin&gt; {
        PokemonServiceBuilder {
            check_health: None,
            do_nothing: None,
            get_pokemon_species: None,
            get_server_statistics: None,
            capture_pokemon: None,
            get_storage: None,
            plugin,
        }
    }
}</code></pre>
<p>This constraint guarantees that all operation handlers are upgraded to a <code>Route</code> using the same set of plugins.</p>
<p>Having to specify all plugins upfront is unlikely to have a negative impact on developers currently using <code>smithy-rs</code>.
We have seen how cumbersome it is to break the startup logic into different functions using the current service builder API. Developers are most likely specifying all plugins and routes in the same function even if the current API allows them to intersperse route registrations and plugin registrations: they would simply have to re-order their registration statements to adopt the API proposed in this RFC.</p>
<h3 id="alternatives-allow-new-plugins-to-be-registered-after-builder-creation"><a class="header" href="#alternatives-allow-new-plugins-to-be-registered-after-builder-creation">Alternatives: allow new plugins to be registered after builder creation</a></h3>
<p>The new design prohibits the following invocation style:</p>
<pre><code class="language-rust ignore">let plugin = ColorPlugin::new();
PokemonService::builder(plugin)
    // [...]
    .get_pokemon_species(get_pokemon_species)
    // Add PrintPlugin
    .print()
    .get_storage(get_storage)
    .build()</code></pre>
<p>We could choose to remove this limitation and allow handlers to be upgraded using a different set of plugins depending on where they were registered.
In the snippet above, for example, we would have:</p>
<ul>
<li><code>get_pokemon_species</code> is upgraded using just the <code>ColorPlugin</code>;</li>
<li><code>get_storage</code> is upgraded using both the <code>ColorPlugin</code> and the <code>PrintPlugin</code>.</li>
</ul>
<p>There are no technical obstacles preventing us from implementing this API, but I believe it could easily lead to confusion and runtime surprises due to a mismatch between what the developer might expect <code>PrintPlugin</code> to apply to (all handlers) and what it actually applies to (handlers registered after <code>.print()</code>).</p>
<p>We can provide developers with other mechanisms to register plugins for a single operation or a subset of operations without introducing ambiguity.
For attaching additional plugins to a single operation, we could introduce a blanket <code>Pluggable</code> implementation for all operations in <code>aws-smithy-http-server</code>:</p>
<pre><code class="language-rust ignore">impl&lt;P, Op, Pl, S, L&gt; Pluggable&lt;Pl&gt; for Operation&lt;S, L&gt; where Pl: Plugin&lt;P, Op, S, L&gt; {
    type Output = Operation&lt;Pl::Service, Pl::Layer&gt;;

    fn apply(self, new_plugin: Pl) -&gt; Self::Output {
       new_plugin.map(self)
   }
}</code></pre>
<p>which would allow developers to invoke <code>op.apply(MyPlugin)</code> or call extensions methods such as <code>op.print()</code> where <code>op</code> is an <code>Operation</code>.
For attaching additional plugins to a subgroup of operations, instead, we could introduce nested builders:</p>
<pre><code class="language-rust ignore">let initial_plugins = ColorPlugin;
let mut builder = PokemonService::builder(initial_plugins)
    .get_pokemon_species(get_pokemon_species);
let additional_plugins = PrintPlugin;
// PrintPlugin will be applied to all handlers registered on the scoped builder returned by `scope`.
let nested_builder = builder.scoped(additional_plugins)
    .get_storage(get_storage)
    .capture_pokemon(capture_pokemon)
    // Register all the routes on the scoped builder with the parent builder.
    // API names are definitely provisional and bikesheddable.
    .attach(builder);
let app = builder.build();</code></pre>
<p>Both proposals are outside the scope of this RFC, but they are shown here for illustrative purposes.</p>
<h3 id="alternatives-lazy-and-eager-on-demand-type-erasure"><a class="header" href="#alternatives-lazy-and-eager-on-demand-type-erasure">Alternatives: lazy and eager-on-demand type erasure</a></h3>
<p>A lot of our issues stem from type mismatch errors: we are encoding the type of our handlers into the overall type of the service builder and, as a consequence, we end up modifying that type every time we set a handler or modify its state.
Type erasure is a common approach for mitigating these issues - reduce those generic parameters to a common type to avoid the mismatch errors.
This whole RFC can be seen as a type erasure proposal - done eagerly, as soon as the handler is registered, using <code>Option&lt;Route&lt;B&gt;&gt;</code> as our "common type" after erasure.</p>
<p>We could try to strike a different balance - i.e. avoid performing type erasure eagerly, but allow developers to erase types on demand.
Based on my analysis, this could happen in two ways:</p>
<ol>
<li>We cast handlers into a <code>Box&lt;dyn Upgradable&lt;Protocol, Operation, Exts, Body, Plugin&gt;&gt;</code> to which we can later apply plugins (lazy type erasure);</li>
<li>We upgrade registered handlers to <code>Route&lt;B&gt;</code> and apply plugins in the process (eager type erasure on-demand).</li>
</ol>
<p>Let's ignore these implementation issues for the time being to focus on what the ergonomics would look like assuming we can actually perform type erasure.
In practice, we are going to assume that:</p>
<ul>
<li>In approach 1), we can call <code>.boxed()</code> on a registered operation and get a <code>Box&lt;dyn Upgradable&gt;</code> back;</li>
<li>In approach 2), we can call <code>.erase()</code> on the entire service builder and convert all registered operations to <code>Route&lt;B&gt;</code> while keeping the <code>MissingOperation</code> entries as they are. After <code>erase</code> has been called, you can no longer register plugins (or, alternatively, the plugins you register will only apply new handlers).</li>
</ul>
<p>We are going to explore both approaches under the assumption that we want to preserve compile-time verification for missing handlers. If we are willing to abandon compile-time verification, we get better ergonomics since all <code>OpX</code> and <code>ExtsX</code> generic parameters can be erased (i.e. we no longer need to worry about <code>MissingOperation</code>).</p>
<h4 id="on-boxdyn-upgradableprotocol-operation-exts-body-plugin"><a class="header" href="#on-boxdyn-upgradableprotocol-operation-exts-body-plugin">On <code>Box&lt;dyn Upgradable&lt;Protocol, Operation, Exts, Body, Plugin&gt;&gt;</code></a></h4>
<p>This is the current definition of the <code>Upgradable</code> trait:</p>
<pre><code class="language-rust ignore">/// Provides an interface to convert a representation of an operation to a HTTP [`Service`](tower::Service) with
/// canonical associated types.
pub trait Upgradable&lt;Protocol, Operation, Exts, Body, Plugin&gt; {
    type Service: Service&lt;http::Request&lt;Body&gt;, Response = http::Response&lt;BoxBody&gt;&gt;;

    /// Performs an upgrade from a representation of an operation to a HTTP [`Service`](tower::Service).
    fn upgrade(self, plugin: &amp;Plugin) -&gt; Self::Service;
}</code></pre>
<p>In order to perform type erasure, we need to determine:</p>
<ul>
<li>what type parameters we are going to pass as generic arguments to <code>Upgradable</code>;</li>
<li>what type we are going to use for the associated type <code>Service</code>.</li>
</ul>
<p>We have:</p>
<ul>
<li>there is a single known protocol for a service, therefore we can set <code>Protocol</code> to its concrete type (e.g. <code>AwsRestJson1</code>);</li>
<li>each handler refers to a different operation, therefore we cannot erase the <code>Operation</code> and the <code>Exts</code> parameters;</li>
<li>both <code>Body</code> and <code>Plugin</code> appear as generic parameters on the service builder itself, therefore we can set them to the same type;</li>
<li>we can use <code>Route&lt;B&gt;</code> to normalize the <code>Service</code> associated type.</li>
</ul>
<p>The above leaves us with two unconstrained type parameters, <code>Operation</code> and <code>Exts</code>, for each operation. Those unconstrained type parameters leak into the type signature of the service builder itself. We therefore find ourselves having, again, 2N+2 type parameters.</p>
<h4 id="branching"><a class="header" href="#branching">Branching</a></h4>
<p>Going back to the branching example:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let builder = if check_database {
    builder.check_health(check_health)
} else {
    builder.check_health(check_health_with_database)
};
let app = builder.build();</code></pre>
<p>In approach 1), we could leverage the <code>.boxed()</code> method to convert the actual <code>OpX</code> type into a <code>Box&lt;dyn Upgradable&gt;</code>, thus ensuring that both branches return the same type:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let builder = if check_database {
    builder.check_health_operation(Operation::from_handler(check_health).boxed())
} else {
    builder.check_health_operation(Operation::from_handler(check_health_with_database).boxed())
};
let app = builder.build();</code></pre>
<p>The same cannot be done when conditionally registering a route, because on the <code>else</code> branch we cannot convert <code>MissingOperation</code> into a <code>Box&lt;dyn Upgradable&gt;</code> since <code>MissingOperation</code> doesn't implement <code>Upgradable</code> - the pillar on which we built all our compile-time safety story.</p>
<pre><code class="language-rust ignore">// This won't compile!
let builder = if check_database {
    builder.check_health_operation(Operation::from_handler(check_health).boxed())
} else {
    builder
};</code></pre>
<p>In approach 2), we can erase the whole builder in both branches when they both register a route:</p>
<pre><code class="language-rust ignore">let check_database: bool = /* */;
let boxed_builder = if check_database {
    builder.check_health(check_health).erase()
} else {
    builder.check_health(check_health_with_database).erase()
};
let app = boxed_builder.build();</code></pre>
<p>but, like in approach 1), we will still get a type mismatch error if one of the two branches leaves the route unset.</p>
<h4 id="refactoring-into-smaller-functions"><a class="header" href="#refactoring-into-smaller-functions">Refactoring into smaller functions</a></h4>
<p>Developers would still have to spell out all generic parameters when writing a function that takes in a builder as a parameter:</p>
<pre><code class="language-rust ignore">fn partial_setup&lt;Op1, Op2, Op3, Op4, Op5, Op6, Body, Plugin&gt;(
    builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6, Body, Plugin&gt;,
) -&gt; PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6, Body, Plugin&gt; {
    builder
}</code></pre>
<p>Writing the signature after having modified the builder becomes easier though.
In approach 1), they can explicitly change the touched operation parameters to the boxed variant:</p>
<pre><code class="language-rust ignore">fn partial_setup&lt;Op1, Op2, Op3, Op4, Op5, Op6, Exts4, Body, Plugin&gt;(
    builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6, Body, Plugin, Exts4=Exts4&gt;,
) -&gt; PokemonServiceBuilder&lt;
        Op1, Op2, Op3, Box&lt;dyn Upgradable&lt;AwsRestJson1, GetServerStatistics, Exts4, Body, Plugin&gt;&gt;,
        Op5, Op6, Body, Plugin, Body, Plugin, Exts4=Exts
    &gt; {
    builder.get_server_statistics(get_server_statistics)
}</code></pre>
<p>It becomes trickier in approach 2), since to retain compile-time safety on the builder we expect <code>erase</code> to map <code>MissingOperation</code> into <code>MissingOperation</code>. Therefore, we can't write something like this:</p>
<pre><code class="language-rust ignore">fn partial_setup&lt;Body, Op1, Op2, Op3, Op4, Op5, Op6&gt;(
    builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;,
) -&gt; PokemonServiceBuilder&lt;Route&lt;B&gt;, Route&lt;B&gt;, Route&lt;B&gt;, Route&lt;B&gt;, Route&lt;B&gt;, Route&lt;B&gt;&gt; {
    builder.get_server_statistics(get_server_statistics).()
}</code></pre>
<p>The compiler would reject it since it can't guarantee that all other operations can be erased to a <code>Route&lt;B&gt;</code>. This is likely to require something along the lines of:</p>
<pre><code class="language-rust ignore">fn partial_setup&lt;Body, Op1, Op2, Op3, Op4, Op5, Op6&gt;(
    builder: PokemonServiceBuilder&lt;Op1, Op2, Op3, Op4, Op5, Op6&gt;,
) -&gt; PokemonServiceBuilder&lt;&lt;Op1 as TypeErase&gt;::Erased, &lt;Op2 as TypeErase&gt;::Erased, &lt;Op3 as TypeErase&gt;::Erased, &lt;Op4 as TypeErase&gt;::Erased, &lt;Op5 as TypeErase&gt;::Erased, &lt;Op6 as TypeErase&gt;::Erased&gt;
where
    // Omitting a bunch of likely needed additional generic parameters and bounds here
    Op1: TypeErase,
    Op2: TypeErase,
    Op3: TypeErase,
    Op4: TypeErase,
    Op5: TypeErase,
    Op6: TypeErase,
{
    builder.get_server_statistics(get_server_statistics).()
}</code></pre>
<h4 id="summary-2"><a class="header" href="#summary-2">Summary</a></h4>
<p>Both approaches force us to have a number of generic parameters that scales linearly with the number of operations on the service, affecting the ergonomics of the resulting API in both the branching and the refactoring scenarios.
We believe that the ergonomics advantages of the proposal advanced by this RFC outweigh the limitation of having to specify your plugins upfront, when creating the builder instance.</p>
<h3 id="builder-extensions-what-now"><a class="header" href="#builder-extensions-what-now">Builder extensions: what now?</a></h3>
<p>The <code>Pluggable</code> trait was an interesting development out of <a href="rfcs/rfc0020_service_builder.html">RFC 20</a>: it allows you to attach methods to a service builder using an extension trait.</p>
<pre><code class="language-rust ignore">/// An extension to service builders to add the `print()` function.
pub trait PrintExt: aws_smithy_http_server::plugin::Pluggable&lt;PrintPlugin&gt; {
    /// Causes all operations to print the operation name when called.
    ///
    /// This works by applying the [`PrintPlugin`].
    fn print(self) -&gt; Self::Output
        where
            Self: Sized,
    {
        self.apply(PrintPlugin)
    }
}</code></pre>
<p>This pattern needs to be revisited if we want to move forward with this RFC, since new plugins cannot be registered after the builder has been instantiated.
My recommendation would be to implement <code>Pluggable</code> for <code>PluginStack</code>, providing the same pattern ahead of the creation of the builder:</p>
<pre><code class="language-rust ignore">// Currently you'd have to go for `PluginStack::new(IdentityPlugin, IdentityPlugin)`,
// but that can be smoothed out even if this RFC isn't approved.
let plugin_stack = PluginStack::default()
    // Use the extension method
    .print();
let app = PokemonService::builder(plugin_stack)
    .get_pokemon_species(get_pokemon_species)
    .get_storage(get_storage)
    .get_server_statistics(get_server_statistics)
    .capture_pokemon(capture_pokemon)
    .do_nothing(do_nothing)
    .build()?;</code></pre>
<h2 id="playing-around-with-the-design"><a class="header" href="#playing-around-with-the-design">Playing around with the design</a></h2>
<p>The API proposed in this RFC has been manually implemented for the Pokemon service. You can find the code <a href="https://github.com/LukeMathWalker/builder-experiments">here</a>.</p>
<h2 id="changes-checklist-17"><a class="header" href="#changes-checklist-17">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>codegen-server</code> to generate the proposed service builder API
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1954">https://github.com/smithy-lang/smithy-rs/pull/1954</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>Pluggable</code> for <code>PluginStack</code>
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1954">https://github.com/smithy-lang/smithy-rs/pull/1954</a></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Evaluate the introduction of a <code>PluginBuilder</code> as the primary API to compose multiple plugins (instead of <code>PluginStack::new(IdentityPlugin, IdentityPlugin).apply(...)</code>)
<ul>
<li><a href="https://github.com/smithy-lang/smithy-rs/pull/1971">https://github.com/smithy-lang/smithy-rs/pull/1971</a></li>
</ul>
</li>
</ul>
<div class="footnote-definition" id="further-dev-productivity-improvements"><sup class="footnote-definition-label">1</sup>
<p>The impact of a runtime error on developer productivity can be further minimised by encouraging adoption of integration testing; this can be achieved, among other options, by authoring guides that highlight its benefits and provide implementation guidance.</p>
</div>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-requestid-in-business-logic-handlers"><a class="header" href="#rfc-requestid-in-business-logic-handlers">RFC: RequestID in business logic handlers</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: server</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0024_request_id.html#changes-checklist">Changes Checklist</a> section.</p>
<h2 id="terminology-13"><a class="header" href="#terminology-13">Terminology</a></h2>
<ul>
<li><strong>RequestID</strong>: a service-wide request's unique identifier</li>
<li><strong>UUID</strong>: a universally unique identifier</li>
</ul>
<p>RequestID is an element that uniquely identifies a client request. RequestID is used by services to map all logs, events and
specific data to a single operation. This RFC discusses whether and how smithy-rs can make that value available to customers.</p>
<p>Services use a RequestID to collect logs related to the same request and see its flow through the various operations,
help clients debug requests by sharing this value and, in some cases, use this value to perform their business logic. RequestID is unique across a service at least within a certain timeframe.</p>
<p>This value for the purposes above must be set by the service.</p>
<p>Having the client send the value brings the following challenges:</p>
<ul>
<li>The client could repeatedly send the same RequestID</li>
<li>The client could send no RequestID</li>
<li>The client could send a malformed or malicious RequestID (like in <a href="https://en.wikipedia.org/wiki/Shellshock_(software_bug)">1</a> and
<a href="https://cwiki.apache.org/confluence/display/WW/S2-045">2</a>).</li>
</ul>
<p>To minimise the attack surface and provide a uniform experience to customers, servers should generate the value.
However, services should be free to read the ID sent by clients in HTTP headers: it is common for services to
read the request ID a client sends, record it and send it back upon success. A client may want to send the same value to multiple services.
Services should still decide to have their own unique request ID per actual call.</p>
<p>RequestIDs are not to be used by multiple services, but only within a single service.</p>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented-1"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-1">The user experience if this RFC is implemented</a></h2>
<p>The proposal is to implement a <code>RequestId</code> type and make it available to middleware and business logic handlers, through <a href="rfcs/../server/from_parts.html">FromParts</a> and as a <code>Service</code>.
To aid customers already relying on clients' request IDs, there will be two types: <code>ClientRequestId</code> and <code>ServerRequestId</code>.</p>
<ol>
<li>Implementing <code>FromParts</code> for <code>Extension&lt;RequestId&gt;</code> gives customers the ability to write their handlers:</li>
</ol>
<pre><code class="language-rust ignore">pub async fn handler(
    input: input::Input,
    request_id: Extension&lt;ServerRequestId&gt;,
) -&gt; ...</code></pre>
<pre><code class="language-rust ignore">pub async fn handler(
    input: input::Input,
    request_id: Extension&lt;ClientRequestId&gt;,
) -&gt; ...</code></pre>
<p><code>ServerRequestId</code> and <code>ClientRequestId</code> will be injected into the extensions by a layer.
This layer can also be used to open a span that will log the request ID: subsequent logs will be in the scope of that span.</p>
<ol start="2">
<li>ServerRequestId format:</li>
</ol>
<p>Common formats for RequestIDs are:</p>
<ul>
<li>UUID: a random string, represented in hex, of 128 bits from IETF RFC 4122: <code>7c038a43-e499-4162-8e70-2d4d38595930</code></li>
<li>The hash of a sequence such as <code>date+thread+server</code>: <code>734678902ea938783a7200d7b2c0b487</code></li>
<li>A verbose description: <code>current_ms+hostname+increasing_id</code></li>
</ul>
<p>For privacy reasons, any format that provides service details should be avoided. A random string is preferred.
The proposed format is to use UUID, version 4.</p>
<p>A <code>Service</code> that inserts a RequestId in the extensions will be implemented as follows:</p>
<pre><code class="language-rust ignore">impl&lt;R, S&gt; Service&lt;http::Request&lt;R&gt;&gt; for ServerRequestIdProvider&lt;S&gt;
where
    S: Service&lt;http::Request&lt;R&gt;&gt;,
{
    type Response = S::Response;
    type Error = S::Error;
    type Future = S::Future;

    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        self.inner.poll_ready(cx)
    }

    fn call(&amp;mut self, mut req: http::Request&lt;R&gt;) -&gt; Self::Future {
        req.extensions_mut().insert(ServerRequestId::new());
        self.inner.call(req)
    }
}</code></pre>
<p>For client request IDs, the process will be, in order:</p>
<ul>
<li>If a header is found matching one of the possible ones, use it</li>
<li>Otherwise, None</li>
</ul>
<p><code>Option</code> is used to distinguish whether a client had provided an ID or not.</p>
<pre><code class="language-rust ignore">impl&lt;R, S&gt; Service&lt;http::Request&lt;R&gt;&gt; for ClientRequestIdProvider&lt;S&gt;
where
    S: Service&lt;http::Request&lt;R&gt;&gt;,
{
    type Response = S::Response;
    type Error = S::Error;
    type Future = S::Future;

    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        self.inner.poll_ready(cx)
    }

    fn call(&amp;mut self, mut req: http::Request&lt;R&gt;) -&gt; Self::Future {
        for possible_header in self.possible_headers {
            if let Some(id) = req.headers.get(possible_header) {
                req.extensions_mut().insert(Some(ClientRequestId::new(id)));
                return self.inner.call(req)
            }
        }
        req.extensions_mut().insert(None);
        self.inner.call(req)
    }
}</code></pre>
<p>The string representation of a generated ID will be valid for this regex:</p>
<ul>
<li>For <code>ServerRequestId</code>: <code>/^[A-Za-z0-9_-]{,48}$/</code></li>
<li>For <code>ClientRequestId</code>: see <a href="https://httpwg.org/specs/rfc9110.html#rfc.section.5.5">the spec</a></li>
</ul>
<p>Although the generated ID is opaque, this will give guarantees to customers as to what they can expect, if the server ID is ever updated to a different format.</p>
<h2 id="changes-checklist-18"><a class="header" href="#changes-checklist-18">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>ServerRequestId</code>: a <code>new()</code> function that generates a UUID, with <code>Display</code>, <code>Debug</code> and <code>ToStr</code> implementations</li>
<li><input disabled="" type="checkbox"/>
Implement <code>ClientRequestId</code>: <code>new()</code> that wraps a string (the header value) and the header in which the value could be found, with <code>Display</code>, <code>Debug</code> and <code>ToStr</code> implementations</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>FromParts</code> for <code>Extension&lt;ServerRequestId&gt;</code></li>
<li><input disabled="" type="checkbox"/>
Implement <code>FromParts</code> for <code>Extension&lt;ClientRequestId&gt;</code></li>
</ul>
<h2 id="changes-since-the-rfc-has-been-approved"><a class="header" href="#changes-since-the-rfc-has-been-approved">Changes since the RFC has been approved</a></h2>
<p>This RFC has been changed to only implement <code>ServerRequestId</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-constraint-traits"><a class="header" href="#rfc-constraint-traits">RFC: Constraint traits</a></h1>
<blockquote>
<p>Status: Implemented.</p>
<p>See the description of <a href="https://github.com/smithy-lang/smithy-rs/pull/1342">the PR</a> that laid the
foundation for the implementation of constraint traits for a complete
reference. See the <a href="https://github.com/smithy-lang/smithy-rs/pull/2040">Better Constraint Violations</a> RFC too for subsequent
improvements to this design.</p>
<p>See the uber <a href="https://github.com/smithy-lang/smithy-rs/issues/1401">tracking issue</a> for pending work.</p>
</blockquote>
<p><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html">Constraint traits</a> are used to constrain the values that can be provided for a
shape.</p>
<p>For example, given the following Smithy model,</p>
<pre><code class="language-smithy">@length(min: 18)
Integer Age
</code></pre>
<p>the integer <code>Age</code> must take values greater than or equal to 18.</p>
<p>Constraint traits are most useful when enforced as part of <em>input</em> model
validation to a service. When a server receives a request whose contents
deserialize to input data that violates the modeled constraints, the operation
execution's preconditions are not met, and as such rejecting the request
without executing the operation is expected behavior.</p>
<p>Constraint traits can also be applied to operation output member shapes, but
the expectation is that service implementations <em>not fail</em> to render a response
when an output value does not meet the specified constraints. From
<a href="https://github.com/awslabs/smithy/issues/1039">awslabs/smithy#1039</a>:</p>
<blockquote>
<p>This might seem counterintuitive, but our philosophy is that a change in
server-side state should not be hidden from the caller unless absolutely
necessary. Refusing to service an invalid request should always prevent
server-side state changes, but refusing to send a response will not, as
there's generally no reasonable route for a server implementation to unwind
state changes due to a response serialization failure.</p>
</blockquote>
<p><em>In general</em>, clients should not enforce constraint traits in generated code.
Clients must also never enforce constraint traits when sending requests. This
is because:</p>
<ul>
<li>addition and removal of constraint traits are backwards-compatible from a
client's perspective (although this is <em>not</em> documented anywhere in the
Smithy specification),</li>
<li>the client may have been generated with an older version of the model; and</li>
<li>the most recent model version might have lifted some constraints.</li>
</ul>
<p>On the other hand, server SDKs constitute <em>the</em> source of truth for the
service's behavior, so they interpret the model in all its strictness.</p>
<p>The Smithy spec defines 8 constraint traits:</p>
<ul>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#enum-trait"><code>enum</code></a>,</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#idref-trait"><code>idRef</code></a>,</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#length-trait"><code>length</code></a>,</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#pattern-trait"><code>pattern</code></a>,</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#private-trait"><code>private</code></a>,</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#range-trait"><code>range</code></a>,</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#required-trait"><code>required</code></a>; and</li>
<li><a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#uniqueItems-trait"><code>uniqueItems</code></a>.</li>
</ul>
<p>The <code>idRef</code> and <code>private</code> traits are enforced at SDK generation time by the
<a href="https://github.com/awslabs/smithy"><code>awslabs/smithy</code></a> libraries and bear no relation to generated Rust code.</p>
<p>The only constraint trait enforcement that is generated by smithy-rs clients
should be and is the <code>enum</code> trait, which renders Rust <code>enum</code>s.</p>
<p>The <code>required</code> trait is already and only enforced by smithy-rs servers since
<a href="https://github.com/smithy-lang/smithy-rs/pull/1148">#1148</a>.</p>
<p>That leaves 4 traits: <code>length</code>, <code>pattern</code>, <code>range</code>, and <code>uniqueItems</code>.</p>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>This section addresses how to implement and enforce the <code>length</code>, <code>pattern</code>,
<code>range</code>, and <code>uniqueItems</code> traits. We will use the <code>length</code> trait applied to a
<code>string</code> shape as a running example. The implementation of this trait mostly
carries over to the other three.</p>
<h3 id="example-implementation-for-the-length-trait"><a class="header" href="#example-implementation-for-the-length-trait">Example implementation for the <code>length</code> trait</a></h3>
<p>Consider the following Smithy model:</p>
<pre><code class="language-smithy">@length(min: 1, max: 69)
string NiceString
</code></pre>
<p>The central idea to the implementation of constraint traits is: <a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">parse, don't
validate</a>. Instead of code-generating a Rust <code>String</code> to represent <code>NiceString</code>
values and perform the <em>validation</em> at request deserialization, we can
<a href="https://www.lpalmieri.com/posts/2020-12-11-zero-to-production-6-domain-modelling/">leverage Rust's type system to guarantee domain invariants</a>. We can generate a
wrapper <a href="https://doc.rust-lang.org/1.9.0/book/structs.html#tuple-structs">tuple struct</a> that <em>parses</em> the string's value and is "tight" in the
set of values it can accept:</p>
<pre><code class="language-rust ignore">pub struct NiceString(String);

impl TryFrom&lt;String&gt; for NiceString {
    type Error = nice_string::ConstraintViolation;

    fn try_from(value: String) -&gt; Result&lt;Self, Self::Error&gt; {
        let num_code_points = value.chars().count();
        if 1 &lt;= num_code_points &amp;&amp; num_code_points &lt;= 69 {
            Ok(Self(value))
        } else {
            Err(nice_string::ConstraintViolation::Length(num_code_points))
        }
    }
}</code></pre>
<p>(Note that we're using the <em>linear</em> time check <code>chars().count()</code> instead of
<code>len()</code> on the input value, since the Smithy specification says the <code>length</code>
trait counts <a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#length-trait">the number of <em>Unicode code points</em> when applied to string
shapes</a>.)</p>
<p>The goal is to enforce, at the type-system level, that these constrained
structs always hold valid data. It should be impossible for the service
implementer, without resorting to <code>unsafe</code> Rust, to construct a <code>NiceString</code>
that violates the model. The actual check is performed in the implementation of
<a href="https://doc.rust-lang.org/std/convert/trait.TryFrom.html"><code>TryFrom</code></a><code>&lt;InnerType&gt;</code> for the generated struct, which makes it convenient to use
the <a href="https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html#a-shortcut-for-propagating-errors-the--operator"><code>?</code> operator for error propagation</a>. Each constrained struct will have a
related <code>std::error::Error</code> enum type to signal the <em>first</em> parsing failure,
with one enum variant per applied constraint trait:</p>
<pre><code class="language-rust ignore">pub mod nice_string {
    pub enum ConstraintViolation {
        /// Validation error holding the number of Unicode code points found, when a value between `1` and
        /// `69` (inclusive) was expected.
        Length(usize),
    }

    impl std::error::Error for ConstraintViolation {}
}</code></pre>
<p><a href="https://doc.rust-lang.org/nightly/std/error/trait.Error.html"><code>std::error::Error</code></a> requires <a href="https://doc.rust-lang.org/std/fmt/trait.Display.html"><code>Display</code></a> and <a href="https://doc.rust-lang.org/std/fmt/trait.Debug.html"><code>Debug</code></a>. We will
<code>#[derive(Debug)]</code>, unless the shape also has the <a href="https://awslabs.github.io/smithy/1.0/spec/core/documentation-traits.html#sensitive-trait"><code>sensitive</code> trait</a>, in which
case we will just print the name of the struct:</p>
<pre><code class="language-rust ignore">impl std::fmt::Debug for ConstraintViolation {
    fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) -&gt; std::fmt::Result {
        let mut formatter = f.debug_struct("ConstraintViolation");
        formatter.finish()
    }
}</code></pre>
<p><code>Display</code> is used to produce human-friendlier representations. Its
implementation might be called when formatting a <a href="https://developer.mozilla.org/en-US/docs/web/http/status/400">400 HTTP response message</a> in
certain protocols, for example.</p>
<h3 id="request-deserialization"><a class="header" href="#request-deserialization">Request deserialization</a></h3>
<p>We will continue to deserialize the different parts of the HTTP message into
the regular Rust standard library types. However, just before the
deserialization function returns, we will convert the type into the wrapper
tuple struct that will eventually be handed over to the operation handler. This
is what we're <em>already</em> doing when deserializing strings into <code>enums</code>. For
example, given the Smithy model:</p>
<pre><code class="language-smithy">@enum([
    { name: "Spanish", value: "es" },
    { name: "English", value: "en" },
    { name: "Japanese", value: "jp" },
])
string Language
</code></pre>
<p>the code the client generates when deserializing a string from a JSON document
into the <code>Language</code> enum is (excerpt):</p>
<pre><code class="language-rust ignore">...
match key.to_unescaped()?.as_ref() {
    "language" =&gt; {
        builder = builder.set_language(
            aws_smithy_json::deserialize::token::expect_string_or_null(
                tokens.next(),
            )?
            .map(|s| {
                s.to_unescaped()
                    .map(|u| crate::model::Language::from(u.as_ref()))
            })
            .transpose()?,
        );
    }
    _ =&gt; aws_smithy_json::deserialize::token::skip_value(tokens)?,
}
...</code></pre>
<p>Note how the <code>String</code> gets converted to the enum via <code>Language::from()</code>.</p>
<pre><code class="language-rust ignore">impl std::convert::From&lt;&amp;str&gt; for Language {
    fn from(s: &amp;str) -&gt; Self {
        match s {
            "es" =&gt; Language::Spanish,
            "en" =&gt; Language::English,
            "jp" =&gt; Language::Japanese,
            other =&gt; Language::Unknown(other.to_owned()),
        }
    }
}</code></pre>
<p>For constrained shapes we would do the same to parse the inner deserialized
value into the wrapper tuple struct, except for these differences:</p>
<ol>
<li>For enums, the client generates an <code>Unknown</code> variant that "contains new
variants that have been added since this code was generated". The server
does not need such a variant (<a href="https://github.com/smithy-lang/smithy-rs/issues/1187">#1187</a>).</li>
<li>Conversions into the tuple struct are fallible (<code>try_from()</code> instead of
<code>from()</code>). These errors will result in a <code>my_struct::ConstraintViolation</code>.</li>
</ol>
<h2 id="length-trait"><a class="header" href="#length-trait"><code>length</code> trait</a></h2>
<p>We will enforce the length constraint by calling <code>len()</code> on Rust's <code>Vec</code>
(<code>list</code> and <code>set</code> shapes), <code>HashMap</code> (<code>map</code> shapes) and our
<a href="https://docs.rs/aws-smithy-types/latest/aws_smithy_types/struct.Blob.html"><code>aws_smithy_types::Blob</code></a> (<code>bytes</code> shapes).</p>
<p>We will enforce the length constraint trait on <code>String</code> (<code>string</code> shapes) by
calling <code>.chars().count()</code>.</p>
<h2 id="pattern-trait"><a class="header" href="#pattern-trait"><code>pattern</code> trait</a></h2>
<p>The <a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#pattern-trait"><code>pattern</code> trait</a></p>
<blockquote>
<p>restricts string shape values to a specified regular expression.</p>
</blockquote>
<p>We will implement this by using the <code>regex</code>'s crate <a href="https://docs.rs/regex/latest/regex/struct.Regex.html#method.is_match"><code>is_match</code></a>. We will use
<a href="https://docs.rs/once_cell/latest/once_cell/"><code>once_cell</code></a> to compile the regex only the first time it is required.</p>
<h2 id="uniqueitems-trait"><a class="header" href="#uniqueitems-trait"><code>uniqueItems</code> trait</a></h2>
<p>The <a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html#uniqueitems-trait"><code>uniqueItems</code> trait</a></p>
<blockquote>
<p>indicates that the items in a <a href="https://awslabs.github.io/smithy/1.0/spec/core/model.html#list"><code>List</code></a> MUST be unique.</p>
</blockquote>
<p>If the list shape is <code>sparse</code>, more than one <code>null</code> value violates this
constraint.</p>
<p>We will enforce this by copying <em>references</em> to the <code>Vec</code>'s elements into a
<code>HashSet</code> and checking that the sizes of both containers coincide.</p>
<h2 id="trait-precedence-and-naming-of-the-tuple-struct"><a class="header" href="#trait-precedence-and-naming-of-the-tuple-struct">Trait precedence and naming of the tuple struct</a></h2>
<p>From <a href="https://awslabs.github.io/smithy/1.0/spec/core/constraint-traits.html?highlight=enum#trait-precedence">the spec</a>:</p>
<blockquote>
<p>Some constraints can be applied to shapes as well as structure members. If a
constraint of the same type is applied to a structure member and the shape
that the member targets, the trait applied to the member takes precedence.</p>
</blockquote>
<pre><code class="language-smithy">structure ShoppingCart {
    @range(min: 7, max:12)
    numberOfItems: PositiveInteger
}

@range(min: 1)
integer PositiveInteger
</code></pre>
<p>In the above example,</p>
<blockquote>
<p>the range trait applied to numberOfItems takes precedence over the one
applied to PositiveInteger. The resolved minimum will be 7, and the maximum
12.</p>
</blockquote>
<p>When the constraint trait is applied to a member shape, the tuple struct's name
will be the PascalCased name of the member shape, <code>NumberOfItems</code>.</p>
<h2 id="unresolved-questions"><a class="header" href="#unresolved-questions">Unresolved questions</a></h2>
<ol>
<li>Should we code-generate unsigned integer types (<code>u16</code>, <code>u32</code>, <code>u64</code>) when
the <code>range</code> trait is applied with <code>min</code> set to a value greater than or equal
to 0?
<ul>
<li>A user has even suggested to use the <code>std::num::NonZeroUX</code> types (e.g.
<a href="https://doc.rust-lang.org/std/num/struct.NonZeroU64.html"><code>NonZeroU64</code></a>) when <code>range</code> is applied with <code>min</code> set to a value greater
than 0.</li>
<li>UPDATE: This requires further design work. There are interoperability
concerns: for example, the positive range of a
<code>u32</code> is strictly greater than that of an <code>i32</code>, so clients wouldn't be
able to receive values within the non-overlapping range.</li>
</ul>
</li>
<li>In request deserialization, should we fail with the first violation and
immediately render a response, or attempt to parse the entire request and
provide a complete and structured report?
<ul>
<li>UPDATE: We will provide a response containing all violations. See the
"Collecting Constraint Violations" section in the <a href="https://github.com/smithy-lang/smithy-rs/pull/2040">Better Constraint
Violations</a> RFC.</li>
</ul>
</li>
<li>Should we provide a mechanism for the service implementer to construct a
Rust type violating the modeled constraints in their business logic e.g. a
<code>T::new_unchecked()</code> constructor? This could be useful (1) when the user
<em>knows</em> the provided inner value does not violate the constraints and
doesn't want to incur the performance penalty of the check; (2) when the
struct is in a transient invalid state. However:
<ul>
<li>(2) is arguably a modelling mistake and a separate struct to represent
the transient state would be a better approach,</li>
<li>the user could use <code>unsafe</code> Rust to bypass the validation; and</li>
<li>adding this constructor is a backwards-compatible change, so it can
always be added later if this feature is requested.</li>
<li>UPDATE: We decided to punt on this until users express interest.</li>
</ul>
</li>
</ol>
<h2 id="alternative-design"><a class="header" href="#alternative-design">Alternative design</a></h2>
<p>An alternative design with less public API surface would be to perform
constraint validation at request deserialization, but hand over a regular
"loose" type (e.g. <code>String</code> instead of <code>NiceString</code>) that allows for values
violating the constraints. If we were to implement this approach, we can
implement it by wrapping the incoming value in the aforementioned tuple struct
to perform the validation, and immediately unwrap it.</p>
<p>Comparative advantages:</p>
<ul>
<li>Validation remains an internal detail of the framework. If the semantics of a
constraint trait change, the behavior of the service is still
backwards-incompatibly affected, but user code is not.</li>
<li>Less "invasive". Baking validation in the generated type might be deemed as
the service framework overreaching responsibilities.</li>
</ul>
<p>Comparative disadvantages:</p>
<ul>
<li>It becomes <em>possible</em> to send responses with invalid operation outputs. All
the service framework could do is log the validation errors.</li>
<li>Baking validation at the type-system level gets rid of an entire class of
logic errors.</li>
<li>Less idiomatic (this is subjective). The pattern of wrapping a more primitive
type to guarantee domain invariants is widespread in the Rust ecosystem. The
standard library makes use of it extensively.</li>
</ul>
<p>Note that <em>both</em> designs are backwards incompatible in the sense that you can't
migrate from one to the other without breaking user code.</p>
<p>UPDATE: We ended up implementing both designs, adding a flag to opt into the
alternative design. Refer to the mentions of the <code>publicConstrainedTypes</code> flag
in the description of the <a href="https://github.com/smithy-lang/smithy-rs/pull/1342">Builders of builders PR</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-client-crate-organization"><a class="header" href="#rfc-client-crate-organization">RFC: Client Crate Organization</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: clients (and may impact servers due to shared codegen)</p>
</blockquote>
<p>This RFC proposes changing the organization structure of the generated client crates to:</p>
<ol>
<li>Make discovery in the crate documentation easier.</li>
<li>Facilitate re-exporting types from runtime crates in related modules without name collisions.</li>
<li>Facilitate feature gating operations for faster compile times in the future.</li>
</ol>
<h2 id="previous-organization"><a class="header" href="#previous-organization">Previous Organization</a></h2>
<p>Previously, crates were organized as such:</p>
<pre><code class="language-text">.
├── client
|   ├── fluent_builders
|   |   └── &lt;One fluent builder per operation&gt;
|   ├── Builder (*)
|   └── Client
├── config
|   ├── retry
|   |   ├── RetryConfig (*)
|   |   ├── RetryConfigBuilder (*)
|   |   └── RetryMode (*)
|   ├── timeout
|   |   ├── TimeoutConfig (*)
|   |   └── TimeoutConfigBuilder (*)
|   ├── AsyncSleep (*)
|   ├── Builder
|   ├── Config
|   └── Sleep (*)
├── error
|   ├── &lt;One module per error to contain a single struct named `Builder`&gt;
|   ├── &lt;One struct per error named `${error}`&gt;
|   ├── &lt;One struct per operation named `${operation}Error`&gt;
|   └── &lt;One enum per operation named `${operation}ErrorKind`&gt;
├── http_body_checksum (empty)
├── input
|   ├── &lt;One module per input to contain a single struct named `Builder`&gt;
|   └── &lt;One struct per input named `${operation}Input`&gt;
├── lens (empty)
├── middleware
|   └── DefaultMiddleware
├── model
|   ├── &lt;One module per shape to contain a single struct named `Builder`&gt;
|   └── &lt;One struct per shape&gt;
├── operation
|   ├── customize
|   |   ├── ClassifyRetry (*)
|   |   ├── CustomizableOperation
|   |   ├── Operation (*)
|   |   ├── RetryKind (*)
|   └── &lt;One struct per operation&gt;
├── output
|   ├── &lt;One module per output to contain a single struct named `Builder`&gt;
|   └── &lt;One struct per output named `${operation}Input`&gt;
├── paginator
|   ├── &lt;One struct per paginated operation named `${operation}Paginator`&gt;
|   └── &lt;Zero to one struct(s) per paginated operation named `${operation}PaginatorItems`&gt;
├── presigning
|   ├── config
|   |   ├── Builder
|   |   ├── Error
|   |   └── PresigningConfig
|   └── request
|       └── PresignedRequest
├── types
|   ├── AggregatedBytes (*)
|   ├── Blob (*)
|   ├── ByteStream (*)
|   ├── DateTime (*)
|   └── SdkError (*)
├── AppName (*)
├── Client
├── Config
├── Credentials (*)
├── Endpoint (*)
├── Error
├── ErrorExt (for some services)
├── PKG_VERSION
└── Region (*)
</code></pre>
<p><code>(*)</code> - signifies that a type is re-exported from one of the runtime crates</p>
<h2 id="proposed-changes"><a class="header" href="#proposed-changes">Proposed Changes</a></h2>
<p>This RFC proposes reorganizing types by operation first and foremost, and then rearranging
other pieces to reduce codegen collision risk.</p>
<h3 id="establish-a-pattern-for-builder-organization"><a class="header" href="#establish-a-pattern-for-builder-organization">Establish a pattern for builder organization</a></h3>
<p>Builders (distinct from fluent builders) are generated alongside all inputs, outputs, models, and errors.
They all follow the same overall pattern (where <code>shapeType</code> is <code>Input</code>, <code>Output</code>, or empty for models/errors):</p>
<pre><code class="language-text">.
└── module
    ├── &lt;One module per shape to contain a single struct named `Builder`&gt;
    └── &lt;One struct per shape named `${prefix}${shapeType}`&gt;
</code></pre>
<p>This results in large lists of modules that all have exactly one item in them, which makes browsing
the documentation difficult, and introduces the possibility of name collisions when re-exporting modules
from the runtime crates.</p>
<p>Builders should adopt a prefix and go into a single <code>builders</code> module, similar to how the fluent builders
currently work:</p>
<pre><code class="language-text">.
├── module
|   └── builders
|       └── &lt;One struct per shape named `${prefix}${shapeType}Builder`&gt;
└──---- &lt;One struct per shape named `${prefix}${shapeType}`&gt;
</code></pre>
<h3 id="organize-code-generated-types-by-operation"><a class="header" href="#organize-code-generated-types-by-operation">Organize code generated types by operation</a></h3>
<p>All code generated for an operation that isn't shared between operations will go into
operation-specific modules. This includes inputs, outputs, errors, parsers, and paginators.
Types shared across operations will remain in another module (discussed below), and
serialization/deserialization logic for those common types will also reside in that
common location for now. If operation feature gating occurs in the future, further
optimization can be done to track which of these are used by feature, or they can
be reorganized (this would be discussed in a future RFC and is out of scope here).</p>
<p>With code generated operations living in <code>crate::operation</code>, there is a high chance of name
collision with the <code>customize</code> module. To resolve this, <code>customize</code> will be moved into
<code>crate::client</code>.</p>
<p>The new <code>crate::operation</code> module will look as follows:</p>
<pre><code class="language-text">.
└── operation
    └── &lt;One module per operation named after the operation in lower_snake_case&gt;
        ├── paginator
        |   ├── `${operation}Paginator`
        |   └── `${operation}PaginatorItems`
        ├── builders
        |   ├── `${operation}FluentBuilder`
        |   ├── `${operation}InputBuilder`
        |   └── `${operation}OutputBuilder`
        ├── `${operation}Error`
        ├── `${operation}Input`
        ├── `${operation}Output`
        └── `${operation}Parser` (private/doc hidden)
</code></pre>
<h3 id="reorganize-the-crate-root"><a class="header" href="#reorganize-the-crate-root">Reorganize the crate root</a></h3>
<p>The crate root should only host the most frequently used types, or phrased differently,
the types that are critical to making a service call with default configuration,
or that are required for the most frequent config changes (such as setting credentials,
or changing the region/endpoint).</p>
<p>Previously, the following were exported in root:</p>
<pre><code class="language-text">.
├── AppName
├── Client
├── Config
├── Credentials
├── Endpoint
├── Error
├── ErrorExt (for some services)
├── PKG_VERSION
└── Region
</code></pre>
<p>The <code>AppName</code> is infrequently set, and will be moved into <code>crate::config</code>. Customers are encouraged
to use <code>aws-config</code> crate to resolve credentials, region, and endpoint. Thus, these types no longer
need to be at the top-level, and will be moved into <code>crate::config</code>. <code>ErrorExt</code> will be moved into
<code>crate::error</code>, but <code>Error</code> will stay in the crate root so that customers that alias the SDK crate
can easily reference it in their <code>Result</code>s:</p>
<pre><code class="language-rust ignore">use aws_sdk_s3 as s3;

fn some_function(/* ... */) -&gt; Result&lt;(), s3::Error&gt; {
    /* ... */
}</code></pre>
<p>The <code>PKG_VERSION</code> should move into a new <code>meta</code> module, which can also include other values in the future
such as the SHA-256 hash of the model used to produce the crate, or the version of smithy-rs that generated it.</p>
<h3 id="conditionally-remove-builder-from-crateclient"><a class="header" href="#conditionally-remove-builder-from-crateclient">Conditionally remove <code>Builder</code> from <code>crate::client</code></a></h3>
<p>Previously, the Smithy <code>Client</code> builder was re-exported alongside the SDK fluent <code>Client</code>
so that non-SDK clients could easily customize the underlying Smithy client by using
the fluent client's <code>Client::with_config</code> function or <code>From&lt;aws_smithy_client::client::Client&lt;C, M, R&gt;&gt;</code>
trait implementation.</p>
<p>This makes sense for non-SDK clients where customization of the connector and middleware types is supported
generically, but less sense for SDKs since the SDK clients are hardcoded to use <code>DynConnector</code> and <code>DynMiddleware</code>.</p>
<p>Thus, the Smithy client <code>Builder</code> should not be re-exported for SDKs.</p>
<h3 id="create-a-primitives-module"><a class="header" href="#create-a-primitives-module">Create a <code>primitives</code> module</a></h3>
<p>Previously, <code>crate::types</code> held re-exported types from <code>aws-smithy-types</code> that are used
by code generated structs/enums.</p>
<p>This module will be renamed to <code>crate::primitives</code> so that the name <code>types</code> can be
repurposed in the next section.</p>
<h3 id="repurpose-the-types-module"><a class="header" href="#repurpose-the-types-module">Repurpose the <code>types</code> module</a></h3>
<p>The name <code>model</code> is meaningless outside the context of code generation (although there is precedent
since both the Java V2 and Kotlin SDKs use the term). Previously, this module held all the generated
structs/enums that are referenced by inputs, outputs, and errors.</p>
<p>This RFC proposes that this module be renamed to <code>types</code>, and that all code generated types
for shapes that are reused between operations (basically anything that is not an input, output,
or error) be moved here. This would look as follows:</p>
<pre><code class="language-text">.
└── types
    ├── error
    |   ├── builders
    |   |   └── &lt;One struct per error named `${error}Builder`&gt;
    |   └── &lt;One struct per error named `${error}`&gt;
    ├── builders
    |   └── &lt;One struct per shape named `${shape}Builder`&gt;
    └── &lt;One struct per shape&gt;
</code></pre>
<p>Customers using the fluent builder should be able to just <code>use ${crate}::types::*;</code> to immediately
get access to all the shared types needed by the operations they are calling.</p>
<p>Additionally, moving the top-level code generated error types into <code>crate::types</code> will eliminate a name
collision issue in the <code>crate::error</code> module.</p>
<h3 id="repurpose-the-original-crateerror-module"><a class="header" href="#repurpose-the-original-crateerror-module">Repurpose the original <code>crate::error</code> module</a></h3>
<p>The <code>error</code> module is significantly smaller after all the code generated error types
are moved out of it. This top-level module is now available for re-exports and utilities.</p>
<p>The following will be re-exported in <code>crate::error</code>:</p>
<ul>
<li><code>aws_smithy_http::result::SdkError</code></li>
<li><code>aws_smithy_types::error::display::DisplayErrorContext</code></li>
</ul>
<p>For crates that have an <code>ErrorExt</code>, it will also be moved into <code>crate::error</code>.</p>
<h3 id="flatten-the-presigning-module"><a class="header" href="#flatten-the-presigning-module">Flatten the <code>presigning</code> module</a></h3>
<p>The <code>crate::presigning</code> module only has four members, so it should be flattened from:</p>
<pre><code class="language-text">.
└── presigning
    ├── config
    |   ├── Builder
    |   ├── Error
    |   └── PresigningConfig
    └── request
        └── PresignedRequest
</code></pre>
<p>to:</p>
<pre><code class="language-text">.
└── presigning
    ├── PresigningConfigBuilder
    ├── PresigningConfigError
    ├── PresigningConfig
    └── PresignedRequest
</code></pre>
<p>At the same time, <code>Builder</code> and <code>Error</code> will be renamed to <code>PresigningConfigBuilder</code> and <code>PresigningConfigError</code>
respectively since these will rarely be referred to directly (preferring <code>PresigningConfig::builder()</code> instead; the
error will almost always be unwrapped).</p>
<h3 id="remove-the-empty-modules"><a class="header" href="#remove-the-empty-modules">Remove the empty modules</a></h3>
<p>The <code>lens</code> and <code>http_body_checksum</code> modules have nothing inside them,
and their documentation descriptions are not useful to customers:</p>
<blockquote>
<p><code>lens</code>: Generated accessors for nested fields</p>
</blockquote>
<blockquote>
<p><code>http_body_checksum</code>: Functions for modifying requests and responses for the purposes of checksum validation</p>
</blockquote>
<p>These modules hold private functions that are used by other generated code, and should just be made
private or <code>#[doc(hidden)]</code> if necessary.</p>
<h2 id="new-organization"><a class="header" href="#new-organization">New Organization</a></h2>
<p>All combined, the following is the new publicly visible organization:</p>
<pre><code class="language-text">.
├── client
|   ├── customize
|   |   ├── ClassifyRetry (*)
|   |   ├── CustomizableOperation
|   |   ├── Operation (*)
|   |   └── RetryKind (*)
|   ├── Builder (only in non-SDK crates) (*)
|   └── Client
├── config
|   ├── retry
|   |   ├── RetryConfig (*)
|   |   ├── RetryConfigBuilder (*)
|   |   └── RetryMode (*)
|   ├── timeout
|   |   ├── TimeoutConfig (*)
|   |   └── TimeoutConfigBuilder (*)
|   ├── AppName (*)
|   ├── AsyncSleep (*)
|   ├── Builder
|   ├── Config
|   ├── Credentials (*)
|   ├── Endpoint (*)
|   ├── Region (*)
|   └── Sleep (*)
├── error
|   ├── DisplayErrorContext (*)
|   ├── ErrorExt (for some services)
|   └── SdkError (*)
├── meta
|   └── PKG_VERSION
├── middleware
|   └── DefaultMiddleware
├── operation
|   └── &lt;One module per operation named after the operation in lower_snake_case&gt;
|       ├── paginator
|       |   ├── `${operation}Paginator`
|       |   └── `${operation}PaginatorItems`
|       ├── builders
|       |   ├── `${operation}FluentBuilder`
|       |   ├── `${operation}InputBuilder`
|       |   └── `${operation}OutputBuilder`
|       ├── `${operation}Error`
|       ├── `${operation}Input`
|       ├── `${operation}Output`
|       └── `${operation}Parser` (private/doc hidden)
├── presigning
|   ├── PresigningConfigBuilder
|   ├── PresigningConfigError
|   ├── PresigningConfig
|   └── PresignedRequest
├── primitives
|   ├── AggregatedBytes (*)
|   ├── Blob (*)
|   ├── ByteStream (*)
|   └── DateTime (*)
├── types
|   ├── error
|   |   ├── builders
|   |   |   └── &lt;One struct per error named `${error}Builder`&gt;
|   |   └── &lt;One struct per error named `${error}`&gt;
|   ├── builders
|   |   └── &lt;One struct per shape named `${shape}Builder`&gt;
|   └── &lt;One struct per shape&gt;
├── Client
├── Config
└── Error
</code></pre>
<p><code>(*)</code> - signifies that a type is re-exported from one of the runtime crates</p>
<h2 id="changes-checklist-19"><a class="header" href="#changes-checklist-19">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::AppName</code> into <code>crate::config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::PKG_VERSION</code> into a new <code>crate::meta</code> module</li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::Endpoint</code> into <code>crate::config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::Credentials</code> into <code>crate::config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::Region</code> into <code>crate::config</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::operation::customize</code> into <code>crate::client</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Finish refactor to decouple client/server modules</li>
<li><input disabled="" type="checkbox" checked=""/>
Organize code generated types by operation</li>
<li><input disabled="" type="checkbox" checked=""/>
Reorganize builders</li>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>crate::types</code> to <code>crate::primitives</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>crate::model</code> to <code>crate::types</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::error</code> into <code>crate::types</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Only re-export <code>aws_smithy_client::client::Builder</code> for non-SDK clients (remove from SDK clients)</li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::ErrorExt</code> into <code>crate::error</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Re-export <code>aws_smithy_types::error::display::DisplayErrorContext</code> and <code>aws_smithy_http::result::SdkError</code> in <code>crate::error</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move <code>crate::paginator</code> into <code>crate::operation</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Flatten <code>crate::presigning</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Hide or remove <code>crate::lens</code> and <code>crate::http_body_checksum</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Move fluent builders into <code>crate::operation::x::builders</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Remove/hide operation <code>ParseResponse</code> implementations in <code>crate::operation</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Update "Crate Organization" top-level section in generated crate docs</li>
<li><input disabled="" type="checkbox" checked=""/>
Update all module docs</li>
<li><input disabled="" type="checkbox" checked=""/>
Break up modules/files so that they're not 30k lines of code
<ul>
<li><input disabled="" type="checkbox" checked=""/>
models/types; each struct/enum should probably get its own file with pub-use</li>
<li><input disabled="" type="checkbox" checked=""/>
models/types::builders: now this needs to get split up</li>
<li><input disabled="" type="checkbox" checked=""/>
<code>client.rs</code></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Fix examples</li>
<li><input disabled="" type="checkbox" checked=""/>
Write changelog</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-endpoints-20"><a class="header" href="#rfc-endpoints-20">RFC: Endpoints 2.0</a></h1>
<!-- RFCs start with the "RFC" status and are then either "Implemented" or "Rejected".  -->
<blockquote>
<p>Status: RFC</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0027_endpoints_20.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC defines how the Rust SDK will integrate with the next generation of endpoint resolution logic (Endpoints 2.0).
Endpoints 2.0 defines a rules language for resolving endpoints. The Rust SDK will code-generate Rust code from this
intermediate language and use this to create service-specific endpoint resolvers.</p>
<p>Endpoints 2.0 will be a core feature and be available for generic clients as well as the AWS SDK.</p>
<!-- The "Terminology" section is optional but is really useful for defining the technical terms you're using in the RFC -->
<h2 id="terminology-14"><a class="header" href="#terminology-14">Terminology</a></h2>
<ul>
<li><strong>Generic client</strong>: In reference to features/code that is <em>not</em> AWS specific and is supported for all Smithy clients.</li>
<li><strong>Rules language</strong>: A JSON-based rules language used to resolve endpoints</li>
<li><a href="rfcs/rfc0027_endpoints_20.html#the-endpoint-struct"><strong>Smithy Endpoint</strong></a>: An endpoint, as returned from the rules-language. This contains a URI,
headers, and configuration map of <code>String -&gt; Document</code> (<code>properties</code>). This must
undergo <a href="rfcs/rfc0027_endpoints_20.html#converting-a-smithy-endpoint-to-an-aws-endpoint">another level of transformation</a> before it
can be used as an <code>AwsEndpoint</code>.</li>
<li><strong>AWS Endpoint</strong>: An endpoint with explicit signing configuration applied. AWS Endpoints need to contain region &amp;
service metadata to control signing.</li>
<li><strong>Middleware</strong>: A transformation applied to a request, prior to request dispatch</li>
<li><strong>Endpoint Parameters</strong>: A code-generated structure for each service which contains service-specific (and general)
endpoint parameters.</li>
</ul>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented-2"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-2">The user experience if this RFC is implemented</a></h2>
<h3 id="overview-1"><a class="header" href="#overview-1">Overview</a></h3>
<p>SDKs will generate a new, public, <code>endpoint</code> module. The module will contain a <a href="rfcs/rfc0027_endpoints_20.html#endpoint-params"><code>Params</code></a> structure
and
a <a href="rfcs/rfc0027_endpoints_20.html#the-default-endpoint-resolver"><code>DefaultResolver</code></a>. Supporting these modules, a private <code>endpoints_impl</code> module will
be generated.</p>
<blockquote>
<p><strong>Why generate two modules</strong>?</p>
<p>Generating two separate modules, <code>endpoint</code> and <code>endpoint_impl</code> ensures that we don't have namespace collisions
between hand-written and generated
code.</p>
</blockquote>
<p>SDK middleware will be updated to use the new <a href="rfcs/rfc0027_endpoints_20.html#the-endpoint-struct"><code>smithy_types::Endpoint</code></a>. During request
construction in <code>make_operation</code>, a <a href="rfcs/rfc0027_endpoints_20.html#the-endpoint-struct">smithy endpoint</a> will be inserted into the property bag. The
endpoint middleware will be updated to extract the Smithy endpoint from the property bag and set the request endpoint &amp;
signing information accordingly (see: <a href="rfcs/rfc0027_endpoints_20.html#converting-a-smithy-endpoint-to-an-aws-endpoint">Converting to AWS Endpoint</a>.</p>
<p>The following flow chart traces the endpoints 2.0 influence on a request via the green boxes.</p>
<pre class="mermaid">flowchart TD
    globalConfig(&quot;SDK global configuration (e.g. region provider, UseFIPS, etc.)&quot;)

    serviceConfig(&quot;Modeled, service specific configuration information (clientContextParams)&quot;)

    operationConfig(&quot;Operation-specific configuration (S3 Bucket, accountId, etc.)&quot;)

    getObject[&quot;S3::GetObject&quot;]

    params[&quot;Create endpoint parameters&quot;]

    evaluate[&quot;Evaluate ruleset&quot;]

    rules[&quot;Generated Endpoint Ruleset for S3&quot;]

    middleware[&quot;Apply endpoint &amp; properties to request via endpoint middleware&quot;]



    style getObject fill:green,stroke:#333,stroke-width:4px
    style params fill:green,stroke:#333,stroke-width:4px
    style evaluate fill:green,stroke:#333,stroke-width:4px
    style middleware fill:green,stroke:#333,stroke-width:4px

    getObject ==&gt; params
    globalConfig ---&gt; params
    operationConfig --&gt; params
    serviceConfig ---&gt; params

    rules --&gt; evaluate
    params --&gt; evaluate
    evaluate --&gt; middleware
</pre>
<h3 id="overriding-endpoints"><a class="header" href="#overriding-endpoints">Overriding Endpoints</a></h3>
<p>In the general case, users will not be impacted by Endpoints 2.0 with one exception: today, users can provide a
global endpoint provider that can override different services. There is a single <code>ResolveAwsEndpoint</code> trait that
is shared across all services. However, this isn't the case for <code>Endpoints 2.0</code> where the trait actually has a generic
parameter:</p>
<pre><code class="language-rust ignore">pub trait ResolveEndpoint&lt;T&gt;: Send + Sync {
    fn resolve_endpoint(&amp;self, params: &amp;T) -&gt; Result&lt;Endpoint, BoxError&gt;;
}</code></pre>
<p>The trait itself would then be parameterized by service-specific endpoint parameter, eg:
<code>aws_sdk_s3::endpoint::Params</code>. The endpoint parameters we would use for S3 (e.g. including <code>Bucket</code>) are different
from the endpoint parameters we might use for a service like DynamoDB which, today, doesn't have any custom endpoint
behavior.</p>
<p>Going forward we will to provide two different avenues for customers to customize endpoints:</p>
<ol>
<li>Configuration driven URL override. This mechanism hasn't been specified, but suppose that the Rust SDK supported
an <code>SDK_ENDPOINT</code> environment variable. This variable would be an input to the existing endpoint resolver.
machinery and would be backwards compatible with other SDKs (e.g. by prefixing the bucket as a host label for S3).</li>
<li>Wholesale endpoint resolver override. In this case, customers would gain access to all endpoint parameters and be
able to write their own resolver.</li>
</ol>
<p>This RFC proposes making the following changes:</p>
<ol>
<li>For the current <em>global</em> ability to override an endpoint, instead of accepting an <code>AwsEndpoint</code>, accept a URI. This
will simplify the interface for most customers who don't actually need logic-driven endpoint construction. The
Endpoint that can be set will be passed in as the <code>SDK::Endpoint</code> built-in. This will be renamed to <code>endpoint_url</code>
for clarity. <strong>All</strong> AWS services <strong>MUST</strong> accept the <code>SDK::Endpoint</code> built-in.</li>
<li>For complex, service-specific behavior, customers will be able to provide a service specific endpoint resolver at
client construction time. This resolver will be parameterized with the service-specific parameters type, (
eg. <code>aws_sdk_s3::endpoint::Params</code>). Finally, customers will be able to access the <code>default_resolver()</code> for AWS
services directly. This will enable them to utilize the default S3 endpoint resolver in their resolver
implementation.</li>
</ol>
<p><strong>Example: overriding the endpoint URI globally</strong></p>
<pre><code class="language-rust ignore">async fn main() {
    let sdk_conf = aws_config::from_env().endpoint_url("http://localhost:8123").load().await;
    let dynamo = aws_sdk_dynamodb::Client::new(&amp;sdk_conf);
    // snip ...
}</code></pre>
<p><strong>Example: overriding the endpoint resolver for a service</strong></p>
<pre><code class="language-rust ignore">/// Resolve to Localhost when an environment variable is set
struct CustomDdbResolver;

impl ResolveEndpoint&lt;aws_sdk_dynamodb::endpoint::Params&gt; for CustomDdbResolver {
    fn resolve_endpoint(&amp;self, params: &amp;Params) -&gt; Result&lt;Endpoint, EndpointResolutionError&gt; {
        // custom resolver to redirect to DDB local if a flag is set
        let base_endpoint = aws_sdk_dynamodb::endpoint::default_resolver().resolve_endpoint(params).expect("valid endpoint should be resolved");
        if env::var("LOCAL") == Ok("true") {
            // update the URI on the returned endpoint to localhost while preserving the other properties
            Ok(base_endpoint.builder().uri("http://localhost:8888").build())
        } else {
            Ok(base_endpoint)
        }
    }
}

async fn main() {
    let conf = aws_config::load_from_env().await;
    let ddb_conf = aws_sdk_dynamodb::config::Builder::from(&amp;conf).endpoint_resolver(CustomDdbResolver);
    let dynamodb = aws_sdk_dynamodb::Client::from_conf(ddb_conf);
}</code></pre>
<p>Note: for generic clients, they cannot use <code>endpoint_url</code>—this is because <code>endpoint_url</code> is dependent on rules and
generic
clients do not necessarily rules. However, they can use the <code>impl&lt;T&gt; ResolveEndpoint&lt;T&gt; for &amp;'static str { ... }</code>
implementation.</p>
<blockquote>
<p><strong>What about alternative S3 implementations? How do we say "don't put prefix bucket on this?"</strong></p>
<p>For cases where users want to use the provided URL directly with no modification users will need to rely on service
specific configuration, like forcing path style addressing for S3.</p>
</blockquote>
<p><em>Alternative Design</em>: <a href="rfcs/rfc0027_endpoints_20.html#context-aware-endpoint-traits">Context Aware Endpoint Trait</a></p>
<blockquote>
<p><em>Optional addition</em>: We could add an additional <code>EndpointResolver</code> parameter to <code>SdkConfig</code> that exposed a global
trait
where <code>Params</code> is <code>&amp;dyn Any</code> similar to <a href="rfcs/rfc0027_endpoints_20.html#context-aware-endpoint-traits">Context Aware Endpoint Trait</a>. If these were
<strong>both</strong> set, a runtime panic would alert users to the misconfiguration.</p>
</blockquote>
<h3 id="new-endpoint-traits"><a class="header" href="#new-endpoint-traits">New Endpoint Traits</a></h3>
<p>The new endpoint resolution trait and <code>Endpoint</code> struct will be available for generic clients. AWS endpoint middleware
will pull the <code>Endpoint</code> out of the property bag and read the properties to determine auth/signing + any other AWS
metadata that may be required.</p>
<p>An example of the <code>Endpoint</code> struct is below. This struct will be in <code>aws-smithy-types</code>, however, it should initially be
gated with documentation warning about stability.</p>
<h4 id="the-endpoint-struct"><a class="header" href="#the-endpoint-struct">The Endpoint Struct</a></h4>
<pre><code class="language-rust ignore">// module: `aws_smithy_types::endpoint`
// potential optimization to reduce / remove allocations for keys which are almost always static
// this can also just be `String`
type MaybeStatic&lt;T&gt; = Cow&lt;'static, T&gt;;

/// Endpoint
#[derive(Debug, PartialEq)]
pub struct Endpoint {
    // Note that this allows `Endpoint` to contain an invalid URI. During conversion to an actual endpoint, the
    // the middleware can fail, returning a `ConstructionFailure` to the user
    url: MaybeStatic&lt;str&gt;,
    headers: HashMap&lt;MaybeStatic&lt;str&gt;, Vec&lt;MaybeStatic&lt;str&gt;&gt;&gt;,
    properties: HashMap&lt;MaybeStatic&lt;str&gt;, aws_smithy_types::Document&gt;,
}

// not shown:
// - impl block with standard accessors
// - builder, designed to be invoked / used by generated code</code></pre>
<blockquote>
<p><strong>What's an Endpoint property?</strong></p>
<p>Endpoint properties, on their own, have no intrinsic meaning. Endpoint properties have established conventions for AWS
SDKs. Other Smithy implementors may choose a different pattern. For AWS SDKs, the <code>authSchemes</code> key is an ordered list
of authentication/signing schemes supported by the Endpoint that the SDK should use.</p>
</blockquote>
<p>To perform produce an <code>Endpoint</code> struct we have a generic <code>ResolveEndpoint</code> trait which will be both generic in terms of
parameters and being "smithy-generic:</p>
<pre><code class="language-rust ignore">// module: `smithy_types::endpoint` or `aws_smithy_client`??
pub trait ResolveEndpoint&lt;Params&gt;: Send + Sync {
    /// Resolves an `Endpoint` for `Params`
    fn resolve_endpoint(&amp;self, params: &amp;Params) -&gt; Result&lt;aws_smithy_types::Endpoint, EndpointResolutionError&gt;;
}</code></pre>
<p>All Smithy services that have the <code>@endpointRuleSet</code> trait applied to the service shape will code generate a default
endpoint resolver implementation. The default endpoint resolver <strong>MUST</strong> be public, so that customers can delegate to it
if they wish to override the endpoint resolver.</p>
<h3 id="endpoint-params"><a class="header" href="#endpoint-params">Endpoint Params</a></h3>
<p>We've mentioned "service specific endpoint parameters" a few times. In Endpoints 2.0, we will code generate Endpoint
Parameters for every service based on their rules. <strong>Note</strong>: the endpoint parameters themselves are generated solely
from the ruleset. The Smithy model provides additional information about parameter binding, but that only influences how
the parameters are set, <em>not</em> how they are generated.</p>
<p><strong>Example <code>Params</code> struct for S3:</strong></p>
<pre><code class="language-rust ignore">#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq, std::fmt::Debug)]
/// Configuration parameters for resolving the correct endpoint
pub struct Params {
    pub(crate) bucket: std::option::Option&lt;std::string::String&gt;,
    pub(crate) region: std::option::Option&lt;std::string::String&gt;,
    pub(crate) use_fips: bool,
    pub(crate) use_dual_stack: bool,
    pub(crate) endpoint: std::option::Option&lt;std::string::String&gt;,
    pub(crate) force_path_style: std::option::Option&lt;bool&gt;,
    pub(crate) accelerate: bool,
    pub(crate) disable_access_points: std::option::Option&lt;bool&gt;,
    pub(crate) disable_mrap: std::option::Option&lt;bool&gt;,
}

impl Params {
    /// Create a builder for [`Params`]
    pub fn builder() -&gt; crate::endpoint_resolver::Builder {
        crate::endpoint_resolver::Builder::default()
    }
    /// Gets the value for bucket
    pub fn bucket(&amp;self) -&gt; std::option::Option&lt;&amp;str&gt; {
        self.bucket.as_deref()
    }
    /// Gets the value for region
    pub fn region(&amp;self) -&gt; std::option::Option&lt;&amp;str&gt; {
        self.region.as_deref()
    }
    /// Gets the value for use_fips
    pub fn use_fips(&amp;self) -&gt; std::option::Option&lt;bool&gt; {
        Some(self.use_fips)
    }
    /// Gets the value for use_dual_stack
    pub fn use_dual_stack(&amp;self) -&gt; std::option::Option&lt;bool&gt; {
        Some(self.use_dual_stack)
    }
    // ... more accessors
}</code></pre>
<h3 id="the-default-endpoint-resolver"><a class="header" href="#the-default-endpoint-resolver">The default endpoint resolver</a></h3>
<p>When an endpoint ruleset is present, Smithy will code generate an endpoint resolver from that ruleset. The endpoint
resolver
<strong>MUST</strong> be a struct so that it can store/cache computations (such as a partition resolver that has compiled regexes).</p>
<pre><code class="language-rust ignore">pub struct DefaultEndpointResolver {
    partition_resolver: PartitionResolver
}

impl ResolveEndpoint&lt;crate::endpoint::Params&gt; for DefaultEndpointResolver {
    fn resolve_endpoint(&amp;self, params: &amp;Params) -&gt; Result&lt;aws_smithy_types::Endpoint, EndpointResolutionError&gt; {
        // delegate to private impl
        crate::endpoints_impl::resolve_endpoint(params)
    }
}</code></pre>
<p><code>DefaultEndpointResolver</code> <strong>MUST</strong> be publicly accessible and offer both a default constructor and the ability to
configure resolution behavior (e.g. by supporting adding additional partitions.)</p>
<h2 id="how-to-actually-implement-this-rfc-1"><a class="header" href="#how-to-actually-implement-this-rfc-1">How to actually implement this RFC</a></h2>
<p>To describe how this feature will work, let's take a step-by-step path through endpoint resolution.</p>
<ol>
<li>
<p>A user defines a service client, possibly with some client specific configuration like region.</p>
<blockquote>
<p><code>@clientContextParams</code> are code generated onto the client <code>Config</code>
. <a href="rfcs/rfc0027_endpoints_20.html#code-generating-client-context-params">Code generating <code>@clientContextParams</code></a></p>
</blockquote>
</li>
<li>
<p>A user invokes an operation like <code>s3::GetObject</code>. A <a href="rfcs/rfc0027_endpoints_20.html#creating-params">params object is created</a>. In the body
of <code>make_operation()</code>, this is passed to <code>config.endpoint_resolver</code> to load a generic endpoint. The <code>Result</code> of the
of the endpoint resolution is written into the property bag.</p>
</li>
<li>
<p>The generic smithy middleware (<code>SmithyEndpointStage</code>) sets the request endpoint.</p>
</li>
<li>
<p>The AWS auth middleware (<code>AwsAuthStage</code>) reads the endpoint out of the property bag and applies signing overrides.</p>
</li>
<li>
<p>The request is signed &amp; dispatched</p>
</li>
</ol>
<p>The other major piece of implementation required is actually implementing the rules engine. To learn more about
rules-engine internals, skip to <a href="rfcs/rfc0027_endpoints_20.html#implementing-the-rules-engine">implementing the rules engine</a>.</p>
<h3 id="code-generating-client-context-params"><a class="header" href="#code-generating-client-context-params">Code generating client context params</a></h3>
<p>When a smithy model uses the <code>@clientContextParams</code> trait, we need to generate client params onto the Rust SDK. This is
a <strong>Smithy-native</strong> feature. This should be implemented as a "standard" config decorator that reads traits from the
current model.</p>
<details>
<summary>Kotlin Snippet for Client context params</summary>
<pre><code class="language-kotlin">class ClientContextDecorator(ctx: ClientCodegenContext) : NamedSectionGenerator&lt;ServiceConfig&gt;() {
    private val contextParams = ctx.serviceShape.getTrait&lt;ClientContextParamsTrait&gt;()?.parameters.orEmpty().toList()
        .map { (key, value) -&gt; ContextParam.fromClientParam(key, value, ctx.symbolProvider) }

    data class ContextParam(val name: String, val type: Symbol, val docs: String?) {
        companion object {
            private fun toSymbol(shapeType: ShapeType, symbolProvider: RustSymbolProvider): Symbol =
                symbolProvider.toSymbol(
                    when (shapeType) {
                        ShapeType.STRING -&gt; StringShape.builder().id("smithy.api#String").build()
                        ShapeType.BOOLEAN -&gt; BooleanShape.builder().id("smithy.api#Boolean").build()
                        else -&gt; TODO("unsupported type")
                    }
                )

            fun fromClientParam(
                name: String,
                definition: ClientContextParamDefinition,
                symbolProvider: RustSymbolProvider
            ): ContextParam {
                return ContextParam(
                    RustReservedWords.escapeIfNeeded(name.toSnakeCase()),
                    toSymbol(definition.type, symbolProvider),
                    definition.documentation.orNull()
                )
            }
        }
    }

    override fun section(section: ServiceConfig): Writable {
        return when (section) {
            is ServiceConfig.ConfigStruct -&gt; writable {
                contextParams.forEach { param -&gt;
                    rust("pub (crate) ${param.name}: #T,", param.type.makeOptional())
                }
            }
            ServiceConfig.ConfigImpl -&gt; emptySection
            ServiceConfig.BuilderStruct -&gt; writable {
                contextParams.forEach { param -&gt;
                    rust("${param.name}: #T,", param.type.makeOptional())
                }
            }
            ServiceConfig.BuilderImpl -&gt; writable {
                contextParams.forEach { param -&gt;
                    param.docs?.also { docs(it) }
                    rust(
                        """
                        pub fn ${param.name}(mut self, ${param.name}: #T) -&gt; Self {
                            self.${param.name} = Some(${param.name});
                            self
                        }
                        """,
                        param.type
                    )
                }
            }
            ServiceConfig.BuilderBuild -&gt; writable {
                contextParams.forEach { param -&gt;
                    rust("${param.name}: self.${param.name},")
                }
            }
            else -&gt; emptySection
        }
    }
}
</code></pre>
</details>
<h3 id="creating-params"><a class="header" href="#creating-params">Creating <code>Params</code></a></h3>
<p><code>Params</code> will be created and utilized in generic code generation.</p>
<p><code>make_operation()</code> needs to load the parameters from several configuration sources. These sources have a priority order.
To handle this priority order, we will load from all sources in reverse priority order, with lower priority sources
overriding higher priority ones.</p>
<details>
<summary>Implementation of operation decorator</summary>
<pre><code class="language-kotlin">class EndpointParamsDecorator(
    private val ctx: ClientCodegenContext,
    private val operationShape: OperationShape,
) : OperationCustomization() {
    val idx = ContextIndex.of(ctx.model)
    private val ruleset = EndpointRuleset.fromNode(ctx.serviceShape.expectTrait&lt;EndpointRuleSetTrait&gt;().ruleSet)

    override fun section(section: OperationSection): Writable {
        return when (section) {
            is OperationSection.MutateInput -&gt; writable {
                rustTemplate(
                    """
                    let params = #{Params}::builder()
                        #{builder:W}.expect("invalid endpoint");
                    """,
                    "Params" to EndpointParamsGenerator(ruleset).paramsStruct(),
                    "builder" to builderFields(section)
                )
            }
            is OperationSection.MutateRequest -&gt; writable {
                rust("// ${section.request}.properties_mut().insert(params);")
            }
            else -&gt; emptySection
        }
    }

    private fun builderFields(section: OperationSection.MutateInput) = writable {
        val memberParams = idx.getContextParams(operationShape)
        val builtInParams = ruleset.parameters.toList().filter { it.isBuiltIn }
        // first load builtins and their defaults
        builtInParams.forEach { param -&gt;
            val defaultProviders = section.endpointCustomizations.mapNotNull { it.defaultFor(param, section.config) }
            if (defaultProviders.size &gt; 1) {
                error("Multiple providers provided a value for the builtin $param")
            }
            defaultProviders.firstOrNull()?.also { defaultValue -&gt;
                rust(".set_${param.name.rustName()}(#W)", defaultValue)
            }
        }
        // these can be overridden with client context params
        idx.getClientContextParams(ctx.serviceShape).forEach { (name, _param) -&gt;
            rust(".set_${name.toSnakeCase()}(${section.config}.${name.toSnakeCase()}.as_ref())")
        }

        // lastly, allow these to be overridden by members
        memberParams.forEach { (memberShape, param) -&gt;
            rust(".set_${param.name.toSnakeCase()}(${section.input}.${ctx.symbolProvider.toMemberName(memberShape)}.as_ref())")
        }
        rust(".build()")
    }
}
</code></pre>
</details>
<h4 id="loading-values-for-builtins"><a class="header" href="#loading-values-for-builtins">Loading values for builtIns</a></h4>
<p>The fundamental point of builtIn values is enabling <em>other</em> code generators to define where these values come from.
Because of that, we will need to expose the ability to customize AwsBuiltIns. One way to do this is with a new
customization type, <code>EndpointCustomization</code>:</p>
<pre><code class="language-kotlin">fun endpointCustomizations(
    clientCodegenContext: C,
    operation: OperationShape,
    baseCustomizations: List&lt;EndpointCustomization&gt;
): List&lt;EndpointCustomization&gt; = baseCustomizations


abstract class EndpointCustomization {
    abstract fun defaultFor(parameter: Parameter, config: String): Writable?
}
</code></pre>
<p>Customizations have the ability to specify the default value for a parameter. (Of course, these customizations need to
be wired in properly.)</p>
<h3 id="converting-a-smithy-endpoint-to-an-aws-endpoint"><a class="header" href="#converting-a-smithy-endpoint-to-an-aws-endpoint">Converting a Smithy Endpoint to an AWS Endpoint</a></h3>
<p>A Smithy endpoint has an untyped, string-&gt;<code>Document</code> collection of properties. We need to interpret these properties to
handle actually resolving an endpoint. As part of the <code>AwsAuthStage</code>, we load authentication schemes from the endpoint
properties and use these to configure signing on the request.</p>
<p><strong>Note</strong>: Authentication schemes are <strong>NOT</strong> required as part of an endpoint. When the auth schemes are not set, the
default
authentication should be used. The Rust SDK will set <code>SigningRegion</code> and <code>SigningName</code> in the property bag by default
as part of <code>make_operation</code>.</p>
<h3 id="implementing-the-rules-engine"><a class="header" href="#implementing-the-rules-engine">Implementing the rules engine</a></h3>
<p>The Rust SDK code converts the rules into Rust code that will be compiled.</p>
<!-- Include a checklist of all the things that need to happen for this RFC's implementation to be considered complete -->
<h2 id="changes-checklist-20"><a class="header" href="#changes-checklist-20">Changes checklist</a></h2>
<p><strong>Rules Engine</strong></p>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Endpoint rules code generator</li>
<li><input disabled="" type="checkbox" checked=""/>
Endpoint params code generator</li>
<li><input disabled="" type="checkbox" checked=""/>
Endpoint tests code generator</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement ruleset standard library functions as inlineables. Note: pending future refactoring work, the <code>aws.</code>
functions will need to be integrated into the smithy core endpoint resolver.</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement partition function &amp; ability to customize partitions
<strong>SDK Integration</strong></li>
<li><input disabled="" type="checkbox" checked=""/>
Add a Smithy endpoint resolver to the service config, with a default that loads the default endpoint resolver.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>SdkConfig</code> to accept a URI instead of an implementation of <code>ResolveAwsEndpoint</code>. This change can be done
standalone.</li>
<li><input disabled="" type="checkbox" checked=""/>
Remove/deprecate the <code>ResolveAwsEndpoint</code> trait and replace it with the vanilla Smithy trait. Potentially, provide
a bridge.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>make_operation</code> to write a <a href="rfcs/rfc0027_endpoints_20.html#the-endpoint-struct"><code>smithy::Endpoint</code></a> into the property bag</li>
<li><input disabled="" type="checkbox" checked=""/>
Update AWS Endpoint middleware to work off of a <a href="rfcs/rfc0027_endpoints_20.html#the-endpoint-struct"><code>smithy::Endpoint</code></a></li>
<li><input disabled="" type="checkbox" checked=""/>
Wire the endpoint override to the <code>SDK::Endpoint</code> builtIn parameter</li>
<li><input disabled="" type="checkbox" checked=""/>
Remove the old smithy endpoint</li>
</ul>
<h2 id="alternative-designs"><a class="header" href="#alternative-designs">Alternative Designs</a></h2>
<h3 id="context-aware-endpoint-traits"><a class="header" href="#context-aware-endpoint-traits">Context Aware Endpoint Traits</a></h3>
<p>An alternative design that could provide more flexibility is a context-aware endpoint trait where the return type would
give context about the endpoint being returned. This would, for example, allow a customer to say explicitly "don't
modify this endpoint":</p>
<pre><code class="language-rust ignore">enum ContextualEndpoint {
    /// Just the URI please. Pass it into the default endpoint resolver as a baseline
    Uri { uri: Uri, immutable: bool },

    /// A fully resolved, ready to rumble endpoint. Don't bother hitting the default endpoint resolver, just use what
    /// I've got.
    AwsEndpoint(AwsEndpoint)
}

trait ResolveGlobalEndpoint {
    fn resolve_endpoint(params: &amp;dyn Any) -&gt; Result&lt;ContextualEndpoint, EndpointResolutionError&gt;;
}</code></pre>
<p>Service clients would then use <code>ResolveGlobalEndpoint</code>, optional specified from <code>SdkConfig</code> to perform routing
decisions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-sdk-credential-cache-type-safety"><a class="header" href="#rfc-sdk-credential-cache-type-safety">RFC: SDK Credential Cache Type Safety</a></h1>
<blockquote>
<p>Status: Implemented in <a href="https://github.com/smithy-lang/smithy-rs/pull/2122">smithy-rs#2122</a></p>
<p>Applies to: AWS SDK for Rust</p>
</blockquote>
<p>At time of writing (2022-10-11), the SDK's credentials provider can be customized by providing:</p>
<ol>
<li>A profile credentials file to modify the default provider chain</li>
<li>An instance of one of the credentials providers implemented in <code>aws-config</code>, such as
the <code>AssumeRoleCredentialsProvider</code>, <code>ImdsCredentialsProvider</code>, and so on.</li>
<li>A custom struct that implements the <code>ProvideCredentials</code></li>
</ol>
<p>The problem this RFC examines is that when options 2 and 3 above are exercised, the customer
needs to be aware of credentials caching and put additional effort to ensure caching is set up
correctly (and that double caching doesn't occur). This is especially difficult to get right
since some built-in credentials providers (such as <code>AssumeRoleCredentialsProvider</code>) already
have caching, while most others do not and need to be wrapped in <code>LazyCachingCredentialsProvider</code>.</p>
<p>The goal of this RFC is to create an API where Rust's type system ensures caching is set up
correctly, or explicitly opted out of.</p>
<h2 id="credentialscache-and-configloadercredentials_cache"><a class="header" href="#credentialscache-and-configloadercredentials_cache"><code>CredentialsCache</code> and <code>ConfigLoader::credentials_cache</code></a></h2>
<p>A new config method named <code>credentials_cache()</code> will be added to <code>ConfigLoader</code> and the
generated service <code>Config</code> builders that takes a <code>CredentialsCache</code> instance. This <code>CredentialsCache</code>
will be a struct with several functions on it to create and configure the cache.</p>
<p>Client creation will ultimately be responsible for taking this <code>CredentialsCache</code> instance
and wrapping the given (or default) credentials provider.</p>
<p>The <code>CredentialsCache</code> would look as follows:</p>
<pre><code class="language-rust ignore">enum Inner {
    Lazy(LazyConfig),
    // Eager doesn't exist today, so this is purely for illustration
    Eager(EagerConfig),
    // Custom may not be implemented right away
    // Not naming or specifying the custom cache trait for now since its out of scope
    Custom(Box&lt;dyn SomeCacheTrait&gt;),

    NoCaching,
}
pub struct CredentialsCache {
    inner: Inner,
}

impl CredentialsCache {
    // These methods use default cache settings
    pub fn lazy() -&gt; Self { /* ... */ }
    pub fn eager() -&gt; Self { /* ... */ }

    // Unprefixed methods return a builder that can take customizations
    pub fn lazy_builder() -&gt; LazyBuilder { /* ... */ }
    pub fn eager_builder() -&gt; EagerBuilder { /* ... */ }

    // Later, when custom implementations are supported
    pub fn custom(cache_impl: Box&lt;dyn SomeCacheTrait&gt;) -&gt; Self { /* ... */ }

    pub(crate) fn create_cache(
        self,
        provider: Box&lt;dyn ProvideCredentials&gt;,
        sleep_impl: Arc&lt;dyn AsyncSleep&gt;
    ) -&gt; SharedCredentialsProvider {
        // Note: SharedCredentialsProvider would get renamed to SharedCredentialsCache.
        // This code is using the old name to make it clearer that it already exists,
        // and the rename is called out in the change checklist.
        SharedCredentialsProvider::new(
            match self {
                Self::Lazy(inner) =&gt; LazyCachingCredentialsProvider::new(provider, settings.time, /* ... */),
                Self::Eager(_inner) =&gt; unimplemented!(),
                Self::Custom(_custom) =&gt; unimplemented!(),
                Self::NoCaching =&gt; unimplemented!(),
            }
        )
    }
}</code></pre>
<p>Using a struct over a trait prevents custom caching implementations, but if customization is desired,
a <code>Custom</code> variant could be added to the inner enum that has its own trait that customers implement.</p>
<p>The <code>SharedCredentialsProvider</code> needs to be updated to take a cache implementation in addition to
the <code>impl ProvideCredentials + 'static</code>. A sealed trait could be added to facilitate this.</p>
<p>Customers that don't care about credential caching can configure credential providers
without needing to think about it:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials_provider(ImdsCredentialsProvider::builder().build())
    .load()
    .await;</code></pre>
<p>However, if they want to customize the caching, they can do so without modifying
the credentials provider at all (in case they want to use the default):</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials_cache(CredentialsCache::default_eager())
    .load()
    .await;</code></pre>
<p>The <code>credentials_cache</code> will default to <code>CredentialsCache::default_lazy()</code> if not provided.</p>
<h2 id="changes-checklist-21"><a class="header" href="#changes-checklist-21">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Remove cache from <code>AssumeRoleProvider</code></li>
<li><input disabled="" type="checkbox"/>
Implement <code>CredentialsCache</code> with its <code>Lazy</code> variant and builder</li>
<li><input disabled="" type="checkbox"/>
Add <code>credentials_cache</code> method to <code>ConfigLoader</code></li>
<li><input disabled="" type="checkbox"/>
Refactor <code>ConfigLoader</code> to take <code>CredentialsCache</code> instead of <code>impl ProvideCredentials + 'static</code></li>
<li><input disabled="" type="checkbox"/>
Refactor <code>SharedCredentialsProvider</code> to take a cache implementation in addition to an <code>impl ProvideCredentials + 'static</code></li>
<li><input disabled="" type="checkbox"/>
Remove <code>ProvideCredentials</code> impl from <code>LazyCachingCredentialsProvider</code></li>
<li><input disabled="" type="checkbox"/>
Rename <code>LazyCachingCredentialsProvider</code> -&gt; <code>LazyCredentialsCache</code></li>
<li><input disabled="" type="checkbox"/>
Refactor the SDK <code>Config</code> code generator to be consistent with <code>ConfigLoader</code></li>
<li><input disabled="" type="checkbox"/>
Write changelog upgrade instructions</li>
<li><input disabled="" type="checkbox"/>
Fix examples (if there are any for configuring caching)</li>
</ul>
<h2 id="appendix-alternatives-considered"><a class="header" href="#appendix-alternatives-considered">Appendix: Alternatives Considered</a></h2>
<h3 id="alternative-a-providecachedcredentials-trait"><a class="header" href="#alternative-a-providecachedcredentials-trait">Alternative A: <code>ProvideCachedCredentials</code> trait</a></h3>
<p>In this alternative, <code>aws-types</code> has a <code>ProvideCachedCredentials</code> in addition to <code>ProvideCredentials</code>.
All individual credential providers (such as <code>ImdsCredentialsProvider</code>) implement <code>ProvideCredentials</code>,
while credential caches (such as <code>LazyCachingCredentialsProvider</code>) implement the <code>ProvideCachedCredentials</code>.
The <code>ConfigLoader</code> would only take <code>impl ProvideCachedCredentials</code>.</p>
<p>This allows customers to provide their own caching solution by implementing <code>ProvideCachedCredentials</code>,
while requiring that caching be done correctly through the type system since <code>ProvideCredentials</code> is
only useful inside the implementation of <code>ProvideCachedCredentials</code>.</p>
<p>Caching can be opted out by creating a <code>NoCacheCredentialsProvider</code> that implements <code>ProvideCachedCredentials</code>
without any caching logic, although this wouldn't be recommended and this provider wouldn't be vended
in <code>aws-config</code>.</p>
<p>Example configuration:</p>
<pre><code class="language-rust ignore">// Compiles
let sdk_config = aws_config::from_env()
    .credentials(
        LazyCachingCredentialsProvider::builder()
            .load(ImdsCredentialsProvider::new())
            .build()
    )
    .load()
    .await;

// Doesn't compile
let sdk_config = aws_config::from_env()
    // Wrong type: doesn't implement `ProvideCachedCredentials`
    .credentials(ImdsCredentialsProvider::new())
    .load()
    .await;</code></pre>
<p>Another method could be added to <code>ConfigLoader</code> that makes it easier to use the default cache:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials_with_default_cache(ImdsCredentialsProvider::new())
    .load()
    .await;</code></pre>
<h4 id="proscons"><a class="header" href="#proscons">Pros/cons</a></h4>
<ul>
<li>:+1: It's flexible, and somewhat enforces correct cache setup through types.</li>
<li>:+1: Removes the possibility of double caching since the cache implementations won't
implement <code>ProvideCredentials</code>.</li>
<li>:-1: Customers may unintentionally implement <code>ProvideCachedCredentials</code> instead of <code>ProvideCredentials</code>
for a custom provider, and then not realize they're not benefiting from caching.</li>
<li>:-1: The documentation needs to make it very clear what the differences are between <code>ProvideCredentials</code>
and <code>ProvideCachedCredentials</code> since they will look identical.</li>
<li>:-1: It's possible to implement both <code>ProvideCachedCredentials</code> and <code>ProvideCredentials</code>, which
breaks the type safety goals.</li>
</ul>
<h3 id="alternative-b-cachecredentials-trait"><a class="header" href="#alternative-b-cachecredentials-trait">Alternative B: <code>CacheCredentials</code> trait</a></h3>
<p>This alternative is similar to alternative A, except that the cache trait is distinct from <code>ProvideCredentials</code> so
that it's more apparent when mistakenly implementing the wrong trait for a custom credentials provider.</p>
<p>A <code>CacheCredentials</code> trait would be added that looks as follows:</p>
<pre><code class="language-rust ignore">pub trait CacheCredentials: Send + Sync + Debug {
    async fn cached(&amp;self, now: SystemTime) -&gt; Result&lt;Credentials, CredentialsError&gt;;
}</code></pre>
<p>Instances implementing <code>CacheCredentials</code> need to own the <code>ProvideCredentials</code> implementation
to make both lazy and eager credentials caching possible.</p>
<p>The configuration examples look identical to Option A.</p>
<h4 id="proscons-1"><a class="header" href="#proscons-1">Pros/cons</a></h4>
<ul>
<li>:+1: It's flexible, and enforces correct cache setup through types slightly better than Option A.</li>
<li>:+1: Removes the possibility of double caching since the cache implementations won't
implement <code>ProvideCredentials</code>.</li>
<li>:-1: Customers can still unintentionally implement the wrong trait and miss out on caching when
creating custom credentials providers, but it will be more apparent than in Option A.</li>
<li>:-1: It's possible to implement both <code>CacheCredentials</code> and <code>ProvideCredentials</code>, which
breaks the type safety goals.</li>
</ul>
<h3 id="alternative-c-credentialscache-struct-with-composition"><a class="header" href="#alternative-c-credentialscache-struct-with-composition">Alternative C: <code>CredentialsCache</code> struct with composition</a></h3>
<p>The struct approach posits that customers don't need or want to implement custom credential caching,
but at the same time, doesn't make it impossible to add custom caching later.</p>
<p>The idea is that there would be a struct called <code>CredentialsCache</code> that specifies the desired
caching approach for a given credentials provider:</p>
<pre><code class="language-rust ignore">pub struct LazyCache {
    credentials_provider: Arc&lt;dyn ProvideCredentials&gt;,
    // ...
}

pub struct EagerCache {
    credentials_provider: Arc&lt;dyn ProvideCredentials&gt;,
    // ...
}

pub struct CustomCache {
    credentials_provider: Arc&lt;dyn ProvideCredentials&gt;,
    // Not naming or specifying the custom cache trait for now since its out of scope
    cache: Arc&lt;dyn SomeCacheTrait&gt;
}

enum CredentialsCacheInner {
    Lazy(LazyCache),
    // Eager doesn't exist today, so this is purely for illustration
    Eager(EagerCache),
    // Custom may not be implemented right away
    Custom(CustomCache),
}

pub struct CredentialsCache {
    inner: CredentialsCacheInner,
}

impl CredentialsCache {
    // Methods prefixed with `default_` just use the default cache settings
    pub fn default_lazy(provider: impl ProvideCredentials + 'static) -&gt; Self { /* ... */ }
    pub fn default_eager(provider: impl ProvideCredentials + 'static) -&gt; Self { /* ... */ }

    // Unprefixed methods return a builder that can take customizations
    pub fn lazy(provider: impl ProvideCredentials + 'static) -&gt; LazyBuilder { /* ... */ }
    pub fn eager(provider: impl ProvideCredentials + 'static) -&gt; EagerBuilder { /* ... */ }

    pub(crate) fn create_cache(
        self,
        sleep_impl: Arc&lt;dyn AsyncSleep&gt;
    ) -&gt; SharedCredentialsProvider {
        // ^ Note: SharedCredentialsProvider would get renamed to SharedCredentialsCache.
        // This code is using the old name to make it clearer that it already exists,
        // and the rename is called out in the change checklist.
        SharedCredentialsProvider::new(
            match self {
                Self::Lazy(inner) =&gt; LazyCachingCredentialsProvider::new(inner.credentials_provider, settings.time, /* ... */),
                Self::Eager(_inner) =&gt; unimplemented!(),
                Self::Custom(_custom) =&gt; unimplemented!(),
            }
        )
    }
}</code></pre>
<p>Using a struct over a trait prevents custom caching implementations, but if customization is desired,
a <code>Custom</code> variant could be added to the inner enum that has its own trait that customers implement.</p>
<p>The <code>SharedCredentialsProvider</code> needs to be updated to take a cache implementation rather
than <code>impl ProvideCredentials + 'static</code>. A sealed trait could be added to facilitate this.</p>
<p>Configuration would look as follows:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials(CredentialsCache::default_lazy(ImdsCredentialsProvider::builder().build()))
    .load()
    .await;</code></pre>
<p>The <code>credentials_provider</code> method on <code>ConfigLoader</code> would only take <code>CredentialsCache</code> as an argument
so that the SDK could not be configured without credentials caching, or if opting out of caching becomes
a use case, then a <code>CredentialsCache::NoCache</code> variant could be made.</p>
<p>Like alternative A, a convenience method can be added to make using the default cache easier:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials_with_default_cache(ImdsCredentialsProvider::builder().build())
    .load()
    .await;</code></pre>
<p>In the future if custom caching is added, it would look as follows:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials(
        CredentialsCache::custom(ImdsCredentialsProvider::builder().build(), MyCache::new())
    )
    .load()
    .await;</code></pre>
<p>The <code>ConfigLoader</code> wouldn't be able to immediately set its credentials provider since other values
from the config are needed to construct the cache (such as <code>sleep_impl</code>). Thus, the <code>credentials</code>
setter would merely save off the <code>CredentialsCache</code> instance, and then when <code>load</code> is called,
the complete <code>SharedCredentialsProvider</code> would be constructed:</p>
<pre><code class="language-rust ignore">pub async fn load(self) -&gt; SdkConfig {
    // ...
    let credentials_provider = self.credentials_cache.create_cache(sleep_impl);
    // ...
}</code></pre>
<h4 id="proscons-2"><a class="header" href="#proscons-2">Pros/cons</a></h4>
<ul>
<li>:+1: Removes the possibility of missing out on caching when implementing a custom provider.</li>
<li>:+1: Removes the possibility of double caching since the cache implementations won't
implement <code>ProvideCredentials</code>.</li>
<li>:-1: Requires thinking about caching when only wanting to customize the credentials provider</li>
<li>:-1: Requires a lot of boilerplate in <code>aws-config</code> for the builders, enum variant structs, etc.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-finding-new-home-for-credential-types"><a class="header" href="#rfc-finding-new-home-for-credential-types">RFC: Finding New Home for Credential Types</a></h1>
<blockquote>
<p>Status: Implemented in <a href="https://github.com/smithy-lang/smithy-rs/pull/2108">smithy-rs#2108</a></p>
<p>Applies to: clients</p>
</blockquote>
<p>This RFC supplements <a href="https://github.com/smithy-lang/smithy-rs/blob/main/design/src/rfcs/rfc0028_sdk_credential_cache_type_safety.md">RFC 28</a> and discusses for the selected design where to place the types for credentials providers, credentials caching, and everything else that comes with them.</p>
<p>It is assumed that the primary motivation behind the introduction of type safe credentials caching remains the same as the preceding RFC.</p>
<h2 id="assumptions"><a class="header" href="#assumptions">Assumptions</a></h2>
<p>This document assumes that the following items in the changes checklist in the preceding RFC have been implemented:</p>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>CredentialsCache</code> with its <code>Lazy</code> variant and builder</li>
<li><input disabled="" type="checkbox" checked=""/>
Add the <code>credentials_cache</code> method to <code>ConfigLoader</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>SharedCredentialsProvider</code> to <code>SharedCredentialsCache</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Remove <code>ProvideCredentials</code> impl from <code>LazyCachingCredentialsProvider</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Rename <code>LazyCachingCredentialsProvider</code> -&gt; <code>LazyCredentialsCache</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Refactor the SDK <code>Config</code> code generator to be consistent with <code>ConfigLoader</code></li>
</ul>
<h2 id="problems"><a class="header" href="#problems">Problems</a></h2>
<p>Here is how our attempt to implement the selected design in the preceding RFC can lead to an obstacle. Consider this code snippet we are planning to support:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::from_env()
    .credentials_cache(CredentialsCache::lazy())
    .load()
    .await;

let client = aws_sdk_s3::Client::new(&amp;sdk_config);</code></pre>
<p>A <code>CredentialsCache</code> created by <code>CredentialsCache::lazy()</code> above will internally go through three crates before the variable <code>client</code> has been created:</p>
<ol>
<li><code>aws-config</code>: after it has been passed to <code>aws_config::ConfigLoader::credentials_cache</code></li>
</ol>
<pre><code class="language-rust ignore">// in lib.rs

impl ConfigLoader {
    // --snip--
    pub fn credentials_cache(mut self, credentials_cache: CredentialsCache) -&gt; Self {
        self.credentials_cache = Some(credentials_cache);
        self
    }
    // --snip--
}</code></pre>
<ol start="2">
<li><code>aws-types</code>: after <code>aws_config::ConfigLoader::load</code> has passed it to <code>aws_types::sdk_config::Builder::credentials_cache</code></li>
</ol>
<pre><code class="language-rust ignore">// in sdk_config.rs

impl Builder {
    // --snip--
    pub fn credentials_cache(mut self, cache: CredentialsCache) -&gt; Self {
        self.set_credentials_cache(Some(cache));
        self
    }
    // --snip--
}</code></pre>
<ol start="3">
<li><code>aws-sdk-s3</code>: after <code>aws_sdk_s3::Client::new</code> has been called with the variable <code>sdk_config</code></li>
</ol>
<pre><code class="language-rust ignore">// in client.rs

impl Client {
    // --snip--
    pub fn new(sdk_config: &amp;aws_types::sdk_config::SdkConfig) -&gt; Self {
        Self::from_conf(sdk_config.into())
    }
    // --snip--
}</code></pre>
<p>calls</p>
<pre><code class="language-rust ignore">// in config.rs

impl From&lt;&amp;aws_types::sdk_config::SdkConfig&gt; for Builder {
    fn from(input: &amp;aws_types::sdk_config::SdkConfig) -&gt; Self {
        let mut builder = Builder::default();
        builder = builder.region(input.region().cloned());
        builder.set_endpoint_resolver(input.endpoint_resolver().clone());
        builder.set_retry_config(input.retry_config().cloned());
        builder.set_timeout_config(input.timeout_config().cloned());
        builder.set_sleep_impl(input.sleep_impl());
	builder.set_credentials_cache(input.credentials_cache().cloned());
        builder.set_credentials_provider(input.credentials_provider().cloned());
        builder.set_app_name(input.app_name().cloned());
        builder.set_http_connector(input.http_connector().cloned());
        builder
    }
}

impl From&lt;&amp;aws_types::sdk_config::SdkConfig&gt; for Config {
    fn from(sdk_config: &amp;aws_types::sdk_config::SdkConfig) -&gt; Self {
        Builder::from(sdk_config).build()
    }
}</code></pre>
<p>What this all means is that <code>CredentialsCache</code> needs to be accessible from <code>aws-config</code>, <code>aws-types</code>, and <code>aws-sdk-s3</code> (SDK client crates, to be more generic). We originally assumed that <code>CredentialsCache</code> would be defined in <code>aws-config</code> along with <code>LazyCredentialsCache</code>, but the assumption no longer holds because <code>aws-types</code> and <code>aws-sdk-s3</code> do not depend upon <code>aws-config</code>.</p>
<p>Therefore, we need to find a new place in which to create credentials caches accessible from the aforementioned crates.</p>
<h2 id="proposed-solution-1"><a class="header" href="#proposed-solution-1">Proposed Solution</a></h2>
<p>We propose to move the following items to a new crate called <code>aws-credential-types</code>:</p>
<ul>
<li>All items in <code>aws_types::credentials</code> and their dependencies</li>
<li>All items in <code>aws_config::meta::credentials</code> and their dependencies</li>
</ul>
<p>For the first bullet point, we move types and traits associated with credentials out of <code>aws-types</code>. Crucially, the <code>ProvideCredentials</code> trait now lives in <code>aws-credential-types</code>.</p>
<p>For the second bullet point, we move the items related to credentials caching. <code>CredentialsCache</code> with its <code>Lazy</code> variant and builder lives in <code>aws-credential-types</code> and <code>CredentialsCache::create_cache</code> will be marked as <code>pub</code>. One area where we make an adjustment, though, is that <code>LazyCredentialsCache</code> depends on <code>aws_types::os_shim_internal::TimeSource</code> so we need to move <code>TimeSource</code> into <code>aws-credentials-types</code> as well.</p>
<p>A result of the above arrangement will give us the following module dependencies (only showing what's relevant):</p>
<p align="center">
  <img width="800" alt="Selected design" src="https://user-images.githubusercontent.com/15333866/207222687-8dd2430c-2865-4161-85bc-ee1410040d38.png">
<p>
<ul>
<li>:+1: <code>aws_types::sdk_config::Builder</code> and a service client <code>config::Builder</code> can create a <code>SharedCredentialsCache</code> with a concrete type of credentials cache.</li>
<li>:+1: It avoids cyclic crate dependencies.</li>
<li>:-1: There is one more AWS runtime crate to maintain and version.</li>
</ul>
<h2 id="rejected-alternative"><a class="header" href="#rejected-alternative">Rejected Alternative</a></h2>
<p>An alternative design is to move the following items to a separate crate (tentatively called <code>aws-XXX</code>):</p>
<ul>
<li>All items in <code>aws_types::sdk_config</code>, i.e. <code>SdkConfig</code> and its builder</li>
<li>All items in <code>aws_types::credentials</code> and their dependencies</li>
<li>All items in <code>aws_config::meta::credentials</code> and their dependencies</li>
</ul>
<p>The reason for the first bullet point is that the builder needs to be somewhere it has access to the credentials caching factory function, <code>CredentialsCache::create_cache</code>. The factory function is in <code>aws-XXX</code> and if the builder stayed in <code>aws-types</code>, it would cause a cyclic dependency between those two crates.</p>
<p>A result of the above arrangement will give us the following module dependencies:</p>
<p align="center">
  <img width="800" alt="Option A" src="https://user-images.githubusercontent.com/15333866/206587781-6eca3662-5096-408d-a435-d4023929e727.png">
</p>
<p>We have dismissed this design mainly because we try moving out of the <code>aws-types</code> create as little as possible. Another downside is that <code>SdkConfig</code> sitting together with the items for credentials provider &amp; caching does not give us a coherent mental model for the <code>aws-XXX</code> crate, making it difficult to choose the right name for <code>XXX</code>.</p>
<h2 id="changes-checklist-22"><a class="header" href="#changes-checklist-22">Changes Checklist</a></h2>
<p>The following list does not repeat what is listed in the preceding RFC but does include those new mentioned in the <code>Assumptions</code> section:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Create <code>aws-credential-types</code></li>
<li><input disabled="" type="checkbox"/>
Move all items in <code>aws_types::credentials</code> and their dependencies to the <code>aws-credential-types</code> crate</li>
<li><input disabled="" type="checkbox"/>
Move all items in <code>aws_config::meta::credentials</code> and their dependencies to the <code>aws-credential-types</code> crate</li>
<li><input disabled="" type="checkbox"/>
Update use statements and fully qualified names in the affected places</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-serialization-and-deserialization"><a class="header" href="#rfc-serialization-and-deserialization">RFC: Serialization and Deserialization</a></h1>
<blockquote>
<p>Status: RFC</p>
<p>Applies to: Output, Input, and Builder types as well as <code>DateTime</code>, <code>Document</code>, <code>Blob</code>, and <code>Number</code> implemented in <code>aws_smithy_types</code> crate.</p>
</blockquote>
<h1 id="terminology-15"><a class="header" href="#terminology-15">Terminology</a></h1>
<ul>
<li>Builder
Refers to data types prefixed with <code>Builder</code>, which converts itself into a corresponding data type upon being built. e.g. <code>aws_sdk_dynamodb::input::PutItemInput</code>.</li>
<li>serde
Refers to <code>serde</code> crate.</li>
<li><code>Serialize</code>
Refers to <code>Serialize</code> trait avaialble on <code>serde</code> crate.</li>
<li><code>Deserialize</code>
Refers to <code>Deserialize</code> trait available on <code>serde</code> crate.</li>
</ul>
<h1 id="overview-2"><a class="header" href="#overview-2">Overview</a></h1>
<p>We are going to implement Serialize and Deserialize traits from <code>serde</code> crate to some data types.
Data types that are going to be affected are;</p>
<ul>
<li>builder data types</li>
<li>operation <code>Input</code> types</li>
<li>operation <code>Output</code> types</li>
<li>data types that builder types may have on their field(s)</li>
<li><code>aws_smithy_types::DateTime</code></li>
<li><code>aws_smithy_types::Document</code></li>
<li><code>aws_smithy_types::Blob</code></li>
<li><code>aws_smithy_types::Number</code></li>
</ul>
<p><code>DateTime</code> and <code>Blob</code> implements different serialization/deserialization format for human-readable and non-human readable format; We must emphasize that these 2 formats are not compatible with each other. The reason for this is explained in the <a href="rfcs/rfc0030_serialization_and_deserialization.html#blob">Blob</a> section and <a href="rfcs/rfc0030_serialization_and_deserialization.html#datetime">Date Time</a>.</p>
<p>Additionally, we add <code>fn set_fields</code> to fluent builders to allow users to set the data they deserialized to fluent builders.</p>
<p>Lastly, we emphasize that this RFC does NOT aim to serialize the entire response or request or implement <code>serde</code> traits on data types for server-side code.</p>
<h1 id="use-case"><a class="header" href="#use-case">Use Case</a></h1>
<p>Users have requested <code>serde</code> traits to be implemented on data types implemented in rust SDK.
We have created this RFC with the following use cases in mind.</p>
<ol>
<li><a href="https://github.com/awslabs/aws-sdk-rust/issues/269">[request]: Serialize/Deserialize of models for Lambda events #269</a></li>
<li><a href="https://smithy-lang.github.io/smithy-rs/design/faq.html#why-dont-the-sdk-service-crates-implement-serdeserialize-or-serdedeserialize-for-any-types">Tests</a> as suggested in the design FAQ.</li>
<li>Building tools</li>
</ol>
<h1 id="feature-gate"><a class="header" href="#feature-gate">Feature Gate</a></h1>
<h2 id="enabling-feature"><a class="header" href="#enabling-feature">Enabling Feature</a></h2>
<p>To enable any of the features from this RFC, user must pass <code>--cfg aws-sdk-unstable</code> to rustc.</p>
<p>You can do this by specifying it on env-variable or by config.toml.</p>
<ul>
<li>specifying it on .cargo/config.toml</li>
</ul>
<pre><code class="language-toml">[build]
rustflags = ["--cfg", "aws-sdk-unstable"]
</code></pre>
<ul>
<li>As an environment variable</li>
</ul>
<pre><code class="language-bash">export RUSTFLAGS="--cfg aws-sdk-unstable"
cargo build
</code></pre>
<p>We considered allowing users to enable this feature on a crate-level.</p>
<p>e.g.</p>
<pre><code class="language-toml">[dependencies]
aws_sdk_dynamodb = { version = "0.22.0", features = ["unstable", "serialize"] }
</code></pre>
<p>Compared to the cfg approach, it is lot easier for the users to enable this feature.
However, we believe that cfg approach ensure users won't enable this feature by surprise, and communicate to users that features behind this feature gate can be taken-away or exprience breaking changes any time in future.</p>
<h2 id="feature-gate-for-serialization-and-de-serialization"><a class="header" href="#feature-gate-for-serialization-and-de-serialization">Feature Gate for Serialization and De-serialization</a></h2>
<p><code>Serde</code> traits are implemented behind feature gates.
<code>Serialize</code> is implemented behind <code>serde-serialize</code>, while <code>Deserialize</code> is implemented behind <code>serde-deserialize</code>.
Users must enable the <code>unstable</code> feature to expose those features.</p>
<p>We considered giving each feature a dedicated feature gate such as <code>unstable-serde-serialize</code>.
In this case, we will need to change the name of feature gates entirely once it leaves the unstable status which will cause users to make changes to their code base.
We conclude that this brings no benefit to the users.</p>
<p>Furthermore, we considered naming the fature-gate <code>serialize</code>/<code>deserialize</code>.
However, this way it would be confusing for the users when we add support for different serialization/deserialization framework such as <code>deser</code>.
Thus, to emphasize that the traits is from <code>serde</code> crate, we decided to name it <code>serde-serialize</code>/<code>serde-deserialize</code></p>
<h2 id="keeping-both-features-behind-the-same-feature-gate"><a class="header" href="#keeping-both-features-behind-the-same-feature-gate">Keeping both features behind the same feature gate</a></h2>
<p>We considered keeping both features behind the same feature gate.
There is no significant difference in the complexity of implementation.
We do not see any benefit in keeping them behind the same feature gate as this will only increase compile time when users do not need one of the features.</p>
<h2 id="different-feature-gates-for-different-data-types"><a class="header" href="#different-feature-gates-for-different-data-types">Different feature gates for different data types</a></h2>
<p>We considered implementing different feature gates for output, input, and their corresponding data types.
For example, output and input types can have <code>output-serde-*</code> and <code>input-serde-*</code>.
We are unable to do this as relevant metadata is not available during the code-gen.</p>
<h1 id="implementation-1"><a class="header" href="#implementation-1">Implementation</a></h1>
<h2 id="smithy-types"><a class="header" href="#smithy-types">Smithy Types</a></h2>
<p><code>aws_smithy_types</code> is a crate that implements smithy's data types.
These data types must implement serde traits as well since SDK uses the data types.</p>
<h3 id="blob"><a class="header" href="#blob">Blob</a></h3>
<p><code>Serialize</code> and <code>Deserialize</code> is not implemented with derive macro.</p>
<p>In human-readable format, <code>Blob</code> is serialized as a base64 encoded string and any data to be deserialized as this data type must be encoded in base 64.
Encoding must be carried out by <code>base64::encode</code> function available from <code>aws_smithy_types</code> crate.
Non-human readable format serializes <code>Blob</code> with <code>fn serialize_bytes</code>.</p>
<ul>
<li>Reason behind the implementation of human-readable format</li>
</ul>
<p><code>aws_smithy_types</code> crate comes with functions for encoding/decoding base 64, which makes the implementation simpler.
Additionally, AWS CLI and AWS SDK for other languages require data to be encoded in base 64 when it requires <code>Blob</code> type as input.</p>
<p>We also considered serializing them with <code>serialize_bytes</code>, without encoding them with <code>serialize_bytes</code>.
In this case, the implementation will depend on the implementation of the library author.</p>
<p>There are many different crates, so we decided to survey how some of the most popular crates implement this feature.</p>
<div class="table-wrapper"><table><thead><tr><th>library</th><th>version</th><th>implementation</th><th>all-time downloads on crate.io as of writing (Dec 2022)</th></tr></thead><tbody>
<tr><td>serde_json</td><td>1.0</td><td>Array of number</td><td>109,491,713</td></tr>
<tr><td>toml</td><td>0.5.9</td><td>Array of number</td><td>63,601,994</td></tr>
<tr><td>serde_yaml</td><td>0.9.14</td><td>Unsupported</td><td>23,767,300</td></tr>
</tbody></table>
</div>
<p>First of all, bytes could have hundreds of elements; reading an array of hundreds of numbers will never be a pleasing experience, and it is especially troubling when you are writing data for test cases.
Additionally, it has come to our attention that some crates just doesn't support it, which would hinder users' ability to be productive and tie users' hand.</p>
<p>For the reasons described above, we believe that it is crucial to encode them to string and base64 is favourable over other encoding schemes such as base 16, 32, or Ascii85.</p>
<ul>
<li>Reason behind the implementation of a non-human readable format
We considered using the same logic for non-human readable format as well.
However, readable-ness is not necessary for non-human readable format.
Additionally, non-human readable format tends to emphasize resource efficiency over human-readable format; Base64 encoded string would take up more space, which is not what the users would want.</li>
</ul>
<p>Thus, we believe that implementing a tailored serialization logic would be beneficial to the users.</p>
<h3 id="datetime"><a class="header" href="#datetime">DateTime</a></h3>
<p><code>Serialize</code> and <code>Deserialize</code> is not implemented with derive macro.
For human-readable format, <code>DateTime</code> is serialized in RFC-3339 format;
It expects the value to be in RFC-3339 format when it is Deserialized.</p>
<p>Non-human readable implements <code>DateTime</code> as a tuple of <code>u32</code> and <code>i64</code>; the latter corresponds to <code>seconds</code> field and the first is the <code>seubsecond_nanos</code>.</p>
<ul>
<li>Reason behind the implementation of a human-readable format</li>
</ul>
<p>For serialization, <code>DateTime</code> format already implements a function to encode itself into RFC-3339 format.
For deserialization, it is possible to accept other formats, we can add this later if we find it reasonable.</p>
<ul>
<li>Reason behind the implementation of a non-human readable format</li>
</ul>
<p>Serializing them as tuples of two integers results in a smaller data size and requires less computing power than any string-based format.
Tuple will be smaller in size as it does not require tagging like in maps.</p>
<h3 id="document"><a class="header" href="#document">Document</a></h3>
<p><code>Serialize</code> and <code>Deserialize</code> is implemented with derive macro.
Additionally, it implements container attribute <code>#[serde(untagged)]</code>.
Serde can distinguish each variant without tagging thanks to the difference in each variant's datatypes.</p>
<h3 id="number"><a class="header" href="#number">Number</a></h3>
<p><code>Serialize</code> and <code>Deserialize</code> is implemented with derive macro.
Additionally, it implements container attribute <code>#[serde(untagged)]</code>.</p>
<p>Serde can distinguish each variant without a tag as each variant's content is different.</p>
<h2 id="builder-types-and-non-builder-types"><a class="header" href="#builder-types-and-non-builder-types">Builder Types and Non-Builder Types</a></h2>
<p>Builder types and non Builder types implement <code>Serialize</code> and <code>Deserialize</code> with derive macro.</p>
<p>Example:</p>
<pre><code class="language-rust ignore">#[cfg_attr(
    all(aws-sdk-unstable, feature = "serialize"),
    derive(serde::Serialize)
)]
#[cfg_attr(
    all(aws-sdk-unstable, feature = "deserialize"),
    derive(serde::Deserialize)
)]
#[non_exhaustive]
#[derive(std::clone::Clone, std::cmp::PartialEq)]
pub struct UploadPartCopyOutput {
  ...
}</code></pre>
<h2 id="enum-representation"><a class="header" href="#enum-representation">Enum Representation</a></h2>
<p><code>serde</code> allows programmers to use one of four different tagging (<a href="https://serde.rs/enum-representations.html">internal, external, adjacent, and untagged</a>) when serializing an enum.</p>
<h3 id="untagged"><a class="header" href="#untagged">untagged</a></h3>
<p>You cannot deserialize serialized data in some cases.
For example, <a href="https://docs.rs/aws-sdk-dynamodb/latest/aws_sdk_dynamodb/model/enum.AttributeValue.html">aws_sdk_dynamodb::model::AttributeValue</a> has <code>Null(bool)</code> and <code>Bool(bool)</code>, which you cannot distinguish serialized values without a tag.</p>
<h3 id="internal"><a class="header" href="#internal">internal</a></h3>
<p>This results in compile time error.
<a href="https://serde.rs/enum-representations.html"><em>Using a #[serde(tag = "...")] attribute on an enum containing a tuple variant is an error at compile time</em></a>.</p>
<h3 id="external-and-adjacent"><a class="header" href="#external-and-adjacent">external and adjacent</a></h3>
<p>We are left with <code>external</code> and <code>adjacent</code> tagging.
External tagging is the default way.
This RFC can be achieved either way.</p>
<p>The resulting size of the serialized data is smaller when tagged externally, as adjacent tagging will require a tag even when a variant has no content.</p>
<p>For the reasons mentioned above, we implement an enum that is externally tagged.</p>
<h2 id="data-types-to-skip-serializationdeserialization"><a class="header" href="#data-types-to-skip-serializationdeserialization">Data Types to Skip Serialization/Deserialization</a></h2>
<p>We are going to skip serialization and deserialization of fields that have the datatype that corresponds to <code>@streaming blob</code> from smithy.
Any fields with these data types are tagged with <code>#[serde(skip)]</code>.</p>
<p>By skipping, corresponding field's value will be assigned the value generated by <code>Default</code> trait.</p>
<p>As of writing, <code>aws_smithy_http::byte_stream::ByteStream</code> is the only data type that is affected by this decision.</p>
<p>Here is an example of data types affected by this decision:</p>
<ul>
<li><code>aws_sdk_s3::input::put_object_input::PutObjectInput</code></li>
</ul>
<p>We considered serializing them as bytes, however, it could take some time for a stream to reach the end, and the resulting serialized data may be too big for itself to fit into the ram.</p>
<p>Here is an example snippet.</p>
<pre><code class="language-rust ignore">#[allow(missing_docs)]
#[cfg_attr(
    all(aws-sdk-unstable, feature = "serde-serialize"),
    derive(serde::Serialize)
)]
#[cfg_attr(
    all(aws-sdk-unstable, feature = "serde-deserialize"),
    derive(serde::Deserialize)
)]
#[non_exhaustive]
#[derive(std::fmt::Debug)]
pub struct PutObjectInput {
    pub acl: std::option::Option&lt;crate::model::ObjectCannedAcl&gt;,
    pub body: aws_smithy_http::byte_stream::ByteStream,
    // ... other fields
}</code></pre>
<h2 id="data-types-to-exclude-from-serde-code-generation"><a class="header" href="#data-types-to-exclude-from-serde-code-generation">Data types to exclude from ser/de code generation</a></h2>
<p>For data types that include <code>@streaming union</code> in any of their fields, we do NOT implement <code>serde</code> traits.</p>
<p>As of writing, following Rust data types corresponds to <code>@streaming union</code>.</p>
<ul>
<li><code>aws_smithy_http::event_stream::Receiver</code></li>
<li><code>aws_smithy_http::event_stream::EventStreamSender</code></li>
</ul>
<p>Here is an example of data type affected by this decision;</p>
<ul>
<li><code>aws_sdk_transcribestreaming::client::fluent_builders::StartMedicalStreamTranscription</code></li>
</ul>
<p>We considered skipping relevant fields on serialization and creating a custom de-serialization function which creates event stream that will always result in error when a user tries to send/receive data.
However, we believe that our decision is justified for following reason.</p>
<ul>
<li>All for operations that feature event streams since the stream is ephemeral (tied to the HTTP connection), and is effectively unusable after serialization and deserialization</li>
<li>Most event stream operations don't have fields that go along with them, making the stream the sole component in them, which makes ser/de not so useful</li>
<li>SDK that uses event stream, such as <code>aws-sdk-transcribestreaming</code> only has just over 5000 all-time downloads with recent downloads of just under 1000 as of writing (2023/01/21); It makes it difficult to justify since the implementation impacts smaller number of people.</li>
</ul>
<h2 id="serde-traits-implemented-on-builder-of-output-types"><a class="header" href="#serde-traits-implemented-on-builder-of-output-types"><code>Serde</code> traits implemented on Builder of Output Types</a></h2>
<p>Output data, such as <code>aws_sdk_dynamodb::output::UpdateTableOutput</code> has builder types.
These builder types are available to users, however, no API requires users to build data types by themselves.</p>
<p>We considered removing traits from these data types.</p>
<p>Removing serde traits on these types will help reduce compile time, however, builder type can be useful, for example, for testing.
We have prepared examples <a href="rfcs/UseCaseExamples">here</a>.</p>
<h2 id="fn-set_fields-to-allow-users-to-use-externally-created-input"><a class="header" href="#fn-set_fields-to-allow-users-to-use-externally-created-input"><code>fn set_fields</code> to allow users to use externally created <code>Input</code></a></h2>
<p>Currently, to set the value to fluent builders, users must call setter methods for each field.
SDK does not have a method that allows users to use deserialized <code>Input</code>.
Thus, we add a new method <code>fn set_fields</code> to <code>Client</code> types.
This method accepts inputs and replaces all parameters that <code>Client</code> has with the new one.</p>
<pre><code class="language-rust ignore">pub fn set_fields(mut self, input_type: path::to::input_type) -&gt; path::to::input_type {
    self.inner = input_type;
    self
}</code></pre>
<p>Users can use <code>fn set_fields</code> to replace the parameters in fluent builders.
You can find examples <a href="rfcs/rfc0030_serialization_and_deserialization.html#UseCaseExamples">here</a>.</p>
<h1 id="other-concerns"><a class="header" href="#other-concerns">Other Concerns</a></h1>
<h2 id="model-evolution"><a class="header" href="#model-evolution">Model evolution</a></h2>
<p>SDK will introduce new fields and we may see new data types in the future.</p>
<p>We believe that this will not be a problem.</p>
<h3 id="introduction-of-new-fields"><a class="header" href="#introduction-of-new-fields">Introduction of New Fields</a></h3>
<p>Most fields are <code>Option&lt;T&gt;</code> type.
When the user de-serializes data written for a format before the new fields were introduced, new fields will be assigned with <code>None</code> type.</p>
<p>If a field isn't <code>Option</code>, <code>serde</code> uses <code>Default</code> trait unless a custom de-serialization/serialization is specified to generate data to fill the field.
If the new field is not an <code>Option&lt;T&gt;</code> type and has no <code>Default</code> implementation, we must implement a custom de-serialization logic.</p>
<p>In the case of serialization, the introduction of new fields will not be an issue unless the data format requires a schema. (e.g. parquet, avro) However, this is outside the scope of this RFC.</p>
<h2 id="introduction-of-new-data-type"><a class="header" href="#introduction-of-new-data-type">Introduction of New Data Type</a></h2>
<p>If a new field introduces a new data type, it will not require any additional work if the data type can derive <code>serde</code> traits.</p>
<p>If the data cannot derive <code>serde</code> traits on its own, then we have two options.
To clarify, this is the same approach we took on <code>Data Type to skip</code> section.</p>
<ol>
<li>skip
We will simply skip serializing/de-serializing. However, we may need to implement custom serialization/de-serialization logic if a value is not wrapped with <code>Option</code>.</li>
<li>custom serialization/de-serialization logic
We can implement tailored serialization/de-serialization logic.</li>
</ol>
<p>Either way, we will mention this on the generated docs to avoid surprising users.</p>
<p>e.g.</p>
<pre><code class="language-rust ignore">#[derive(serde::Serialize, serde::Deserialize)]
struct OutputV1 {
  string_field: Option&lt;String&gt;
}

#[derive(serde::Serialize, serde::Deserialize)]
struct OutputV2 {
  string_field: Option&lt;String&gt;,
  // this will always be treated as None value by serde
  #[serde(skip)]
  skip_not_serializable: Option&lt;SomeComplexDataType&gt;,
  // We can implement a custom serialization logic
  #[serde(serialize_with = "custom_serilization_logic", deserialize_with = "custom_deserilization_logic")]
  not_derive_able: SomeComplexDataType,
  // Serialization will be skipped, and de-serialization will be handled with the function provided on default tag
  #[serde(skip, default = "default_value")]
  skip_with_custom: DataTypeWithoutDefaultTrait,
}</code></pre>
<h1 id="discussions"><a class="header" href="#discussions">Discussions</a></h1>
<h2 id="sensitive-information"><a class="header" href="#sensitive-information">Sensitive Information</a></h2>
<p>If serialized data contains sensitive information, it will not be masked.
We mention that fields can compromise such information on every struct field to ensure that users know this.</p>
<h2 id="compile-time"><a class="header" href="#compile-time">Compile Time</a></h2>
<p>We ran the following benchmark on C6a.2xlarge instance with 50gb of GP2 SSD.
The commit hash of the code is a8e2e19129aead4fbc8cf0e3d34df0188a62de9f.</p>
<p>It clearly shows an increase in compile time.
Users are advised to consider the use of software such as <a href="https://github.com/mozilla/sccache">sccache</a> or <a href="https://github.com/rui314/mold">mold</a> to reduce the compile time.</p>
<ul>
<li>
<p><code>aws-sdk-dynamodb</code></p>
<ul>
<li>
<p>when compiled with debug profile</p>
<div class="table-wrapper"><table><thead><tr><th>command</th><th>real time</th><th>user time</th><th>sys time</th></tr></thead><tbody>
<tr><td>cargo build</td><td>0m35.728s</td><td>2m24.243s</td><td>0m11.868s</td></tr>
<tr><td>cargo build --features unstable-serde-serialize</td><td>0m38.079s</td><td>2m26.082s</td><td>0m11.631s</td></tr>
<tr><td>cargo build --features unstable-serde-deserialize</td><td>0m45.689s</td><td>2m34.000s</td><td>0m11.978s</td></tr>
<tr><td>cargo build --all-features</td><td>0m48.959s</td><td>2m45.688s</td><td>0m13.359s</td></tr>
</tbody></table>
</div></li>
<li>
<p>when compiled with release profile</p>
<div class="table-wrapper"><table><thead><tr><th>command</th><th>real time</th><th>user time</th><th>sys time</th></tr></thead><tbody>
<tr><td>cargo build --release</td><td>0m52.040s</td><td>5m0.841s</td><td>0m11.313s</td></tr>
<tr><td>cargo build --release --features unstable-serde-serialize</td><td>0m53.153s</td><td>5m4.069s</td><td>0m11.577s</td></tr>
<tr><td>cargo build --release --features unstable-serde-deserialize</td><td>1m0.107s</td><td>5m10.231s</td><td>0m11.699s</td></tr>
<tr><td>cargo build --release --all-features</td><td>1m3.198s</td><td>5m26.076s</td><td>0m12.311s</td></tr>
</tbody></table>
</div></li>
</ul>
</li>
<li>
<p><code>aws-sdk-ec2</code></p>
<ul>
<li>
<p>when compiled with debug profile</p>
<div class="table-wrapper"><table><thead><tr><th>command</th><th>real time</th><th>user time</th><th>sys time</th></tr></thead><tbody>
<tr><td>cargo build</td><td>1m20.041s</td><td>2m14.592s</td><td>0m6.611s</td></tr>
<tr><td>cargo build --features unstable-serde-serialize</td><td>2m0.555s</td><td>4m24.881s</td><td>0m16.131s</td></tr>
<tr><td>cargo build --features unstable-serde-deserialize</td><td>3m10.857s</td><td>5m34.246s</td><td>0m18.844s</td></tr>
<tr><td>cargo build --all-features</td><td>3m31.473s</td><td>6m1.052s</td><td>0m19.681s</td></tr>
</tbody></table>
</div></li>
<li>
<p>when compiled with release profile</p>
<div class="table-wrapper"><table><thead><tr><th>command</th><th>real time</th><th>user time</th><th>sys time</th></tr></thead><tbody>
<tr><td>cargo build --release</td><td>2m29.480s</td><td>9m19.530s</td><td>0m15.957s</td></tr>
<tr><td>cargo build --release --features unstable-serde-serialize</td><td>2m45.002s</td><td>9m43.098s</td><td>0m16.886s</td></tr>
<tr><td>cargo build --release --features unstable-serde-deserialize</td><td>3m47.531s</td><td>10m52.017s</td><td>0m18.404s</td></tr>
<tr><td>cargo build --release --all-features</td><td>3m45.208s</td><td>8m46.168s</td><td>0m10.211s</td></tr>
</tbody></table>
</div></li>
</ul>
</li>
</ul>
<h2 id="misleading-results"><a class="header" href="#misleading-results">Misleading Results</a></h2>
<p>SDK team previously expressed concern that serialized data may be misleading.
We believe that features implemented as part of this RFC do not produce a misleading result as we focus on builder types and it's corresponding data types which are mapped to serde's data type model with the derive macro.</p>
<h1 id="appendix"><a class="header" href="#appendix">Appendix</a></h1>
<h2 id="use-case-examples"><a class="header" href="#use-case-examples"><a href="rfcs/UseCaseExamples">Use Case Examples</a></a></h2>
<pre><code class="language-rust ignore">use aws_sdk_dynamodb::{Client, Error};

async fn example(read_builder: bool) -&gt; Result&lt;(), Error&gt; {
    // getting the client
    let shared_config = aws_config::load_from_env().await;
    let client = Client::new(&amp;shared_config);

    // de-serializing input's builder types and input types from json
    let deserialized_input = if read_builder {
      let mut parameter: aws_sdk_dynamodb::input::list_tables_input::Builder = serde_json::from_str(include_str!("./builder.json"));
      parameter.set_exclusive_start_table_name("some_name").build()
    } else {
      let input: aws_sdk_dynamodb::input::ListTablesInput = serde_json::from_str(include_str!("./input.json"));
      input
    };

    // sending request using the deserialized input
    let res = client.list_tables().set_fields(deserialized_input).send().await?;
    println!("DynamoDB tables: {:?}", res.table_names);

    let out: aws_sdk_dynamodb::output::ListTablesOutput = {
      // say you want some of the field to have certain values
      let mut out_builder: aws_sdk_dynamodb::output::list_tables_output::Builder = serde_json::from_str(r#"
        {
          table_names: [ "table1", "table2" ]
        }
      "#);
      // but you don't really care about some other values
      out_builder.set_last_evaluated_table_name(res.last_evaluated_table_name()).build()
    };
    assert_eq!(res, out);

    // serializing json output
    let json_output = serde_json::to_string(res).unwrap();
    // you can save the serialized input
    println!(json_output);
    Ok(())
}</code></pre>
<h2 id="changes-checklist-23"><a class="header" href="#changes-checklist-23">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Implement human-redable serialization for <code>DateTime</code> and <code>Blob</code> in <code>aws_smithy_types</code></li>
<li><input disabled="" type="checkbox"/>
Implement non-human-redable serialization for <code>DateTime</code> and <code>Blob</code> in <code>aws_smithy_types</code></li>
<li><input disabled="" type="checkbox"/>
Implement <code>Serialize</code> and <code>Deserialize</code> for relevant data types in <code>aws_smithy_types</code></li>
<li><input disabled="" type="checkbox"/>
Modify Kotlin's codegen so that generated Builder and non-Builder types implement <code>Serialize</code> and <code>Deserialize</code></li>
<li><input disabled="" type="checkbox"/>
Add feature gate for <code>Serialize</code> and <code>Deserialize</code></li>
<li><input disabled="" type="checkbox"/>
Prepare examples</li>
<li><input disabled="" type="checkbox"/>
Prepare reproducible compile time benchmark</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-providing-fallback-credentials-on-external-timeout"><a class="header" href="#rfc-providing-fallback-credentials-on-external-timeout">RFC: Providing fallback credentials on external timeout</a></h1>
<blockquote>
<p>Status: Implemented in <a href="https://github.com/smithy-lang/smithy-rs/pull/2246">smithy-rs#2246</a></p>
<p>Applies to: client</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0031_providing_fallback_credentials_on_timeout.html#changes-checklist">Changes Checklist</a> section.</p>
<p>This RFC proposes a fallback mechanism for credentials providers on external timeout (see the <a href="rfcs/rfc0031_providing_fallback_credentials_on_timeout.html#terminology">Terminology</a> section), allowing them to continue serving (possibly expired) credentials for the sake of overall reliability of the intended service; The IMDS credentials provider is an example that must fulfill such a requirement to support static stability.</p>
<h2 id="terminology-16"><a class="header" href="#terminology-16">Terminology</a></h2>
<ul>
<li>External timeout: The name of the timeout that occurs when a duration elapses before an async call to <code>provide_credentials</code> returns. In this case, <code>provide_credentials</code> returns no credentials.</li>
<li>Internal timeout: The name of the timeout that occurs when a duration elapses before an async call to some function, inside the implementation of <code>provide_credentials</code>, returns. Examples include connection timeouts, TLS negotiation timeouts, and HTTP request timeouts. Implementations of <code>provide_credentials</code> may handle these failures at their own discretion e.g. by returning <em>(possibly expired)</em> credentials or a <code>CredentialsError</code>.</li>
<li>Static stability: Continued availability of a service in the face of impaired dependencies.</li>
</ul>
<h2 id="assumption"><a class="header" href="#assumption">Assumption</a></h2>
<p>This RFC is concerned only with external timeouts, as the cost of poor API design is much higher in this case than for internal timeouts. The former will affect a public trait implemented by all credentials providers whereas the latter can be handled locally by individual credentials providers without affecting one another.</p>
<h2 id="problem"><a class="header" href="#problem">Problem</a></h2>
<p>We have mentioned static stability. Supporting it calls for the following functional requirement, among others:</p>
<ul>
<li>REQ 1: Once a credentials provider has served credentials, it should continue serving them in the event of a timeout (whether internal or external) while obtaining refreshed credentials.</li>
</ul>
<p>Today, we have the following trait method to obtain credentials:</p>
<pre><code class="language-rust ignore">fn provide_credentials&lt;'a&gt;(&amp;'a self) -&gt; future::ProvideCredentials&lt;'a&gt;
where
    Self: 'a,</code></pre>
<p>This method returns a future, which can be raced against a timeout future as demonstrated by the following code snippet from <code>LazyCredentialsCache</code>:</p>
<pre><code class="language-rust ignore">let timeout_future = self.sleeper.sleep(self.load_timeout); // by default self.load_timeout is 5 seconds.
// --snip--
let future = Timeout::new(provider.provide_credentials(), timeout_future);
let result = cache
   .get_or_load(|| async move {
        let credentials = future.await.map_err(|_err| {
            CredentialsError::provider_timed_out(load_timeout)
        })??;
        // --snip--
    }).await;
// --snip--</code></pre>
<p>This creates an external timeout for <code>provide_credentials</code>. If <code>timeout_future</code> wins the race, a future for <code>provide_credentials</code> gets dropped, <code>timeout_future</code> returns an error, and the error is mapped to <code>CredentialsError::ProviderTimedOut</code> and returned. This makes it impossible for the variable <code>provider</code> above to serve credentials as stated in REQ 1.</p>
<p>A more complex use case involves <code>CredentialsProviderChain</code>. It is a manifestation of the chain of responsibility pattern and keeps calling the <code>provide_credentials</code> method on each credentials provider down the chain until credentials are returned by one of them. In addition to REQ 1, we have the following functional requirement with respect to <code>CredentialsProviderChain</code>:</p>
<ul>
<li>REQ 2: Once a credentials provider in the chain has returned credentials, it should continue serving them even in the event of a timeout (whether internal or external) without falling back to another credentials provider.</li>
</ul>
<p>Referring back to the code snippet above, we analyze two relevant cases (and suppose provider 2 below must meet REQ 1 and REQ 2 in each case):</p>
<p><strong>Case 1:</strong> Provider 2 successfully loaded credentials but later failed to do so because an external timeout kicked in.</p>
<p align="center">
<img width="750" alt="chain-provider-ext-timeout-1" src="https://user-images.githubusercontent.com/15333866/212421638-d08e4821-2dbe-497f-82c5-c78aab8acbe9.png">
</p>
<p>The figure above illustrates an example. This <code>CredentialsProviderChain</code> consists of three credentials providers. When <code>CredentialsProviderChain::provide_credentials</code> is called, provider 1's <code>provide_credentials</code> is called but does not find credentials so passes the torch to provider 2, which in turn successfully loads credentials and returns them. The next time the method is called, provider 1 does not find credentials but neither does provider 2 this time, because an external timeout by <code>timeout_future</code> given to the whole chain kicked in and the future is dropped while provider 2's <code>provide_credentials</code> was running. Given the functional requirements, provider 2 should return the previously available credentials but today the code snippet from <code>LazyCredentialsCache</code> returns a <code>CredentialsError::ProviderTimedOut</code> instead.</p>
<p><strong>Case 2:</strong> Provider 2 successfully loaded credentials but later was not reached because its preceding provider was still running when an external timeout kicked in.</p>
<p align="center">
<img width="750" alt="chain-provider-ext-timeout-2" src="https://user-images.githubusercontent.com/15333866/212421712-8c6eab11-a0c1-4229-8ba3-67b0bb6056e7.png">
</p>
<p>The figure above illustrates an example with the same setting as the previous figure. Again, when <code>CredentialsProviderChain::provide_credentials</code> is called the first time, provider 1 does not find credentials but provider 2 does. The next time the method is called, provider 1 is still executing <code>provide_credentials</code> and then an external timeout by <code>timeout_future</code> kicked in. Consequently, the execution of <code>CredentialsProviderChain::provide_credentials</code> has been terminated. Given the functional requirements, provider 2 should return the previously available credentials but today the code snippet from <code>LazyCredentialsCache</code> returns <code>CredentialsError::ProviderTimedOut</code> instead.</p>
<h2 id="proposal-4"><a class="header" href="#proposal-4">Proposal</a></h2>
<p>To address the problem in the previous section, we propose to add a new method to the <code>ProvideCredentials</code> trait called <code>fallback_on_interrupt</code>. This method allows credentials providers to have a fallback mechanism on an external timeout and to serve credentials to users if needed. There are two options as to how it is implemented, either as a synchronous primitive or as an asynchronous primitive.</p>
<h4 id="option-a-synchronous-primitive"><a class="header" href="#option-a-synchronous-primitive">Option A: Synchronous primitive</a></h4>
<pre><code class="language-rust ignore">pub trait ProvideCredentials: Send + Sync + std::fmt::Debug {
    // --snip--

    fn fallback_on_interrupt(&amp;self) -&gt; Option&lt;Credentials&gt; {
        None
    }
}</code></pre>
<ul>
<li>:+1: Users can be guided to use only synchronous primitives when implementing <code>fallback_on_interrupt</code>.</li>
<li>:-1: It cannot support cases where fallback credentials are asynchronously retrieved.</li>
<li>:-1: It may turn into a blocking operation if it takes longer than it should.</li>
</ul>
<h4 id="option-b-asynchronous-primitive"><a class="header" href="#option-b-asynchronous-primitive">Option B: Asynchronous primitive</a></h4>
<pre><code class="language-rust ignore">mod future {
    // --snip--

    // This cannot use `OnlyReady` in place of `BoxFuture` because
    // when a chain of credentials providers implements its own
    // `fallback_on_interrupt`, it needs to await fallback credentials
    // in its inner providers. Thus, `BoxFuture` is required.
    pub struct FallbackOnInterrupt&lt;'a&gt;(NowOrLater&lt;Option&lt;Credentials&gt;, BoxFuture&lt;'a, Option&lt;Credentials&gt;&gt;&gt;);

    // impls for FallbackOnInterrupt similar to those for the ProvideCredentials future newtype
}

pub trait ProvideCredentials: Send + Sync + std::fmt::Debug {
    // --snip--

    fn fallback_on_interrupt&lt;'a&gt;(&amp;'a self) -&gt; future::FallbackOnInterrupt&lt;'a&gt; {
        future::FallbackOnInterrupt::ready(None)
    }
}</code></pre>
<ul>
<li>:+1: It is async from the beginning, so less likely to introduce a breaking change.</li>
<li>:-1: We may have to consider yet another timeout for <code>fallback_on_interrupt</code> itself.</li>
</ul>
<p>Option A cannot be reversible in the future if we are to support the use case for asynchronously retrieving the fallback credentials, whereas option B allows us to continue supporting both ready and pending futures when retrieving the fallback credentials. However, <code>fallback_on_interrupt</code> is supposed to return credentials that have been set aside in case <code>provide_credentials</code> is timed out. To express that intent, we choose option A and document that users should NOT go fetch new credentials in <code>fallback_on_interrupt</code>.</p>
<p>The user experience for the code snippet in question will look like this once this proposal is implemented:</p>
<pre><code class="language-rust ignore">let timeout_future = self.sleeper.sleep(self.load_timeout); // by default self.load_timeout is 5 seconds.
// --snip--
let future = Timeout::new(provider.provide_credentials(), timeout_future);
let result = cache
    .get_or_load(|| {
        async move {
           let credentials = match future.await {
                Ok(creds) =&gt; creds?,
                Err(_err) =&gt; match provider.fallback_on_interrupt() { // can provide fallback credentials
                    Some(creds) =&gt; creds,
                    None =&gt; return Err(CredentialsError::provider_timed_out(load_timeout)),
                }
            };
            // --snip--
        }
    }).await;
// --snip--</code></pre>
<h2 id="how-to-actually-implement-this-rfc-2"><a class="header" href="#how-to-actually-implement-this-rfc-2">How to actually implement this RFC</a></h2>
<p>Almost all credentials providers do not have to implement their own <code>fallback_on_interrupt</code> except for <code>CredentialsProviderChain</code> (<code>ImdsCredentialsProvider</code> also needs to implement <code>fallback_on_interrupt</code> when we are adding static stability support to it but that is outside the scope of this RFC).</p>
<p>Considering the two cases we analyzed above, implementing <code>CredentialsProviderChain::fallback_on_interrupt</code> is not so straightforward. Keeping track of whose turn in the chain it is to call <code>provide_credentials</code> when an external timeout has occurred is a challenging task. Even if we figured it out, that would still not satisfy <code>Case 2</code> above, because it was provider 1 that was actively running when the external timeout kicked in, but the chain should return credentials from provider 2, not from provider 1.</p>
<p>With that in mind, consider instead the following approach:</p>
<pre><code class="language-rust ignore">impl ProvideCredentials for CredentialsProviderChain {
    // --snip--

    fn fallback_on_interrupt(&amp;self) -&gt; Option&lt;Credentials&gt; { {
        for (_, provider) in &amp;self.providers {
            match provider.fallback_on_interrupt() {
                creds @ Some(_) =&gt; return creds,
                None =&gt; {}
            }
        }
        None
    }
}</code></pre>
<p><code>CredentialsProviderChain::fallback_on_interrupt</code> will invoke each provider's <code>fallback_on_interrupt</code> method until credentials are returned by one of them. It ensures that the updated code snippet for <code>LazyCredentialsCache</code> can return credentials from provider 2 in both <code>Case 1</code> and <code>Case 2</code>. Even if <code>timeout_future</code> wins the race, the execution subsequently calls <code>provider.fallback_on_interrupt()</code> to obtain fallback credentials from provider 2, assuming provider 2's <code>fallback_on_interrupt</code> is implemented to return fallback credentials accordingly.</p>
<p>The downside of this simple approach is that the behavior is not clear if more than one credentials provider in the chain can return credentials from their <code>fallback_on_interrupt</code>. Note, however, that it is the exception rather than the norm for a provider's <code>fallback_on_interrupt</code> to return fallback credentials, at least at the time of writing (01/13/2023). The fact that it returns fallback credentials means that the provider successfully loaded credentials at least once, and it usually continues serving credentials on subsequent calls to <code>provide_credentials</code>.</p>
<p>Should we have more than one provider in the chain that can potentially return fallback credentials from <code>fallback_on_interrupt</code>, we could configure the behavior of <code>CredentialsProviderChain</code> managing in what order and how each <code>fallback_on_interrupt</code> should be executed. See the <a href="rfcs/rfc0031_providing_fallback_credentials_on_timeout.html#possible-enhancement">Possible enhancement
</a> section for more details. The use case described there is an extreme edge case, but it's worth exploring what options are available to us with the proposed design.</p>
<h2 id="alternative"><a class="header" href="#alternative">Alternative</a></h2>
<p>In this section, we will describe an alternative approach that we ended up dismissing as unworkable.</p>
<p>Instead of <code>fallback_on_interrupt</code>, we considered the following method to be added to the <code>ProvideCredentials</code> trait:</p>
<pre><code class="language-rust ignore">pub trait ProvideCredentials: Send + Sync + std::fmt::Debug {
    // --snip--

    /// Returns a future that provides credentials within the given `timeout`.
    ///
    /// The default implementation races `provide_credentials` against
    /// a timeout future created from `timeout`.
    fn provide_credentials_with_timeout&lt;'a&gt;(
        &amp;'a self,
        sleeper: Arc&lt;dyn AsyncSleep&gt;,
        timeout: Duration,
    ) -&gt; future::ProvideCredentials&lt;'a&gt;
    where
        Self: 'a,
    {
        let timeout_future = sleeper.sleep(timeout);
        let future = Timeout::new(self.provide_credentials(), timeout_future);
        future::ProvideCredentials::new(async move {
            let credentials = future
                .await
                .map_err(|_err| CredentialsError::provider_timed_out(timeout))?;
            credentials
        })
    }</code></pre>
<p><code>provide_credentials_with_timeout</code> encapsulated the timeout race and allowed users to specify how long the external timeout for <code>provide_credentials</code> would be. The code snippet from <code>LazyCredentialsCache</code> then looked like</p>
<pre><code class="language-rust ignore">let sleeper = Arc::clone(&amp;self.sleeper);
let load_timeout = self.load_timeout; // by default self.load_timeout is 5 seconds.
// --snip--
let result = cache
    .get_or_load(|| {
        async move {
            let credentials = provider
                .provide_credentials_with_timeout(sleeper, load_timeout)
                .await?;
            // --snip--
        }
    }).await;
// --snip--</code></pre>
<p>However, implementing <code>CredentialsProviderChain::provide_credentials_with_timeout</code> quickly ran into the following problem:</p>
<pre><code class="language-rust ignore">impl ProvideCredentials for CredentialsProviderChain {
    // --snip--

    fn provide_credentials_with_timeout&lt;'a&gt;(
        &amp;'a self,
        sleeper: Arc&lt;dyn AsyncSleep&gt;,
        timeout: Duration,
    ) -&gt; future::ProvideCredentials&lt;'a&gt;
    where
        Self: 'a,
    {
        future::ProvideCredentials::new(self.credentials_with_timeout(sleeper, timeout))
    }
}

impl CredentialsProviderChain {
    // --snip--

    async fn credentials_with_timeout(
        &amp;self,
        sleeper: Arc&lt;dyn AsyncSleep&gt;,
        timeout: Duration,
    ) -&gt; provider::Result {
        for (_, provider) in &amp;self.providers {
            match provider
                .provide_credentials_with_timeout(Arc::clone(&amp;sleeper), /* how do we calculate timeout for each provider ? */)
                .await
            {
                Ok(credentials) =&gt; {
                    return Ok(credentials);
                }
                Err(CredentialsError::ProviderTimedOut(_)) =&gt; {
                    // --snip--
                }
                Err(err) =&gt; {
                   // --snip--
                }
           }
        }
        Err(CredentialsError::provider_timed_out(timeout))
    }</code></pre>
<p>There are mainly two problems with this approach. The first problem is that as shown above, there is no sensible way to calculate a timeout for each provider in the chain. The second problem is that exposing a parameter like <code>timeout</code> at a public trait's level is giving too much control to users; delegating overall timeout to the individual provider means each provider has to get it right.</p>
<h2 id="changes-checklist-24"><a class="header" href="#changes-checklist-24">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Add <code>fallback_on_interrupt</code> method to the <code>ProvideCredentials</code> trait with the default implementation</li>
<li><input disabled="" type="checkbox"/>
Implement <code>CredentialsProviderChain::fallback_on_interrupt</code></li>
<li><input disabled="" type="checkbox"/>
Implement <code>DefaultCredentialsChain::fallback_on_interrupt</code></li>
<li><input disabled="" type="checkbox"/>
Add unit tests for <code>Case 1</code> and <code>Case 2</code></li>
</ul>
<h2 id="possible-enhancement"><a class="header" href="#possible-enhancement">Possible enhancement</a></h2>
<p>We will describe how to customize the behavior for <code>CredentialsProviderChain::fallback_on_interrupt</code>. We are only demonstrating how much the proposed design can be extended and currently do not have concrete use cases to implement using what we present in this section.</p>
<p>As described in the <a href="rfcs/rfc0031_providing_fallback_credentials_on_timeout.html#proposal">Proposal</a> section, <code>CredentialsProviderChain::fallback_on_interrupt</code> traverses the chain from the head to the tail and returns the first fallback credentials found. This precedence policy works most of the time, but when we have more than one provider in the chain that can potentially return fallback credentials, it could break in the following edge case (we are still basing our discussion on the code snippet from <code>LazyCredentialsCache</code> but forget REQ 1 and REQ 2 for the sake of simplicity).</p>
<p align="center">
<img width="800" alt="fallback_on_interrupt_appendix excalidraw" src="https://user-images.githubusercontent.com/15333866/213618808-d19892d8-5c83-4039-9940-280dcd2a8cf1.png">
</p>
<p>During the first call to <code>CredentialsProviderChain::provide_credentials</code>, provider 1 fails to load credentials, maybe due to an internal timeout, and then provider 2 succeeds in loading its credentials (call them credentials 2) and internally stores them for <code>Provider2::fallback_on_interrupt</code> to return them subsequently. During the second call, provider 1 succeeds in loading credentials (call them credentials 1) and internally stores them for <code>Provider1::fallback_on_interrupt</code> to return them subsequently. Suppose, however, that credentials 1's expiry is earlier than credentials 2's expiry. Finally, during the third call, <code>CredentialsProviderChain::provide_credentials</code> did not complete due to an external timeout. <code>CredentialsProviderChain::fallback_on_interrupt</code> then returns credentials 1, when it should return credentials 2 whose expiry is later, because of the precedence policy.</p>
<p>This a case where <code>CredentialsProviderChain::fallback_on_interrupt</code> requires the recency policy for fallback credentials found in provider 1 and provider 2, not the precedence policy. The following figure shows how we can set up such a chain:</p>
<p align="center">
<img width="700" alt="heterogeneous_policies_for_fallback_on_interrupt" src="https://user-images.githubusercontent.com/15333866/213755875-ac6fddbc-0f1b-4437-af16-6e0dbe08ae04.png">
</p>
<p>The outermost chain is a <code>CredentialsProviderChain</code> and follows the precedence policy for <code>fallback_on_interrupt</code>. It contains a sub-chain that, in turn, contains provider 1 and provider 2. This sub-chain implements its own <code>fallback_on_interrupt</code> to realize the recency policy for fallback credentials found in provider 1 and provider 2. Conceptually, we have</p>
<pre><code class="language-rust ignore">pub struct FallbackRecencyChain {
    provider_chain: CredentialsProviderChain,
}

impl ProvideCredentials for FallbackRecencyChain {
    fn provide_credentials&lt;'a&gt;(&amp;'a self) -&gt; future::ProvideCredentials&lt;'a&gt;
    where
        Self: 'a,
    {
        // Can follow the precedence policy for loading credentials
        // if it chooses to do so.
    }

    fn fallback_on_interrupt(&amp;self) -&gt; Option&lt;Credentials&gt; {
        // Iterate over `self.provider_chain` and return
        // fallback credentials whose expiry is the most recent.
    }
}</code></pre>
<p>We can then compose the entire chain like so:</p>
<pre><code class="language-rust ignore">let provider_1 = /* ... */
let provider_2 = /* ... */
let provider_3 = /* ... */

let sub_chain = CredentialsProviderChain::first_try("Provider1", provider_1)
    .or_else("Provider2", provider_2);

let recency_chain = /* Create a FallbackRecencyChain with sub_chain */

let final_chain = CredentialsProviderChain::first_try("fallback_recency", recency_chain)
    .or_else("Provider3", provider_3);</code></pre>
<p>The <code>fallback_on_interrupt</code> method on <code>final_chain</code> still traverses from the head to the tail, but once it hits <code>recency_chain</code>, <code>fallback_on_interrupt</code> on <code>recency_chain</code> respects the expiry of fallback credentials found in its inner providers.</p>
<p>What we have presented in this section can be generalized thanks to chain composability. We could have different sub-chains, each implementing its own policy for <code>fallback_on_interrupt</code>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-better-constraint-violations"><a class="header" href="#rfc-better-constraint-violations">RFC: Better Constraint Violations</a></h1>
<blockquote>
<p>Status: Accepted</p>
<p>Applies to: server</p>
</blockquote>
<p>During and after <a href="https://github.com/smithy-lang/smithy-rs/pull/1199">the design</a> and <a href="https://github.com/smithy-lang/smithy-rs/pull/1342">the core
implementation</a> of <a href="https://awslabs.github.io/smithy/2.0/spec/constraint-traits.html">constraint traits</a> in the server
SDK, some problems relating to constraint violations were identified. This RFC
sets out to explain and address three of them: <a href="rfcs/rfc0032_better_constraint_violations.html#impossible-constraint-violations">impossible constraint
violations</a>, <a href="rfcs/rfc0032_better_constraint_violations.html#collecting-constraint-violations">collecting constraint
violations</a>, and <a href="rfcs/rfc0032_better_constraint_violations.html#tightness-of-constraint-violations">"tightness" of constraint
violations</a>. The RFC explains each of them
in turn, solving them in an iterative and pedagogical manner, i.e. the solution
of a problem depends on the previous ones having been solved with their
proposed solutions. The three problems are meant to be addressed atomically in
one changeset (see the <a href="rfcs/rfc0032_better_constraint_violations.html#checklist">Checklist</a>) section.</p>
<p>Note: code snippets from generated SDKs in this document are abridged so as to
be didactic and relevant to the point being made. They are accurate with
regards to commit <a href="https://github.com/smithy-lang/smithy-rs/tree/2226feff8f7fa884204f81a50d7e016386912acc"><code>2226fe</code></a>.</p>
<h2 id="terminology-17"><a class="header" href="#terminology-17">Terminology</a></h2>
<p><a href="https://github.com/smithy-lang/smithy-rs/pull/1199">The design</a> and the description of <a href="https://github.com/smithy-lang/smithy-rs/pull/1342">the
PR</a> where the core implementation of constraint traits
was made are recommended prior reading to understand this RFC.</p>
<ul>
<li><strong>Shape closure</strong>: the set of shapes a shape can "reach", including itself.</li>
<li><strong>Transitively constrained shape</strong>: a shape whose closure includes:
<ol>
<li>a shape with a <a href="https://awslabs.github.io/smithy/2.0/spec/constraint-traits.html">constraint trait</a> attached,</li>
<li>a (member) shape with a <a href="https://smithy.io/2.0/spec/type-refinement-traits.html#required-trait"><code>required</code> trait</a> attached,</li>
<li>an <a href="https://smithy.io/2.0/spec/simple-types.html#enum"><code>enum</code> shape</a>; or</li>
<li>an <a href="https://smithy.io/2.0/spec/simple-types.html#intenum"><code>intEnum</code> shape</a>.</li>
</ol>
</li>
<li>A <strong>directly constrained shape</strong> is any of these:
<ol>
<li>a shape with a <a href="https://awslabs.github.io/smithy/2.0/spec/constraint-traits.html">constraint trait</a> attached,</li>
<li>a (member) shape with a <a href="https://smithy.io/2.0/spec/type-refinement-traits.html#required-trait"><code>required</code> trait</a> attached,</li>
<li>an <a href="https://smithy.io/2.0/spec/simple-types.html#enum"><code>enum</code> shape</a>,</li>
<li>an <a href="https://smithy.io/2.0/spec/simple-types.html#intenum"><code>intEnum</code> shape</a>; or</li>
<li>a <a href="https://smithy.io/2.0/spec/aggregate-types.html#structure"><code>structure</code> shape</a> with at least one <code>required</code> member shape.</li>
</ol>
</li>
<li><strong>Constrained type</strong>: the Rust type a constrained shape gets rendered as. For
shapes that are not <code>structure</code>, <code>union</code>, <code>enum</code> or <code>intEnum</code> shapes, these
are wrapper <a href="https://doc.rust-lang.org/rust-by-example/generics/new_types.html">newtype</a>s.</li>
</ul>
<p>In the absence of a qualifier, "constrained shape" should be interpreted as
"transitively constrained shape".</p>
<h2 id="impossible-constraint-violations"><a class="header" href="#impossible-constraint-violations">Impossible constraint violations</a></h2>
<h3 id="background-2"><a class="header" href="#background-2">Background</a></h3>
<p>A constrained type has a fallible constructor by virtue of it implementing the
<a href="https://doc.rust-lang.org/std/convert/trait.TryFrom.html"><code>TryFrom</code></a> trait. The error type this constructor may yield is known as a
<strong>constraint violation</strong>:</p>
<pre><code class="language-rust ignore">impl TryFrom&lt;UnconstrainedType&gt; for ConstrainedType {
    type Error = ConstraintViolation;

    fn try_from(value: UnconstrainedType) -&gt; Result&lt;Self, Self::Error&gt; {
        ...
    }
}</code></pre>
<p>The <code>ConstraintViolation</code> type is a Rust <code>enum</code> with one variant per way
"constraining" the input value may fail. So, for example, the following Smithy
model:</p>
<pre><code class="language-smithy">structure A {
    @required
    member: String,
}
</code></pre>
<p>Yields:</p>
<pre><code class="language-rust ignore">/// See [`A`](crate::model::A).
pub mod a {
    #[derive(std::cmp::PartialEq, std::fmt::Debug)]
    /// Holds one variant for each of the ways the builder can fail.
    pub enum ConstraintViolation {
        /// `member` was not provided but it is required when building `A`.
        MissingMember,
    }
}</code></pre>
<p>Constraint violations are always Rust <code>enum</code>s, even if they only have one
variant.</p>
<p>Constraint violations can occur in application code:</p>
<pre><code class="language-rust ignore">use my_server_sdk::model

let res = model::a::Builder::default().build(); // We forgot to set `member`.

match res {
    Ok(a) =&gt; { ... },
    Err(e) =&gt; {
        assert_eq!(model::a::ConstraintViolation::MissingMember, e);
    }
}</code></pre>
<h3 id="problem-1"><a class="header" href="#problem-1">Problem</a></h3>
<p>Currently, the constraint violation types we generate are used by <em>both</em>:</p>
<ol>
<li>the server framework upon request deserialization; and</li>
<li>by users in application code.</li>
</ol>
<p>However, the kinds of constraint violations that can occur in application code
can sometimes be a <em>strict subset</em> of those that can occur during request
deserialization.</p>
<p>Consider the following model:</p>
<pre><code class="language-smithy">@length(min: 1, max: 69)
map LengthMap {
    key: String,
    value: LengthString
}

@length(min: 2, max: 69)
string LengthString
</code></pre>
<p>This produces:</p>
<pre><code class="language-rust ignore">pub struct LengthMap(
    pub(crate) std::collections::HashMap&lt;std::string::String, crate::model::LengthString&gt;,
);

impl
    std::convert::TryFrom&lt;
        std::collections::HashMap&lt;std::string::String, crate::model::LengthString&gt;,
    &gt; for LengthMap
{
    type Error = crate::model::length_map::ConstraintViolation;

    /// Constructs a `LengthMap` from an
    /// [`std::collections::HashMap&lt;std::string::String,
    /// crate::model::LengthString&gt;`], failing when the provided value does not
    /// satisfy the modeled constraints.
    fn try_from(
        value: std::collections::HashMap&lt;std::string::String, crate::model::LengthString&gt;,
    ) -&gt; Result&lt;Self, Self::Error&gt; {
        let length = value.len();
        if (1..=69).contains(&amp;length) {
            Ok(Self(value))
        } else {
            Err(crate::model::length_map::ConstraintViolation::Length(length))
        }
    }
}

pub mod length_map {
    pub enum ConstraintViolation {
        Length(usize),
        Value(
            std::string::String,
            crate::model::length_string::ConstraintViolation,
        ),
    }
    ...
}</code></pre>
<p>Observe how the <code>ConstraintViolation::Value</code> variant is never constructed.
Indeed, this variant is impossible to be constructed <em>in application code</em>: a
user has to provide a map whose values are already constrained <code>LengthString</code>s
to the <code>try_from</code> constructor, which only enforces the map's <code>@length</code> trait.</p>
<p>The reason why these seemingly "impossible violations" are being generated is
because they can arise during request deserialization. Indeed, the server
framework deserializes requests into <strong>fully unconstrained types</strong>. These are
types holding unconstrained types all the way through their closures. For
instance, in the case of structure shapes, builder types (the unconstrained
type corresponding to the structure shape) <a href="https://github.com/smithy-lang/smithy-rs/pull/1342">hold
builders</a> all the way down.</p>
<p>In the case of the above model, below is the alternate <code>pub(crate)</code> constructor
the server framework uses upon deserialization. Observe how
<code>LengthMapOfLengthStringsUnconstrained</code> is <em>fully unconstrained</em> and how the
<code>try_from</code> constructor can yield <code>ConstraintViolation::Value</code>.</p>
<pre><code class="language-rust ignore">pub(crate) mod length_map_of_length_strings_unconstrained {
    #[derive(Debug, Clone)]
    pub(crate) struct LengthMapOfLengthStringsUnconstrained(
        pub(crate) std::collections::HashMap&lt;std::string::String, std::string::String&gt;,
    );

    impl std::convert::TryFrom&lt;LengthMapOfLengthStringsUnconstrained&gt;
        for crate::model::LengthMapOfLengthStrings
    {
        type Error = crate::model::length_map_of_length_strings::ConstraintViolation;
        fn try_from(value: LengthMapOfLengthStringsUnconstrained) -&gt; Result&lt;Self, Self::Error&gt; {
            let res: Result&lt;
                std::collections::HashMap&lt;std::string::String, crate::model::LengthString&gt;,
                Self::Error,
            &gt; = value
                .0
                .into_iter()
                .map(|(k, v)| {
                    let v: crate::model::LengthString = k.try_into().map_err(Self::Error::Key)?;

                    Ok((k, v))
                })
                .collect();
            let hm = res?;
            Self::try_from(hm)
        }
    }
}</code></pre>
<p>In conclusion, the user is currently exposed to an internal detail of how the
framework operates that has no bearing on their application code. They
shouldn't be exposed to impossible constraint violation variants in their Rust
docs, nor have to <code>match</code> on these variants when handling errors.</p>
<p>Note: <a href="https://github.com/smithy-lang/smithy-rs/blob/27020be3421fb93e35692803f9a795f92feb1d19/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/MapConstraintViolationGenerator.kt#L66-L69">this comment</a> alludes to the problem described above.</p>
<h3 id="solution-proposal"><a class="header" href="#solution-proposal">Solution proposal</a></h3>
<p>The problem can be mitigated by adding <code>#[doc(hidden)]</code> to the internal
variants and <code>#[non_exhaustive]</code> to the enum. We're already doing this in some
constraint violation types.</p>
<p>However, a "less leaky" solution is achieved by <em>splitting</em> the constraint
violation type into two types, which this RFC proposes:</p>
<ol>
<li>one for use by the framework, with <code>pub(crate)</code> visibility, named
<code>ConstraintViolationException</code>; and</li>
<li>one for use by user application code, with <code>pub</code> visibility, named
<code>ConstraintViolation</code>.</li>
</ol>
<pre><code class="language-rust ignore">pub mod length_map {
    pub enum ConstraintViolation {
        Length(usize),
    }
    pub (crate) enum ConstraintViolationException {
        Length(usize),
        Value(
            std::string::String,
            crate::model::length_string::ConstraintViolation,
        ),
    }
}</code></pre>
<p>Note that, to some extent, the spirit of this approach is <a href="https://github.com/smithy-lang/smithy-rs/blob/9a4c1f304f6f5237d480cfb56dad2951d927d424/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/ServerBuilderGenerator.kt#L78-L81">already currently
present</a>
in the case of builder types when <code>publicConstrainedTypes</code> is set to <code>false</code>:</p>
<ol>
<li><a href="https://github.com/smithy-lang/smithy-rs/blob/2226feff8f7fa884204f81a50d7e016386912acc/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/ServerBuilderGenerator.kt"><code>ServerBuilderGenerator.kt</code></a> renders the usual builder type that enforces
constraint traits, setting its visibility to <code>pub (crate)</code>, for exclusive
use by the framework.</li>
<li><a href="https://github.com/smithy-lang/smithy-rs/blob/2226feff8f7fa884204f81a50d7e016386912acc/codegen-server/src/main/kotlin/software/amazon/smithy/rust/codegen/server/smithy/generators/ServerBuilderGeneratorWithoutPublicConstrainedTypes.kt"><code>ServerBuilderGeneratorWithoutPublicConstrainedTypes.kt</code></a> renders the
builder type the user is exposed to: this builder does not take in
constrained types and does not enforce all modeled constraints.</li>
</ol>
<h2 id="collecting-constraint-violations"><a class="header" href="#collecting-constraint-violations">Collecting constraint violations</a></h2>
<h3 id="background-3"><a class="header" href="#background-3">Background</a></h3>
<p>Constrained operations are currently required to have
<code>smithy.framework#ValidationException</code> as a member in their <a href="https://smithy.io/2.0/spec/service-types.html#operation"><code>errors</code>
property</a>. This is the
shape that is rendered in responses when a request contains data that violates
the modeled constraints.</p>
<p>The shape is defined in the
<a href="https://search.maven.org/artifact/software.amazon.smithy/smithy-validation-model"><code>smithy-validation-model</code></a>
Maven package, <a href="https://github.com/awslabs/smithy/blob/main/smithy-validation-model/model/smithy.framework.validation.smithy">as
follows</a>:</p>
<pre><code class="language-smithy">$version: "2.0"

namespace smithy.framework

/// A standard error for input validation failures.
/// This should be thrown by services when a member of the input structure
/// falls outside of the modeled or documented constraints.
@error("client")
structure ValidationException {

    /// A summary of the validation failure.
    @required
    message: String,

    /// A list of specific failures encountered while validating the input.
    /// A member can appear in this list more than once if it failed to satisfy multiple constraints.
    fieldList: ValidationExceptionFieldList
}

/// Describes one specific validation failure for an input member.
structure ValidationExceptionField {
    /// A JSONPointer expression to the structure member whose value failed to satisfy the modeled constraints.
    @required
    path: String,

    /// A detailed description of the validation failure.
    @required
    message: String
}

list ValidationExceptionFieldList {
    member: ValidationExceptionField
}
</code></pre>
<p>It was mentioned in the <a href="https://github.com/smithy-lang/smithy-rs/pull/1199#discussion_r809300673">constraint traits
RFC</a>, and
implicit in the definition of Smithy's
<a href="https://github.com/awslabs/smithy/blob/main/smithy-validation-model/model/smithy.framework.validation.smithy"><code>smithy.framework.ValidationException</code></a>
shape, that server frameworks should respond with a <em>complete</em> collection of
errors encountered during constraint trait enforcement to the client.</p>
<h3 id="problem-2"><a class="header" href="#problem-2">Problem</a></h3>
<p>As of writing, the <code>TryFrom</code> constructor of constrained types whose shapes have
more than one constraint trait attached can only yield a single error. For
example, the following shape:</p>
<pre><code class="language-smithy">@pattern("[a-f0-5]*")
@length(min: 5, max: 10)
string LengthPatternString
</code></pre>
<p>Yields:</p>
<pre><code class="language-rust ignore">pub struct LengthPatternString(pub(crate) std::string::String);

impl LengthPatternString {
    fn check_length(
        string: &amp;str,
    ) -&gt; Result&lt;(), crate::model::length_pattern_string::ConstraintViolation&gt; {
        let length = string.chars().count();

        if (5..=10).contains(&amp;length) {
            Ok(())
        } else {
            Err(crate::model::length_pattern_string::ConstraintViolation::Length(length))
        }
    }

    fn check_pattern(
        string: String,
    ) -&gt; Result&lt;String, crate::model::length_pattern_string::ConstraintViolation&gt; {
        let regex = Self::compile_regex();

        if regex.is_match(&amp;string) {
            Ok(string)
        } else {
            Err(crate::model::length_pattern_string::ConstraintViolation::Pattern(string))
        }
    }

    pub fn compile_regex() -&gt; &amp;'static regex::Regex {
        static REGEX: once_cell::sync::Lazy&lt;regex::Regex&gt; = once_cell::sync::Lazy::new(|| {
            regex::Regex::new(r#"[a-f0-5]*"#).expect(r#"The regular expression [a-f0-5]* is not supported by the `regex` crate; feel free to file an issue under https://github.com/smithy-lang/smithy-rs/issues for support"#)
        });

        &amp;REGEX
    }
}

impl std::convert::TryFrom&lt;std::string::String&gt; for LengthPatternString {
    type Error = crate::model::length_pattern_string::ConstraintViolation;

    /// Constructs a `LengthPatternString` from an [`std::string::String`],
    /// failing when the provided value does not satisfy the modeled constraints.
    fn try_from(value: std::string::String) -&gt; Result&lt;Self, Self::Error&gt; {
        Self::check_length(&amp;value)?;

        let value = Self::check_pattern(value)?;

        Ok(Self(value))
    }
}</code></pre>
<p>Observe how a failure to adhere to the <code>@length</code> trait will short-circuit the
evaluation of the constructor, when the value could technically also not adhere
with the <code>@pattern</code> trait.</p>
<p>Similarly, constrained structures fail upon encountering the first member that
violates a constraint.</p>
<p>Additionally, <em>in framework request deserialization code</em>:</p>
<ul>
<li>collections whose members are constrained fail upon encountering the first
member that violates the constraint,</li>
<li>maps whose keys and/or values are constrained fail upon encountering the
first violation; and</li>
<li>structures whose members are constrained fail upon encountering the first
member that violates the constraint,</li>
</ul>
<p>In summary, any shape that is transitively constrained yields types whose
constructors (both the internal one and the user-facing one) currently
short-circuit upon encountering the first violation.</p>
<h3 id="solution-proposal-1"><a class="header" href="#solution-proposal-1">Solution proposal</a></h3>
<p>The deserializing architecture lends itself to be easily refactored so that we
can collect constraint violations before returning them. Indeed, note that
deserializers enforce constraint traits in a two-step phase: first, the
<em>entirety</em> of the unconstrained value is deserialized, <em>then</em> constraint traits
are enforced by feeding the entire value to the <code>TryFrom</code> constructor.</p>
<p>Let's consider a <code>ConstraintViolations</code> type (note the plural) that represents
a collection of constraint violations that can occur <em>within user application
code</em>. Roughly:</p>
<pre><code class="language-rust ignore">pub ConstraintViolations&lt;T&gt;(pub(crate) Vec&lt;T&gt;);

impl&lt;T&gt; IntoIterator&lt;Item = T&gt; for ConstraintViolations&lt;T&gt; { ... }

impl std::convert::TryFrom&lt;std::string::String&gt; for LengthPatternString {
    type Error = ConstraintViolations&lt;crate::model::length_pattern_string::ConstraintViolation&gt;;

    fn try_from(value: std::string::String) -&gt; Result&lt;Self, Self::Error&gt; {
        // Check constraints and collect violations.
        ...
    }
}</code></pre>
<ul>
<li>The main reason for wrapping a vector in <code>ConstraintViolations</code> as opposed to
directly returning the vector is forwards-compatibility: we may want to
expand <code>ConstraintViolations</code> with conveniences.</li>
<li>If the constrained type can only ever yield a single violation, we will
dispense with <code>ConstraintViolations</code> and keep directly returning the
<code>crate::model::shape_name::ConstraintViolation</code> type.</li>
</ul>
<p>We will analogously introduce a <code>ConstraintViolationExceptions</code> type that
represents a collection of constraint violations that can occur <em>within the
framework's request deserialization code</em>. This type will be <code>pub(crate)</code> and
will be the one the framework will map to Smithy's <code>ValidationException</code> that
eventually gets serialized into the response.</p>
<h4 id="collecting-constraint-violations-may-constitute-a-dos-attack-vector"><a class="header" href="#collecting-constraint-violations-may-constitute-a-dos-attack-vector">Collecting constraint violations may constitute a DOS attack vector</a></h4>
<p>This is a problem that <em>already</em> exists as of writing, but that collecting
constraint violations highlights, so it is a good opportunity, from a
pedagogical perspective, to explain it here. Consider the following model:</p>
<pre><code class="language-smithy">@length(max: 3)
list ListOfPatternStrings {
    member: PatternString
}

@pattern("expensive regex to evaluate")
string PatternString
</code></pre>
<p>Our implementation currently enforces constraints <em>from the leaf to the root</em>:
when enforcing the <code>@length</code> constraint, the <code>TryFrom</code> constructor the server
framework uses gets a <code>Vec&lt;String&gt;</code> and <em>first</em> checks the members adhere to
the <code>@pattern</code> trait, and only <em>after</em> is the <code>@length</code> trait checked. This
means that if a client sends a request with <code>n &gt;&gt;&gt; 3</code> list members, the
expensive check runs <code>n</code> times, when a constant-time check inspecting the
length of the input vector would have sufficed to reject the request.
Additionally, we may want to avoid serializing <code>n</code> <code>ValidationExceptionField</code>s
due to performance concerns.</p>
<ol>
<li>A possibility to circumvent this is making the <code>@length</code> validator special,
having it bound the other validators via effectively permuting the order of
the checks and thus short-circuiting.
<ul>
<li>In general, it's unclear what constraint traits should cause
short-circuiting. A probably reasonable rule of thumb is to include
traits that can be attached directly to aggregate shapes: as of writing,
that would be <code>@uniqueItems</code> on list shapes and <code>@length</code> on list shapes.</li>
</ul>
</li>
<li>Another possiblity is to <em>do nothing</em> and value <em>complete</em> validation
exception response messages over trying to mitigate this with special
handling. One could argue that these kind of DOS attack vectors should be
taken care of with a separate solution e.g. a layer that bounds a request
body's size to a reasonable default (see <a href="https://github.com/tokio-rs/axum/pull/1420">how Axum added
this</a>). We will provide a similar
request body limiting mechanism regardless.</li>
</ol>
<p>This RFC advocates for implementing the first option, arguing that <a href="https://github.com/smithy-lang/smithy-rs/pull/2040#discussion_r1036226762">it's fair
to say that the framework should return an error that is as informative as
possible, but it doesn't necessarily have to be
complete</a>.
However, we will also write a layer, applied by default to all server SDKs,
that bounds a request body's size to a reasonable (yet high) default. Relying
on users to manually apply the layer is dangerous, since such a configuration
is <a href="https://jfrog.com/blog/watch-out-for-dos-when-using-rusts-popular-hyper-package/">trivially
exploitable</a>.
Users can always manually apply the layer again to their resulting service if
they want to further restrict a request's body size.</p>
<h2 id="tightness-of-constraint-violations"><a class="header" href="#tightness-of-constraint-violations">"Tightness" of constraint violations</a></h2>
<h3 id="problem-3"><a class="header" href="#problem-3">Problem</a></h3>
<p><code>ConstraintViolationExceptions</code> <a href="https://www.ecorax.net/tightness/">is not
"tight"</a> in that there's nothing in the type
system that indicates to the user, when writing the custom validation error
mapping function, that the iterator will not return a sequence of
<code>ConstraintViolationException</code>s that is actually impossible to occur in
practice.</p>
<p>Recall that <code>ConstraintViolationException</code>s are <code>enum</code>s that model both direct
constraint violations as well as transitive ones. For example, given the model:</p>
<pre><code class="language-smithy">@length(min: 1, max: 69)
map LengthMap {
    key: String,
    value: LengthString
}

@length(min: 2, max: 69)
string LengthString
</code></pre>
<p>The corresponding <code>ConstraintViolationException</code> Rust type for the <code>LengthMap</code>
shape is:</p>
<pre><code class="language-rust ignore">pub mod length_map {
    pub enum ConstraintViolation {
        Length(usize),
    }
    pub (crate) enum ConstraintViolationException {
        Length(usize),
        Value(
            std::string::String,
            crate::model::length_string::ConstraintViolationException,
        ),
    }
}</code></pre>
<p><code>ConstraintViolationExceptions</code> is just a container over this type:</p>
<pre><code class="language-rust ignore">pub ConstraintViolationExceptions&lt;T&gt;(pub(crate) Vec&lt;T&gt;);

impl&lt;T&gt; IntoIterator&lt;Item = T&gt; for ConstraintViolationExceptions&lt;T&gt; { ... }</code></pre>
<p>There might be multiple map values that fail to adhere to the constraints in
<code>LengthString</code>, which would make the iterator yield multiple
<code>length_map::ConstraintViolationException::Value</code>s; however, at most one
<code>length_map::ConstraintViolationException::Length</code> can be yielded <em>in
practice</em>. This might be obvious to the service owner when inspecting the model
and the Rust docs, but it's not expressed in the type system.</p>
<p>The above tightness problem has been formulated in terms of
<code>ConstraintViolationExceptions</code>, because the fact that
<code>ConstraintViolationExceptions</code> contain transitive constraint violations
highlights the tightness problem. Note, however, that <strong>the tightness problem
also afflicts <code>ConstraintViolations</code></strong>.</p>
<p>Indeed, consider the following model:</p>
<pre><code class="language-smithy">@pattern("[a-f0-5]*")
@length(min: 5, max: 10)
string LengthPatternString
</code></pre>
<p>This would yield:</p>
<pre><code class="language-rust ignore">pub struct ConstraintViolations&lt;T&gt;(pub(crate) Vec&lt;T&gt;);

impl&lt;T&gt; IntoIterator&lt;Item = T&gt; for ConstraintViolations&lt;T&gt; { ... }

pub mod length_pattern_string {
    pub enum ConstraintViolation {
        Length(usize),
        Pattern(String)
    }
}

impl std::convert::TryFrom&lt;std::string::String&gt; for LengthPatternString {
    type Error = ConstraintViolations&lt;crate::model::length_pattern_string::ConstraintViolation&gt;;

    fn try_from(value: std::string::String) -&gt; Result&lt;Self, Self::Error&gt; {
        // Check constraints and collect violations.
        ...
    }
}</code></pre>
<p>Observe how the iterator of an instance of
<code>ConstraintViolations&lt;crate::model::length_pattern_string::ConstraintViolation&gt;</code>,
may, a priori, yield e.g. the
<code>length_pattern_string::ConstraintViolation::Length</code> variant twice, when it's
clear that the iterator should contain <em>at most one</em> of each of
<code>length_pattern_string::ConstraintViolation</code>'s variants.</p>
<h3 id="final-solution-proposal"><a class="header" href="#final-solution-proposal">Final solution proposal</a></h3>
<p>We propose a tighter API design.</p>
<ol>
<li>We substitute <code>enum</code>s for <code>struct</code>s whose members are all <code>Option</code>al,
representing all the constraint violations that can occur.</li>
<li>For list shapes and map shapes:
<ol>
<li>we implement <code>IntoIterator</code> on an additional <code>struct</code> <code>Members</code>
representing only the violations that can occur on the collection's
members.</li>
<li>we add a <em>non</em> <code>Option</code>-al field to the <code>struct</code> representing the
constraint violations of type <code>Members</code>.</li>
</ol>
</li>
</ol>
<p>Let's walk through an example. Take the last model:</p>
<pre><code class="language-smithy">@pattern("[a-f0-5]*")
@length(min: 5, max: 10)
string LengthPatternString
</code></pre>
<p>This would yield, as per the first substitution:</p>
<pre><code class="language-rust ignore">pub mod length_pattern_string {
    pub struct ConstraintViolations {
        pub length: Option&lt;constraint_violation::Length&gt;,
        pub pattern: Option&lt;constraint_violation::Pattern&gt;,
    }

    pub mod constraint_violation {
        pub struct Length(usize);
        pub struct Pattern(String);
    }
}

impl std::convert::TryFrom&lt;std::string::String&gt; for LengthPatternString {
    type Error = length_pattern_string::ConstraintViolations;

    // The error type returned by this constructor, `ConstraintViolations`,
    // will always have _at least_ one member set.
    fn try_from(value: std::string::String) -&gt; Result&lt;Self, Self::Error&gt; {
        // Check constraints and collect violations.
        ...
    }
}</code></pre>
<p>We now expand the model to highlight the second step of the algorithm:</p>
<pre><code class="language-smithy">@length(min: 1, max: 69)
map LengthMap {
    key: String,
    value: LengthString
}
</code></pre>
<p>This gives us:</p>
<pre><code class="language-rust ignore">pub mod length_map {
    pub struct ConstraintViolations {
        pub length: Option&lt;constraint_violation::Length&gt;,

        // Would be `Option&lt;T&gt;` in the case of an aggregate shape that is _not_ a
        // list shape or a map shape.
        pub member_violations: constraint_violation::Members,
    }

    pub mod constraint_violation {
        // Note that this could now live outside the `length_map` module and be
        // reused across all `@length`-constrained shapes, if we expanded it with
        // another `usize` indicating the _modeled_ value in the `@length` trait; by
        // keeping it inside `length_map` we can hardcode that value in the
        // implementation of e.g. error messages.
        pub struct Length(usize);

        pub struct Members {
            pub(crate) Vec&lt;Member&gt;
        }

        pub struct Member {
            // If the map's key shape were constrained, we'd have a `key`
            // field here too.

            value: Option&lt;Value&gt;
        }

        pub struct Value(
            std::string::String,
            crate::model::length_string::ConstraintViolation,
        );

        impl IntoIterator&lt;Item = Member&gt; for Members { ... }
    }
}</code></pre>
<hr />
<p>The above examples have featured the tight API design with
<code>ConstraintViolation</code>s. Of course, we will apply the same design in the case of
<code>ConstraintViolationException</code>s. For the sake of completeness, let's expand our
model yet again with a structure shape:</p>
<pre><code class="language-smithy">structure A {
    @required
    member: String,

    @required
    length_map: LengthMap,
}
</code></pre>
<p>And this time let's feature <em>both</em> the resulting
<code>ConstraintViolationExceptions</code> and <code>ConstraintViolations</code> types:</p>
<pre><code class="language-rust ignore">pub mod a {
    pub struct ConstraintViolationExceptions {
        // All fields must be `Option`, despite the members being `@required`,
        // since no violations for their values might have occurred.

        pub missing_member_exception: Option&lt;constraint_violation_exception::MissingMember&gt;,
        pub missing_length_map_exception: Option&lt;constraint_violation_exception::MissingLengthMap&gt;,
        pub length_map_exceptions: Option&lt;crate::model::length_map::ConstraintViolationExceptions&gt;,
    }

    pub mod constraint_violation_exception {
        pub struct MissingMember;
        pub struct MissingLengthMap;
    }

    pub struct ConstraintViolations {
        pub missing_member: Option&lt;constraint_violation::MissingMember&gt;,
        pub missing_length_map: Option&lt;constraint_violation::MissingLengthMap&gt;,
    }

    pub mod constraint_violation {
        pub struct MissingMember;
        pub struct MissingLengthMap;
    }
}</code></pre>
<p>As can be intuited, the only differences are that:</p>
<ul>
<li><code>ConstraintViolationExceptions</code> hold transitive violations while
<code>ConstraintViolations</code> only need to expose direct violations (as explained in
the <a href="rfcs/rfc0032_better_constraint_violations.html#impossible-constraint-violations">Impossible constraint violations</a>
section),</li>
<li><code>ConstraintViolationExceptions</code> have members suffixed with <code>_exception</code>, as
is the module name.</li>
</ul>
<p>Note that while the constraint violation (exception) type names are plural, the
module names are always singular.</p>
<p>We also make a conscious decision of, in this case of structure shapes, making
the types of all members <code>Option</code>s, for simplicity. Another choice would have
been to make <code>length_map_exceptions</code> not <code>Option</code>-al, and, in the case where no
violations in <code>LengthMap</code> values occurred, set
<code>length_map::ConstraintViolations::length</code> to <code>None</code> and
<code>length_map::ConstraintViolations::member_violations</code> eventually reach an empty
iterator. However, it's best that we use the expressiveness of <code>Option</code>s at the
earliest ("highest" in the shape hierarchy) opportunity: if a member is <code>Some</code>,
it means it (eventually) reaches data.</p>
<h2 id="checklist"><a class="header" href="#checklist">Checklist</a></h2>
<p>Unfortunately, while this RFC <em>could</em> be implemented iteratively (i.e. solve
each of the problems in turn), it would introduce too much churn and throwaway
work: solving the tightness problem requires a more or less complete overhaul
of the constraint violations code generator. It's best that all three problems
be solved in the same changeset.</p>
<ul>
<li><input disabled="" type="checkbox"/>
Generate <code>ConstraintViolations</code> and <code>ConstraintViolationExceptions</code> types
so as to not reify <a href="rfcs/rfc0032_better_constraint_violations.html#impossible-constraint-violations">impossible constraint
violations</a>, add the ability to <a href="rfcs/rfc0032_better_constraint_violations.html#collecting-constraint-violations">collect
constraint
violations</a>, and solve the <a href="rfcs/rfc0032_better_constraint_violations.html#tightness-of-constraint-violations">"tightness" problem of constraint violations</a>.</li>
<li><input disabled="" type="checkbox"/>
Special-case generated request deserialization code for operations
using <code>@length</code> and <code>@uniqueItems</code> constrained shapes whose closures reach
other constrained shapes so that the validators for these two traits
short-circuit upon encountering a number of inner constraint violations
above a certain threshold.</li>
<li><input disabled="" type="checkbox"/>
Write and expose a layer, applied by default to all generated server SDKs,
that bounds a request body's size to a reasonable (yet high) default, to prevent <a href="https://jfrog.com/blog/watch-out-for-dos-when-using-rusts-popular-hyper-package/">trivial DoS attacks</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-improving-access-to-request-ids-in-sdk-clients"><a class="header" href="#rfc-improving-access-to-request-ids-in-sdk-clients">RFC: Improving access to request IDs in SDK clients</a></h1>
<blockquote>
<p>Status: Implemented in <a href="https://github.com/smithy-lang/smithy-rs/pull/2129">#2129</a></p>
<p>Applies to: AWS SDK clients</p>
</blockquote>
<p>At time of writing, customers can retrieve a request ID in one of four ways in the Rust SDK:</p>
<ol>
<li>For error cases where the response parsed successfully, the request ID can be retrieved
via accessor method on operation error. This also works for unmodeled errors so long as
the response parsing succeeds.</li>
<li>For error cases where a response was received but parsing fails, the response headers
can be retrieved from the raw response on the error, but customers have to manually extract
the request ID from those headers (there's no convenient accessor method).</li>
<li>For all error cases where the request ID header was sent in the response, customers can
call <code>SdkError::into_service_error</code> to transform the <code>SdkError</code> into an operation error,
which has a <code>request_id</code> accessor on it.</li>
<li>For success cases, the customer can't retrieve the request ID at all if they use the fluent
client. Instead, they must manually make the operation and call the underlying Smithy client
so that they have access to <code>SdkSuccess</code>, which provides the raw response where the request ID
can be manually extracted from headers.</li>
</ol>
<p>Only one of these mechanisms is convenient and ergonomic. The rest need considerable improvements.
Additionally, the request ID should be attached to tracing events where possible so that enabling
debug logging reveals the request IDs without any code changes being necessary.</p>
<p>This RFC proposes changes to make the request ID easier to access.</p>
<h2 id="terminology-18"><a class="header" href="#terminology-18">Terminology</a></h2>
<ul>
<li><strong>Request ID:</strong> A unique identifier assigned to and associated with a request to AWS that is
sent back in the response headers. This identifier is useful to customers when requesting support.</li>
<li><strong>Operation Error:</strong> Operation errors are code generated for each operation in a Smithy model.
They are an enum of every possible modeled error that that operation can respond with, as well
as an <code>Unhandled</code> variant for any unmodeled or unrecognized errors.</li>
<li><strong>Modeled Errors:</strong> Any error that is represented in a Smithy model with the <code>@error</code> trait.</li>
<li><strong>Unmodeled Errors:</strong> Errors that a service responds with that do not appear in the Smithy model.</li>
<li><strong>SDK Clients:</strong> Clients generated for the AWS SDK, including "adhoc" or "one-off" clients.</li>
<li><strong>Smithy Clients:</strong> Any clients not generated for the AWS SDK, excluding "adhoc" or "one-off" clients.</li>
</ul>
<h2 id="sdksmithy-purity"><a class="header" href="#sdksmithy-purity">SDK/Smithy Purity</a></h2>
<p>Before proposing any changes, the topic of purity needs to be covered. Request IDs are not
currently a Smithy concept. However, at time of writing, the request ID concept is leaked into
the non-SDK rust runtime crates and generated code via the <a href="https://docs.rs/aws-smithy-types/0.51.0/aws_smithy_types/error/struct.Error.html">generic error</a> struct and the
<code>request_id</code> functions on generated operation errors (e.g., <a href="https://docs.rs/aws-sdk-s3/0.21.0/aws_sdk_s3/error/struct.GetObjectError.html#method.request_id"><code>GetObjectError</code> example in S3</a>).</p>
<p>This RFC attempts to remove these leaks from Smithy clients.</p>
<h2 id="proposed-changes-1"><a class="header" href="#proposed-changes-1">Proposed Changes</a></h2>
<p>First, we'll explore making it easier to retrieve a request ID from errors,
and then look at making it possible to retrieve them from successful responses.
To see the customer experience of these changes, see the <strong>Example Interactions</strong>
section below.</p>
<h3 id="make-request-id-retrieval-on-errors-consistent"><a class="header" href="#make-request-id-retrieval-on-errors-consistent">Make request ID retrieval on errors consistent</a></h3>
<p>One could argue that customers being able to convert a <code>SdkError</code> into an operation error
that has a request ID on it is sufficient. However, there's no way to write a function
that takes an error from any operation and logs a request ID, so it's still not ideal.</p>
<p>The <code>aws-http</code> crate needs to have a <code>RequestId</code> trait on it to facilitate generic
request ID retrieval:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait RequestId {
    /// Returns the request ID if it's available.
    fn request_id(&amp;self) -&gt; Option&lt;&amp;str&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>This trait will be implemented for <code>SdkError</code> in <code>aws-http</code> where it is declared,
complete with logic to pull the request ID header out of the raw HTTP responses
(it will always return <code>None</code> for event stream <code>Message</code> responses; an additional
trait may need to be added to <code>aws-smithy-http</code> to facilitate access to the headers).
This logic will try different request ID header names in order of probability
since AWS services have a couple of header name variations. <code>x-amzn-requestid</code> is
the most common, with <code>x-amzn-request-id</code> being the second most common.</p>
<p><code>aws-http</code> will also implement <code>RequestId</code> for <code>aws_smithy_types::error::Error</code>,
and the <code>request_id</code> method will be removed from <code>aws_smithy_types::error::Error</code>.
Places that construct <code>Error</code> will place the request ID into its <code>extras</code> field,
where the <code>RequestId</code> trait implementation can retrieve it.</p>
<p>A codegen decorator will be added to <code>sdk-codegen</code> to implement <code>RequestId</code> for
operation errors, and the existing <code>request_id</code> accessors will be removed from
<code>CombinedErrorGenerator</code> in <code>codegen-core</code>.</p>
<p>With these changes, customers can directly access request IDs from <code>SdkError</code> and
operations errors by importing the <code>RequestId</code> trait. Additionally, the Smithy/SDK
purity is improved since both places where request IDs are leaked to Smithy clients
will be resolved.</p>
<h3 id="implement-requestid-for-outputs"><a class="header" href="#implement-requestid-for-outputs">Implement <code>RequestId</code> for outputs</a></h3>
<p>To make it possible to retrieve request IDs when using the fluent client, the new
<code>RequestId</code> trait can be implemented for outputs.</p>
<p>Some services (e.g., Transcribe Streaming) model the request ID header in their
outputs, while other services (e.g., Directory Service) model a request ID
field on errors. In some cases, services take <code>RequestId</code> as a modeled input
(e.g., IoT Event Data). It follows that it is possible, but unlikely, that
a service could have a field named <code>RequestId</code> that is not the same concept
in the future.</p>
<p>Thus, name collisions are going to be a concern for putting a request ID accessor
on output. However, if it is implemented as a trait, then this concern is partially
resolved. In the vast majority of cases, importing <code>RequestId</code> will provide the
accessor without any confusion. In cases where it is already modeled and is the
same concept, customers will likely just use it and not even realize they didn't
import the trait. The only concern is future cases where it is modeled as a
separate concept, and as long as customers don't import <code>RequestId</code> for something
else in the same file, that confusion can be avoided.</p>
<p>In order to implement <code>RequestId</code> for outputs, either the original response needs
to be stored on the output, or the request ID needs to be extracted earlier and
stored on the output. The latter will lead to a small amount of header lookup
code duplication.</p>
<p>In either case, the <code>StructureGenerator</code> needs to be customized in <code>sdk-codegen</code>
(Appendix B outlines an alternative approach to this and why it was dismissed).
This will be done by adding customization hooks to <code>StructureGenerator</code> similar
to the ones for <code>ServiceConfigGenerator</code> so that a <code>sdk-codegen</code> decorator can
conditionally add fields and functions to any generated structs. A hook will
also be needed to additional trait impl blocks.</p>
<p>Once the hooks are in place, a decorator will be added to store either the original
response or the request ID on outputs, and then the <code>RequestId</code> trait will be
implemented for them. The <code>ParseResponse</code> trait implementation will be customized
to populate this new field.</p>
<p>Note: To avoid name collisions of the request ID or response on the output struct,
these fields can be prefixed with an underscore. It shouldn't be possible for SDK
fields to code generate with this prefix given the model validation rules in place.</p>
<h3 id="implement-requestid-for-operation-and-operationresponse"><a class="header" href="#implement-requestid-for-operation-and-operationresponse">Implement <code>RequestId</code> for <code>Operation</code> and <code>operation::Response</code></a></h3>
<p>In the case that a customer wants to ditch the fluent client, it should still
be easy to retrieve a request ID. To do this, <code>aws-http</code> will provide <code>RequestId</code>
implementations for <code>Operation</code> and <code>operation::Response</code>. These implementations
will likely make the other <code>RequestId</code> implementations easier to implement as well.</p>
<h3 id="implement-requestid-for-result"><a class="header" href="#implement-requestid-for-result">Implement <code>RequestId</code> for <code>Result</code></a></h3>
<p>The <code>Result</code> returned by the SDK should directly implement <code>RequestId</code> when both
its <code>Ok</code> and <code>Err</code> variants implement <code>RequestId</code>. This will make it possible
for a customer to feed the return value from <code>send()</code> directly to a request ID logger.</p>
<h2 id="example-interactions"><a class="header" href="#example-interactions">Example Interactions</a></h2>
<h3 id="generic-handling-case"><a class="header" href="#generic-handling-case">Generic Handling Case</a></h3>
<pre><code class="language-rust ignore">// A re-export of the RequestId trait
use aws_sdk_service::primitives::RequestId;

fn my_request_id_logging_fn(request_id: &amp;dyn RequestId) {
    println!("request ID: {:?}", request_id.request_id());
}

let result = client.some_operation().send().await?;
my_request_id_logging_fn(&amp;result);</code></pre>
<h3 id="success-case"><a class="header" href="#success-case">Success Case</a></h3>
<pre><code class="language-rust ignore">use aws_sdk_service::primitives::RequestId;

let output = client.some_operation().send().await?;
println!("request ID: {:?}", output.request_id());</code></pre>
<h3 id="error-case-with-sdkerror"><a class="header" href="#error-case-with-sdkerror">Error Case with <code>SdkError</code></a></h3>
<pre><code class="language-rust ignore">use aws_sdk_service::primitives::RequestId;

match client.some_operation().send().await {
    Ok(_) =&gt; { /* handle OK */ }
    Err(err) =&gt; {
        println!("request ID: {:?}", output.request_id());
    }
}</code></pre>
<h3 id="error-case-with-operation-error"><a class="header" href="#error-case-with-operation-error">Error Case with operation error</a></h3>
<pre><code class="language-rust ignore">use aws_sdk_service::primitives::RequestId;

match client.some_operation().send().await {
    Ok(_) =&gt; { /* handle OK */ }
    Err(err) =&gt; match err.into_service_err() {
        err @ SomeOperationError::SomeError(_) =&gt; { println!("request ID: {:?}", err.request_id()); }
        _ =&gt; { /* don't care */ }
    }
}</code></pre>
<h2 id="changes-checklist-25"><a class="header" href="#changes-checklist-25">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create the <code>RequestId</code> trait in <code>aws-http</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Implement for errors
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>RequestId</code> for <code>SdkError</code> in <code>aws-http</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Remove <code>request_id</code> from <code>aws_smithy_types::error::Error</code>, and store request IDs in its <code>extras</code> instead</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>RequestId</code> for <code>aws_smithy_types::error::Error</code> in <code>aws-http</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Remove generation of <code>request_id</code> accessors from <code>CombinedErrorGenerator</code> in <code>codegen-core</code></li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement for outputs
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add customization hooks to <code>StructureGenerator</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add customization hook to <code>ParseResponse</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Add customization hook to <code>HttpBoundProtocolGenerator</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Customize output structure code gen in <code>sdk-codegen</code> to add either a request ID or a response field</li>
<li><input disabled="" type="checkbox" checked=""/>
Customize <code>ParseResponse</code> in <code>sdk-codegen</code> to populate the outputs</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>RequestId</code> for <code>Operation</code> and <code>operation::Response</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Implement <code>RequestId</code> for <code>Result&lt;O, E&gt;</code> where <code>O</code> and <code>E</code> both implement <code>RequestId</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Re-export <code>RequestId</code> in generated crates</li>
<li><input disabled="" type="checkbox" checked=""/>
Add integration tests for each request ID access point</li>
</ul>
<h2 id="appendix-a-alternate-solution-for-access-on-successful-responses"><a class="header" href="#appendix-a-alternate-solution-for-access-on-successful-responses">Appendix A: Alternate solution for access on successful responses</a></h2>
<p>Alternatively, for successful responses, a second <code>send</code> method (that is difficult to name)w
be added to the fluent client that has a return value that includes both the output and
the request ID (or entire response).</p>
<p>This solution was dismissed due to difficulty naming, and the risk of name collision.</p>
<h2 id="appendix-b-adding-requestid-as-a-string-to-outputs-via-model-transform"><a class="header" href="#appendix-b-adding-requestid-as-a-string-to-outputs-via-model-transform">Appendix B: Adding <code>RequestId</code> as a string to outputs via model transform</a></h2>
<p>The request ID could be stored on outputs by doing a model transform in <code>sdk-codegen</code> to add a
<code>RequestId</code> member field. However, this causes problems when an output already has a <code>RequestId</code> field,
and requires the addition of a synthetic trait to skip binding the field in the generated
serializers/deserializers.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="smithy-orchestrator"><a class="header" href="#smithy-orchestrator">Smithy Orchestrator</a></h1>
<blockquote>
<p>status: implemented
applies-to: The smithy client</p>
</blockquote>
<p>This RFC proposes a new process for constructing client requests and handling service responses. This new process is intended to:</p>
<ul>
<li>Improve the user experience by</li>
<li>Simplifying several aspects of sending a request</li>
<li>Adding more extension points to the request/response lifecycle</li>
<li>Improve the maintainer experience by</li>
<li>Making our SDK more similar in structure to other AWS SDKs</li>
<li>Simplifying many aspects of the request/response lifecycle</li>
<li>Making room for future changes</li>
</ul>
<p>Additionally, functionality that the SDKs currently provide like retries, logging, and auth with be incorporated into this new process in such a way as to make it more configurable and understandable.</p>
<p>This RFC references but is not the source of truth on:</p>
<ul>
<li>Interceptors: To be described in depth in a future RFC.</li>
<li>Runtime Plugins: To be described in depth in a future RFC.</li>
</ul>
<h2 id="tldr"><a class="header" href="#tldr">TLDR;</a></h2>
<p>When a smithy client communicates with a smithy service, messages are handled by an "orchestrator." The orchestrator runs in two main phases:</p>
<ol>
<li>Constructing configuration.
<ul>
<li>This process is user-configurable with "runtime plugins."</li>
<li>Configuration is stored in a typemap.</li>
</ul>
</li>
<li>Transforming a client request into a server response.
<ul>
<li>This process is user-configurable with "interceptors."</li>
<li>Interceptors are functions that are run by "hooks" in the request/response lifecycle.</li>
</ul>
</li>
</ol>
<h2 id="terminology-19"><a class="header" href="#terminology-19">Terminology</a></h2>
<ul>
<li><strong>SDK Client</strong>: A high-level abstraction allowing users to make requests to remote services.</li>
<li><strong>Remote Service</strong>: A remote API that a user wants to use. Communication with a remote service usually happens over HTTP. The remote service is usually, but not necessarily, an AWS service.</li>
<li><strong>Operation</strong>: A high-level abstraction representing an interaction between an *SDK Client and a <em>remote service</em>.</li>
<li><strong>Input Message</strong>: A modeled request passed into an <em>SDK client</em>. For example, S3’s <code>ListObjectsRequest</code>.</li>
<li><strong>Transport Request Message</strong>: A message that can be transmitted to a <em>remote service</em>. For example, an HTTP request.</li>
<li><strong>Transport Response Message</strong>: A message that can be received from a <em>remote service</em>. For example, an HTTP response.</li>
<li><strong>Output Message</strong>: A modeled response or exception returned to an <em>SDK client</em> caller. For example, S3’s <code>ListObjectsResponse</code> or <code>NoSuchBucketException</code>.</li>
<li><strong>The request/response lifecycle</strong>: The process by which an <em>SDK client</em> makes requests and receives responses from a <em>remote service</em>. This process is enacted and managed by the <em>orchestrator</em>.</li>
<li><strong>Orchestrator</strong>: The code within an <em>SDK client</em> that handles the process of making requests and receiving responses from <em>remote services</em>. The orchestrator is configurable by modifying the <em>runtime plugins</em> it's built from. The orchestrator is responsible for calling <em>interceptors</em> at the appropriate times in the <em>request/response lifecycle</em>.</li>
<li><strong>Interceptor</strong>/<strong>Hook</strong>: A generic extension point within the <em>orchestrator</em>. Supports "anything that someone should be able to do", NOT "anything anyone might want to do". These hooks are:
<ul>
<li>Either <strong>read-only</strong> or <strong>read/write</strong>.</li>
<li>Able to read and modify the <strong>Input</strong>, <strong>Transport Request</strong>, <strong>Transport Response</strong>, or <strong>Output</strong> messages.</li>
</ul>
</li>
<li><strong>Runtime Plugin</strong>: Runtime plugins are similar to interceptors, but they act on configuration instead of requests and response. Both users and services may define runtime plugins. Smithy also defines several default runtime plugins used by most clients. See the F.A.Q. for a list of plugins with descriptions.</li>
<li><strong>ConfigBag</strong>: A <code>typemap</code> that's equivalent to <a href="https://docs.rs/http/latest/http/struct.Extensions.html"><code>http::Extensions</code></a>. Used to store configuration for the orchestrator.</li>
</ul>
<h2 id="the-user-experience-if-this-rfc-is-implemented-3"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-3">The user experience if this RFC is implemented</a></h2>
<p>For many users, the changes described by this RFC will be invisible. Making a request with an orchestrator-based SDK client looks very similar to the way requests were made pre-RFC:</p>
<pre><code class="language-rust ignore">let sdk_config = aws_config::load_from_env().await;
let client = aws_sdk_s3::Client::new(&amp;sdk_config);
let res = client.get_object()
    .bucket("a-bucket")
    .key("a-file.txt")
    .send()
    .await?;

match res {
    Ok(res) =&gt; println!("success: {:?}"),
    Err(err) =&gt; eprintln!("failure: {:?}")
};</code></pre>
<p>Users may further configure clients and operations with <strong>runtime plugins</strong>, and they can modify requests and responses with <strong>interceptors</strong>. We'll examine each of these concepts in the following sections.</p>
<h3 id="service-clients-and-operations-are-configured-with-runtime-plugins"><a class="header" href="#service-clients-and-operations-are-configured-with-runtime-plugins">Service clients and operations are configured with runtime plugins</a></h3>
<blockquote>
<p>The exact implementation of <strong>runtime plugins</strong> is left for another RFC. That other RFC will be linked here once it's written. To get an idea of what they may look like, see the <em>"Layered configuration, stored in type maps"</em> section of this RFC.</p>
</blockquote>
<p>Runtime plugins construct and modify client configuration. Plugin initialization is the first step of sending a request, and plugins set in later steps can override the actions of earlier plugins. Plugin ordering is deterministic and non-customizable.</p>
<p>While AWS services define a default set of plugins, users may define their own plugins, and set them by calling the appropriate methods on a service's config, client, or operation. Plugins are specifically meant for constructing service and operation configuration. If a user wants to define behavior that should occur at specific points in the <em>request/response lifecycle</em>, then they should instead consider defining an <em>interceptor</em>.</p>
<h3 id="requests-and-responses-are-modified-by-interceptors"><a class="header" href="#requests-and-responses-are-modified-by-interceptors">Requests and responses are modified by interceptors</a></h3>
<p>Interceptors are similar to middlewares, in that they are functions that can read and modify request and response state. However, they are more restrictive than middlewares in that they can't modify the "control flow" of the request/response lifecycle. This is intentional. Interceptors can be registered on a client or operation, and the orchestrator is responsible for calling interceptors at the appropriate time. Users MUST NOT perform blocking IO within an interceptor. Interceptors are sync, and are not intended to perform large amounts of work. This makes them easier to reason about and use. Depending on when they are called, interceptors may read and modify <em>input messages</em>, <em>transport request messages</em>, <em>transport response messages</em>, and <em>output messages</em>. Additionally, all interceptors may write to a context object that is shared between all interceptors.</p>
<h4 id="currently-supported-hooks"><a class="header" href="#currently-supported-hooks">Currently supported hooks</a></h4>
<ol>
<li><strong>Read Before Execution <em>(Read-Only)</em></strong>: Before anything happens. This is the first
thing the SDK calls during operation execution.</li>
<li><strong>Modify Before Serialization <em>(Read/Write)</em></strong>: Before the input message given by
the customer is marshalled into a transport request message. Allows modifying the
input message.</li>
<li><strong>Read Before Serialization <em>(Read-Only)</em></strong>: The last thing the SDK calls before
marshaling the input message into a transport message.</li>
<li><strong>Read After Serialization <em>(Read-Only)</em></strong>: The first thing the SDK calls after marshaling the input message into a transport message.</li>
<li><em>(Retry Loop)</em>
<ol>
<li><strong>Modify Before Retry Loop <em>(Read/Write)</em></strong>: The last thing the SDK calls before entering the retry look. Allows modifying the transport message.</li>
<li><strong>Read Before Attempt <em>(Read-Only)</em></strong>: The first thing the SDK calls “inside” of the retry loop.</li>
<li><strong>Modify Before Signing <em>(Read/Write)</em></strong>: Before the transport request message is signed. Allows modifying the transport message.</li>
<li><strong>Read Before Signing <em>(Read-Only)</em></strong>: The last thing the SDK calls before signing the transport request message.</li>
<li>**Read After Signing (Read-Only)****: The first thing the SDK calls after signing the transport request message.</li>
<li><strong>Modify Before Transmit <em>(Read/Write)</em></strong>: Before the transport request message is sent to the service. Allows modifying the transport message.</li>
<li><strong>Read Before Transmit <em>(Read-Only)</em></strong>: The last thing the SDK calls before sending the transport request message.</li>
<li><strong>Read After Transmit <em>(Read-Only)</em></strong>: The last thing the SDK calls after receiving the transport response message.</li>
<li><strong>Modify Before Deserialization <em>(Read/Write)</em></strong>: Before the transport response message is unmarshaled. Allows modifying the transport response message.</li>
<li><strong>Read Before Deserialization <em>(Read-Only)</em></strong>: The last thing the SDK calls before unmarshalling the transport response message into an output message.</li>
<li><strong>Read After Deserialization <em>(Read-Only)</em></strong>: The last thing the SDK calls after unmarshaling the transport response message into an output message.</li>
<li><strong>Modify Before Attempt Completion <em>(Read/Write)</em></strong>: Before the retry loop ends. Allows modifying the unmarshaled response (output message or error).</li>
<li><strong>Read After Attempt <em>(Read-Only)</em></strong>: The last thing the SDK calls “inside” of the retry loop.</li>
</ol>
</li>
<li><strong>Modify Before Execution Completion <em>(Read/Write)</em></strong>: Before the execution ends. Allows modifying the unmarshaled response (output message or error).</li>
<li><strong>Read After Execution <em>(Read-Only)</em></strong>: After everything has happened. This is the last thing the SDK calls during operation execution.</li>
</ol>
<h3 id="interceptor-context"><a class="header" href="#interceptor-context">Interceptor context</a></h3>
<p>As mentioned above, interceptors may read/write a context object that is shared between all interceptors:</p>
<pre><code class="language-rust ignore">pub struct InterceptorContext&lt;ModReq, TxReq, TxRes, ModRes&gt; {
    // a.k.a. the input message
    modeled_request: ModReq,
    // a.k.a. the transport request message
    tx_request: Option&lt;TxReq&gt;,
    // a.k.a. the output message
    modeled_response: Option&lt;ModRes&gt;,
    // a.k.a. the transport response message
    tx_response: Option&lt;TxRes&gt;,
    // A type-keyed map
    properties: SharedPropertyBag,
}</code></pre>
<p>The optional request and response types in the interceptor context can only be accessed by interceptors that are run after specific points in the <em>request/response lifecycle</em>. Rather than go into depth in this RFC, I leave that to a future "Interceptors RFC."</p>
<h2 id="how-to-implement-this-rfc"><a class="header" href="#how-to-implement-this-rfc">How to implement this RFC</a></h2>
<h3 id="integrating-with-the-orchestrator"><a class="header" href="#integrating-with-the-orchestrator">Integrating with the orchestrator</a></h3>
<p>Imagine we have some sort of request signer. This signer doesn't refer to any orchestrator types. All it needs is a <code>HeaderMap</code> along with two strings, and will return a signature in string form.</p>
<pre><code class="language-rust ignore">struct Signer;

impl Signer {
    fn sign(headers: &amp;http::HeaderMap, signing_name: &amp;str, signing_region: &amp;str) -&gt; String {
        todo!()
    }
}</code></pre>
<p>Now imagine things from the orchestrator's point of view. It requires something that implements an <code>AuthOrchestrator</code> which will be responsible for resolving the correct auth
scheme, identity, and signer for an operation, as well as signing the request</p>
<pre><code class="language-rust ignore">pub trait AuthOrchestrator&lt;Req&gt;: Send + Sync + Debug {
    fn auth_request(&amp;self, req: &amp;mut Req, cfg: &amp;ConfigBag) -&gt; Result&lt;(), BoxError&gt;;
}

// And it calls that `AuthOrchestrator` like so:
fn invoke() {
    // code omitted for brevity

    // Get the request to be signed
    let tx_req_mut = ctx.tx_request_mut().expect("tx_request has been set");
    // Fetch the auth orchestrator from the bag
    let auth_orchestrator = cfg
        .get::&lt;Box&lt;dyn AuthOrchestrator&lt;Req&gt;&gt;&gt;()
        .ok_or("missing auth orchestrator")?;
    // Auth the request
    auth_orchestrator.auth_request(tx_req_mut, cfg)?;

    // code omitted for brevity
}</code></pre>
<p>The specific implementation of the <code>AuthOrchestrator</code> is what brings these two things together:</p>
<pre><code class="language-rust ignore">struct Sigv4AuthOrchestrator;

impl AuthOrchestrator for Sigv4AuthOrchestrator {
    fn auth_request(&amp;self, req: &amp;mut http::Request&lt;SdkBody&gt;, cfg: &amp;ConfigBag) -&gt; Result&lt;(), BoxError&gt; {
        let signer = Signer;
        let signing_name = cfg.get::&lt;SigningName&gt;().ok_or(Error::MissingSigningName)?;
        let signing_region = cfg.get::&lt;SigningRegion&gt;().ok_or(Error::MissingSigningRegion)?;
        let headers = req.headers_mut();

        let signature = signer.sign(headers, signing_name, signing_region);
        match cfg.get::&lt;SignatureLocation&gt;() {
            Some(SignatureLocation::Query) =&gt; req.query.set("sig", signature),
            Some(SignatureLocation::Header) =&gt; req.headers_mut().insert("sig", signature),
            None =&gt; return Err(Error::MissingSignatureLocation),
        };

        Ok(())
    }
}</code></pre>
<p>This intermediate code should be free from as much logic as possible. Whenever possible, we must maintain this encapsulation. Doing so will make the Orchestrator more flexible, maintainable, and understandable.</p>
<h3 id="layered-configuration-stored-in-type-maps"><a class="header" href="#layered-configuration-stored-in-type-maps">Layered configuration, stored in type maps</a></h3>
<blockquote>
<p><strong>Type map</strong>: A data structure where stored values are keyed by their type. Hence, only one value can be stored for a given type.</p>
<p><em>See <a href="https://docs.rs/typemap">typemap</a>, <a href="https://docs.rs/crate/type-map">type-map</a>, <a href="https://docs.rs/http/latest/http/struct.Extensions.html">http::Extensions</a>, and <a href="https://docs.rs/actix-http/latest/actix_http/struct.Extensions.html">actix_http::Extensions</a> for examples.</em></p>
</blockquote>
<pre><code class="language-rust ignore"> let conf: ConfigBag = aws_config::from_env()
    // Configuration can be common to all smithy clients
    .with(RetryConfig::builder().disable_retries().build())
    // Or, protocol-specific
    .with(HttpClient::builder().build())
    // Or, AWS-specific
    .with(Region::from("us-east-1"))
    // Or, service-specific
    .with(S3Config::builder().force_path_style(false).build())
    .await;

let client = aws_sdk_s3::Client::new(&amp;conf);

client.list_buckets()
    .customize()
    // Configuration can be set on operations as well as clients
    .with(HttpConfig::builder().conn(some_other_conn).build())
    .send()
    .await;</code></pre>
<p>Setting configuration that will not be used wastes memory and can make debugging more difficult. Therefore, configuration defaults are only set when they're relevant. For example, if a smithy service doesn't support HTTP, then no HTTP client will be set.</p>
<h4 id="what-is-layered-configuration"><a class="header" href="#what-is-layered-configuration">What is "layered" configuration?</a></h4>
<p>Configuration has precedence. Configuration set on an operation will override configuration set on a client, and configuration set on a client will override default configuration. However, configuration with a higher precedence can also augment configuration with a lower precedence. For example:</p>
<pre><code class="language-rust ignore">let conf: ConfigBag = aws_config::from_env()
    .with(
        SomeConfig::builder()
            .option_a(1)
            .option_b(2)
            .option_c(3)
    )
    .build()
    .await;

let client = aws_sdk_s3::Client::new(&amp;conf);

client.list_buckets()
    .customize()
    .with(
        SomeConfig::builder()
            .option_a(0)
            .option_b(Value::Inherit)
            .option_c(Value::Unset)
    )
    .build()
    .send()
    .await;</code></pre>
<p>In the above example, when the <code>option_a</code>, <code>option_b</code>, <code>option_c</code>, values of <code>SomeConfig</code> are accessed, they'll return:</p>
<ul>
<li><code>option_a</code>: <code>0</code></li>
<li><code>option_b</code>: <code>2</code></li>
<li><code>option_c</code>: No value</li>
</ul>
<p>Config values are wrapped in a special enum called <code>Value</code> with three variants:</p>
<ul>
<li><code>Value::Set</code>: A set value that will override values from lower layers.</li>
<li><code>Value::Unset</code>: An explicitly unset value that will override values from lower layers.</li>
<li><code>Value::Inherit</code>: An explicitly unset value that will inherit a value from a lower layer.</li>
</ul>
<p>Builders are defined like this:</p>
<pre><code class="language-rust ignore">struct SomeBuilder {
    value: Value&lt;T&gt;,
}

impl struct SomeBuilder&lt;T&gt; {
    fn new() -&gt; Self {
        // By default, config values inherit from lower-layer configs
        Self { value: Value::Inherit }
    }

    fn some_field(&amp;mut self, value: impl Into&lt;Value&lt;T&gt;&gt;) -&gt; &amp;mut self {
        self.value = value.into();
        self
    }
}</code></pre>
<p>Because of <code>impl Into&lt;Value&lt;T&gt;&gt;</code>, users don't need to reference the <code>Value</code> enum unless they want to "unset" a value.</p>
<h4 id="layer-separation-and-precedence"><a class="header" href="#layer-separation-and-precedence">Layer separation and precedence</a></h4>
<p>Codegen defines default sets of interceptors and runtime plugins at various "levels":</p>
<ol>
<li>AWS-wide defaults set by codegen.</li>
<li>Service-wide defaults set by codegen.</li>
<li>Operation-specific defaults set by codegen.</li>
</ol>
<p>Likewise, users may mount their own interceptors and runtime plugins:</p>
<ol>
<li>The AWS config level, e.g. <code>aws_types::Config</code>.</li>
<li>The service config level, e.g. <code>aws_sdk_s3::Config</code>.</li>
<li>The operation config level, e.g. <code>aws_sdk_s3::Client::get_object</code>.</li>
</ol>
<p>Configuration is resolved in a fixed manner by reading the "lowest level" of config available, falling back to "higher levels" only when no value has been set. Therefore, at least 3 separate <code>ConfigBag</code>s are necessary, and user configuration has precedence over codegen-defined default configuration. With that in mind, resolution of configuration would look like this:</p>
<ol>
<li>Check user-set operation config.</li>
<li>Check codegen-defined operation config.</li>
<li>Check user-set service config.</li>
<li>Check codegen-defined service config.</li>
<li>Check user-set AWS config.</li>
<li>Check codegen-defined AWS config.</li>
</ol>
<h3 id="the-aws-smithy-orchestrator-crate"><a class="header" href="#the-aws-smithy-orchestrator-crate">The <code>aws-smithy-orchestrator</code> crate</a></h3>
<p><em>I've omitted some of the error conversion to shorten this example and make it easier to understand. The real version will be messier.</em></p>
<pre><code class="language-rust ignore">/// `In`: The input message e.g. `ListObjectsRequest`
/// `Req`: The transport request message e.g. `http::Request&lt;SmithyBody&gt;`
/// `Res`: The transport response message e.g. `http::Response&lt;SmithyBody&gt;`
/// `Out`: The output message. A `Result` containing either:
///     - The 'success' output message e.g. `ListObjectsResponse`
///     - The 'failure' output message e.g. `NoSuchBucketException`
pub async fn invoke&lt;In, Req, Res, T&gt;(
    input: In,
    interceptors: &amp;mut Interceptors&lt;In, Req, Res, Result&lt;T, BoxError&gt;&gt;,
    runtime_plugins: &amp;RuntimePlugins,
    cfg: &amp;mut ConfigBag,
) -&gt; Result&lt;T, BoxError&gt;
    where
        // The input must be Clone in case of retries
        In: Clone + 'static,
        Req: 'static,
        Res: 'static,
        T: 'static,
{
    let mut ctx: InterceptorContext&lt;In, Req, Res, Result&lt;T, BoxError&gt;&gt; =
        InterceptorContext::new(input);

    runtime_plugins.apply_client_configuration(cfg)?;
    interceptors.client_read_before_execution(&amp;ctx, cfg)?;

    runtime_plugins.apply_operation_configuration(cfg)?;
    interceptors.operation_read_before_execution(&amp;ctx, cfg)?;

    interceptors.read_before_serialization(&amp;ctx, cfg)?;
    interceptors.modify_before_serialization(&amp;mut ctx, cfg)?;

    let request_serializer = cfg
        .get::&lt;Box&lt;dyn RequestSerializer&lt;In, Req&gt;&gt;&gt;()
        .ok_or("missing serializer")?;
    let req = request_serializer.serialize_request(ctx.modeled_request_mut(), cfg)?;
    ctx.set_tx_request(req);

    interceptors.read_after_serialization(&amp;ctx, cfg)?;
    interceptors.modify_before_retry_loop(&amp;mut ctx, cfg)?;

    loop {
        make_an_attempt(&amp;mut ctx, cfg, interceptors).await?;
        interceptors.read_after_attempt(&amp;ctx, cfg)?;
        interceptors.modify_before_attempt_completion(&amp;mut ctx, cfg)?;

        let retry_strategy = cfg
            .get::&lt;Box&lt;dyn RetryStrategy&lt;Result&lt;T, BoxError&gt;&gt;&gt;&gt;()
            .ok_or("missing retry strategy")?;
        let mod_res = ctx
            .modeled_response()
            .expect("it's set during 'make_an_attempt'");
        if retry_strategy.should_retry(mod_res, cfg)? {
            continue;
        }

        interceptors.modify_before_completion(&amp;mut ctx, cfg)?;
        let trace_probe = cfg
            .get::&lt;Box&lt;dyn TraceProbe&gt;&gt;()
            .ok_or("missing trace probes")?;
        trace_probe.dispatch_events(cfg);
        interceptors.read_after_execution(&amp;ctx, cfg)?;

        break;
    }

    let (modeled_response, _) = ctx.into_responses()?;
    modeled_response
}

// Making an HTTP request can fail for several reasons, but we still need to
// call lifecycle events when that happens. Therefore, we define this
// `make_an_attempt` function to make error handling simpler.
async fn make_an_attempt&lt;In, Req, Res, T&gt;(
    ctx: &amp;mut InterceptorContext&lt;In, Req, Res, Result&lt;T, BoxError&gt;&gt;,
    cfg: &amp;mut ConfigBag,
    interceptors: &amp;mut Interceptors&lt;In, Req, Res, Result&lt;T, BoxError&gt;&gt;,
) -&gt; Result&lt;(), BoxError&gt;
    where
        In: Clone + 'static,
        Req: 'static,
        Res: 'static,
        T: 'static,
{
    interceptors.read_before_attempt(ctx, cfg)?;

    let tx_req_mut = ctx.tx_request_mut().expect("tx_request has been set");
    let endpoint_orchestrator = cfg
        .get::&lt;Box&lt;dyn EndpointOrchestrator&lt;Req&gt;&gt;&gt;()
        .ok_or("missing endpoint orchestrator")?;
    endpoint_orchestrator.resolve_and_apply_endpoint(tx_req_mut, cfg)?;

    interceptors.modify_before_signing(ctx, cfg)?;
    interceptors.read_before_signing(ctx, cfg)?;

    let tx_req_mut = ctx.tx_request_mut().expect("tx_request has been set");
    let auth_orchestrator = cfg
        .get::&lt;Box&lt;dyn AuthOrchestrator&lt;Req&gt;&gt;&gt;()
        .ok_or("missing auth orchestrator")?;
    auth_orchestrator.auth_request(tx_req_mut, cfg)?;

    interceptors.read_after_signing(ctx, cfg)?;
    interceptors.modify_before_transmit(ctx, cfg)?;
    interceptors.read_before_transmit(ctx, cfg)?;

    // The connection consumes the request but we need to keep a copy of it
    // within the interceptor context, so we clone it here.
    let res = {
        let tx_req = ctx.tx_request_mut().expect("tx_request has been set");
        let connection = cfg
            .get::&lt;Box&lt;dyn Connection&lt;Req, Res&gt;&gt;&gt;()
            .ok_or("missing connector")?;
        connection.call(tx_req, cfg).await?
    };
    ctx.set_tx_response(res);

    interceptors.read_after_transmit(ctx, cfg)?;
    interceptors.modify_before_deserialization(ctx, cfg)?;
    interceptors.read_before_deserialization(ctx, cfg)?;
    let tx_res = ctx.tx_response_mut().expect("tx_response has been set");
    let response_deserializer = cfg
        .get::&lt;Box&lt;dyn ResponseDeserializer&lt;Res, Result&lt;T, BoxError&gt;&gt;&gt;&gt;()
        .ok_or("missing response deserializer")?;
    let res = response_deserializer.deserialize_response(tx_res, cfg)?;
    ctx.set_modeled_response(res);

    interceptors.read_after_deserialization(ctx, cfg)?;

    Ok(())
}</code></pre>
<h4 id="traits"><a class="header" href="#traits">Traits</a></h4>
<p>At various points in the execution of <code>invoke</code>, trait objects are fetched from the <code>ConfigBag</code>. These are preliminary definitions of those traits:</p>
<pre><code class="language-rust ignore">pub trait TraceProbe: Send + Sync + Debug {
    fn dispatch_events(&amp;self, cfg: &amp;ConfigBag) -&gt; BoxFallibleFut&lt;()&gt;;
}

pub trait RequestSerializer&lt;In, TxReq&gt;: Send + Sync + Debug {
    fn serialize_request(&amp;self, req: &amp;mut In, cfg: &amp;ConfigBag) -&gt; Result&lt;TxReq, BoxError&gt;;
}

pub trait ResponseDeserializer&lt;TxRes, Out&gt;: Send + Sync + Debug {
    fn deserialize_response(&amp;self, res: &amp;mut TxRes, cfg: &amp;ConfigBag) -&gt; Result&lt;Out, BoxError&gt;;
}

pub trait Connection&lt;TxReq, TxRes&gt;: Send + Sync + Debug {
    fn call(&amp;self, req: &amp;mut TxReq, cfg: &amp;ConfigBag) -&gt; BoxFallibleFut&lt;TxRes&gt;;
}

pub trait RetryStrategy&lt;Out&gt;: Send + Sync + Debug {
    fn should_retry(&amp;self, res: &amp;Out, cfg: &amp;ConfigBag) -&gt; Result&lt;bool, BoxError&gt;;
}

pub trait AuthOrchestrator&lt;Req&gt;: Send + Sync + Debug {
    fn auth_request(&amp;self, req: &amp;mut Req, cfg: &amp;ConfigBag) -&gt; Result&lt;(), BoxError&gt;;
}

pub trait EndpointOrchestrator&lt;Req&gt;: Send + Sync + Debug {
    fn resolve_and_apply_endpoint(&amp;self, req: &amp;mut Req, cfg: &amp;ConfigBag) -&gt; Result&lt;(), BoxError&gt;;
    fn resolve_auth_schemes(&amp;self) -&gt; Result&lt;Vec&lt;String&gt;, BoxError&gt;;
}</code></pre>
<h2 id="faq"><a class="header" href="#faq">F.A.Q.</a></h2>
<ul>
<li>The orchestrator is a large and complex feature, with many moving parts. How can we ensure that multiple people can contribute in parallel?
<ul>
<li>By defining the entire orchestrator and agreeing on its structure, we can then move on to working on individual runtime plugins and interceptors.</li>
</ul>
</li>
<li>What is the precedence of interceptors?
<ul>
<li>The precedence of interceptors is as follows:
<ul>
<li>Interceptors registered via Smithy default plugins.</li>
<li><em>(AWS Services only)</em> Interceptors registered via AWS default plugins.</li>
<li>Interceptors registered via service-customization plugins.</li>
<li>Interceptors registered via client-level plugins.</li>
<li>Interceptors registered via client-level configuration.</li>
<li>Interceptors registered via operation-level plugins.</li>
<li>Interceptors registered via operation-level configuration.</li>
</ul>
</li>
</ul>
</li>
<li>What runtime plugins will be defined in <code>smithy-rs</code>?
<ul>
<li><code>RetryStrategy</code>: Configures how requests are retried.</li>
<li><code>TraceProbes</code>: Configures locations to which SDK metrics are published.</li>
<li><code>EndpointProviders</code>: Configures which hostname an SDK will call when making a request.</li>
<li><code>HTTPClients</code>: Configures how remote services are called.</li>
<li><code>IdentityProviders</code>: Configures how customers identify themselves to remote services.</li>
<li><code>HTTPAuthSchemes</code> &amp; <code>AuthSchemeResolvers</code>: Configures how customers authenticate themselves to remote services.</li>
<li><code>Checksum Algorithms</code>: Configures how an SDK calculates request and response checksums.</li>
</ul>
</li>
</ul>
<h2 id="changes-checklist-26"><a class="header" href="#changes-checklist-26">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create a new <code>aws-smithy-runtime</code> crate.
<ul>
<li>Add orchestrator implementation</li>
<li>Define the orchestrator/runtime plugin interface traits
<ul>
<li><code>TraceProbe</code></li>
<li><code>RequestSerializer&lt;In, TxReq&gt;</code></li>
<li><code>ResponseDeserializer&lt;TxRes, Out&gt;</code></li>
<li><code>Connection&lt;TxReq, TxRes&gt;</code></li>
<li><code>RetryStrategy&lt;Out&gt;</code></li>
<li><code>AuthOrchestrator&lt;Req&gt;</code></li>
<li><code>EndpointOrchestrator&lt;Req&gt;</code></li>
</ul>
</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Create a new <code>aws-smithy-runtime-api</code> crate.
<ul>
<li>Add <code>ConfigBag</code> module</li>
<li>Add <code>retries</code> module
<ul>
<li>Add <code>rate_limiting</code> sub-module</li>
</ul>
</li>
<li>Add <code>interceptors</code> module
<ul>
<li><code>Interceptor</code> trait</li>
<li><code>InterceptorContext</code> impl</li>
</ul>
</li>
<li>Add <code>runtime_plugins</code> module</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Create a new integration test that ensures the orchestrator works.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-collection-defaults"><a class="header" href="#rfc-collection-defaults">RFC: Collection Defaults</a></h1>
<!-- RFCs start with the "RFC" status and are then either "Implemented" or "Rejected".  -->
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: client</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0035_collection_defaults.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC proposes a <strong>breaking change</strong> to how generated clients automatically provide default values for collections. Currently the SDK generated fields for <code>List</code> generate optional values:</p>
<pre><code class="language-rust ignore">    /// &lt;p&gt; Container for elements related to a particular part.
    pub fn parts(&amp;self) -&gt; Option&lt;&amp;[crate::types::Part]&gt; {
        self.parts.as_deref()
    }</code></pre>
<p>This is <em>almost never</em> what users want and leads to code noise when using collections:</p>
<pre><code class="language-rust ignore">async fn get_builds() {
    let project = codebuild
        .list_builds_for_project()
        .project_name(build_project)
        .send()
        .await?;
    let build_ids = project
        .ids()
        .unwrap_or_default();
    //  ^^^^^^^^^^^^^^^^^^ this is pure noise
}</code></pre>
<p>This RFC proposes unwrapping into default values in our accessor methods.</p>
<!-- The "Terminology" section is optional but is really useful for defining the technical terms you're using in the RFC -->
<h2 id="terminology-20"><a class="header" href="#terminology-20">Terminology</a></h2>
<ul>
<li><strong>Accessor</strong>: The Rust SDK defines accessor methods on modeled structures for fields to make them more convenient for users</li>
<li><strong>Struct field</strong>: The accessors point to concrete fields on the struct itself.</li>
</ul>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented-4"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-4">The user experience if this RFC is implemented</a></h2>
<p>In the current version of the SDK, users must call <code>.unwrap_or_default()</code> frequently.
Once this RFC is implemented, users will be able to use these accessors directly. In the rare case where users need to
distinguish be <code>None</code> and <code>[]</code>, we will direct users towards <code>model.&lt;field&gt;.is_some()</code>.</p>
<pre><code class="language-rust ignore">async fn get_builds() {
    let project = codebuild
        .list_builds_for_project()
        .project_name(build_project)
        .send()
        .await?;
    let build_ids = project.ids();
    // Goodbye to this line:
    //    .unwrap_or_default();
}</code></pre>
<!-- Explain the implementation of this new feature -->
<h2 id="how-to-actually-implement-this-rfc-3"><a class="header" href="#how-to-actually-implement-this-rfc-3">How to actually implement this RFC</a></h2>
<p>In order to implement this feature, we need update the code generate accessors for lists and maps to add <code>.unwrap_or_default()</code>. Because we are returning slices <code>unwrap_or_default()</code> does not produce any additional allocations for empty collection.</p>
<h3 id="could-this-be-implemented-for-hashmap"><a class="header" href="#could-this-be-implemented-for-hashmap">Could this be implemented for <code>HashMap</code>?</a></h3>
<p>This works for lists because we are returning a slice (allowing a statically owned <code>&amp;[]</code> to be returned.) If we want to support HashMaps in the future this <em>is</em> possible by using <code>OnceCell</code> to create empty HashMaps for requisite types. This would allow us to return references to those empty maps.</p>
<h3 id="isnt-this-handled-by-the-default-trait"><a class="header" href="#isnt-this-handled-by-the-default-trait">Isn't this handled by the default trait?</a></h3>
<p>No, many existing APIs don't have the default trait.</p>
<!-- Include a checklist of all the things that need to happen for this RFC's implementation to be considered complete -->
<h2 id="changes-checklist-27"><a class="header" href="#changes-checklist-27">Changes checklist</a></h2>
<p>Estimated total work: 2 days</p>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Update accessor method generation to auto flatten lists</li>
<li><input disabled="" type="checkbox" checked=""/>
Update docs for accessors to guide users to <code>.field.is_some()</code> if they MUST determine if the field was set.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-eliminating-public-http-dependencies"><a class="header" href="#rfc-eliminating-public-http-dependencies">RFC: Eliminating Public <code>http</code> dependencies</a></h1>
<blockquote>
<p>Status: Accepted</p>
<p>Applies to: client</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0036_http_dep_elimination.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC defines how we plan to refactor the SDK to allow the SDK to consume a <code>1.0</code> version of <code>hyper</code>, <code>http-body</code>,
and <code>http</code> at a later date. Currently, <code>hyper</code> is <code>0.14.x</code> and a <code>1.0</code> release candidate series is in progress. However,
there are <a href="https://github.com/orgs/hyperium/projects/1/views/4">open questions</a> that may significantly delay the launch
of
these three crates. We do not want to tie the <code>1.0</code> of the Rust SDK to these crates.</p>
<!-- The "Terminology" section is optional but is really useful for defining the technical terms you're using in the RFC -->
<h2 id="terminology-21"><a class="header" href="#terminology-21">Terminology</a></h2>
<ul>
<li><strong>http-body</strong>: A crate (and trait) defining how HTTP bodies work. Notably, the change from <code>0.*</code> to <code>1.0</code> changes <code>http-body</code>
to operate on frames instead of having separate methods.</li>
<li><code>http</code> (crate): a low level crate of <code>http</code> primitives (no logic, just requests and responses)</li>
<li>ossified dependency: An ossified dependency describes a dependency that, when a new version is released, cannot be utilized without breaking changes. For example, if the <code>mutate_request</code> function on every operation operates on <code>&amp;mut http::Request</code> where <code>http = 0.2</code>, that dependency is "ossified." Compare this to a function that offers the ability to convert something into an <code>http = 0.2</code> request—since http=1 and http=0.2 are largely equivalent, the
existence of this function does not prevent us from using http = 1 in the future. In general terms, <strong>functions that operate on references are much more likely to ossify</strong>—There is no practical way for someone to mutate an <code>http = 0.2</code> request if you have an <code>http = 1</code> request other than a time-consuming clone, and reconversion process.</li>
</ul>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="why-is-this-important"><a class="header" href="#why-is-this-important">Why is this important?</a></h2>
<p><strong>Performance</strong>:
At some point in the Future, <code>hyper = 1</code>, <code>http = 1</code> and <code>http-body = 1</code> will be released. It takes ~1-2 microseconds to rebuild an HTTP request. If we assume that <code>hyper = 1</code> will only operate on <code>http = 1</code> requests, then if we can't use <code>http = 1</code> requests internally, our only way of supporting <code>hyper = 1</code> will be to convert the HTTP request at dispatch time. Besides pinning us to a potentially unsupported version of the HTTP crate, this will prevent us from directly dispatching requests in an efficient manner. With a total overhead of 20µs for the SDK, 1µs is not insignificant. Furthermore, it grows as the number of request headers grow. A benchmark should be run for a realistic HTTP request e.g. one that we send to S3.</p>
<p><strong>Hyper Upgrade</strong>:
Hyper 1 is significantly more flexible than Hyper 0.14.x, especially WRT to connection management &amp; pooling. If we don't make these changes, the upgrade to Hyper 1.x could be significantly more challenging.</p>
<p><strong>Security Fixes</strong>:
If we're still on <code>http = 0.*</code> and a vulnerability is identified, we may end up needing to manually contribute the patch. The <code>http</code> crate is not trivial and contains parsing logic and optimized code (including a non-trivial amount of <code>unsafe</code>). <a href="https://github.com/hyperium/http/issues/412">See this GitHub issue</a>. Notable is that one issue may be unsound and result in changing the public API.</p>
<p><strong>API Friendliness</strong>
If we ship with an API that public exposes customers to <code>http = 0.*</code>, we have the API forever. We have to consider that we aren't shipping the Rust SDK for this month or even this year but probably the Rust SDK for the next 5-10 years.</p>
<p><strong>Future CRT Usage</strong>
If we make this change, we enable a future where we can use the CRT HTTP request type natively without needing a last minute conversion to the CRT HTTP Request type.</p>
<pre><code class="language-rust ignore">struct HttpRequest {
  inner: Inner
}

enum Inner {
  Httpv0(http_0::Request),
  Httpv1(http_1::Request),
  Crt(aws_crt_http::Request)
}</code></pre>
<h2 id="the-user-experience-if-this-rfc-is-implemented-5"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-5">The user experience if this RFC is implemented</a></h2>
<p>Customers are impacted in 3 main locations:</p>
<ol>
<li>HTTP types in Interceptors</li>
<li>HTTP types in <code>customize(...)</code></li>
<li>HTTP types in Connectors</li>
</ol>
<p>In all three of these cases, users would interact with our <code>http</code> wrapper types instead.</p>
<p>In the current version of the SDK, we expose public dependencies on the <code>http</code> crate in several key places:</p>
<ol>
<li>The <code>sigv4</code> crate. The <code>sigv4</code> crate currently operates directly on many types from the <code>http</code> crate. This is unnecessary and actually makes the crate more difficult to use. Although <code>http</code> may be used internally, <code>http</code> will be removed from the public API of this crate.</li>
<li>Interceptor Context: <code>interceptor</code>s can mutate the HTTP request through an unshielded interface. This requires creating a <a href="rfcs/rfc0036_http_dep_elimination.html#http-request-wrapper">wrapper layer around <code>http::Request</code></a> and updating already written interceptors.</li>
<li><code>aws-config</code>: <code>http::Response</code> and <code>uri</code></li>
<li>A long tail of exposed requests and responses in the runtime crates. Many of these crates will be removed post-orchestrator so this can be temporarily delayed.</li>
</ol>
<!-- Explain the implementation of this new feature -->
<h2 id="how-to-actually-implement-this-rfc-4"><a class="header" href="#how-to-actually-implement-this-rfc-4">How to actually implement this RFC</a></h2>
<h3 id="enabling-api-evolution"><a class="header" href="#enabling-api-evolution">Enabling API evolution</a></h3>
<p>One key mechanism that we SHOULD use for allowing our APIs to evolve in the future is usage of <code>~</code> version bounds for the runtime crates after releasing 1.0.</p>
<h3 id="http-request-wrapper"><a class="header" href="#http-request-wrapper">Http Request Wrapper</a></h3>
<p>In order to enable HTTP evolution, we will create a set of wrapper structures around <code>http::Request</code> and <code>http::Response</code>. These will use <code>http = 0</code> internally. Since the HTTP crate itself is quite small, including private dependencies on both versions of the crate is a workable solution. In general, we will aim for an API that is close to drop-in compatible to the HTTP crate while ensuring that a different crate could be used as the backing storage.</p>
<pre><code class="language-rust ignore">// since it's our type, we can default `SdkBody`
pub struct Request&lt;B = SdkBody&gt; {
    // this uses the http = 0.2 request. In the future, we can make an internal enum to allow storing an http = 1
    http_0: http::Request&lt;B&gt;
}</code></pre>
<p><strong>Conversion to/from <code>http::Request</code></strong>
One key property here is that although converting to/from an <code>http::Request</code> <strong>can</strong> be expensive, this is <em>not</em> ossification of the API. This is because the API can support converting from/to both <code>http = 0</code> and <code>http = 1</code> in the future—because it offers mutation of the request via a unified interface, the request would only need to be converted once for dispatch if there was a mismatch (instead of repeatedly). At some point in the future, the <code>http = 0</code> representation could be deprecated and removed or feature gated.</p>
<p><strong>Challenges</strong></p>
<ol>
<li>Creating an HTTP API which is forwards compatible, idiomatic and "truthful" without relying on existing types from Hyper—e.g. when adding a header, we need to account for the possibility that a header is invalid.</li>
<li>Allow for future forwards-compatible evolution in the API—A lot of thought went into the <code>http</code> crate API w.r.t method parameters, types, and generics. Although we can aim for a simpler solution in some cases (e.g. accepting <code>&amp;str</code> instead of <code>HeaderName</code>), we need to be careful that we do so while allowing API evolution.</li>
</ol>
<h3 id="removing-the-sigv4-http-dependency"><a class="header" href="#removing-the-sigv4-http-dependency">Removing the SigV4 HTTP dependency</a></h3>
<p>The SigV4 crate signs a number of <code>HTTP</code> types directly. We should change it to accept strings, and when appropriate, iterators of strings for headers.</p>
<h3 id="removing-the-http-dependency-from-generated-clients"><a class="header" href="#removing-the-http-dependency-from-generated-clients">Removing the HTTP dependency from generated clients</a></h3>
<p>Generated clients currently include a public HTTP dependency in <code>customize</code>. This should be changed to accept our <code>HTTP</code> wrapper type instead or be restricted to a subset of operations (e.g. <code>add_header</code>) while forcing users to add an interceptor if they need full control.</p>
<!-- Include a checklist of all the things that need to happen for this RFC's implementation to be considered complete -->
<h2 id="changes-checklist-28"><a class="header" href="#changes-checklist-28">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Create the <code>http::Request</code> wrapper. Carefully audit for compatibility without breaking changes. 5 Days.</li>
<li><input disabled="" type="checkbox"/>
Refactor currently written interceptors to use the wrapper: 2 days.</li>
<li><input disabled="" type="checkbox"/>
Refactor the SigV4 crate to remove the HTTP dependency from the public interface: 2 days.</li>
<li><input disabled="" type="checkbox"/>
Add / validate support for SdkBody <code>http-body = 1.0rc.2</code> either in a PR or behind a feature gate. Test this to
ensure it works with Hyper. Some previous work here exists: 1 week</li>
<li><input disabled="" type="checkbox"/>
Remove <code>http::Response</code> and <code>Uri</code> from the public exposed types in <code>aws-config</code>: 1-4 days.</li>
<li><input disabled="" type="checkbox"/>
Long tail of other usages: 1 week</li>
<li><input disabled="" type="checkbox"/>
Implement <code>~</code> versions for SDK Crate =&gt; runtime crate dependencies: 1 week</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-the-http-wrapper-type"><a class="header" href="#rfc-the-http-wrapper-type">RFC: The HTTP Wrapper Type</a></h1>
<!-- RFCs start with the "RFC" status and are then either "Implemented" or "Rejected".  -->
<blockquote>
<p>Status: RFC</p>
<p>Applies to: client</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0037_http_wrapper.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC defines the API of our wrapper types around <code>http::Request</code> and <code>http::Response</code>. For more information about why we are wrapping these types, see <a href="rfcs/./rfc0036_http_dep_elimination.html">RFC 0036: The HTTP Dependency</a>.</p>
<!-- The "Terminology" section is optional but is really useful for defining the technical terms you're using in the RFC -->
<h2 id="terminology-22"><a class="header" href="#terminology-22">Terminology</a></h2>
<ul>
<li><code>Extensions</code> / "Request Extensions": The <code>http</code> crate Request/Response types include a typed property bag to store additional metadata along with the request.</li>
</ul>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented-6"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-6">The user experience if this RFC is implemented</a></h2>
<p>In the current version of the SDK, external customers and internal code interacts directly with the <a href="https://crates.io/crates/http"><code>http</code></a> crate. Once this RFC is implemented, interactions at the <strong>public</strong> API level will occur with our own <code>http</code> types instead.</p>
<p>Our types aim to be nearly drop-in-compatible for types in the <code>http</code> crate, however:</p>
<ol>
<li>We will not expose existing HTTP types in public APIs in ways that are ossified.</li>
<li>When possible, we aim to simplify the APIs to make them easier to use.</li>
<li>We will add SDK specific helper functionality when appropriate, e.g. first-level support for applying an endpoint to a request.</li>
</ol>
<!-- Explain the implementation of this new feature -->
<h2 id="how-to-actually-implement-this-rfc-5"><a class="header" href="#how-to-actually-implement-this-rfc-5">How to actually implement this RFC</a></h2>
<p>We will need to add two types, <code>HttpRequest</code> and <code>HttpResponse</code>.</p>
<h4 id="to-string-or-not-to-string"><a class="header" href="#to-string-or-not-to-string">To string or not to String</a></h4>
<p>Our header library restricts header names and values to <code>String</code>s (UTF-8).</p>
<p>Although the <code>http</code> library is very precise in its representation—it allows for <code>HeaderValue</code>s that are both a super and subset of <code>String</code>—a superset because headers support arbitrary binary data but a subset because headers cannot contain control characters like <code>\n</code>.</p>
<p>Although technically allowed, headers containing arbitrary binary data are not widely supported. Generally, Smithy protocols will use base-64 encoding when storing binary data in headers.</p>
<p>Finally, it's nicer for users if they can stay in "string land". Because of this, HttpRequest and Response expose header names and values as strings. Internally, the current design uses <code>HeaderName</code> and <code>HeaderValue</code>, however, there is a gate on construction that enforces that values are valid UTF-8.</p>
<p><strong>This is a one way door because <code>.as_str()</code> would panic in the future if we allow non-string values into headers.</strong></p>
<h4 id="where-should-these-types-live"><a class="header" href="#where-should-these-types-live">Where should these types live?</a></h4>
<p>These types will be used by all orchestrator functionality, so they will be housed in <code>aws-smithy-runtime-api</code></p>
<h4 id="whats-in-and-whats-out"><a class="header" href="#whats-in-and-whats-out">What's in and what's out?</a></h4>
<p>At the onset, these types focus on supporting the most ossified usages: <code>&amp;mut</code> modification of HTTP types. They <strong>do not</strong>
support construction of HTTP types, other than <code>impl From&lt;http::Request&gt;</code> and <code>From&lt;http::Response&gt;</code>. We will also make it
possible to use <code>http::HeaderName</code> / <code>http::HeaderValue</code> in a zero-cost way.</p>
<h4 id="the-asheadercomponent-trait"><a class="header" href="#the-asheadercomponent-trait">The <code>AsHeaderComponent</code> trait</a></h4>
<p>All header insertion methods accept <code>impl AsHeaderComponent</code>. This allows us to provide a nice user experience while taking
advantage of zero-cost usage of <code>'static str</code>. We will seal this trait to prevent external usage. We will have separate implementation for:</p>
<ul>
<li><code>&amp;'static str</code></li>
<li><code>String</code></li>
<li>http02x::HeaderName</li>
</ul>
<h4 id="additional-functionality"><a class="header" href="#additional-functionality">Additional Functionality</a></h4>
<p>Our wrapper type will add the following additional functionality:</p>
<ol>
<li>Support for <code>self.try_clone()</code></li>
<li>Support for <code>&amp;mut self.apply_endpoint(...)</code></li>
</ol>
<h4 id="handling-failure"><a class="header" href="#handling-failure">Handling failure</a></h4>
<p>There is no stdlib type that cleanly defines what may be placed into headers—String is too broad (even if we restrict to ASCII). This RFC proposes moving fallibility to the APIs:</p>
<pre><code class="language-rust ignore">impl HeadersMut&lt;'_&gt; {
    pub fn try_insert(
        &amp;mut self,
        key: impl AsHeaderComponent,
        value: impl AsHeaderComponent,
    ) -&gt; Result&lt;Option&lt;String&gt;, BoxError&gt; {
        // ...
    }
}</code></pre>
<p>This allows us to offer user-friendly types while still avoiding runtime panics. We also offer <code>insert</code> and <code>append</code> which panic on invalid values.</p>
<h4 id="request-extensions"><a class="header" href="#request-extensions">Request Extensions</a></h4>
<p>There is ongoing work which MAY restrict HTTP extensions to clone types. We will preempt that by:</p>
<ol>
<li>Preventing <code>Extensions</code> from being present when initially constructing our HTTP request wrapper.</li>
<li>Forbidding non-clone extensions from being inserted into the wrapped request.</li>
</ol>
<p>This also enables supporting request extensions for different downstream providers by allowing cloning into different extension types.</p>
<h4 id="proposed-implementation"><a class="header" href="#proposed-implementation">Proposed Implementation</a></h4>
<details>
<summary>Proposed Implementation of `request`</summary>
<pre><code class="language-rust ignore">{{#include ../../../rust-runtime/aws-smithy-runtime-api/src/client/http/request.rs}}</code></pre>
</details>
<h3 id="future-work"><a class="header" href="#future-work">Future Work</a></h3>
<p>Currently, the only way to construct <code>Request</code> is from a compatible type (e.g. <code>http02x::Request</code>)</p>
<h2 id="changes-checklist-29"><a class="header" href="#changes-checklist-29">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Implement initial implementation and test it against the SDK as written</li>
<li><input disabled="" type="checkbox"/>
Add test suite of <code>HTTP</code> wrapper</li>
<li><input disabled="" type="checkbox"/>
External design review</li>
<li><input disabled="" type="checkbox" checked=""/>
Update the SigV4 crate to remove <code>http</code> API dependency</li>
<li><input disabled="" type="checkbox"/>
Update the SDK to use the new type (breaking change)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-user-configurable-retry-classification"><a class="header" href="#rfc-user-configurable-retry-classification">RFC: User-configurable retry classification</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: client</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0038_retry_classifier_customization.html#changes-checklist">Changes Checklist</a> section.</p>
<p>This RFC defines the user experience and implementation of user-configurable
retry classification. Custom retry classifiers enable users to change what
responses are retried while still allowing them to rely on defaults set by SDK
authors when desired.</p>
<h2 id="terminology-23"><a class="header" href="#terminology-23">Terminology</a></h2>
<ul>
<li><strong>Smithy Service</strong>: An HTTP service, whose API is modeled with the <a href="https://www.smithy.io">Smithy
IDL</a>.</li>
<li><strong>Smithy Client</strong>: An HTTP client generated by smithy-rs from a <code>.smithy</code>
model file.</li>
<li><strong>AWS SDK</strong>: A <strong>smithy client</strong> that's specifically configured to work with
an AWS service.</li>
<li><strong>Operation</strong>: A modeled interaction with a service, defining the proper input
and expected output shapes, as well as important metadata related to request
construction. "Sending" an operation implies sending one or more HTTP requests
to a <strong>Smithy service</strong>, and then receiving an output or error in response.</li>
<li><strong>Orchestrator</strong>: The client code which manages the request/response pipeline.
The orchestrator is responsible for:
<ul>
<li>Constructing, serializing, and sending requests.</li>
<li>Receiving, deserializing, and (optionally) retrying requests.</li>
<li>Running interceptors <em>(not covered in this RFC)</em> and handling errors.</li>
</ul>
</li>
<li><strong>Runtime Component</strong>: A part of the orchestrator responsible for a specific
function. Runtime components are used by the orchestrator itself, may depend
on specific configuration, and must not be changed by interceptors. Examples
include the endpoint resolver, retry strategy, and request signer.</li>
<li><strong>Runtime Plugin</strong>: Code responsible for setting and <strong>runtime components</strong>
and related configuration. Runtime plugins defined by codegen are responsible
for setting default configuration and altering the behavior of <strong>Smithy
clients</strong> including the <strong>AWS SDKs</strong>.</li>
</ul>
<h2 id="how-the-orchestrator-should-model-retries"><a class="header" href="#how-the-orchestrator-should-model-retries">How the orchestrator should model retries</a></h2>
<p>A <strong>Retry Strategy</strong> is the process by which the orchestrator determines when
and how to retry failed requests. Only one retry strategy may be set at any
given time. During its operation, the retry strategy relies on a series of
<strong>Retry Classifiers</strong> to determine if and how a failed request should be
retried. Retry classifiers each have a <strong>Retry Classifier Priority</strong> so that
regardless of whether they are set during config or operation construction,
they'll always run in a consistent order.</p>
<p>Classifiers are each run in turn by the retry strategy:</p>
<pre><code class="language-rust ignore">pub fn run_classifiers_on_ctx(
    classifiers: impl Iterator&lt;Item = SharedRetryClassifier&gt;,
    ctx: &amp;InterceptorContext,
) -&gt; RetryAction {
    // By default, don't retry
    let mut result = RetryAction::NoActionIndicated;

    for classifier in classifiers {
        let new_result = classifier.classify_retry(ctx);

        // If the result is `NoActionIndicated`, continue to the next classifier
        // without overriding any previously-set result.
        if new_result == RetryAction::NoActionIndicated {
            continue;
        }

        // Otherwise, set the result to the new result.
        tracing::trace!(
            "Classifier '{}' set the result of classification to '{}'",
            classifier.name(),
            new_result
        );
        result = new_result;

        // If the result is `RetryForbidden`, stop running classifiers.
        if result == RetryAction::RetryForbidden {
            tracing::trace!("retry classification ending early because a `RetryAction::RetryForbidden` was emitted",);
            break;
        }
    }

    result
}</code></pre>
<p><em>NOTE: User-defined retry strategies are responsible for calling <code>run_classifiers_on_ctx</code>.</em></p>
<p>Lower-priority classifiers run first, but the retry actions they return may be
overridden by higher-priority classifiers. Classification stops immediately if
any classifier returns <code>RetryAction::RetryForbidden</code>.</p>
<h2 id="the-user-experience-if-this-rfc-is-implemented-7"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-7">The user experience if this RFC is implemented</a></h2>
<p>In the current version of the SDK, users are unable to configure retry
classification, except by defining a custom retry strategy. Once this RFC is
implemented, users will be able to define and set their own classifiers.</p>
<h3 id="defining-a-custom-classifier"><a class="header" href="#defining-a-custom-classifier">Defining a custom classifier</a></h3>
<pre><code class="language-rust ignore">#[derive(Debug)]
struct CustomRetryClassifier;

impl ClassifyRetry for CustomRetryClassifier {
    fn classify_retry(
        &amp;self,
        ctx: &amp;InterceptorContext,
    ) -&gt; Option&lt;RetryAction&gt; {
        // Check for a result
        let output_or_error = ctx.output_or_error();
        // Check for an error
        let error = match output_or_error {
            // Typically, when the response is OK or unset
            // then `RetryAction::NoActionIndicated` is returned.
            Some(Ok(_)) | None =&gt; return RetryAction::NoActionIndicated,
            Some(Err(err)) =&gt; err,
        };

        todo!("inspect the error to determine if a retry attempt should be made.")
    }

    fn name(&amp;self) -&gt; &amp;'static str { "my custom retry classifier" }

    fn priority(&amp;self) -&gt; RetryClassifierPriority {
        RetryClassifierPriority::default()
    }
}</code></pre>
<h4 id="choosing-a-retry-classifier-priority"><a class="header" href="#choosing-a-retry-classifier-priority">Choosing a retry classifier priority</a></h4>
<p>Sticking with the default priority is often the best choice. Classifiers should
restrict the number of cases they can handle in order to avoid having to compete
with other classifiers. When two classifiers would classify a response in two
different ways, the priority system gives us the ability to decide which
classifier should be respected.</p>
<p>Internally, priority is implemented with a simple numeric system. In order to
give the smithy-rs team the flexibility to make future changes, this numeric
system is private and inaccessible to users. Instead, users may set the priority
of classifiers relative to one another with the <code>with_lower_priority_than</code> and
<code>with_higher_priority_than</code> methods:</p>
<pre><code class="language-rust ignore">impl RetryClassifierPriority {
    /// Create a new `RetryClassifierPriority` with lower priority than the given priority.
    pub fn with_lower_priority_than(other: Self) -&gt; Self { ... }

    /// Create a new `RetryClassifierPriority` with higher priority than the given priority.
    pub fn with_higher_priority_than(other: Self) -&gt; Self { ... }
}</code></pre>
<p>For example, if it was important for our <code>CustomRetryClassifier</code> in the previous
example to run <em>before</em> the default <code>HttpStatusCodeClassifier</code>, a user would
define the <code>CustomRetryClassifier</code> priority like this:</p>
<pre><code class="language-rust ignore">impl ClassifyRetry for CustomRetryClassifier {
    fn priority(&amp;self) -&gt; RetryClassifierPriority {
        RetryClassifierPriority::run_before(RetryClassifierPriority::http_status_code_classifier())
    }
}</code></pre>
<p>The priorities of the three default retry classifiers
(<code>HttpStatusCodeClassifier</code>, <code>ModeledAsRetryableClassifier</code>, and
<code>TransientErrorClassifier</code>) are all public for this purpose. Users may <strong>ONLY</strong>
set a retry priority relative to an existing retry priority.</p>
<h4 id="retryaction-and-retryreason"><a class="header" href="#retryaction-and-retryreason"><code>RetryAction</code> and <code>RetryReason</code></a></h4>
<p>Retry classifiers communicate to the retry strategy by emitting <code>RetryAction</code>s:</p>
<pre><code class="language-rust ignore">/// The result of running a [`ClassifyRetry`] on a [`InterceptorContext`].
#[non_exhaustive]
#[derive(Clone, Eq, PartialEq, Debug, Default)]
pub enum RetryAction {
    /// When a classifier can't run or has no opinion, this action is returned.
    ///
    /// For example, if a classifier requires a parsed response and response parsing failed,
    /// this action is returned. If all classifiers return this action, no retry should be
    /// attempted.
    #[default]
    NoActionIndicated,
    /// When a classifier runs and thinks a response should be retried, this action is returned.
    RetryIndicated(RetryReason),
    /// When a classifier runs and decides a response must not be retried, this action is returned.
    ///
    /// This action stops retry classification immediately, skipping any following classifiers.
    RetryForbidden,
}</code></pre>
<p>When a retry is indicated by a classifier, the action will contain a <code>RetryReason</code>:</p>
<pre><code class="language-rust ignore">/// The reason for a retry.
#[non_exhaustive]
#[derive(Clone, Eq, PartialEq, Debug)]
pub enum RetryReason {
    /// When an error is received that should be retried, this reason is returned.
    RetryableError {
        /// The kind of error.
        kind: ErrorKind,
        /// A server may tell us to retry only after a specific time has elapsed.
        retry_after: Option&lt;Duration&gt;,
    },
}</code></pre>
<p><em>NOTE: <code>RetryReason</code> currently only has a single variant, but it's defined as an <code>enum</code> for <a href="https://en.wikipedia.org/wiki/Forward_compatibility">forward compatibility</a> purposes.</em></p>
<p><code>RetryAction</code>'s <code>impl</code> defines several convenience methods:</p>
<pre><code class="language-rust ignore">impl RetryAction {
    /// Create a new `RetryAction` indicating that a retry is necessary.
    pub fn retryable_error(kind: ErrorKind) -&gt; Self {
        Self::RetryIndicated(RetryReason::RetryableError {
            kind,
            retry_after: None,
        })
    }

    /// Create a new `RetryAction` indicating that a retry is necessary after an explicit delay.
    pub fn retryable_error_with_explicit_delay(kind: ErrorKind, retry_after: Duration) -&gt; Self {
        Self::RetryIndicated(RetryReason::RetryableError {
            kind,
            retry_after: Some(retry_after),
        })
    }

    /// Create a new `RetryAction` indicating that a retry is necessary because of a transient error.
    pub fn transient_error() -&gt; Self {
        Self::retryable_error(ErrorKind::TransientError)
    }

    /// Create a new `RetryAction` indicating that a retry is necessary because of a throttling error.
    pub fn throttling_error() -&gt; Self {
        Self::retryable_error(ErrorKind::ThrottlingError)
    }

    /// Create a new `RetryAction` indicating that a retry is necessary because of a server error.
    pub fn server_error() -&gt; Self {
        Self::retryable_error(ErrorKind::ServerError)
    }

    /// Create a new `RetryAction` indicating that a retry is necessary because of a client error.
    pub fn client_error() -&gt; Self {
        Self::retryable_error(ErrorKind::ClientError)
    }
}</code></pre>
<h3 id="setting-classifiers"><a class="header" href="#setting-classifiers">Setting classifiers</a></h3>
<p>The interface for setting classifiers is very similar to the interface of
settings interceptors:</p>
<pre><code class="language-rust ignore">// All service configs support these setters. Operations support a nearly identical API.
impl ServiceConfigBuilder {
    /// Add type implementing ClassifyRetry that will be used by the RetryStrategy
    /// to determine what responses should be retried.
    ///
    /// A retry classifier configured by this method will run according to its priority.
    pub fn retry_classifier(mut self, retry_classifier: impl ClassifyRetry + 'static) -&gt; Self {
        self.push_retry_classifier(SharedRetryClassifier::new(retry_classifier));
        self
    }

    /// Add a SharedRetryClassifier that will be used by the RetryStrategy to
    /// determine what responses should be retried.
    ///
    /// A retry classifier configured by this method will run according to its priority.
    pub fn push_retry_classifier(&amp;mut self, retry_classifier: SharedRetryClassifier) -&gt; &amp;mut Self {
        self.runtime_components.push_retry_classifier(retry_classifier);
        self
    }

    /// Set SharedRetryClassifiers for the builder, replacing any that were
    /// previously set.
    pub fn set_retry_classifiers(&amp;mut self, retry_classifiers: impl IntoIterator&lt;Item = SharedRetryClassifier&gt;) -&gt; &amp;mut Self {
        self.runtime_components.set_retry_classifiers(retry_classifiers.into_iter());
        self
    }
}</code></pre>
<h3 id="default-classifiers"><a class="header" href="#default-classifiers">Default classifiers</a></h3>
<p>Smithy clients have three classifiers enabled by default:</p>
<ul>
<li><code>ModeledAsRetryableClassifier</code>: Checks for errors that are marked as retryable
in the smithy model. If one is encountered, returns
<code>RetryAction::RetryIndicated</code>. Requires a parsed response.</li>
<li><code>TransientErrorClassifier</code>: Checks for timeout, IO, and connector errors. If
one is encountered, returns <code>RetryAction::RetryIndicated</code>.  Requires a parsed
response.</li>
<li><code>HttpStatusCodeClassifier</code>: Checks the HTTP response's status code. By
default, this classifies <code>500</code>, <code>502</code>, <code>503</code>, and <code>504</code> errors as
<code>RetryAction::RetryIndicated</code>.  The list of retryable status codes may be
customized when creating this classifier with the
<code>HttpStatusCodeClassifier::new_from_codes</code> method.</li>
</ul>
<p>AWS clients enable the three smithy classifiers as well as one more by default:</p>
<ul>
<li><code>AwsErrorCodeClassifier</code>: Checks for errors with AWS error codes marking them
as either transient or throttling errors. If one is encountered, returns
<code>RetryAction::RetryIndicated</code>. Requires a parsed response. This classifier
will also check the HTTP response for an <code>x-amz-retry-after</code> header. If one is
set, then the returned <code>RetryAction</code> will include the explicit delay.</li>
</ul>
<p>The priority order of these classifiers is as follows:</p>
<ol>
<li><em>(highest priority)</em> <code>TransientErrorClassifier</code></li>
<li><code>ModeledAsRetryableClassifier</code></li>
<li><code>AwsErrorCodeClassifier</code></li>
<li><em>(lowest priority)</em> <code>HttpStatusCodeClassifier</code></li>
</ol>
<p>The priority order of the default classifiers is not configurable. However, it's
possible to wrap a default classifier in a newtype and set your desired priority
when implementing the <code>ClassifyRetry</code> trait, delegating the <code>classify_retry</code> and
<code>name</code> fields to the inner classifier.</p>
<h4 id="disable-default-classifiers"><a class="header" href="#disable-default-classifiers">Disable default classifiers</a></h4>
<p>Disabling the default classifiers is possible, but not easy. They are set at
different points during config and operation construction, and must be unset at
each of those places. A far simpler solution is to implement your own classifier
that has the highest priority.</p>
<p>Still, if completely removing the other classifiers is desired, use the
<code>set_retry_classifiers</code> method on the config to replace the config-level
defaults and then set a config override on the operation that does the same.</p>
<h2 id="how-to-actually-implement-this-rfc-6"><a class="header" href="#how-to-actually-implement-this-rfc-6">How to actually implement this RFC</a></h2>
<p>In order to implement this feature, we must:</p>
<ul>
<li>Update the current retry classification system so that individual classifiers
as well as collections of classifiers can be easily composed together.</li>
<li>Create two new configuration mechanisms for users that allow them to customize
retry classification at the service level and at the operation level.</li>
<li>Update retry classifiers so that they may 'short-circuit' the chain, ending
retry classification immediately.</li>
</ul>
<h3 id="the-retryclassifier-trait"><a class="header" href="#the-retryclassifier-trait">The <code>RetryClassifier</code> trait</a></h3>
<pre><code class="language-rust ignore">/// The result of running a [`ClassifyRetry`] on a [`InterceptorContext`].
#[non_exhaustive]
#[derive(Clone, Eq, PartialEq, Debug)]
pub enum RetryAction {
    /// When an error is received that should be retried, this action is returned.
    Retry(ErrorKind),
    /// When the server tells us to retry after a specific time has elapsed, this action is returned.
    RetryAfter(Duration),
    /// When a response should not be retried, this action is returned.
    NoRetry,
}

/// Classifies what kind of retry is needed for a given [`InterceptorContext`].
pub trait ClassifyRetry: Send + Sync + fmt::Debug {
    /// Run this classifier on the [`InterceptorContext`] to determine if the previous request
    /// should be retried. If the classifier makes a decision, `Some(RetryAction)` is returned.
    /// Classifiers may also return `None`, signifying that they have no opinion of whether or
    /// not a request should be retried.
    fn classify_retry(
        &amp;self,
        ctx: &amp;InterceptorContext,
        preceding_action: Option&lt;RetryAction&gt;,
    ) -&gt; Option&lt;RetryAction&gt;;

    /// The name of this retry classifier.
    ///
    /// Used for debugging purposes.
    fn name(&amp;self) -&gt; &amp;'static str;

    /// The priority of this retry classifier. Classifiers with a higher priority will run before
    /// classifiers with a lower priority. Classifiers with equal priorities make no guarantees
    /// about which will run first.
    fn priority(&amp;self) -&gt; RetryClassifierPriority {
        RetryClassifierPriority::default()
    }
}</code></pre>
<h3 id="resolving-the-correct-order-of-multiple-retry-classifiers"><a class="header" href="#resolving-the-correct-order-of-multiple-retry-classifiers">Resolving the correct order of multiple retry classifiers</a></h3>
<p>Because each classifier has a defined priority, and because
<code>RetryClassifierPriority</code> implements <code>PartialOrd</code> and <code>Ord</code>, the standard
library's <a href="https://doc.rust-lang.org/stable/std/primitive.slice.html#method.sort">sort</a> method may be used to correctly arrange classifiers. The
<code>RuntimeComponents</code> struct is responsible for storing classifiers, so it's also
responsible for sorting them whenever a new classifier is added. Thus, when a
retry strategy fetches the list of classifiers, they'll already be in the
expected order.</p>
<h2 id="questions-and-answers"><a class="header" href="#questions-and-answers">Questions and answers</a></h2>
<ul>
<li><strong>Q:</strong> Should retry classifiers be fallible?
<ul>
<li><strong>A:</strong> I think no, because of the added complexity. If we make them fallible
then we'll have to decide what happens when classifiers fail. Do we skip
them or does classification end? The retry strategy is responsible for
calling the classifiers, so it be responsible for deciding how to handle a
classifier error. I don't foresee a use case where an error returned by a
classifier would be interpreted either by classifiers following the failed
classifier or the retry strategy.</li>
</ul>
</li>
</ul>
<h2 id="changes-checklist-30"><a class="header" href="#changes-checklist-30">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add retry classifiers field and setters to <code>RuntimeComponents</code> and <code>RuntimeComponentsBuilder</code>.
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add unit tests ensuring that classifier priority is respected by <code>RuntimeComponents::retry_classifiers</code>, especially when multiple layers of config are in play.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add codegen customization allowing users to set retry classifiers on service configs.</li>
<li><input disabled="" type="checkbox" checked=""/>
Add codegen for setting default classifiers at the service level.
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add integration tests for setting classifiers at the service level.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add codegen for settings default classifiers that require knowledge of operation error types at the operation level.
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add integration tests for setting classifiers at the operation level.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement retry classifier priority.
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add unit tests for retry classifier priority.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Update existing tests that would fail for lack of a retry classifier.</li>
</ul>
<!-- Links -->
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-forward-compatible-errors"><a class="header" href="#rfc-forward-compatible-errors">RFC: Forward Compatible Errors</a></h1>
<!-- RFCs start with the "RFC" status and are then either "Implemented" or "Rejected".  -->
<blockquote>
<p>Status: RFC</p>
<p>Applies to: client</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0039_forward_compatible_errors.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC defines an approach for making it forwards-compatible to convert <strong>unmodeled</strong> <code>Unhandled</code> errors into modeled ones. This occurs as servers update their models to include errors that were previously unmodeled.</p>
<p>Currently, SDK errors are <strong>not</strong> forward compatible in this way. If a customer matches <code>Unhandled</code> in addition to the <code>_</code> branch and a new variant is added, <strong>they will fail to match the new variant</strong>. We currently handle this issue with enums by prevent useful information from being readable from the <code>Unknown</code> variant.</p>
<p>This is related to ongoing work on the <a href="https://github.com/rust-lang/rust/issues/89554"><code>non_exhaustive_omitted_patterns</code> lint</a> which would produce a compiler warning when a new variant was added even when <code>_</code> was used.</p>
<!-- The "Terminology" section is optional but is really useful for defining the technical terms you're using in the RFC -->
<h2 id="terminology-24"><a class="header" href="#terminology-24">Terminology</a></h2>
<p>For purposes of discussion, consider the following error:</p>
<pre><code class="language-rust ignore">#[non_exhaustive]
pub enum AbortMultipartUploadError {
    NoSuchUpload(NoSuchUpload),
    Unhandled(Unhandled),
}</code></pre>
<ul>
<li><strong>Modeled Error</strong>: An error with an named variant, e.g. <code>NoSuchUpload</code> above</li>
<li><strong>Unmodeled Error</strong>: Any other error, e.g. if the server returned <code>ValidationException</code> for the above operation.</li>
<li><strong>Error code</strong>: All errors across all protocols provide a <code>code</code>, a unique method to identify an error across the service closure.</li>
</ul>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented-8"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-8">The user experience if this RFC is implemented</a></h2>
<p>In the current version of the SDK, users match the <code>Unhandled</code> variant. They can then read the code from the <code>Unhandled</code> variant because <a href="https://docs.rs/aws-smithy-types/0.56.1/aws_smithy_types/error/struct.Unhandled.html"><code>Unhandled</code></a> implements the <code>ProvideErrorMetadata</code> trait as well as the standard-library <code>std::error::Error</code> trait.</p>
<blockquote>
<p>Note: It's possible to write correct code today because the operation-level and service-level errors already expose <code>code()</code> via <code>ProvideErrorMetadata</code>. This RFC describes mechanisms to guide customers to write forward-compatible code.</p>
</blockquote>
<pre><code class="language-rust ignore"><span class="boring">fn docs() {
</span>    match client.get_object().send().await {
        Ok(obj) =&gt; { ... },
        Err(e) =&gt; match e.into_service_error() {
            GetObjectError::NotFound =&gt; { ... },
            GetObjectError::Unhandled(err) if err.code() == "ValidationException" =&gt; { ... }
            other =&gt; { /** do something with this variant */ }
        }
    }
<span class="boring">}</span></code></pre>
<p>We must instead guide customers into the following pattern:</p>
<pre><code class="language-rust ignore"><span class="boring">fn docs() {
</span>    match client.get_object().send().await {
        Ok(obj) =&gt; { ... },
        Err(e) =&gt; match e.into_service_error() {
            GetObjectError::NotFound =&gt; { ... },
            err if err.code() == "ValidationException" =&gt; { ... },
            err =&gt; warn!("{}", err.code()),
        }
    }
<span class="boring">}</span></code></pre>
<p>In this example, because customers are <em>not</em> matching on the <code>Unhandled</code> variant explicitly this code is forward compatible for <code>ValidationException</code> being introduced in the future.</p>
<p><strong>Guiding Customers to this Pattern</strong>
There are two areas we need to handle:</p>
<ol>
<li>Prevent customers from extracting useful information from <code>Unhandled</code></li>
<li>Alert customers <em>currently</em> using unhandled what to use instead. For example, the following code is still problematic:
<pre><code class="language-rust ignore">    match err {
        GetObjectError::NotFound =&gt; { ... },
        err @ GetObject::Unhandled(_) if err.code() == Some("ValidationException") =&gt; { ... }
    }</code></pre>
</li>
</ol>
<p>For <code>1</code>, we need to remove the <code>ProvideErrorMetadata</code> trait implementation from <code>Unhandled</code>. We would expose this isntead through a layer of indirection to enable code generated to code to still read the data.</p>
<p>For <code>2</code>, we would deprecate the <code>Unhandled</code> variants with a message clearly indicating how this code should be written.</p>
<h2 id="how-to-actually-implement-this-rfc-7"><a class="header" href="#how-to-actually-implement-this-rfc-7">How to actually implement this RFC</a></h2>
<h3 id="locking-down-unhandled"><a class="header" href="#locking-down-unhandled">Locking down <code>Unhandled</code></a></h3>
<p>In order to prevent accidental matching on <code>Unhandled</code>, we need to make it hard to extract useful information from <code>Unhandled</code> itself. We will do this by removing the <code>ProvideErrorMetadata</code> trait implementation and exposing the following method:</p>
<pre><code class="language-rust ignore">#[doc(hidden)]
/// Introspect the error metadata of this error.
///
/// This method should NOT be used from external code because matching on `Unhandled` directly is a backwards-compatibility
/// hazard. See `RFC-0039` for more information.
pub fn introspect(&amp;self) -&gt; impl ProvideErrorMetadata + '_ {
   struct Introspected&lt;'a&gt;(&amp;'a Unhandled);
   impl ProvideErrorMetadata for Introspected { ... }
   Introspected(self)
}</code></pre>
<p>Generated code would this use <code>introspect</code> when supporting <strong>top-level</strong> <code>ErrorMetadata</code> (e.g. for <a href="https://docs.rs/aws-sdk-s3/latest/aws_sdk_s3/enum.Error.html"><code>aws_sdk_s3::Error</code></a>).</p>
<h3 id="deprecating-the-variant"><a class="header" href="#deprecating-the-variant">Deprecating the Variant</a></h3>
<p>The <code>Unhandled</code> variant will be deprecated to prevent users from matching on it inadvertently.</p>
<pre><code class="language-rust ignore">enum GetObjectError {
   NotFound(NotFound),
   #[deprecated("Matching on `Unhandled` directly is a backwards compatibility hazard. Use `err if err.error_code() == ...` instead. See [here](&lt;docs about using errors&gt;) for more information.")]
   Unhandled(Unhandled)
}</code></pre>
<h3 id=""><a class="header" href="#"></a></h3>
<!-- Include a checklist of all the things that need to happen for this RFC's implementation to be considered complete -->
<h2 id="changes-checklist-31"><a class="header" href="#changes-checklist-31">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
Generate code to deprecate unhandled variants. Determine the best way to allow <code>Unhandled</code> to continue to be constructed in client code</li>
<li><input disabled="" type="checkbox"/>
Generate code to deprecate the <code>Unhandled</code> variant for the service meta-error. Consider how this interacts with non-service errors.</li>
<li><input disabled="" type="checkbox"/>
Update <code>Unhandled</code> to make it useless on its own and expose information via an <code>Introspect</code> doc hidden struct.</li>
<li><input disabled="" type="checkbox"/>
Update developer guide to address this issue.</li>
<li><input disabled="" type="checkbox"/>
Changelog &amp; Upgrade Guidance</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><!-- Give your RFC a descriptive name saying what it would accomplish or what feature it defines -->
<h1 id="rfc-behavior-versions"><a class="header" href="#rfc-behavior-versions">RFC: Behavior Versions</a></h1>
<!-- RFCs start with the "RFC" status and are then either "Implemented" or "Rejected".  -->
<blockquote>
<p>Status: RFC</p>
<p>Applies to: client</p>
</blockquote>
<!-- A great RFC will include a list of changes at the bottom so that the implementor can be sure they haven't missed anything -->
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0040_behavior_versions.html#changes-checklist">Changes Checklist</a> section.</p>
<!-- Insert a short paragraph explaining, at a high level, what this RFC is for -->
<p>This RFC describes "Behavior Versions," a mechanism to allow SDKs to ship breaking behavioral changes like a new retry strategy, while allowing customers who rely on extremely consistent behavior to evolve at their own pace.</p>
<p>By adding behavior major versions (BMV) to the Rust SDK, we will make it possible to ship new secure/recommended defaults to new customers without impacting legacy customers.</p>
<p>The fundamental issue stems around our inability to communicate and decouple releases of service updates and behavior within a single major version.</p>
<p>Both legacy and new SDKs have the need to alter their SDKs default. Historically, this caused new customers on legacy SDKs to be subject to legacy defaults, even when a better alternative existed.</p>
<p>For new SDKs, a GA cutline presents difficult choices around timeline and features that can’t be added later without altering behavior.</p>
<p>Both of these use cases are addressed by Behavior Versions.</p>
<!-- Explain how users will use this new feature and, if necessary, how this compares to the current user experience -->
<h2 id="the-user-experience-if-this-rfc-is-implemented-9"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-9">The user experience if this RFC is implemented</a></h2>
<p>In the current version of the SDK, users can construct clients without indicating any sort of behavior major version.
Once this RFC is implemented, there will be two ways to set a behavior major version:</p>
<ol>
<li>In code via <code>aws_config::defaults(BehaviorVersion::latest())</code> and <code>&lt;service&gt;::Config::builder().behavior_version(...)</code>. This will also work for <code>config_override</code>.</li>
<li>By enabling <code>behavior-version-latest</code> in either <code>aws-config</code> (which brings back <code>from_env</code>) OR a specific generated SDK crate</li>
</ol>
<pre><code class="language-toml"># Cargo.toml
[dependencies]
aws-config = { version = "1", features = ["behavior-version-latest"] }
# OR
aws-sdk-s3 = { version = "1", features = ["behavior-version-latest"] }
</code></pre>
<p>If no <code>BehaviorVersion</code> is set, the client will panic during construction.</p>
<p><code>BehaviorVersion</code> is an opaque struct with initializers like <code>::latest()</code>, <code>::v2023_11_09()</code>. Downstream code can check the version by calling methods like <code>::supports_v1()</code></p>
<p>When new BMV are added, the previous version constructor will be marked as <code>deprecated</code>. This serves as a mechanism to alert customers that a new BMV exists to allow them to upgrade.</p>
<h2 id="how-to-actually-implement-this-rfc-8"><a class="header" href="#how-to-actually-implement-this-rfc-8">How to actually implement this RFC</a></h2>
<p>In order to implement this feature, we need to create a <code>BehaviorVersion</code> struct, add config options to <code>SdkConfig</code> and <code>aws-config</code>, and wire it throughout the stack.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Behavior major-version of the client
///
/// Over time, new best-practice behaviors are introduced. However, these behaviors might not be backwards
/// compatible. For example, a change which introduces new default timeouts or a new retry-mode for
/// all operations might be the ideal behavior but could break existing applications.
#[derive(Debug, Clone)]
pub struct BehaviorVersion {
    // currently there is only 1 MV so we don't actually need anything in here.
    _private: (),
}
<span class="boring">}</span></code></pre></pre>
<p>To help customers migrate, we are including <code>from_env</code> hooks that set <code>behavior-version-latest</code> that are <em>deprecated</em>. This allows customers to see that they are missing the required cargo feature and add it to remove the deprecation warning.</p>
<p>Internally, <code>BehaviorVersion</code> will become an additional field on <code>&lt;client&gt;::Config</code>. It is <em>not</em> ever stored in the <code>ConfigBag</code> or in <code>RuntimePlugins</code>.</p>
<p>When constructing the set of "default runtime plugins," the default runtime plugin parameters will be passed the <code>BehaviorVersion</code>. This will select the correct runtime plugin. Logging will clearly indicate which plugin was selected.</p>
<h2 id="design-alternatives-considered"><a class="header" href="#design-alternatives-considered">Design Alternatives Considered</a></h2>
<p>An original design was also considered that made BMV optional and relied on documentation to steer customers in the right direction. This was
deemed too weak of a mechanism to ensure that customers aren't broken by unexpected changes.</p>
<h2 id="changes-checklist-32"><a class="header" href="#changes-checklist-32">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Create <code>BehaviorVersion</code> and the BMV runtime plugin</li>
<li><input disabled="" type="checkbox" checked=""/>
Add BMV as a required runtime component</li>
<li><input disabled="" type="checkbox" checked=""/>
Wire up setters throughout the stack</li>
<li><input disabled="" type="checkbox" checked=""/>
Add tests of BMV (set via aws-config, cargo features &amp; code params)</li>
<li><input disabled="" type="checkbox" checked=""/>
<del>Remove <code>aws_config::from_env</code> deprecation stand-ins</del> We decided to persist these deprecations</li>
<li><input disabled="" type="checkbox" checked=""/>
Update generated usage examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-improve-client-error-ergonomics"><a class="header" href="#rfc-improve-client-error-ergonomics">RFC: Improve Client Error Ergonomics</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: clients</p>
</blockquote>
<p>This RFC proposes some changes to code generated errors to make them easier to use for customers.
With the SDK and code generated clients, customers have two primary use-cases that should be made
easy without compromising the compatibility rules established in <a href="rfcs/./rfc0022_error_context_and_compatibility.html">RFC-0022</a>:</p>
<ol>
<li>Checking the error type</li>
<li>Retrieving information specific to that error type</li>
</ol>
<h2 id="case-study-handling-an-error-in-s3"><a class="header" href="#case-study-handling-an-error-in-s3">Case Study: Handling an error in S3</a></h2>
<p>The following is an example of handling errors with S3 with the latest generated (and unreleased)
SDK as of 2022-12-07:</p>
<pre><code class="language-rust ignore">let result = client
    .get_object()
    .bucket(BUCKET_NAME)
    .key("some-key")
    .send()
    .await;
    match result {
        Ok(_output) =&gt; { /* Do something with the output */ }
        Err(err) =&gt; match err.into_service_error() {
            GetObjectError { kind, .. } =&gt; match kind {
                GetObjectErrorKind::InvalidObjectState(value) =&gt; println!("invalid object state: {:?}", value),
                GetObjectErrorKind::NoSuchKey(_) =&gt; println!("object didn't exist"),
            }
            err @ GetObjectError { .. } if err.code() == Some("SomeUnmodeledError") =&gt; {}
            err @ _ =&gt; return Err(err.into()),
        },
    }</code></pre>
<p>The refactor that implemented <a href="rfcs/./rfc0022_error_context_and_compatibility.html">RFC-0022</a> added the <code>into_service_error()</code> method on <code>SdkError</code> that
infallibly converts the <code>SdkError</code> into the concrete error type held by the <code>SdkError::ServiceError</code> variant.
This improvement lets customers discard transient failures and immediately handle modeled errors
returned by the service.</p>
<p>Despite this, the code is still quite verbose.</p>
<h2 id="proposal-combine-error-and-errorkind"><a class="header" href="#proposal-combine-error-and-errorkind">Proposal: Combine <code>Error</code> and <code>ErrorKind</code></a></h2>
<p>At time of writing, each operation has both an <code>Error</code> and <code>ErrorKind</code> type generated.
The <code>Error</code> type holds information that is common across all operation errors: message,
error code, "extra" key/value pairs, and the request ID.</p>
<p>The <code>ErrorKind</code> is always nested inside the <code>Error</code>, which results in the verbose
nested matching shown in the case study above.</p>
<p>To make error handling more ergonomic, the code generated <code>Error</code> and <code>ErrorKind</code> types
should be combined. Hypothetically, this would allow for the case study above to look as follows:</p>
<pre><code class="language-rust ignore">let result = client
    .get_object()
    .bucket(BUCKET_NAME)
    .key("some-key")
    .send()
    .await;
match result {
    Ok(_output) =&gt; { /* Do something with the output */ }
    Err(err) =&gt; match err.into_service_error() {
        GetObjectError::InvalidObjectState(value) =&gt; {
            println!("invalid object state: {:?}", value);
        }
        err if err.is_no_such_key() =&gt; {
            println!("object didn't exist");
        }
        err if err.code() == Some("SomeUnmodeledError") =&gt; {}
        err @ _ =&gt; return Err(err.into()),
    },
}</code></pre>
<p>If a customer only cares about checking one specific error type, they can also do:</p>
<pre><code class="language-rust ignore">match result {
    Ok(_output) =&gt; { /* Do something with the output */ }
    Err(err) =&gt; {
        let err = err.into_service_error();
        if err.is_no_such_key() {
            println!("object didn't exist");
        } else {
            return Err(err);
        }
    }
}</code></pre>
<p>The downside of this is that combining the error types requires adding the general error
metadata to each generated error struct so that it's accessible by the enum error type.
However, this aligns with our tenet of making things easier for customers even if it
makes it harder for ourselves.</p>
<h2 id="changes-checklist-33"><a class="header" href="#changes-checklist-33">Changes Checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Merge the <code>${operation}Error</code>/<code>${operation}ErrorKind</code> code generators to only generate an <code>${operation}Error</code> enum:
<ul>
<li>Preserve the <code>is_${variant}</code> methods</li>
<li>Preserve error metadata by adding it to each individual variant's context struct</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Write upgrade guidance</li>
<li><input disabled="" type="checkbox" checked=""/>
Fix examples</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-file-per-change-changelog"><a class="header" href="#rfc-file-per-change-changelog">RFC: File-per-change changelog</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: client and server</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0042_file_per_change_changelog.html#changes-checklist">Changes Checklist</a> section.</p>
<p>Historically, the smithy-rs and AWS SDK for Rust's changelogs and release notes have been
generated from the <code>changelogger</code> tool in <code>tools/ci-build/changelogger</code>. This is a tool built
specifically for development and release of smithy-rs, and it requires developers to add
changelog entries to a root <code>CHANGELOG.next.toml</code> file. Upon release, the <code>[[smithy-rs]]</code> entries
in this file go into the smithy-rs release notes, and the <code>[[aws-sdk-rust]]</code> entries are associated
with a smithy-rs release commit hash, and added to the <code>aws/SDK_CHANGELOG.next.json</code> for
incorporation into the AWS SDK's changelog when it releases.</p>
<p>This system has gotten us far, but it has always made merging PRs into main more difficult
since the central <code>CHANGELOG.next.toml</code> file is almost always a merge conflict for two PRs
with changelog entries.</p>
<p>This RFC proposes a new approach to change logging that will remedy the merge conflict issue,
and explains how this can be done without disrupting the current release process.</p>
<h2 id="the-proposed-developer-experience"><a class="header" href="#the-proposed-developer-experience">The proposed developer experience</a></h2>
<p>There will be a <code>changelog/</code> directory in the smithy-rs root where
developers can add changelog entry Markdown files. Any file name can be picked
for these entries. Suggestions are the development branch name for the
change, or the PR number.</p>
<p>The changelog entry format will change to make it easier to duplicate entries
across both smithy-rs and aws-sdk-rust, a common use-case.</p>
<p>This new format will make use of Markdown front matter in the YAML format.
This change in format has a couple benefits:</p>
<ul>
<li>It's easier to write change entries in Markdown than in a TOML string.</li>
<li>There's no way to escape special characters (such as quotes) in a TOML string,
so the text that can be a part of the message will be expanded.</li>
</ul>
<p>While it would be preferable to use TOML for the front matter (and there are libraries
that support that), it will use YAML so that GitHub's Markdown renderer will recognize it.</p>
<p>A changelog entry file will look as follows:</p>
<pre><code class="language-markdown">---
# Adding `aws-sdk-rust` here duplicates this entry into the SDK changelog.
applies_to: ["client", "server", "aws-sdk-rust"]
authors: ["author1", "author2"]
references: ["smithy-rs#1234", "aws-sdk-rust#1234"]
# The previous `meta` section is broken up into its constituents:
breaking: false
# This replaces "tada":
new_feature: false
bug_fix: false
---

Some message for the change.
</code></pre>
<h2 id="implementation-2"><a class="header" href="#implementation-2">Implementation</a></h2>
<p>When a release is performed, the release script will generate the release notes,
update the <code>CHANGELOG.md</code> file, copy SDK changelog entries into the SDK,
and delete all the files in <code>changelog/</code>.</p>
<h3 id="sdk-entries"><a class="header" href="#sdk-entries">SDK Entries</a></h3>
<p>The SDK changelog entries currently end up in <code>aws/SDK_CHANGELOG.next.json</code>, and each entry
is given <code>age</code> and <code>since_commit</code> entries. The age is a number that starts at zero, and gets
incremented with every smithy-rs release. When it reaches a hardcoded threshold, that entry
is removed from <code>aws/SDK_CHANGELOG.next.json</code>. The SDK release process uses the <code>since_commit</code>
to determine which changelog entries go into the next SDK release's changelog.</p>
<p>The SDK release process doesn't write back to smithy-rs, and history has shown that it
can't since this leads to all sorts of release issues as PRs get merged into smithy-rs
while the release is in progress. Thus, this <code>age</code>/<code>since_commit</code> dichotomy needs to
stay in place.</p>
<p>The <code>aws/SDK_CHANGELOG.next.json</code> will stay in place in its current format without changes.
Its JSON format is capable of escaping characters in the message string, so it will be
compatible with the transition from TOML to Markdown with YAML front matter.</p>
<p>The <code>SDK_CHANGELOG.next.json</code> file has had merge conflicts in the past, but this only
happened when the release process wasn't followed correctly. If we're consistent with
our release process, it should never have conflicts.</p>
<h3 id="safety-requirements"><a class="header" href="#safety-requirements">Safety requirements</a></h3>
<p>Implementation will be tricky since it needs to be done without disrupting the existing
release process. The biggest area of risk is the SDK sync job that generates individual
commits in the aws-sdk-rust repo for each commit in the smithy-rs release. Fortunately,
the <code>changelogger</code> is invoked a single time at the very end of that process, and only
the latest <code>changelogger</code> version that is included in the build image. Thus, we can safely
refactor the <code>changelogger</code> tool so long as the command-line interface for it remains
backwards compatible. (We <em>could</em> change the CLI interface as well, but it will
require synchronizing the smithy-rs changes with changes to the SDK release scripts.)</p>
<p>At a high level, these requirements must be observed to do this refactor safely:</p>
<ul>
<li>The CLI for the <code>changelogger render</code> subcommand <em>MUST</em> stay the same, or have minimal
backwards compatible changes made to it.</li>
<li>The <code>SDK_CHANGELOG.next.json</code> format can change, but <em>MUST</em> remain a single JSON file.
If it is changed at all, the existing file <em>MUST</em> be transitioned to the new format,
and a mechanism <em>MUST</em> be in place for making sure it is the correct format after
merging with other PRs. It's probably better to leave this file alone though, or make
any changes to it backwards compatible.</li>
</ul>
<h2 id="future-improvements"><a class="header" href="#future-improvements">Future Improvements</a></h2>
<p>After the initial migration, additional niceties could be added such as pulling authors
from git history rather than needing to explicitly state them (at least by default; there
should always be an option to override the author in case a maintainer adds a changelog
entry on behalf of a contributor).</p>
<h2 id="changes-checklist-34"><a class="header" href="#changes-checklist-34">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Refactor changelogger and smithy-rs-tool-common to separate the changelog
serialization format from the internal representation used for rendering and splitting.</li>
<li><input disabled="" type="checkbox" checked=""/>
Implement deserialization for the new Markdown entry format</li>
<li><input disabled="" type="checkbox" checked=""/>
Incorporate new format into the <code>changelogger render</code> subcommand</li>
<li><input disabled="" type="checkbox" checked=""/>
Incorporate new format into the <code>changelogger split</code> subcommand</li>
<li><input disabled="" type="checkbox" checked=""/>
Port existing <code>CHANGELOG.next.toml</code> to individual entries</li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>sdk-lints</code> to fail if <code>CHANGELOG.next.toml</code> exists at all to avoid losing
changelog entries during merges.</li>
<li><input disabled="" type="checkbox" checked=""/>
Dry-run test against the smithy-rs release process.</li>
<li><input disabled="" type="checkbox" checked=""/>
Dry-run test against the SDK release process.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-identity-cache-partitions"><a class="header" href="#rfc-identity-cache-partitions">RFC: Identity Cache Partitions</a></h1>
<blockquote>
<p>Status: Implemented</p>
<p>Applies to: AWS SDK for Rust</p>
</blockquote>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>In the below example two clients are created from the same shared <code>SdkConfig</code> instance and each
invoke a fictitious operation. Assume the operations use the same auth scheme relying on the same identity resolver.</p>
<pre><code class="language-rust ignore">#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn Error&gt;&gt; {

    let config = aws_config::defaults(BehaviorVersion::latest())
        .load()
        .await;

    let c1 = aws_sdk_foo::Client::new(&amp;config);
    c1.foo_operation().send().await;

    let c2 = aws_sdk_bar::Client::new(&amp;config);
    c2.bar_operation().send().await;

    Ok(())
}</code></pre>
<p>There are two problems with this currently.</p>
<ol>
<li>
<p>The identity resolvers (e.g. <code>credentials_provider</code> for SigV4) are re-used but we end up with a different
<a href="https://github.com/smithy-lang/smithy-rs/blob/release-2024-03-25/rust-runtime/aws-smithy-runtime-api/src/client/identity.rs#L41"><code>IdentityCachePartition</code></a>
each time a client is created.</p>
<ul>
<li>More specifically this happens every time a <code>SharedIdentityResolver</code> is <a href="https://github.com/smithy-lang/smithy-rs/blob/release-2024-03-25/rust-runtime/aws-smithy-runtime-api/src/client/identity.rs#L197">created</a>. The conversion from <a href="https://github.com/awslabs/aws-sdk-rust/blob/release-2024-04-01/sdk/sts/src/config.rs#L1207"><code>From&lt;SdkConfig&gt;</code></a>
sets the credentials provider which <a href="https://github.com/awslabs/aws-sdk-rust/blob/release-2024-04-01/sdk/sts/src/config.rs#L960">associates</a> it as
the identity resolver for the auth scheme. Internally this is <a href="https://github.com/awslabs/aws-sdk-rust/blob/release-2024-04-01/sdk/aws-smithy-runtime-api/src/client/runtime_components.rs#L663">converted</a> to <code>SharedIdentityResolver</code> which creates the new partition (if it were already a <code>SharedIdentityResolver</code> this would be detected and a new instance would not be created which means it must be a <code>SharedCredentialsProvider</code> or <code>SharedTokenProvider</code> that is getting converted). The end result is the credentials
provider from shared config is re-used but the cache partition differs so a cache miss occurs the first time
any new client created from that shared config needs credentials.</li>
</ul>
</li>
<li>
<p>The <code>SdkConfig</code> does not create an identity cache by default. Even if the partitioning is fixed, any clients created from
a shared config instance will end up with their own identity cache which also results in having to resolve identity
again. Only if a user supplies an identity cache explicitly when creating shared config would it be re-used across
different clients.</p>
</li>
</ol>
<h3 id="design-intent"><a class="header" href="#design-intent">Design intent</a></h3>
<p>Identity providers and identity caching are intentionally decoupled. This allows caching behavior to be more easily
customized and centrally configured while also removing the need for each identity provider to have to implement
caching. There is some fallout from sharing an identity cache though. This is fairly well documented on
<code>IdentityCachePartition</code> itself.</p>
<pre><code class="language-rust ignore">/// ...
///
/// Identities need cache partitioning because a single identity cache is used across
/// multiple identity providers across multiple auth schemes. In addition, a single auth scheme
/// may have many different identity providers due to operation-level config overrides.
///
/// ...
pub struct IdentityCachePartition(...)</code></pre>
<p>Cache partitioning allows for different identity types to be stored in the same cache instance as long as they
are assigned to a different partition. Partitioning also solves the issue of overriding configuration on a per operation
basis where it would not be the correct or desired behavior to re-use or overwrite the cache if a different resolver
is used.</p>
<p>In other words cache partitioning is effectively tied to a particular instance of an identity resolver. Re-using the
same instance of a resolver <em>SHOULD</em> be allowed to share a cache partition. The fact that this isn't the case
today is an oversight in how types are wrapped and threaded through the SDK.</p>
<h2 id="the-user-experience-if-this-rfc-is-implemented-10"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-10">The user experience if this RFC is implemented</a></h2>
<p>In the current version of the SDK, users are unable to share cached results of identity resolvers via shared <code>SdkConfig</code>
across clients.</p>
<p>Once this RFC is implemented, users that create clients via <code>SdkConfig</code> with the latest behavior version will share
a default identity cache. Shared identity resolvers (e.g. <code>credentials_provider</code>, <code>token_provider</code>, etc) will provide
their own cache partition that is re-used instead of creating a new one each time a provider is converted into a
<code>SharedIdentityResolver</code>.</p>
<h3 id="default-behavior"><a class="header" href="#default-behavior">Default behavior</a></h3>
<pre><code class="language-rust ignore">let config = aws_config::defaults(BehaviorVersion::latest())
    .load()
    .await;

let c1 = aws_sdk_foo::Client::new(&amp;config);
c1.foo_operation().send().await;


let c2 = aws_sdk_bar::Client::new(&amp;config);
// will re-use credentials/identity resolved via c1
c2.bar_operation().send().await;</code></pre>
<p>Operations invoked on <code>c2</code> will see the results of cached identities resolved by client <code>c1</code> (for operations that use
the same identity resolvers). The creation of a default identity cache in <code>SdkConfig</code> if not provided will be added
behind a new behavior version.</p>
<h3 id="opting-out"><a class="header" href="#opting-out">Opting out</a></h3>
<p>Users can disable the shared identity cache by explicitly setting it to <code>None</code>. This will result in each client
creating their own identity cache.</p>
<pre><code class="language-rust ignore">let config = aws_config::defaults(BehaviorVersion::latest())
    // new method similar to `no_credentials()` to disable default cache setup
    .no_identity_cache()
    .load()
    .await;

let c1 = aws_sdk_foo::Client::new(&amp;config);
c1.foo_operation().send().await;


let c2 = aws_sdk_bar::Client::new(&amp;config);
c2.bar_operation().send().await;</code></pre>
<p>The same can be achieved by explicitly supplying a new identity cache to a client:</p>
<pre><code class="language-rust ignore">
let config = aws_config::defaults(BehaviorVersion::latest())
    .load()
    .await;

let c1 = aws_sdk_foo::Client::new(&amp;config);
c1.foo_operation().send().await;

let modified_config = aws_sdk_bar::Config::from(&amp;config)
    .to_builder()
    .identity_cache(IdentityCache::lazy().build())
    .build();

// uses it's own identity cache
let c2 = aws_sdk_bar::Client::from_conf(modified_config);
c2.bar_operation().send().await;</code></pre>
<h3 id="interaction-with-operation-config-override"><a class="header" href="#interaction-with-operation-config-override">Interaction with operation config override</a></h3>
<p>How per/operation configuration override behaves depends on what is provided for an identity resolver.</p>
<pre><code class="language-rust ignore">let config = aws_config::defaults(BehaviorVersion::latest())
    .load()
    .await;

let c1 = aws_sdk_foo::Client::new(&amp;config);

let scoped_creds = my_custom_provider();
let config_override = c1
        .config()
        .to_builder()
        .credentials_provider(scoped_creds);

// override config for two specific operations

c1.operation1()
    .customize()
    .config_override(config_override);
    .send()
    .await;

c1.operation2()
    .customize()
    .config_override(config_override);
    .send()
    .await;</code></pre>
<p>By default if an identity resolver does not provide it's own cache partition then <code>operation1</code> and <code>operation2</code> will
be wrapped in new <code>SharedIdentityResolver</code> instances and get distinct cache partitions. If <code>my_custom_provider()</code>
provides it's own cache partition then <code>operation2</code> will see the cached results.</p>
<p>Users can control this by wrapping their provider into a <code>SharedCredentialsProvider</code> which will claim it's own
cache partition.</p>
<pre><code class="language-rust ignore">
let scoped_creds = SharedCredentialsProvider::new(my_custom_provider());
let config_override = c1
        .config()
        .to_builder()
        .set_credentials_provider(Some(scoped_creds));
...</code></pre>
<h2 id="how-to-actually-implement-this-rfc-9"><a class="header" href="#how-to-actually-implement-this-rfc-9">How to actually implement this RFC</a></h2>
<p>In order to implement this RFC implementations of <code>ResolveIdentity</code> need to be allowed to provide their own cache
partition.</p>
<pre><code class="language-rust ignore">pub trait ResolveIdentity: Send + Sync + Debug {
    ...

    /// Returns the identity cache partition associated with this identity resolver.
    ///
    /// By default this returns `None` and cache partitioning is left up to `SharedIdentityResolver`.
    /// If sharing instances of this type should use the same partition then you should override this
    /// method and return a claimed partition.
    fn cache_partition(&amp;self) -&gt; Option&lt;IdentityCachePartition&gt; {
        None
    }

}</code></pre>
<p>Crucially cache partitions must remain globally unique so this method returns <code>IdentityCachePartition</code> which is
unique by construction. It doesn't matter if partitions are claimed early by an implementation of <code>ResolveIdentity</code>
or at the time they are wrapped in <code>SharedIdentityResolver</code>.</p>
<p>This is because <code>SdkConfig</code> stores instances of <code>SharedCredentialsProvider</code> (or <code>SharedTokenProvider</code>) rather than
<code>SharedIdentityResolver</code> which is what currently knows about cache partitioning. By allowing implementations of <code>ResolveIdentity</code>
to provide their own partition then <code>SharedCredentialsProvider</code> can claim a partition at construction time
and return that which will re-use the same partition anywhere that the provider is shared.</p>
<pre><code class="language-rust ignore">#[derive(Clone, Debug)]
pub struct SharedCredentialsProvider(Arc&lt;dyn ProvideCredentials&gt;, IdentityCachePartition);

impl SharedCredentialsProvider {
    pub fn new(provider: impl ProvideCredentials + 'static) -&gt; Self {
        Self(Arc::new(provider), IdentityCachePartition::new())
    }
}

impl ResolveIdentity for SharedCredentialsProvider {
    ...

    fn cache_partition(&amp;self) -&gt; Option&lt;IdentityCachePartition&gt; {
        Some(self.1)
    }
}
</code></pre>
<p>Additionally a new behavior version must be introduced that conditionally creates a default <code>IdentityCache</code> on <code>SdkConfig</code>
if not explicitly configured (similar to how credentials provider works internally).</p>
<h2 id="alternatives-considered-1"><a class="header" href="#alternatives-considered-1">Alternatives Considered</a></h2>
<p><code>SdkConfig</code> <a href="https://github.com/smithy-lang/smithy-rs/blob/release-2024-03-25/aws/rust-runtime/aws-types/src/sdk_config.rs#L58-L59">internally</a>
stores <code>SharedCredentialsProvider</code>/<code>SharedTokenProvider</code>. Neither of these types knows anything about cache partitioning.
One alternative would be to create and store a <code>SharedIdentityResolver</code> for each identity resolver type.</p>
<pre><code class="language-rust ignore">pub struct SdkConfig {
    ...
    credentials_provider: Option&lt;SharedCredentialsProvider&gt;,
    credentials_identity_provider: Option&lt;SharedIdentityResolver&gt;,
    token_provider: Option&lt;SharedTokenProvider&gt;,
    token_identity_provider: Option&lt;SharedIdentityResolver&gt;,
}</code></pre>
<p>Setting one of the identity resolver types like <code>credentials_provider</code> would also create and set the equivalent
<code>SharedIdentityResolver</code> which would claim a cache partition. When generating the <code>From&lt;SdkConfig&gt;</code> implementations
the identity resolver type would be favored.</p>
<p>There are a few downsides to this approach:</p>
<ol>
<li><code>SdkConfig</code> would have to expose accessor methods for the equivalents
(e.g. <code>credentials_identity_provider(&amp;self) -&gt; Option&lt;&amp;SharedIdentityResolver&gt;</code>). This creates additional noise
and confusion as well as the chance for using the type wrong.</li>
<li>Every new identity type added to <code>SdkConfig</code> would have to be sure to use <code>SharedIdentityResolver</code>.</li>
</ol>
<p>The advantage of the proposed approach of letting <code>ResolveIdentity</code> implementations provide a cache partition means
<code>SdkConfig</code> does not need to change. It also gives customers more control over whether an identity resolver implementation
shares a cache partition or not.</p>
<h2 id="changes-checklist-35"><a class="header" href="#changes-checklist-35">Changes checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>cache_partition()</code> method to <code>ResolveIdentity</code></li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>SharedIdentityResolver::new</code> to use the new <code>cache_partition()</code> method on the <code>resolver</code> to determine if a new cache partition should be created or not</li>
<li><input disabled="" type="checkbox" checked=""/>
Claim a cache partition when <code>SharedCredentialsProvider</code> is created and override the new <code>ResolveIdentity</code> method</li>
<li><input disabled="" type="checkbox" checked=""/>
Claim a cache partition when <code>SharedTokenProvider</code> is created and override the new <code>ResolveIdentity</code> method</li>
<li><input disabled="" type="checkbox" checked=""/>
Introduce new behavior version</li>
<li><input disabled="" type="checkbox" checked=""/>
Conditionally (gated on behavior version) create a new default <code>IdentityCache</code> on <code>SdkConfig</code> if not explicitly configured</li>
<li><input disabled="" type="checkbox" checked=""/>
Add a new <code>no_identity_cache()</code> method to <code>ConfigLoader</code> that marks the identity cache as explicitly unset</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="rfc-environment-defined-service-configuration"><a class="header" href="#rfc-environment-defined-service-configuration">RFC: Environment-defined service configuration</a></h1>
<blockquote>
<p>Status: RFC</p>
<p>Applies to: client</p>
</blockquote>
<p>For a summarized list of proposed changes, see the <a href="rfcs/rfc0044_env_defined_service_config.html#changes-checklist">Changes
Checklist</a> section.</p>
<p>In the AWS SDK for Rust today, customers are limited to setting global
configuration variables in their environment; They cannot set service-specific
variables. Other SDKs and the AWS CLI do allow for setting service-specific
variables.</p>
<p>This RFC proposes an implementation that would enable users to set
service-specific variables in their environment.</p>
<h2 id="terminology-25"><a class="header" href="#terminology-25">Terminology</a></h2>
<ul>
<li><strong>Global configuration</strong>: configuration which will be used for requests to any
service. May be overridden by service-specific configuration.</li>
<li><strong>Service-specific configuration</strong>: configuration which will be used for
requests only to a specific service.</li>
<li><strong>Configuration variable</strong>: A key-value pair that defines configuration e.g.
<code>key = value</code>, <code>key: value</code>, <code>KEY=VALUE</code>, etc.
<ul>
<li>Key and value as used in this RFC refer to each half of a configuration
variable.</li>
</ul>
</li>
<li><strong>Sub-properties</strong>: When parsing config variables from a profile file,
sub-properties are a newline-delimited list of key-value pairs in an indented
block following a <code>&lt;service name&gt;=\n</code> line. <em>For an example, see the <strong>Profile
File Configuration</strong> section of this RFC where sub-properties are declared for
two different services.</em></li>
</ul>
<h2 id="the-user-experience-if-this-rfc-is-implemented-11"><a class="header" href="#the-user-experience-if-this-rfc-is-implemented-11">The user experience if this RFC is implemented</a></h2>
<p>While users can already set global configuration in their environment, this RFC
proposes two new ways to set service-specific configuration in their
environment.</p>
<h3 id="environment-variables"><a class="header" href="#environment-variables">Environment Variables</a></h3>
<p>When defining service-specific configuration with an environment variable, all
keys are formatted like so:</p>
<pre><code class="language-sh">"AWS" + "_" + "&lt;config key in CONST_CASE&gt;" + "_" + "&lt;service ID in CONST_CASE&gt;"
</code></pre>
<p>As an example, setting an endpoint URL for different services would look like
this:</p>
<pre><code class="language-sh">export AWS_ENDPOINT_URL=http://localhost:4444
export AWS_ENDPOINT_URL_ELASTICBEANSTALK=http://localhost:5555
export AWS_ENDPOINT_URL_DYNAMODB=http://localhost:6666
</code></pre>
<p>The first variable sets a global endpoint URL. The second variable overrides the
first variable, but only for the Elastic Beanstalk service. The third variable
overrides the first variable, but only for the DynamoDB service.</p>
<h3 id="profile-file-configuration"><a class="header" href="#profile-file-configuration">Profile File Configuration</a></h3>
<p>When defining service-specific configuration in a profile file, it looks like
this:</p>
<pre><code class="language-ignore">[profile dev]
services = testing-s3-and-eb
endpoint_url = http://localhost:9000

[services testing-s3-and-eb]
s3 =
  endpoint_url = http://localhost:4567
elasticbeanstalk =
  endpoint_url = http://localhost:8000
</code></pre>
<p>When <code>dev</code> is the active profile, all services will use the
<code>http://localhost:9000</code> endpoint URL except where it is overridden. Because the
<code>dev</code> profile references the <code>testing-s3-and-eb</code> services, and because two
service-specific endpoint URLs are set, those URLs will override the
<code>http://localhost:9000</code> endpoint URL when making requests to S3
(<code>http://localhost:4567</code>) and Elastic Beanstalk (<code>http://localhost:8000</code>).</p>
<h3 id="configuration-precedence"><a class="header" href="#configuration-precedence">Configuration Precedence</a></h3>
<p>When configuration is set in multiple places, the value used is determined in
this order of precedence:</p>
<p><em>highest precedence</em></p>
<ol>
<li><em>EXISTING</em> Programmatic client configuration</li>
<li><em>NEW</em> Service-specific environment variables</li>
<li><em>EXISTING</em> Global environment variables</li>
<li><em>NEW</em> Service-specific profile file variables in the active profile</li>
<li><em>EXISTING</em> Global profile file variables in the active profile</li>
</ol>
<p><em>lowest precedence</em></p>
<h2 id="how-to-actually-implement-this-rfc-10"><a class="header" href="#how-to-actually-implement-this-rfc-10">How to actually implement this RFC</a></h2>
<p>This RFC may be implemented in several steps which are detailed below.</p>
<h3 id="sourcing-service-specific-config-from-the-environment-and-profile"><a class="header" href="#sourcing-service-specific-config-from-the-environment-and-profile">Sourcing service-specific config from the environment and profile</a></h3>
<p><code>aws_config::profile::parser::ProfileSet</code> is responsible for storing the active
profile and all profile configuration data. Currently, it only tracks
<code>sso_session</code> and <code>profile</code> sections, so it must be updated to store arbitrary
sections, their properties, and sub-properties. These sections will be publicly
accessible via a new method <code>ProfileSet::other_sections</code> which returns a ref to
a <code>Properties</code> struct.</p>
<p>The <code>Properties</code> struct is defined as follows:</p>
<pre><code class="language-rust ignore">type SectionKey = String;
type SectionName = String;
type PropertyName = String;
type SubPropertyName = String;
type PropertyValue = String;

/// A key for to a property value.
///
/// ```txt
/// # An example AWS profile config section with properties and sub-properties
/// [section-key section-name]
/// property-name = property-value
/// property-name =
///   sub-property-name = property-value
/// ```
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub struct PropertiesKey {
    section_key: SectionKey,
    section_name: SectionName,
    property_name: PropertyName,
    sub_property_name: Option&lt;SubPropertyName&gt;,
}

impl PropertiesKey {
    /// Create a new builder for a `PropertiesKey`.
    pub fn builder() -&gt; Builder {
        Default::default()
    }
}

// The builder code is omitted from this RFC. It allows users to set each field
// individually and then build a PropertiesKey

/// A map of [`PropertiesKey`]s to property values.
#[derive(Clone, Debug, Default, PartialEq, Eq)]
pub struct Properties {
    inner: HashMap&lt;PropertiesKey, PropertyValue&gt;,
}

impl Properties {
    /// Create a new empty [`Properties`].
    pub fn new() -&gt; Self {
        Default::default()
    }

    #[cfg(test)]
    pub(crate) fn new_from_slice(slice: &amp;[(PropertiesKey, PropertyValue)]) -&gt; Self {
        let mut properties = Self::new();
        for (key, value) in slice {
            properties.insert(key.clone(), value.clone());
        }
        properties
    }

    /// Insert a new key/value pair into this map.
    pub fn insert(&amp;mut self, properties_key: PropertiesKey, value: PropertyValue) {
        let _ = self
            .inner
            // If we don't clone then we don't get to log a useful warning for a value getting overwritten.
            .entry(properties_key.clone())
            .and_modify(|v| {
                tracing::trace!("overwriting {properties_key}: was {v}, now {value}");
                *v = value.clone();
            })
            .or_insert(value);
    }

    /// Given a [`PropertiesKey`], return the corresponding value, if any.
    pub fn get(&amp;self, properties_key: &amp;PropertiesKey) -&gt; Option&lt;&amp;PropertyValue&gt; {
        self.inner.get(properties_key)
    }
}</code></pre>
<p>The <code>aws_config::env</code> module remains unchanged. It already provides all the
necessary functionality.</p>
<h3 id="exposing-valid-service-configuration-during-serviceconfig-construction"><a class="header" href="#exposing-valid-service-configuration-during-serviceconfig-construction">Exposing valid service configuration during <code>&lt;service&gt;::Config</code> construction</a></h3>
<p>Environment variables <em>(from <code>Env</code>)</em> and profile variables <em>(from
<code>EnvConfigSections</code>)</em> must be available during the conversion of <code>SdkConfig</code> to
<code>&lt;service&gt;::Config</code>. To accomplish this, we'll define a new trait
<code>LoadServiceConfig</code> and implement it for <code>EnvServiceConfig</code>  which will be
stored in the <code>SdkConfig</code> struct.</p>
<pre><code class="language-rust ignore">/// A struct used with the [`LoadServiceConfig`] trait to extract service config from the user's environment.
// [profile active-profile]
// services = dev
//
// [services dev]
// service-id =
//   config-key = config-value
#[derive(Clone, Debug, PartialEq, Eq, Hash)]
pub struct ServiceConfigKey&lt;'a&gt; {
    service_id: &amp;'a str,
    profile: &amp;'a str,
    env: &amp;'a str,
}

impl&lt;'a&gt; ServiceConfigKey&lt;'a&gt; {
    /// Create a new [`ServiceConfigKey`] builder struct.
    pub fn builder() -&gt; builder::Builder&lt;'a&gt; {
        Default::default()
    }
    /// Get the service ID.
    pub fn service_id(&amp;self) -&gt; &amp;'a str {
        self.service_id
    }
    /// Get the profile key.
    pub fn profile(&amp;self) -&gt; &amp;'a str {
        self.profile
    }
    /// Get the environment key.
    pub fn env(&amp;self) -&gt; &amp;'a str {
        self.env
    }
}

/// Implementers of this trait can provide service config defined in a user's environment.
pub trait LoadServiceConfig: fmt::Debug + Send + Sync {
    /// Given a [`ServiceConfigKey`], return the value associated with it.
    fn load_config(&amp;self, key: ServiceConfigKey&lt;'_&gt;) -&gt; Option&lt;String&gt;;
}

#[derive(Debug)]
pub(crate) struct EnvServiceConfig {
    pub(crate) env: Env,
    pub(crate) env_config_sections: EnvConfigSections,
}

impl LoadServiceConfig for EnvServiceConfig {
    fn load_config(&amp;self, key: ServiceConfigKey&lt;'_&gt;) -&gt; Option&lt;String&gt; {
        let (value, _source) = EnvConfigValue::new()
            .env(key.env())
            .profile(key.profile())
            .service_id(key.service_id())
            .load(&amp;self.env, Some(&amp;self.env_config_sections))?;

        Some(value.to_string())
    }
}</code></pre>
<h3 id="code-generation-1"><a class="header" href="#code-generation-1">Code generation</a></h3>
<p>We require two things to check for when constructing the service config:</p>
<ul>
<li>The service's ID</li>
<li>The service's supported configuration variables</li>
</ul>
<p>We <strong>only</strong> have this information once we get to the service level. Because of
that, we must use code generation to define:</p>
<ul>
<li>What config to look for in the environment</li>
<li>How to validate that config</li>
</ul>
<p>Codegen for configuration must be updated for all config variables that we want
to support. For an example, here's how we'd update the <code>RegionDecorator</code> to check
for service-specific regions:</p>
<pre><code class="language-java">class RegionDecorator : ClientCodegenDecorator {
    // ...
    override fun extraSections(codegenContext: ClientCodegenContext): List&lt;AdHocCustomization&gt; {
        return usesRegion(codegenContext).thenSingletonListOf {
            adhocCustomization&lt;SdkConfigSection.CopySdkConfigToClientConfig&gt; { section -&gt;
                rust(
                    """
                    ${section.serviceConfigBuilder}.set_region(
                        ${section.sdkConfig}
                            .service_config()
                            .and_then(|conf| {
                                conf.load_config(service_config_key($envKey, $profileKey))
                                    .map(Region::new)
                            })
                            .or_else(|| ${section.sdkConfig}.region().cloned()),
                    );
                    """,
                )
            }
        }
    }
    // ...
</code></pre>
<p>To construct the keys necessary to locate the service-specific configuration, we
generate a <code>service_config_key</code> function for each service crate:</p>
<pre><code class="language-java">class ServiceEnvConfigDecorator : ClientCodegenDecorator {
    override val name: String = "ServiceEnvConfigDecorator"
    override val order: Byte = 10

    override fun extras(
        codegenContext: ClientCodegenContext,
        rustCrate: RustCrate,
    ) {
        val rc = codegenContext.runtimeConfig
        val serviceId = codegenContext.serviceShape.sdkId().toSnakeCase().dq()
        rustCrate.withModule(ClientRustModule.config) {
            Attribute.AllowDeadCode.render(this)
            rustTemplate(
                """
                fn service_config_key&lt;'a&gt;(
                    env: &amp;'a str,
                    profile: &amp;'a str,
                ) -&gt; aws_types::service_config::ServiceConfigKey&lt;'a&gt; {
                    #{ServiceConfigKey}::builder()
                        .service_id($serviceId)
                        .env(env)
                        .profile(profile)
                        .build()
                        .expect("all field sets explicitly, can't fail")
                }
                """,
                "ServiceConfigKey" to AwsRuntimeType.awsTypes(rc).resolve("service_config::ServiceConfigKey"),
            )
        }
    }
}
</code></pre>
<h2 id="changes-checklist-36"><a class="header" href="#changes-checklist-36">Changes checklist</a></h2>
<ul>
<li>In <code>aws-types</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>service_config: Option&lt;Arc&lt;dyn LoadServiceConfig&gt;&gt;</code> field to <code>SdkConfig</code> and builder.</li>
<li><input disabled="" type="checkbox" checked=""/>
Add setters and getters for the new <code>service_config</code> field.</li>
<li><input disabled="" type="checkbox" checked=""/>
Add a new <code>service_config</code> module.
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>ServiceConfigKey</code> struct and builder.</li>
<li><input disabled="" type="checkbox" checked=""/>
Add new <code>LoadServiceConfig</code> trait.</li>
</ul>
</li>
</ul>
</li>
<li>In <code>aws-config</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Move profile parsing out of <code>aws-config</code> into <code>aws-runtime</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Deprecate the <code>aws-config</code> reëxports and direct users to <code>aws-runtime</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Add a new <code>EnvServiceConfig</code> struct and implement <code>LoadServiceConfig</code> for it.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update <code>ConfigLoader</code> to set the <code>service_config</code> field in <code>SdkConfig</code>.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update all default providers to use the new of the <code>EnvConfigValue::validate</code> method.</li>
</ul>
</li>
<li>In <code>aws-runtime</code>:
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Rename all profile-related code moved from <code>aws-config</code> to <code>aws-runtime</code> so that it's easier to understand in light of the API changes we're making.</li>
<li><input disabled="" type="checkbox" checked=""/>
Add a new struct <code>PropertiesKey</code> and <code>Properties</code> to store profile data.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Add an integration test that ensures service-specific config has the expected precedence.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update codegen to generate a method to easily construct <code>ServiceConfigKey</code>s.</li>
<li><input disabled="" type="checkbox" checked=""/>
Update codegen to generate code that loads service-specific config from the environment for a limited initial set of config variables:
<ul>
<li>Region</li>
<li>Endpoint URL</li>
<li>Endpoint-related "built-ins" like <code>use_arn_region</code> and <code>disable_multi_region_access_points</code>.</li>
</ul>
</li>
<li><input disabled="" type="checkbox" checked=""/>
Write a <a href="https://github.com/smithy-lang/smithy-rs/discussions/3537">guide</a> for users.
<ul>
<li><input disabled="" type="checkbox" checked=""/>
Explain to users how they can determine a service's ID.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributing"><a class="header" href="#contributing">Contributing</a></h1>
<p>This is a collection of written resources for smithy-rs and SDK contributors.</p>
<ul>
<li><a href="contributing/./contributing/writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.html">Writing and debugging a low-level feature that relies on HTTP</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="writing-and-debugging-a-low-level-feature-that-relies-on-http"><a class="header" href="#writing-and-debugging-a-low-level-feature-that-relies-on-http">Writing and debugging a low-level feature that relies on HTTP</a></h1>
<h2 id="background-4"><a class="header" href="#background-4">Background</a></h2>
<p>This article came about as a result of all the difficulties I encountered while developing the request checksums feature
laid out in the internal-only Flexible Checksums spec <em>(the feature is also highlighted in <a href="https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/">this public blog post</a>.)</em>
I spent much more time developing the feature than I had anticipated. In this article, I'll talk about:</p>
<ul>
<li>How the SDK sends requests with a body</li>
<li>How the SDK sends requests with a streaming body</li>
<li>The various issues I encountered and how I addressed them</li>
<li>Key takeaways for contributors developing similar low-level features</li>
</ul>
<h2 id="how-the-sdk-sends-requests-with-a-body"><a class="header" href="#how-the-sdk-sends-requests-with-a-body">How the SDK sends requests with a body</a></h2>
<p>All interactions between the SDK and a service are modeled as <a href="contributing/../transport/operation.html">"operations"</a>. Operations contain:</p>
<ul>
<li>A base HTTP request (with a potentially streaming body)</li>
<li>A typed property bag of configuration options</li>
<li>A fully generic response handler</li>
</ul>
<p>Users create operations piecemeal with a fluent builder. The options set in the builder are then used to create the
inner HTTP request, becoming headers or triggering specific request-building functionality (In this case, calculating a
checksum and attaching it either as a header or a trailer.)</p>
<p>Here's <a href="https://github.com/awslabs/aws-sdk-rust/blob/1bdfba7f53e77a478f60a1a387e4d9d31fd918fc/sdk/qldbsession/src/input.rs#L197">an example from the QLDB SDK of creating a body</a> from inputs and inserting it into the request to be sent:</p>
<pre><code class="language-rust ignore">let body = aws_smithy_http::body::SdkBody::from(
    crate::operation_ser::serialize_operation_crate_operation_send_command(&amp;self)?,
);

if let Some(content_length) = body.content_length() {
    request = aws_smithy_http::header::set_request_header_if_absent(
        request,
        http::header::CONTENT_LENGTH,
        content_length,
    );
}
let request = request.body(body).expect("should be valid request");</code></pre>
<p>Most all request body creation in the SDKs looks like that. Note how it automatically sets the <code>Content-Length</code> header
whenever the size of the body is known; It'll be relevant later. The body is read into memory and can be inspected
before the request is sent. This allows for things like calculating a checksum and then inserting it into the request
as a header.</p>
<h2 id="how-the-sdk-sends-requests-with-a-streaming-body"><a class="header" href="#how-the-sdk-sends-requests-with-a-streaming-body">How the SDK sends requests with a streaming body</a></h2>
<p>Often, sending a request with a streaming body looks much the same. However, it's not possible to read a streaming
body until you've sent the request. Any metadata that needs to be calculated by inspecting the body must be sent as
trailers. Additionally, some metadata, like <code>Content-Length</code>, can't be sent as a trailer at all.
<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Trailer#directives">MDN maintains a helpful list</a> of metadata that can only be sent as a header.</p>
<pre><code class="language-rust ignore">// When trailers are set, we must send an AWS-specific header that lists them named `x-amz-trailer`.
// For example, when sending a SHA256 checksum as a trailer,
// we have to send an `x-amz-trailer` header telling the service to watch out for it:
request
    .headers_mut()
    .insert(
        http::header::HeaderName::from_static("x-amz-trailer"),
        http::header::HeaderValue::from_static("x-amz-checksum-sha256"),
    );</code></pre>
<h2 id="the-issues-i-encountered-while-implementing-checksums-for-streaming-request-bodies"><a class="header" href="#the-issues-i-encountered-while-implementing-checksums-for-streaming-request-bodies">The issues I encountered while implementing checksums for streaming request bodies</a></h2>
<h3 id="content-encoding-aws-chunked"><a class="header" href="#content-encoding-aws-chunked"><code>Content-Encoding: aws-chunked</code></a></h3>
<p>When sending a request body with trailers, we must use an AWS-specific content encoding called <code>aws-chunked</code>. To encode
a request body for <code>aws-chunked</code> requires us to know the length of each chunk we're going to send before we send it. We
have to prefix each chunk with its size in bytes, represented by one or more <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a> digits. To close the body, we
send a final chunk with a zero. For example, the body "Hello world" would look like this when encoded:</p>
<pre><code class="language-text">B\r\n
Hello world\r\n
0\r\n
</code></pre>
<p>When sending a request body encoded in this way, we need to set two length headers:</p>
<ul>
<li><code>Content-Length</code> is the length of the entire request body, including the chunk size prefix and zero terminator. In the
example above, this would be 19.</li>
<li><code>x-amz-decoded-content-length</code> is the length of the decoded request body. In the example above, this would be 11.</li>
</ul>
<p><em><strong>NOTE:</strong> <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding"><code>Content-Encoding</code></a> is distinct from <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding"><code>Transfer-Encoding</code></a>. It's possible to
construct a request with both <code>Content-Encoding: chunked</code> AND <code>Transfer-Encoding: chunked</code>, although we don't ever need
to do that for SDK requests.</em></p>
<h3 id="s3-requires-a-content-length-unless-you-also-set-transfer-encoding-chunked"><a class="header" href="#s3-requires-a-content-length-unless-you-also-set-transfer-encoding-chunked">S3 requires a <code>Content-Length</code> unless you also set <code>Transfer-Encoding: chunked</code></a></h3>
<p>S3 does not require you to send a <code>Content-Length</code> header if you set the <code>Transfer-Encoding: chunked</code> header. That's
very helpful because it's not always possible to know the total length of a stream of bytes if that's what you're
constructing your request body from. However, when sending trailers, this part of the spec can be misleading.</p>
<ol>
<li>When sending a streaming request, we must send metadata like checksums as trailers</li>
<li>To send a request body with trailers, we must set the <code>Content-Encoding: aws-chunked</code> header</li>
<li>When using <code>aws-chunked</code> encoding for a request body, we must set the <code>x-amz-decoded-content-length</code> header with the
pre-encoding length of the request body.</li>
</ol>
<p>This means that we can't actually avoid having to know and specify the length of the request body when sending a request
to S3. This turns out to not be much of a problem for common use of the SDKs because most streaming request bodies are
constructed from files. In these cases we can ask the operating system for the file size before sending the request. So
long as that size doesn't change during sending of the request, all is well. In any other case, the request will fail.</p>
<h3 id="adding-trailers-to-a-request-changes-the-size-of-that-request"><a class="header" href="#adding-trailers-to-a-request-changes-the-size-of-that-request">Adding trailers to a request changes the size of that request</a></h3>
<p>Headers don't count towards the size of a request body, but trailers do. That means we need to take trailers (which
aren't sent until after the body) into account when setting the <code>Content-Length</code> header (which are sent before the
body.) This means that without setting <code>Transfer-Encoding: chunked</code>, the SDKs only support trailers of known length.
In the case of checksums, we're lucky because they're always going to be the same size. We must also take into account
the fact that checksum values are base64 encoded before being set (this lengthens them.)</p>
<h3 id="hyper-supports-http-request-trailers-but-isnt-compatible-with-content-encoding-aws-chunked"><a class="header" href="#hyper-supports-http-request-trailers-but-isnt-compatible-with-content-encoding-aws-chunked"><code>hyper</code> supports HTTP request trailers but isn't compatible with <code>Content-Encoding: aws-chunked</code></a></h3>
<p>This was a big source of confusion for me, and I only figured out what was happening with the help of <a href="https://github.com/seanmonstar">@seanmonstar</a>.
When using <code>aws-chunked</code> encoding, the trailers have to be appended to the body as part of <code>poll_data</code> instead of
relying on the <code>poll_trailers</code> method. The working <code>http_body::Body</code> implementation of an <code>aws-chunked</code> encoded body
looked like this:</p>
<pre><code class="language-rust ignore">impl Body for AwsChunkedBody&lt;Inner&gt; {
    type Data = Bytes;
    type Error = aws_smithy_http::body::Error;

    fn poll_data(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;Self::Data, Self::Error&gt;&gt;&gt; {
        let this = self.project();
        if *this.already_wrote_trailers {
            return Poll::Ready(None);
        }

        if *this.already_wrote_chunk_terminator {
            return match this.inner.poll_trailers(cx) {
                Poll::Ready(Ok(trailers)) =&gt; {
                    *this.already_wrote_trailers = true;
                    let total_length_of_trailers_in_bytes = this.options.trailer_lens.iter().sum();

                    Poll::Ready(Some(Ok(trailers_as_aws_chunked_bytes(
                        total_length_of_trailers_in_bytes,
                        trailers,
                    ))))
                }
                Poll::Pending =&gt; Poll::Pending,
                Poll::Ready(err) =&gt; Poll::Ready(Some(err)),
            };
        };

        match this.inner.poll_data(cx) {
            Poll::Ready(Some(Ok(mut data))) =&gt; {
                let bytes = if *this.already_wrote_chunk_size_prefix {
                    data.copy_to_bytes(data.len())
                } else {
                    // A chunk must be prefixed by chunk size in hexadecimal
                    *this.already_wrote_chunk_size_prefix = true;
                    let total_chunk_size = this
                        .options
                        .chunk_length
                        .or(this.options.stream_length)
                        .unwrap_or_default();
                    prefix_with_total_chunk_size(data, total_chunk_size)
                };

                Poll::Ready(Some(Ok(bytes)))
            }
            Poll::Ready(None) =&gt; {
                *this.already_wrote_chunk_terminator = true;
                Poll::Ready(Some(Ok(Bytes::from("\r\n0\r\n"))))
            }
            Poll::Ready(Some(Err(e))) =&gt; Poll::Ready(Some(Err(e))),
            Poll::Pending =&gt; Poll::Pending,
        }
    }

    fn poll_trailers(
        self: Pin&lt;&amp;mut Self&gt;,
        _cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Result&lt;Option&lt;HeaderMap&lt;HeaderValue&gt;&gt;, Self::Error&gt;&gt; {
        // When using aws-chunked content encoding, trailers have to be appended to the body
        Poll::Ready(Ok(None))
    }

    fn is_end_stream(&amp;self) -&gt; bool {
        self.already_wrote_trailers
    }

    fn size_hint(&amp;self) -&gt; SizeHint {
        SizeHint::with_exact(
            self.encoded_length()
                .expect("Requests made with aws-chunked encoding must have known size")
                as u64,
        )
    }
}</code></pre>
<h3 id="the-stream-is-closing-early-and-i-dont-know-why"><a class="header" href="#the-stream-is-closing-early-and-i-dont-know-why">"The stream is closing early, and I don't know why"</a></h3>
<p>In my early implementation of <code>http_body::Body</code> for an <code>aws-chunked</code> encoded body, the body wasn't being completely read
out. The problem turned out to be that I was delegating to the <code>is_end_stream</code> trait method of the inner body. Because
the innermost body had no knowledge of the trailers I needed to send, it was reporting that the stream had ended.
The fix was to instead rely on the outermost body's knowledge of its own state in order to determine if all data had
been read.</p>
<h2 id="what-helped-me-to-understand-the-problems-and-their-solutions"><a class="header" href="#what-helped-me-to-understand-the-problems-and-their-solutions">What helped me to understand the problems and their solutions</a></h2>
<ul>
<li>
<p><strong>Reaching out to others that had specific knowledge of a problem:</strong> Talking to a developer that had tackled this
feature for another SDK was a big help. Special thanks is due to <a href="https://github.com/jasdel">@jasdel</a> and the Go v2 SDK team.
<a href="https://github.com/aws/aws-sdk-go-v2/blob/c214cb61990441aa165e216a3f7e845c50d21939/service/internal/checksum/aws_chunked_encoding.go#L90">Their implementation</a> of an <code>aws-chunked</code> encoded body was the basis for
my own implementation.</p>
</li>
<li>
<p><strong>Avoiding codegen</strong>: The process of updating codegen code and then running codegen for each new change you make is
slow compared to running codegen once at the beginning of development and then just manually editing the generated SDK
as necessary. I still needed to run <code>./gradlew :aws:sdk:relocateAwsRuntime :aws:sdk:relocateRuntime</code> whenever I made
changes to a runtime crate but that was quick because it's just copying the files. Keep as much code out of codegen as
possible. It's much easier to modify/debug Rust than it is to write a working codegen module that does the same thing.
Whenever possible, write the codegen modules later, once the design has settled.</p>
</li>
<li>
<p><strong>Using the <code>Display</code> impl for errors:</strong> The <code>Display</code> impl for an error can ofter contain helpful info that might not
be visible when printing with the <code>Debug</code> impl. Case in point was an error I was getting because of the
<code>is_end_stream</code> issue. When <code>Debug</code> printed, the error looked like this:</p>
<pre><code class="language-rust ignore">DispatchFailure(ConnectorError { err: hyper::Error(User(Body), hyper::Error(BodyWriteAborted)), kind: User })</code></pre>
<p>That wasn't too helpful for me on its own. I looked into the <code>hyper</code> source code and found that the <code>Display</code> impl
contained a helpful message, so I matched into the error and printed the <code>hyper::Error</code> with the <code>Display</code> impl:</p>
<pre><code class="language-markdown">user body write aborted: early end, expected 2 more bytes'
</code></pre>
<p>This helped me understand that I wasn't encoding things correctly and was missing a CRLF.</p>
</li>
<li>
<p><strong>Echo Server</strong>: I first used netcat and then later a small echo server written in Rust to see the raw HTTP request
being sent out by the SDK as I was working on it. The Rust SDK supports setting endpoints for request. This is often
used to send requests to something like <a href="https://localstack.cloud/">LocalStack</a>, but I used it to send request to <code>localhost</code> instead:</p>
<pre><code class="language-rust ignore">#[tokio::test]
async fn test_checksum_on_streaming_request_against_s3() {
    let sdk_config = aws_config::from_env()
        .endpoint_resolver(Endpoint::immutable("http://localhost:8080".parse().expect("valid URI")))
        .load().await;
    let s3_client = aws_sdk_s3::Client::new(&amp;sdk_config);

    let input_text = b"Hello world";
    let _res = s3_client
        .put_object()
        .bucket("some-real-bucket")
        .key("test.txt")
        .body(aws_sdk_s3::types::ByteStream::from_static(input_text))
        .checksum_algorithm(ChecksumAlgorithm::Sha256)
        .send()
        .await
        .unwrap();
}</code></pre>
<p>The echo server was based off of an <a href="https://github.com/tokio-rs/axum">axum</a> example and looked like this:</p>
<pre><code class="language-rust ignore">use axum::{
  body::{Body, Bytes},
  http::{request::Parts, Request, StatusCode},
  middleware::{self, Next},
  response::IntoResponse,
  routing::put,
  Router,
};
use std::net::SocketAddr;
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

#[tokio::main]
async fn main() {
  tracing_subscriber::registry().with(tracing_subscriber::EnvFilter::new(
    std::env::var("RUST_LOG").unwrap_or_else(|_| "trace".into()),
  ))
  .with(tracing_subscriber::fmt::layer())
  .init();

  let app = Router::new()
      .route("/", put(|| async move { "200 OK" }))
      .layer(middleware::from_fn(print_request_response));

  let addr = SocketAddr::from(([127, 0, 0, 1], 3000));
  tracing::debug!("listening on {}", addr);
  axum::Server::bind(&amp;addr)
      .serve(app.into_make_service())
      .await
      .unwrap();
}

async fn print_request_response(
  req: Request&lt;Body&gt;,
  next: Next&lt;Body&gt;,
) -&gt; Result&lt;impl IntoResponse, (StatusCode, String)&gt; {
    let (parts, body) = req.into_parts();

    print_parts(&amp;parts).await;
    let bytes = buffer_and_print("request", body).await?;
    let req = Request::from_parts(parts, Body::from(bytes));

    let res = next.run(req).await;

    Ok(res)
}

async fn print_parts(parts: &amp;Parts) {
    tracing::debug!("{:#?}", parts);
}

async fn buffer_and_print&lt;B&gt;(direction: &amp;str, body: B) -&gt; Result&lt;Bytes, (StatusCode, String)&gt;
where
  B: axum::body::HttpBody&lt;Data = Bytes&gt;,
  B::Error: std::fmt::Display,
{
    let bytes = match hyper::body::to_bytes(body).await {
        Ok(bytes) =&gt; bytes,
        Err(err) =&gt; {
            return Err((
                StatusCode::BAD_REQUEST,
                format!("failed to read {} body: {}", direction, err),
            ));
        }
    };

    if let Ok(body) = std::str::from_utf8(&amp;bytes) {
        tracing::debug!("{} body = {:?}", direction, body);
    }

    Ok(bytes)
}</code></pre>
<h2 id="-1"><a class="header" href="#-1"></a></h2>
</li>
</ul>
<p>](writing_and_debugging_a_low-level_feature_that_relies_on_HTTP.md)</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="static/mermaid.min.js"></script>
        <script src="static/mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
